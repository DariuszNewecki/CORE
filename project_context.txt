--- START OF FILE project_context.txt ---

--- START OF PROJECT CONTEXT BUNDLE ---

--- START OF FILE ./.intent/charter/constitution/ACTIVE ---
v2

--- END OF FILE ./.intent/charter/constitution/ACTIVE ---

--- START OF FILE ./.intent/charter/constitution/amendment_process.md ---
# .intent/charter/constitution/amendment_process.md
#
# This document is the single, canonical source of truth for the process of
# amending the CORE Constitution. Adherence is mandatory for all changes to
# files governed by the Charter.

## SECTION 1: CORE PRINCIPLES OF AMENDMENT

1.  **Safety First:** The process is designed to prevent accidental or unauthorized changes. All critical changes require explicit, verifiable human approval.
2.  **Clarity and Intent:** Every proposed change must be accompanied by a clear justification that links it to the system's core principles or mission.
3.  **Auditability:** Every step of the amendment process, from proposal to ratification, must be traceable and recorded.

## SECTION 2: THE STANDARD AMENDMENT PROCESS

This process applies to any modification of a file within the `.intent/charter/` directory.

1.  **Proposal Creation:**
    *   An authorized operator MUST create a formal proposal file (`cr-*.yaml`) according to the `proposal_schema.json`.
    *   The `target_path` MUST be the canonical path to the Charter file being changed.
    *   The `justification` MUST clearly state the reason for the change and which CORE principle it serves.

2.  **Signature and Quorum:**
    *   The proposal MUST be signed by one or more authorized approvers as defined in `approvers.yaml`.
    *   The number of valid signatures MUST meet the quorum requirements defined in `approvers.yaml` for the current operational mode (`development` or `production`).
    *   For changes targeting files listed in `critical_paths.yaml`, the **critical** quorum is required. For all other Charter files, the **standard** quorum applies.

3.  **Validation and Ratification:**
    *   The proposed change MUST pass a full constitutional audit (`core-admin check ci audit`).
    *   The change MAY be subject to a canary deployment as defined in the `canary_policy.yaml`.
    *   Once all checks pass and the quorum is met, the change is considered ratified and can be merged.

## SECTION 3: EMERGENCY PROCEDURES

Emergency procedures, such as the revocation of a compromised key, are detailed in `charter/constitution/operator_lifecycle.md`. Such actions are considered critical amendments and always require the **critical** quorum.
--- END OF FILE ./.intent/charter/constitution/amendment_process.md ---

--- START OF FILE ./.intent/charter/constitution/approvers.yaml ---
# .intent/charter/constitution/approvers.yaml
#
# This file defines the human operators authorized to approve constitutional
# changes and the rules governing that process.

approvers:
  - identity: "core-team@core-system.ai"
    public_key: |
      -----BEGIN PUBLIC KEY-----
      MCowBQYDK2VuAyEA3dK7Jt4jJh6+QvZvY6XcGx3q8R0e7m5JwqYk8qFtU9U=
      -----END PUBLIC KEY-----
    created_at: "2025-08-05T15:50:53.995534+00:00"
    role: "maintainer"
    description: "Primary CORE development team"

  - identity: "security-audit@core-system.ai"
    public_key: |
      -----BEGIN PUBLIC KEY-----
      MCowBQYDK2VuAyEApJ+8mNvL7wY2XfDcR9q3Q5t4yZx7v6hB8gKj0sF3T5U=
      -----END PUBLIC KEY-----
    created_at: "2025-08-05T15:50:53.995534+00:00"
    role: "security"
    description: "Security audit team for constitutional changes"

  - identity: "d.newecki@gmail.com"
    public_key: |
      -----BEGIN PUBLIC KEY-----
      MCowBQYDK2VwAyEAmcbNEgYFEUUNf8XYGZEscamfzqrYHpgKoPHehtPuiDQ=
      -----END PUBLIC KEY-----
    created_at: "2025-08-12T10:36:49.000000Z"
    role: "maintainer"
    description: "Mentor"

quorum:
  # The operational mode should reflect the CORE_ENV variable from mind/config/runtime_requirements.yaml.
  # The system MUST enforce the 'production' quorum rules when CORE_ENV=production.
  current_mode: development
  development:
    standard: 1
    critical: 1
  production:
    standard: 2
    critical: 3

# The list of paths requiring the 'critical' quorum is now managed centrally.
critical_paths_source: "charter/constitution/critical_paths.yaml"

emergency_contact: "security-emergency@core-system.ai"
--- END OF FILE ./.intent/charter/constitution/approvers.yaml ---

--- START OF FILE ./.intent/charter/constitution/approvers.yaml.example ---
# .intent/constitution/approvers.yaml
#
# PURPOSE: This file enables cryptographic verification of constitutional approvals,
# preventing unauthorized changes. It contains the public keys of all authorized
# constitutional approvers for this instance of CORE.
#
# TO ADD A NEW APPROVER:
# 1. Run the command: `core-admin keygen "your.email@example.com"`
# 2. The command will output a JSON/YAML block.
# 3. Paste that block into the 'approvers' list below.

approvers:
  - identity: "your.name@example.com"
    public_key: |
      -----BEGIN PUBLIC KEY-----
      MCowBQYDK2VuAyEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA=
      -----END PUBLIC KEY-----
    created_at: "YYYY-MM-DDTHH:MM:SSZ"
    role: "maintainer"
    description: "Primary maintainer of this CORE instance"

  - identity: "another.approver@example.com"
    public_key: |
      -----BEGIN PUBLIC KEY-----
      MCowBQYDK2VuAyEBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB=
      -----END PUBLIC KEY-----
    created_at: "YYYY-MM-DDTHH:MM:SSZ"
    role: "contributor"
    description: "Authorized contributor"

# Minimum number of valid signatures required to approve a constitutional amendment.
quorum:
  # Regular amendments (e.g., changing a policy) require 1 signature.
  standard: 1
  # Critical changes (e.g., altering this file) require 2 signatures.
  critical: 2

# A list of file paths that are considered "critical". Any proposal targeting
# these files will require the 'critical' quorum to be met.
critical_paths:
  - ".intent/policies/intent_guard.yaml"
  - ".intent/constitution/approvers.yaml"
  - ".intent/meta.yaml"

--- END OF FILE ./.intent/charter/constitution/approvers.yaml.example ---

--- START OF FILE ./.intent/charter/constitution/critical_paths.yaml ---
# .intent/charter/constitution/critical_paths.yaml
#
# This is the single source of truth for all file paths within the constitution
# that are considered critical to the system's safety, integrity, and governance.
#
# Any proposed change targeting one of these paths requires the "critical" quorum
# of approvers as defined in `approvers.yaml`.

paths:
  # The master index of the constitution.
  - ".intent/meta.yaml"

  # Core governance and identity files.
  - "charter/constitution/approvers.yaml"
  - "charter/constitution/operator_lifecycle.md"
  - "charter/constitution/amendment_process.md" # This file itself is critical.

  # The system's core mission statement.
  - "charter/mission/northstar.yaml"
  - "charter/mission/principles.yaml"

  # The most fundamental safety and governance policies.
  - "charter/policies/safety_policy.yaml"
  - "charter/policies/intent_guard_policy.yaml"

  # The definition of enforcement itself.
  - "charter/policies/enforcement_model_policy.yaml"
--- END OF FILE ./.intent/charter/constitution/critical_paths.yaml ---

--- START OF FILE ./.intent/charter/constitution/operator_lifecycle.md ---
# Human Operator Lifecycle Procedures

This document defines the formal, constitutionally-mandated procedures for managing human operators who have the authority to approve changes to the CORE constitution. Adherence to these procedures is mandatory and enforced by peer review during any change to the `approvers.yaml` file.

## Onboarding a New Approver

1.  **Key Generation:** The candidate operator MUST generate a new, secure Ed25519 key pair using the following command from the CORE repository root:
    ```bash
    poetry run core-admin keygen "candidate.email@example.com"
    ```
2.  **Proposal Creation:** A currently active, authorized approver MUST create a formal constitutional amendment proposal.
    - The `target_path` of the proposal MUST be `.intent/constitution/approvers.yaml`.
    - The `justification` MUST clearly state the reason for adding the new approver, including their role and identity.
    - The `content` of the proposal MUST be the complete `approvers.yaml` file with the new approver's YAML block appended.
3.  **Ratification:** The proposal must be signed and approved, meeting the required quorum as defined in `approvers.yaml`. Upon successful canary validation and approval, the new operator is considered active.

## Standard Revocation of an Approver

1.  **Proposal Creation:** An authorized approver MUST create a formal proposal to remove the target operator's block from the `approvers` list in `approvers.yaml`.
2.  **Justification:** The `justification` MUST clearly state the non-emergency reason for revocation (e.g., operator has left the project).
3.  **Ratification:** The proposal must be signed and approved, meeting the required quorum.

## Emergency Revocation of a Compromised Key

1.  **Proposal Creation:** In the event of a suspected or confirmed private key compromise, any active approver MUST immediately create an emergency revocation proposal targeting `approvers.yaml`.
2.  **Quorum:** This proposal requires the **critical** quorum to be met for approval.
3.  **Immediate Invalidation:** The moment a revocation proposal is created for an identity, that identity's signature is considered invalid for all quorum calculations on that proposal and any subsequent proposals until the matter is resolved.
--- END OF FILE ./.intent/charter/constitution/operator_lifecycle.md ---

--- START OF FILE ./.intent/charter/mission/manifesto.md ---
# CORE Manifesto

CORE is not a framework. It is not a plugin system.  
CORE is a system that evolves itself — governed by explicit declarations of purpose, constraints, and structure.

---

### Beliefs

- Software is never done, but it must always be explainable.
- Changes must serve a declared intent — or challenge it explicitly.
- LLMs are powerful, but must be contained by purpose, not left to guess.
- Governance is not bureaucracy; it’s alignment between vision and action.

---

### CORE exists to:

- Understand its own capabilities
- Apply changes safely and transparently
- Validate every change against declared rules
- Learn from its outcomes and improve
- Inspire new systems to govern themselves

---

CORE does not pretend to be perfect.  
But it refuses to be mindless.

--- END OF FILE ./.intent/charter/mission/manifesto.md ---

--- START OF FILE ./.intent/charter/mission/northstar.yaml ---
# .intent/mission/northstar.yaml

# PURPOSE: This fulfills evolvable_structure and defines CORE's NorthStar.
name: CORE
version: "0.1.0"
purpose: >
  CORE is a self-improving, intent-aware development system.
  Its purpose is to orchestrate safe, meaningful, and governed changes
  to its own codebase and related artifacts through intent bundles and introspective loops.

scope:
  - Planning and decomposition of tasks
  - Code generation via LLMs
  - Change validation and governance enforcement
  - Self-introspection and structural analysis
  - Knowledge management via manifests and graphs
  - Continuous self-evaluation and auditability

values:
  - Clarity over cleverness
  - Safety before speed
  - Traceability of every action
  - Alignment with declared purpose
  - Capability-driven reasoning

notes:
  - CORE evolves iteratively, but never silently.
  - All changes must fulfill a declared intent or generate a proposal to revise that intent.
--- END OF FILE ./.intent/charter/mission/northstar.yaml ---

--- START OF FILE ./.intent/charter/mission/principles.yaml ---
# .intent/charter/mission/principles.yaml
#
# CORE's Constitution: clear, enforceable, and readable by humans and LLMs.
# Any agent (including future LLMs) must understand and obey these rules.
# This file contains high-level, aspirational values. Specific, machine-enforceable
# rules are defined in the relevant policy files.

principles:

  - id: clarity_first
    description: >
      Prioritize clear, understandable code and documentation that effectively
      communicates its intent to both humans and machines. If something is
      ambiguous, it must be simplified.

  - id: safe_by_default
    description: >
      Every change must assume rollback or rejection unless explicitly validated.
      No file write, code execution, or intent update may proceed without confirmation.
      Rollback must be possible at every stage.

  - id: reason_with_purpose
    description: >
      Every autonomous planning step must be traceable to a core constitutional
      principle or a declared high-level goal, ensuring all actions are deliberate
      and auditable.

  - id: evolvable_structure
    description: >
      The system's structure and constitution must be designed to evolve safely.
      Self-modification must be governed by a formal, secure, and auditable
      amendment process.

  - id: no_orphaned_logic
    description: >
      No function, file, or rule may exist without being discoverable and traceable
      through the system's operational database. All logic must serve a declared purpose.

  - id: use_intent_bundle
    description: >
      All significant autonomous actions must be executed via a structured
      IntentBundle that reflects the Ten-Phase Loop of Reasoned Action. No phase
      may be skipped.

  - id: minimalism_over_completeness
    description: >
      Prefer small, focused changes. Do not generate stubs, placeholders, or
      unused functions. Unused or untestable logic is a liability and must be removed.

  - id: dry_by_design
    description: >
      "Don't Repeat Yourself." No logic or configuration may be duplicated. If a
      function, pattern, or rule exists in one place, it must be reused or
      referenced, not rewritten.

  - id: single_source_of_truth
    description: >
      The `.intent/` directory is the single source of constitutional truth (the laws).
      The operational database is the single source of operational truth (the current state).
      Derived artifacts (e.g., reports) must be generated from these sources.

  - id: separation_of_concerns
    description: >
      Each architectural domain must have a single, clearly defined responsibility.
      Inter-domain communication must be explicitly declared and governed by the
      constitution.

  - id: predictable_side_effects
    description: >
      Any action that modifies the system's state (e.g., a file write) must be
      explicit, logged, and reversible. Silent or unlogged changes are forbidden.

  - id: policy_change_requires_human_review
    description: >
      Any change to a policy file within the `.intent/policies/` directory must be
      ratified through the formal constitutional amendment process, requiring
      human review and approval.
--- END OF FILE ./.intent/charter/mission/principles.yaml ---

--- START OF FILE ./.intent/charter/policies/agent/agent_policy.yaml ---
policy_id: 18f048cb-b084-4faa-ac62-17fca55fed77
id: agent_policy
version: "1.1.0" # Version bump due to consolidation
title: "Agent Governance Policy"
status: active
purpose: >
  The single source of truth for all rules governing the behavior, reasoning,
  and operational safety of all AI agents within the CORE system.

scope:
  applies_to: ["agents"]

owners:
  accountable: "Core Maintainer"

review:
  frequency: "annual"

rules:
  # --- Safety & Compliance Rules ---
  - id: agent.compliance.no_write_intent
    statement: "Agents MUST NOT write directly to '.intent/charter/**'. Constitutional changes require a formal, human-approved proposal."
    enforcement: error

  - id: agent.compliance.respect_cli_registry
    statement: "All tool invocations and system actions MUST be routed through commands registered in '.intent/mind/knowledge/cli_registry.yaml'."
    enforcement: error

  # --- Reasoning & Auditing Rules ---
  - id: agent.reasoning.trace_required
    statement: "Agents MUST produce a concise, inspectable trace for non-trivial tasks, including inputs, tools used, and outcomes for auditability."
    enforcement: warn

  - id: agent.reasoning.source_attribution
    statement: "All claims, especially those influencing code generation or policy changes, MUST provide source attribution (e.g., file paths, policy IDs)."
    enforcement: warn

  # --- Execution & Safety Rules ---
  - id: agent.execution.no_unverified_code
    statement: "Agents MUST NOT execute or commit any generated or refactored code without first passing it through the full validation pipeline (lint, test, constitutional audit)."
    enforcement: error

  - id: agent.execution.fail_closed
    statement: "If an agent encounters ambiguous instructions or a high-risk uncertainty, it MUST halt its current task and escalate for human clarification rather than proceeding."
    enforcement: warn

  - id: agent.execution.limit_scope
    statement: "Agent actions MUST be limited to the immediate scope of the declared goal. Broad, opportunistic refactoring requires a separate, explicit intent and plan."
    enforcement: warn

# --- Resource Selection Logic (Merged from deduction_policy) ---
resource_selection:
  scoring_weights:
    cost: 0.5
    speed: 0.3
    quality: 0.1
    reasoning: 0.1

  task_specific_overrides:
    - task_keywords: ["docstringwriter", "propose a domain name", "label cluster"]
      weights:
        cost: 0.9
        speed: 0.1
        quality: 0.0
        reasoning: 0.0
    - task_keywords: ["refactor", "architect", "planner", "generate"]
      weights:
        cost: 0.1
        speed: 0.1
        quality: 0.4
        reasoning: 0.4
--- END OF FILE ./.intent/charter/policies/agent/agent_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/agent/micro_proposal_policy.yaml ---
policy_id: a5cbb67a-bbe6-4221-b187-1d88692c1124
id: micro_proposal_policy
version: "1.0.0"
title: "Micro-Proposal Policy (Autonomous Fast Track)"
status: active
purpose: >
  Defines the rules and scope for low-risk, autonomous changes that can be
  auto-approved without requiring the full human-in-the-loop constitutional
  amendment process. This is the primary gate for A1 autonomy.

scope:
  applies_to: [agents, cli]

owners:
  primary: "Governance Lead"
  reviewers: ["Core Maintainer"]

review:
  frequency: "6 months"

rules:
  # Rule 1: Define the set of "safe" actions that can be auto-approved.
  # Initially, we only allow actions that are highly deterministic and low-risk.
  - id: safe_actions
    description: "A list of capability keys that are permitted in micro-proposals."
    enforcement: error
    allowed_actions:
      - "autonomy.self_healing.fix_docstrings"
      - "autonomy.self_healing.format_code"
      - "autonomy.self_healing.fix_headers"

  # Rule 2: Define which parts of the codebase are safe for autonomous modification.
  # We explicitly forbid any changes to the constitution itself (.intent/) or
  # the core governance machinery.
  - id: safe_paths
    description: "Glob patterns for file paths that are safe for autonomous modification."
    enforcement: error
    allowed_paths:
      - "docs/**/*.md"
      - "tests/**/*.py"
      - "src/**/*.py"
    forbidden_paths:
      - ".intent/**"
      - "src/system/governance/**"
      - "src/core/**"
      - "pyproject.toml"
      - "Makefile"

  # Rule 3: All micro-proposals must be validated before application.
  # This ensures that even a safe action on a safe file doesn't introduce errors.
  - id: require_validation
    description: "A micro-proposal must include evidence of a successful pre-flight validation (lint, test, audit)."
    enforcement: error
    required_evidence:
      - "validation_report_id"
--- END OF FILE ./.intent/charter/policies/agent/micro_proposal_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/code/capability_linter_policy.yaml ---
policy_id: cb081a61-5c2b-4623-8249-f26796e68d40
id: capability_linter_policy
version: "1.1.0" # Version bump to reflect #ID change
title: "Capability Linter Policy"
status: active
purpose: >
  To keep the capability catalog clean, owned, and useful by enforcing meaningful
  descriptions, owners, and the correct identity linking mechanism.
scope:
  applies_to: [code, governance, discovery]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "semiannual"

rules:
  - id: caps.meaningful_description
    statement: Capability descriptions in the database MUST be specific and non-placeholder.
    enforcement: error
  - id: caps.owner_required
    statement: Active capabilities in the database MUST have an assigned owner (agent/team).
    enforcement: error
  - id: caps.no_placeholder_text
    statement: Descriptions such as "TBD" or "N/A" are forbidden in the database.
    enforcement: error
  - id: caps.id_format
    statement: "Source code linkers MUST use the form '# ID: <uuid>'."
    enforcement: error
--- END OF FILE ./.intent/charter/policies/code/capability_linter_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/code/code_health_policy.yaml ---
policy_id: f7680a46-87ad-4e1a-8bdb-d6751d787309
id: code_health_policy
version: "1.0.0"
title: "Code Health Policy"
status: active
purpose: >
  To maintain small, focused modules and functions, limit complexity, and encourage
  refactoring before entropy accumulates.
scope:
  applies_to: [code, agents, auditor]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "semiannual"

rules:
  max_cognitive_complexity: 15
  max_nesting_depth: 4
  max_line_length:
    limit: 120
    enforcement: soft
  max_module_lloc: 300
  max_function_lloc: 80
  outlier_standard_deviations: 2.0
  enforce_dead_public_symbols: true
--- END OF FILE ./.intent/charter/policies/code/code_health_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/code/code_style_policy.yaml ---
policy_id: aaa0a228-125d-4013-bfed-c1b58cec0f66
id: code_style_policy
version: "1.0.0"
title: "Code Style Policy"
status: active
purpose: >
  To ensure consistent, readable code across the repository by standardizing
  tooling and expectations for contributors and agents.
scope:
  applies_to: [code, agents, cli]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "annual"

rules:
  - id: style.linter_required
    statement: All changes MUST pass ruff (lint) before merge.
    enforcement: error
  - id: style.formatter_required
    statement: All changes MUST be formatted by black; CI runs black --check.
    enforcement: error
  - id: style.docstrings_public_apis
    statement: Public APIs MUST have docstrings summarizing intent and parameters; private/dunder excluded.
    enforcement: warn
  - id: style.import_order
    statement: Imports MUST follow grouping/order and avoid unused imports (enforced by linter).
    enforcement: warn
  - id: style.fail_on_style_in_ci
    statement: CI MUST fail on style or lint violations (no auto-fixing in CI).
    enforcement: error
--- END OF FILE ./.intent/charter/policies/code/code_style_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/code/naming_conventions_policy.yaml ---
policy_id: fae5215d-a1ee-424f-b5e1-46b08cecc5b9
# .intent/charter/policies/naming_conventions_policy.yaml
id: naming_conventions_policy
version: "1.0.0"
title: "Constitutional Naming Conventions"
status: active
purpose: >
  To provide a single, machine-readable source of truth for all naming
  conventions across the entire repository. This policy governs the structure of
  the constitution itself (.intent/) and the codebase (src/), ensuring clarity
  and predictability as the system evolves.

scope:
  applies_to: ["auditor", "repository"]

owners:
  accountable: "Core Maintainer"

review:
  frequency: "annual"

rules:
  # ==============================================================================
  # PART 1: GOVERNANCE OF THE CONSTITUTION ITSELF (.intent/)
  # ==============================================================================

  - id: intent.policy_file_naming
    description: "All policy files must use snake_case and end with '_policy.yaml'."
    enforcement: error
    scope: ".intent/charter/policies/*.yaml"
    target: "filename"
    pattern: "^[a-z0-9_]+_policy\\.yaml$"

  - id: intent.policy_schema_naming
    description: "Schemas for policy files must end with '_policy_schema.json'."
    enforcement: error
    scope: ".intent/charter/schemas/*_policy_schema.json"
    target: "filename"
    pattern: "^[a-z0-9_]+_policy_schema\\.json$"

  - id: intent.artifact_schema_naming
    description: "Schemas for non-policy artifacts must end with '_schema.[json|yaml]'."
    enforcement: error
    scope: ".intent/charter/schemas/*"
    target: "filename"
    pattern: "^[a-z0-9_]+_schema\\.(json|yaml)$"
    exclusions:
      - "*_policy_schema.json" # Exclude policy schemas to avoid rule conflict.

  - id: intent.prompt_file_naming
    description: "All prompt files must use snake_case and end with '.prompt'."
    enforcement: error
    scope: ".intent/mind/prompts/*.prompt"
    target: "filename"
    pattern: "^[a-z0-9_]+\\.prompt$"

  - id: intent.proposal_file_naming
    description: "All proposal files must follow the 'cr-*.yaml' naming convention."
    enforcement: warn
    scope: ".intent/proposals/*.yaml"
    target: "filename"
    pattern: "^cr-[a-zA-Z0-9_-]+\\.yaml$"
    exclusions:
      - "README.md" # The README is not a proposal.

  # ==============================================================================
  # PART 2: GOVERNANCE OF THE CODEBASE (src/ and tests/)
  # ==============================================================================

  - id: code.python_module_naming
    description: "All Python source files must use snake_case naming."
    enforcement: error
    scope: "src/**/*.py"
    target: "filename"
    pattern: "^[a-z0-9_]+\\.py$"
    exclusions:
      - "__init__.py"

  - id: code.python_test_module_naming
    description: "All Python test files must be prefixed with 'test_'."
    enforcement: error
    scope: "tests/**/*.py"
    target: "filename"
    pattern: "^test_[a-z0-9_]+\\.py$"
    exclusions:
      - "__init__.py"
      - "conftest.py"
--- END OF FILE ./.intent/charter/policies/code/naming_conventions_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/code/refactoring_patterns_policy.yaml ---
policy_id: 17725f7a-25e0-4747-85c4-8d98ea03310e
id: refactoring_patterns_policy
version: "1.0.0"
title: "Refactoring Patterns Policy"
status: active
purpose: >
  Provide safe, repeatable refactoring patterns for agents and developers to
  reduce risk during structural changes.
scope:
  applies_to: [code, agents, cli]
owners:
  primary: "Core Maintainer"
  reviewers: ["Governance Lead"]
review:
  frequency: "12 months"

patterns:
  - id: extract_function
    description: Move a coherent block of logic into a new function with a clear name and docstring.
    guardrails:
      - must_keep_behavior: true
      - add_unit_tests: true
      - run_audit: true

  - id: extract_module
    description: Move related functions/classes into a new module; update imports and domain boundaries.
    guardrails:
      - must_keep_behavior: true
      - update_import_map: true
      - run_audit: true

  - id: introduce_facade
    description: Add a facade/API layer to hide complexity behind a small, stable surface.
    guardrails:
      - document_contract: true
      - avoid_breaking_changes: true
      - run_audit: true

rules:
  - id: refactor.requires_tests
    statement: Any refactor that changes public behavior MUST include tests or proof of equivalence.
    enforcement: error
  - id: refactor.update_capabilities
    statement: When moving symbols, update capability tags and manifests accordingly.
    enforcement: warn
  - id: refactor.audit_after
    statement: A constitutional audit MUST run after refactors before merge.
    enforcement: error

checklist:
  - Confirm chosen pattern’s guardrails are satisfied.
  - Validate imports/domains after moves (no boundary violations).
  - Run tests + audit and attach results to the change.
--- END OF FILE ./.intent/charter/policies/code/refactoring_patterns_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/data/database_policy.yaml ---
policy_id: 1fb8949c-02db-486a-8b9d-556191456de3
id: database_policy
version: "2.1.0" # Version bump for full DB migration
title: "Consolidated Database Governance Policy"
purpose: >
  Provide a durable, auditable ledger of what actually happened in CORE (events, audits, CLI runs, capability history)
  with the database as the single source of operational truth, and file-based artifacts as read-only exports.
scope:
  applies_to: [postgresql]
owners:
  primary: "Security Lead"
  reviewers: ["Governance Lead"]
review:
  frequency: "12 months"
engine:
  type: postgresql
  schema: core
migrations:
  directory: sql
  order:
    - "001_init.sql"
    - "002_catalog.sql"
    - "003_implementations.sql"
    - "004_refactor_to_symbols.sql"
    - "005_add_symbol_key.sql"
    - "006_knowledge_graph_view.sql"
    - "007_capabilities_registry.sql"
    - "008_operational_tables.sql"
    - "009_domain_and_vector_tables.sql" # New migration for domains and vectors
rules:
  - id: db.mind_remains_source
    statement: "`.intent/**` is the single source of constitutional truth; DB is the authoritative source for operational data."
    enforcement: error
  - id: db.schema_declared
    statement: "All tables and columns MUST be declared in the database schema/migrations and validated at CI time."
    enforcement: error
  - id: db.migrations_logged
    statement: "Schema migrations MUST have an id, description, created_at, and approver recorded in the repo."
    enforcement: warn
  - id: db.write_via_governed_cli
    statement: "All writes MUST originate from registered CLI commands (see CLI Governance Policy)."
    enforcement: error
  - id: db.domains_in_db
    statement: "Capability domains MUST be stored in and queried from the database, with `.intent/mind/knowledge/domains.yaml` as a read-only export."
    enforcement: error
  - id: db.vector_index_in_db
    statement: "Vector index data MUST be stored in the database with metadata for EMBED_MODEL_REVISION and LOCAL_EMBEDDING_DIM, with file-based indices as read-only exports."
    enforcement: error
  - id: db.privacy.no_pii_or_secrets
    statement: "Personal data and secrets MUST NOT be stored in operational tables unless explicitly exempted."
    enforcement: error
  - id: db.privacy.masking
    statement: "Logs and audit records MUST redact tokens, keys, and secrets before persistence."
    enforcement: error
  - id: db.privacy.access_least_privilege
    statement: "Access to operational data MUST follow least-privilege via roles/groups."
    enforcement: warn
retention:
  audit_runs_days: 180
  cli_runs_days: 90
  capability_history_days: 365
  proposals_days: 1095
drift:
  development: warn
  production: block
backup_restore:
  cadence: daily
  test_restore_quarterly: true
quorum:
  changes_require_critical_paths: true

--- END OF FILE ./.intent/charter/policies/data/database_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/data/secrets_management_policy.yaml ---
policy_id: ffb2dcec-3a90-45e6-aea7-691dd3b339b3
id: secrets_management_policy
version: "1.0.0"
title: "Secrets Management Policy"
status: active
purpose: >
  Define rules for handling secrets to prevent accidental exposure in source code,
  logs, and outputs.
scope:
  applies_to: [code, ci, logs]
owners:
  primary: "Security Lead"
  reviewers: ["Core Maintainer"]
review:
  frequency: "12 months"

rules:
  - id: no_hardcoded_secrets
    statement: Source code MUST NOT contain hardcoded secrets (API keys, passwords). Use environment variables.
    enforcement: error
    detection:
      patterns:
        - "(A|B|S|G)K[0-9A-Za-z]{30,}" # Common API key patterns
        - 'password\s*[:=]\s*[''""].+[''""]'
      exclude:
        - "tests/**"
        - ".env.example"

  - id: redact_secrets_in_logs
    statement: Logs and telemetry MUST redact sensitive data (tokens, keys, passwords) before persistence.
    enforcement: warn

checklist:
  - Auditor scans for hardcoded secret patterns and fails the build if found outside excluded paths.
  - Periodic manual review of logs to ensure redaction is working as expected.
--- END OF FILE ./.intent/charter/policies/data/secrets_management_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/audit_ignore_policy.yaml ---
policy_id: 232934da-44d6-4ddc-9404-162382caddb7
id: audit_ignore_policy
version: "1.0.1" # Version bump for new ignore rule
title: "Audit Ignore Policy"
status: active
purpose: >
  To allow narrow, explicit exceptions for files or symbols to reduce audit noise
  without weakening the Constitution. Every ignore must have a reason and an expiry date.
scope:
  applies_to: [governance, ci]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "semiannual"

rules:
  - id: ignore.must_expire
    statement: Every ignore MUST include an 'expires' date to force review.
    enforcement: warn
  - id: ignore.must_have_reason
    statement: Every ignore MUST include a reason.
    enforcement: error

ignores:
  - path: "src/**/generated/**"
    reason: "Generated code; excluded from style/health checks."
    expires: "2026-01-01"
  - path: "vendor/**"
    reason: "Third-party code; owned externally."
    expires: "2026-01-01"
  - check_id: "knowledge.source.direct_access"
    path: "src/features/governance/checks/knowledge_source_check.py"
    reason: "This check must contain the string 'knowledge_graph.json' to perform its function. It is an intentional and safe usage."
    expires: "2026-01-01"
  
symbol_ignores:
  - key: "src/core/intent_guard.py::_get_rules_by_severity"
    reason: "Internal helper method, not a public capability."
    expires: "2026-01-01"
  - key: "src/features/governance/checks/health_checks.py::HealthChecks"
    reason: "Temporarily ignoring self-duplication warnings after major refactor."
    expires: "2025-12-01"
  - key: "src/features/governance/checks/style_checks.py::StyleChecks"
    reason: "Temporarily ignoring self-duplication warnings after major refactor."
    expires: "2025-12-01"
  - key: "src/features/governance/checks/security_checks.py::SecurityChecks"
    reason: "Temporarily ignoring self-duplication warnings after major refactor."
    expires: "2025-12-01"
  - key: "src/features/governance/checks/file_checks.py::FileChecks"
    reason: "Temporarily ignoring self-duplication warnings after major refactor."
    expires: "2025-12-01"
  - key: "src/features/governance/checks/manifest_lint.py::ManifestLintCheck"
    reason: "Temporarily ignoring self-duplication warnings after major refactor."
    expires: "2025-12-01"
  - key: "src/features/governance/checks/capability_coverage.py::CapabilityCoverageCheck"
    reason: "Temporarily ignoring self-duplication warnings after major refactor."
    expires: "2025-12-01"

--- END OF FILE ./.intent/charter/policies/governance/audit_ignore_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/auditor_policy.yaml ---
policy_id: ee4d8b52-0b76-41c5-bdd5-41de41126974
# .intent/charter/policies/auditor_policy.yaml
id: auditor_policy
version: "1.0.1"
title: "Constitutional Auditor Policy"
status: active
purpose: >
  Define the identity, responsibilities, and operational mandate of the Constitutional Auditor.
  The Auditor enforces all Charter policies and fails CI when error-level violations are present.

scope:
  applies_to: ["governance", "ci", "system"]

owners:
  accountable: "Core Maintainer"

review:
  frequency: "annual"

rules:
  - id: auditor.must_enforce_error_level
    statement: "If any guard rule with enforcement=error is violated, the audit MUST fail."
    enforcement: error

  - id: auditor.must_report_policy_and_path
    statement: "Findings MUST include policy id, rule id, severity, message, and a concrete file path or symbol key."
    enforcement: error

  - id: auditor.must_respect_ignores
    statement: "The Auditor MUST respect scoped ignores defined in '.intent/charter/policies/audit_ignore_policy.yaml'."
    enforcement: warn

  - id: auditor.output_location
    statement: "When a report file is requested, it MUST be written under 'reports/' and use a stable JSON structure."
    enforcement: warn

  - id: auditor.single_active_constitution
    statement: "Exactly one active constitution version MUST be referenced by '.intent/charter/constitution/ACTIVE'."
    enforcement: error

  - id: auditor.cli_registry_source_of_truth
    statement: "All operator actions MUST be backed by entries in '.intent/mind/knowledge/cli_registry.yaml'."
    enforcement: error

--- END OF FILE ./.intent/charter/policies/governance/auditor_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/available_actions_policy.yaml ---
policy_id: 47eab093-749a-444f-bc97-3d816c2d631c
id: available_actions_policy
version: "1.0.0"
title: "Available Actions Policy"
status: active
purpose: >
  Defines the canonical list of atomic actions that the PlannerAgent is
  constitutionally permitted to include in an execution plan.
scope:
  applies_to: [agents, planner_agent]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "annual"

actions:
  # --- THIS IS THE FIX ---
  - name: "read_file"
    description: "Reads the entire content of a specified file to provide context for subsequent steps."
    required_parameters: ["file_path"]

  - name: "edit_file"
    description: "Performs a surgical replacement of a block of code within an existing file."
    required_parameters: ["file_path", "start_line", "end_line", "new_content"]
  # --- END OF FIX ---

  - name: "create_file"
    description: "Creates a new source code or documentation file at a specified path with the given content."
    required_parameters: ["file_path", "code"]
  
  - name: "edit_function"
    description: "Surgically replaces the code of an existing function or class within a file."
    required_parameters: ["file_path", "symbol_name", "code"]

  - name: "delete_file"
    description: "Deletes an existing file from the repository."
    required_parameters: ["file_path"]

  - name: "create_proposal"
    description: "Creates a formal, human-in-the-loop constitutional amendment proposal (a cr-*.yaml file)."
    required_parameters: ["file_path", "justification", "code"]
    
  - name: "add_capability_tag"
    description: "Adds a new # ID tag to a specific function or class. (Note: This is a legacy action, prefer 'fix assign-ids')."
    required_parameters: ["file_path", "symbol_name", "tag"]
--- END OF FILE ./.intent/charter/policies/governance/available_actions_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/cli_governance_policy.yaml ---
policy_id: cd37bddd-52c8-445a-b842-e229b29e6980
id: cli_governance_policy
version: "1.0.0"
title: "CLI Governance Policy"
status: active
purpose: >
  To govern the structure, registration, and evolution of all commands
  exposed via the core-admin CLI, ensuring clarity and safety.
scope:
  applies_to: [cli, auditor]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "annual"

rules:
  - id: cli.must_be_registered
    statement: "All CLI commands MUST be declaratively registered in '.intent/mind/knowledge/cli_registry.yaml'."
    enforcement: error
  - id: cli.must_have_summary
    statement: "Every registered CLI command MUST have a concise summary for help text."
    enforcement: warn
  - id: cli.must_implement_capability
    statement: "Every CLI command SHOULD implement at least one semantic capability."
    enforcement: warn
--- END OF FILE ./.intent/charter/policies/governance/cli_governance_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/enforcement_model_policy.yaml ---
policy_id: 56dbc018-cb44-44a3-81aa-e9a2dd429069
# .intent/charter/policies/enforcement_model_policy.yaml
version: "2.0.0" # Version bump to signify harmonization
title: "Canonical Enforcement Model Policy"
purpose: >
  Provide the single, consistent meaning for all policy enforcement levels. This
  vocabulary MUST be used by all other policies and schemas to ensure the auditor
  can interpret and act on findings deterministically.

scope:
  applies_to:
    - governance
    - ci
    - agents

owners:
  primary: ["Governance Lead"]
  reviewers: ["Core Maintainer"]

review:
  frequency: "12 months"

levels:
  error:
    description: "A critical violation. This finding MUST block a merge/deploy. The auditor MUST return a non-zero exit code."
    ci_behavior: "fail"
    runtime_behavior: "block"
  warn:
    description: "A non-critical issue or deviation. The finding MUST be reported but SHOULD NOT block a merge/deploy. It must be tracked for resolution."
    ci_behavior: "pass_with_warnings"
    runtime_behavior: "log_and_continue"
  info:
    description: "An informational finding or observation. No action is required, but it provides context for a human reviewer."
    ci_behavior: "ignore"
    runtime_behavior: "ignore"

rules:
  - id: level_must_be_declared
    statement: "Every rule in every policy MUST specify an 'enforcement' level from the set {error, warn, info}."
    enforcement: error
  - id: auditor_maps_levels
    statement: "The constitutional auditor MUST map all findings to the levels defined above and respect their specified CI/runtime behavior."
    enforcement: error
--- END OF FILE ./.intent/charter/policies/governance/enforcement_model_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/intent_crate_policy.yaml ---
policy_id: 6bf96cc9-ffb4-493b-b6f8-05493b4b9d74
id: intent_crate_policy
version: "1.0.0"
title: "Intent Crate Processing Policy"
status: active
purpose: >
  To govern the autonomous, asynchronous processing of change requests (Intent Crates),
  ensuring all changes to the system's state are auditable, validated, and formally managed.

scope:
  applies_to: [governance, system]

owners:
  primary: "Governance Lead"
  reviewers: ["Core Maintainer"]

review:
  frequency: "6 months"

rules:
  - id: crate.location.inbox
    statement: "All new, unprocessed Intent Crates MUST reside in 'work/crates/inbox/'."
    enforcement: error
  
  - id: crate.state.must_move
    statement: "A crate MUST be moved from the inbox to 'processing', and then to 'accepted' or 'rejected'. It MUST NOT be modified in place."
    enforcement: error

  - id: crate.result.required
    statement: "Every processed crate in 'accepted' or 'rejected' MUST contain a 'result.yaml' file detailing the outcome and justification."
    enforcement: error

  - id: crate.acceptance.meta_sync
    statement: "Upon accepting a CONSTITUTIONAL_AMENDMENT crate that adds a new policy or schema, the system MUST autonomously update and commit '.intent/meta.yaml'."
    enforcement: error
  
  - id: crate.acceptance.scaffold_work
    statement: "If a new policy is accepted and requires new auditor checks, the system SHOULD scaffold the necessary check files or methods."
    enforcement: warn
--- END OF FILE ./.intent/charter/policies/governance/intent_crate_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/intent_guard_policy.yaml ---
policy_id: 1d311fd2-97db-462a-bacc-862e8f3c3777
# .intent/charter/policies/intent_guard_policy.yaml
version: "2.0.0" # Version bump to clarify Mind/Charter separation.
title: "Intent Guard Policy"
purpose: >
  Ensure that all actions remain aligned with the Constitution. This policy
  protects the immutable Charter from unauthorized modification and governs the
  process for safe, dynamic updates to the working Mind.

scope:
  applies_to:
    - agents
    - cli
    - governance
    - services

owners:
  primary: ["Governance Lead"]
  reviewers: ["Core Maintainer"]

review:
  frequency: "6 months"

rules:
  - id: charter.write_block
    statement: "The Charter (.intent/charter/**) is immutable. Runtime systems, agents, and tools MUST NOT write to it. Changes require a formal amendment."
    enforcement: error

  - id: charter.change_requires_proposal
    statement: "Any change to the Charter (.intent/charter/**) MUST be executed via a ratified proposal with the required approver quorum."
    enforcement: error

  - id: mind.writes_must_be_governed
    statement: "Writes to the Mind (.intent/mind/**) are permitted but MUST be governed. They must originate from a registered capability and pass all relevant safety and validation checks."
    enforcement: warn

  - id: single_active_constitution
    statement: "Exactly one active constitution version MUST be referenced by '.intent/charter/constitution/ACTIVE'."
    enforcement: error

  - id: cli.registry_source_of_truth
    statement: "All operator actions MUST go through registered CLI commands in 'mind/knowledge/cli_registry.yaml'."
    enforcement: error

  - id: auditor.block_on_violation
    statement: "If any guard rule with enforcement=error is violated, the constitutional auditor MUST fail."
    enforcement: error
--- END OF FILE ./.intent/charter/policies/governance/intent_guard_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/knowledge_source_policy.yaml ---
policy_id: 23a18582-a3a3-459b-b874-78b41f925097
id: knowledge_source_policy
version: "1.0.0"
title: "Knowledge Source of Truth Policy"
status: active
purpose: >
  Enforces the constitutional principle that the database is the single source
  of operational truth. This policy defines the narrow, explicit exceptions
  for tools that are permitted to interact with legacy or intermediate knowledge
  artifacts like knowledge_graph.json.
scope:
  applies_to: [governance, auditor]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "annual"

# This is the list of system tools that are granted a constitutional exception
# to read or write the knowledge_graph.json artifact. All other access is forbidden.
allowed_access_paths:
  - "src/features/introspection/knowledge_graph_service.py"
  - "src/features/governance/checks/knowledge_source_check.py"
--- END OF FILE ./.intent/charter/policies/governance/knowledge_source_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/logging_policy.yaml ---
policy_id: a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6e
id: logging_policy
version: "1.0.0"
title: "Unified Logging Policy"
status: active
purpose: >
  To ensure all system output is standardized, structured, and auditable by mandating
  the use of the shared logger and forbidding unsanctioned output channels like print().

scope:
  applies_to: [code, auditor]

owners:
  primary: "Core Maintainer"

review:
  frequency: "annual"

rules:
  - id: log.no_print_statements
    statement: "The use of print() is forbidden in application code (core, features, services). It is only permitted in the CLI layer for direct user output."
    enforcement: error
    allowed_paths:
      - "src/cli/**"
      - "tests/**" # Allow print in tests for debugging

  - id: log.no_direct_logging_import
    statement: "Direct import and configuration of the standard 'logging' module is forbidden. All loggers must be acquired via 'from shared.logger import getLogger'."
    enforcement: error
    allowed_paths:
      - "src/shared/logger.py" # The module itself is exempt.

--- END OF FILE ./.intent/charter/policies/governance/logging_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/reporting_policy.yaml ---
policy_id: 93e18e85-75cb-47bf-8665-0f793d89b65d
id: reporting_policy
version: 1
title: "Generated Artifacts & Reporting Policy"
status: active
purpose: >
  To constitutionally define the location, format, and governance of all
  transient, machine-generated artifacts (reports, logs, bundles, etc.).
  This policy enforces a strict separation between the permanent, source-of-truth
  "Mind" (.intent/) and the ephemeral outputs of system actions.

scope:
  applies_to: ["agents", "tooling", "cli", "auditor"]

owners:
  accountable: "Core Maintainer"

review:
  frequency: "12 months"

rules:
  - id: reports.canonical_output_directory
    statement: "All generated reports and non-constitutional artifacts MUST be written to the 'reports/' directory at the repository root."
    enforcement: error
  - id: reports.require_header
    statement: "All human-readable text or YAML reports MUST begin with a standardized header block that clearly identifies them as generated artifacts."
    enforcement: warn
  - id: reports.retention_policy
    statement: "Reports are considered ephemeral and MAY be deleted after 30 days. They SHOULD NOT be checked into source control."
    enforcement: info

definitions:
  output_directory: "reports/"
  header_template: |
    # ==============================================================================
    # WARNING: THIS IS A GENERATED REPORT. DO NOT EDIT MANUALLY.
    # It is a transient artifact and SHOULD NOT be used as a primary source of data.
    # Source of Constitutional Truth: .intent/
    # Source of Operational History: CORE Database
    # Generated By: {tool_name}
    # Generated At: {timestamp_utc}
    # ==============================================================================

--- END OF FILE ./.intent/charter/policies/governance/reporting_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/governance/tooling_policy.yaml ---
policy_id: b7c95ae3-05be-4138-8b27-12cd5670f4e9
id: tooling_policy
version: "1.0.0"
title: "Tooling Policy"
status: active
purpose: >
  To define the sanctioned tools and how they are invoked by agents and operators,
  ensuring reproducibility, performance, and constitutional compliance.
scope:
  applies_to: [cli, agents, services]
owners:
  accountable: "Core Maintainer"
review:
  frequency: "annual"

rules:
  - id: tools.registered_only
    statement: "Only tools/commands registered in '.intent/mind/knowledge/cli_registry.yaml' may be invoked by agents/services."
    enforcement: error
  - id: tools.version_pinned
    statement: "Critical tools (linters, formatters, test runners) MUST be version-pinned in pyproject or lockfiles."
    enforcement: warn
  - id: tools.no_write_intent
    statement: "Tooling MUST NOT write to '.intent/charter/**'; proposals are the only path for constitutional changes."
    enforcement: error
--- END OF FILE ./.intent/charter/policies/governance/tooling_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/operations/canary_policy.yaml ---
policy_id: 5bc9a0e5-a6fb-47be-ab2f-82bce1217c84
id: canary_policy
version: "1.0.0"
title: "Canary Policy"
status: active

owners:
  - "Governance Lead"

review:
  frequency: "annual"

canary:
  enabled: true
  scope:
    paths:
      - "src/**"
      - "cli/**"
      - "agents/**"
    modes:
      - "development"
      - "staging"
  abort_conditions:
    - "audit:level=error"
    - "tests:failed>0"
    - "latency:p95>threshold"
  metrics:
    - name: "audit.errors"
      threshold: 0
      direction: "less"
    - name: "tests.failed"
      threshold: 0
      direction: "less"
    - name: "latency.p95.ms"
      threshold: 500
      direction: "less"

--- END OF FILE ./.intent/charter/policies/operations/canary_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/operations/dev_fastpath_policy.yaml ---
policy_id: 4923517d-7e30-48dc-8134-b119714ed2b8
id: dev_fastpath_policy
version: "1.0.0"
title: Developer Fastpath Policy
purpose: >
  Allow fast, local feedback loops for developers while preserving safety via CI hard gates.
scope:
  applies_to:
    - developers
    - cli
    - ci
owners:
  primary: ["DX Lead"]
  reviewers: ["Governance Lead"]
review:
  frequency: "12 months"

rules:
  thresholds:
    max_changed_files: 20
    allow_intent_changes: false
  required_checks:
    - syntax
    - linter
    - formatter
  disallowed_paths:
    - ".intent/**"
    - "src/system/governance/**"

checklist:
  - Pre-commit runs syntax + linter + formatter on changed files (< thresholds).
  - Pre-push runs a mini-audit; CI enforces full auditor run.
  - Any change under .intent/** or governance/** bypasses fastpath and triggers full checks.
--- END OF FILE ./.intent/charter/policies/operations/dev_fastpath_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/operations/incident_response_policy.yaml ---
policy_id: 95df7291-6fc2-4a5b-9f6d-78e9af5ac200
id: incident_response_policy
version: "1.0.0"
title: "Incident Response Policy"
status: active
purpose: >
  Provide a lightweight, auditable process to respond to security and governance incidents.
scope:
  applies_to: [security, governance, ci, services]
owners:
  primary: "Security Lead"
  reviewers: ["Governance Lead"]
review:
  frequency: "12 months"

severity:
  - low
  - medium
  - high
  - critical

rules:
  - id: ir.triage_required
    statement: All incidents MUST be triaged within 24h with severity and owner assigned.
    enforcement: error
  - id: ir.timeline
    statement: A minimal timeline (what happened, when, who, evidence) MUST be recorded.
    enforcement: warn
  - id: ir.comms
    statement: Notifications MUST be sent to maintainers for high/critical incidents.
    enforcement: warn
  - id: ir.postmortem
    statement: High/critical incidents REQUIRE a short postmortem with actions and owners.
    enforcement: warn

checklist:
  - Auditor verifies incident records exist for flagged events (secrets exposure, DB policy violations).
  - Auditor checks postmortems for high/critical incidents within 7 days.
--- END OF FILE ./.intent/charter/policies/operations/incident_response_policy.yaml ---

--- START OF FILE ./.intent/charter/policies/safety_policy.yaml ---
policy_id: 05ffbf34-2e0e-4069-b77e-473923537077
id: safety_policy
version: "1.0.0"
title: "System Safety & Security Policy"
status: active
purpose: >
  The single source of truth for all security and safety policies governing
  code generation, execution, and self-modification.
scope:
  applies_to: [agents, code, ci, services]
owners:
  primary: "Security Lead"
  reviewers: ["Core Maintainer"]
review:
  frequency: "12 months"

rules:
  # ===================================================================
  # RULE: Govern Self-Modification (Immutable Constitution)
  # ===================================================================
  - id: immutable_constitution
    description: >
      The core mission files are immutable and can only be changed via the full,
      human-in-the-loop constitutional amendment process.
    enforcement: warn # This is a meta-rule; its enforcement is the amendment process itself.
    applies_to:
      paths:
        - "charter/mission/principles.yaml"
        - "charter/mission/manifesto.md"
        - "charter/mission/northstar.yaml"

  # ===================================================================
  # RULE: No self-modification of core loop
  # ===================================================================
  - id: deny_core_loop_edit
    description: >
      CORE cannot modify its own core orchestration and governance engine
      without explicit human review via the formal amendment process.
    enforcement: error # An automated change here is a critical violation.
    applies_to:
      paths:
        - "src/core/main.py"
        - "src/core/intent_guard.py"
        - "charter/policies/intent_guard_policy.yaml"
        - "charter/policies/safety_policy.yaml"
    action: require_human_approval
    feedback: |
      🔒 Core logic modification detected. Human review required before application.

  # ===================================================================
  # RULE: Block dangerous execution primitives
  # ===================================================================
  - id: no_dangerous_execution
    description: >
      Generated or modified code must not contain calls to dangerous functions
      that enable arbitrary code execution, shell access, or unsafe deserialization.
    enforcement: error
    scope:
      domains: [core, agents, features]
      exclude:
        - path: "tests/**"
          rationale: "Test files require direct execution for validation"
        - path: "src/core/git_service.py"
          rationale: >
            This file is exempt as it safely uses subprocess.run() without shell=True.
    detection:
      type: regex
      patterns:
        - "eval\\("
        - "exec\\("
        - "compile\\("
        - "os\\.system\\("
        - "os\\.popen\\("
        - "subprocess\\.(run|Popen|call)\\([^)]*shell\\s*=\\s*True"
        - "shutil\\.rmtree\\("
        - "os\\.remove\\("
        - "os\\.rmdir\\("
    action: reject
    feedback: |
      ❌ Dangerous execution detected: '{{pattern}}'. Use safe wrappers or avoid shell=True.

  # ===================================================================
  # RULE: Restrict network access
  # ===================================================================
  - id: restrict_network_access
    description: >
      Only explicitly allowed domains may be contacted. All outbound network
      calls must be through approved integration points.
    enforcement: error
    evidence: ["network_access_log"]
    allowed_domains:
      - "api.openai.com"
      - "github.com"
      - "api.deepseek.com"
      - "api.anthropic.com"
    action: reject
    feedback: |
      ❌ Attempt to contact unauthorized domain: {{domain}}. Update safety_policy.yaml to allow if needed.

  # ===================================================================
  # RULE: All changes must be logged
  # ===================================================================
  - id: change_must_be_logged
    description: >
      Every file change must be preceded by a log entry recorded at CORE_ACTION_LOG_PATH
      with IntentBundle ID and description.
    enforcement: error
    triggers:
      - before_write
    validator: change_log_checker
    action: reject_if_unlogged
    feedback: |
      ❌ No prior log entry found for this change. Write to CORE_ACTION_LOG_PATH before modifying files.
--- END OF FILE ./.intent/charter/policies/safety_policy.yaml ---

--- START OF FILE ./.intent/charter/schemas/agent/agent_policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://core.local/schemas/agent_policy_schema.json",
  "title": "Agent Policy",
  "description": "Constitutional schema for the single, authoritative agent governance policy.",
  "type": "object",
  "required": ["id", "version", "title", "status", "purpose", "rules"],
  "properties": {
    "id": { "const": "agent_policy" },
    "version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "title": { "type": "string" },
    "status": { "enum": ["active", "draft", "deprecated"] },
    "purpose": { "type": "string" },
    "scope": { "type": "object" },
    "owners": { "type": "object" },
    "review": { "type": "object" },
    "rules": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["id", "statement", "enforcement"],
        "properties": {
          "id": { "type": "string" },
          "statement": { "type": "string" },
          "enforcement": { "enum": ["info", "warn", "error"] }
        },
        "additionalProperties": false
      }
    },
    "resource_selection": {
      "type": "object"
    }
  },
  "additionalProperties": true
}
--- END OF FILE ./.intent/charter/schemas/agent/agent_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/agent/cognitive_roles_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Cognitive Roles Policy",
  "description": "Schema for defining abstract cognitive roles and assigning them to named resources.",
  "type": "object",
  "required": ["cognitive_roles"],
  "properties": {
    "cognitive_roles": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["role", "description", "assigned_resource", "required_capabilities"],
        "properties": {
          "role": {
            "type": "string",
            "description": "The unique name of the cognitive role (e.g., 'Planner')."
          },
          "description": {
            "type": "string"
          },
          "assigned_resource": {
            "type": "string",
            "description": "The named resource (e.g., 'deepseek_chat') to assign to this role."
          },
          "required_capabilities": {
            "type": "array",
            "description": "A list of skills required by this role for validation.",
            "items": { "type": "string" }
          }
        }
      }
    }
  },
  "additionalProperties": false
}
--- END OF FILE ./.intent/charter/schemas/agent/cognitive_roles_schema.json ---

--- START OF FILE ./.intent/charter/schemas/agent/micro_proposal_policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://core.local/schemas/micro_proposal_policy_schema.json",
  "title": "Micro-Proposal Policy",
  "description": "Constitutional schema for the policy governing low-risk, autonomous changes.",
  "type": "object",
  "required": ["id", "version", "title", "status", "purpose", "rules"],
  "properties": {
    "id": { "const": "micro_proposal_policy" },
    "version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "title": { "type": "string" },
    "status": { "enum": ["active", "draft", "deprecated"] },
    "purpose": { "type": "string" },
    "scope": { "type": "object" },
    "owners": { "type": "object" },
    "review": { "type": "object" },
    "rules": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["id", "description", "enforcement"],
        "properties": {
          "id": { "type": "string" },
          "description": { "type": "string" },
          "enforcement": { "enum": ["info", "warn", "error"] },
          "allowed_actions": {
            "type": "array",
            "items": { "type": "string" }
          },
          "allowed_paths": {
            "type": "array",
            "items": { "type": "string" }
          },
          "forbidden_paths": {
            "type": "array",
            "items": { "type": "string" }
          },
          "required_evidence": {
            "type": "array",
            "items": { "type": "string" }
          }
        },
        "additionalProperties": true
      }
    }
  },
  "additionalProperties": true
}
--- END OF FILE ./.intent/charter/schemas/agent/micro_proposal_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/agent/resource_manifest_policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "LLM Resource Manifest Policy",
  "description": "Constitutional schema for the policy defining available LLM resources.",
  "type": "object",
  "allOf": [{ "$ref": "policy_schema.json" }],
  "properties": {
    "id": { "const": "resource_manifest_policy" },
    "llm_resources": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["name", "provided_capabilities", "env_prefix"],
        "properties": {
          "name": { "type": "string" },
          "provided_capabilities": { "type": "array", "items": { "type": "string" } },
          "env_prefix": { "type": "string" },
          "performance_metadata": { "type": "object" }
        }
      }
    }
  },
  "required": ["llm_resources"]
}
--- END OF FILE ./.intent/charter/schemas/agent/resource_manifest_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/code/capability_tag_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "CORE Capability Tag Definition",
  "description": "The formal schema for a single, well-defined capability in the CORE system.",
  "type": "object",
  "required": [
    "key",
    "title",
    "description",
    "owner",
    "status",
    "risk_level"
  ],
  "properties": {
    "key": {
      "type": "string",
      "description": "The unique, canonical identifier for the capability, following the 'domain.action' pattern.",
      "pattern": "^[a-z0-9_]+(\\.[a-z0-9_]+)+$"
    },
    "title": {
      "type": "string",
      "description": "A short, human-readable title for the capability.",
      "minLength": 5
    },
    "description": {
      "type": "string",
      "description": "A clear, one-sentence explanation of what this capability does.",
      "minLength": 10
    },
    "owner": {
      "type": "string",
      "description": "The architectural domain that owns and is responsible for this capability."
    },
    "status": {
      "type": "string",
      "description": "The current lifecycle status of the capability.",
      "enum": ["active", "deprecated", "experimental"]
    },
    "risk_level": {
      "type": "string",
      "description": "The assessed risk of invoking this capability (low, medium, or high).",
      "enum": ["low", "medium", "high"]
    },
    "aliases": {
      "type": "array",
      "description": "A list of old or alternative names for this capability to ensure backward compatibility.",
      "items": {
        "type": "string"
      },
      "uniqueItems": true
    },
    "policy_refs": {
      "type": "array",
      "description": "A list of policy files that govern or relate to this capability.",
      "items": {
        "type": "string"
      }
    },
    "vector": {
      "type": "array",
      "description": "A pre-computed semantic vector representing the meaning of the capability's source code.",
      "items": {
        "type": "number"
      }
    }
  },
  "additionalProperties": false
}
--- END OF FILE ./.intent/charter/schemas/code/capability_tag_schema.json ---

--- START OF FILE ./.intent/charter/schemas/code/knowledge_graph_entry_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://core.system/schema/knowledge_graph_entry.json",
  "title": "Knowledge Graph Symbol Entry",
  "description": "Schema for a single symbol (function or class) in the knowledge_graph.json file.",
  "type": "object",
  "required": [
    "key",
    "name",
    "type",
    "file",
    "capability",
    "intent",
    "last_updated",
    "calls",
    "line_number",
    "is_async",
    "parameters",
    "is_class",
    "structural_hash"
  ],
  "properties": {
    "key": { "type": "string", "description": "The unique identifier for the symbol (e.g., 'path/to/file.py::MyClass')." },
    "name": { "type": "string", "description": "The name of the function or class." },
    "type": { "type": "string", "enum": ["FunctionDef", "ClassDef", "AsyncFunctionDef"] },
    "file": { "type": "string", "description": "The relative path to the source file." },
    "tags": {
      "type": "array",
      "items": { "type": "string" },
      "description": "A list of domain tags classifying the symbol's purpose."
    },
    "owner": {
      "type": "string",
      "description": "The agent or team responsible for this capability."
    },
    "capability": { "type": "string", "description": "The unique UUID of the capability this symbol implements, or 'unassigned'." },
    "intent": { "type": "string", "description": "A clear, concise statement of the symbol's purpose." },
    "docstring": { "type": ["string", "null"], "description": "The raw docstring from source code." },
    "calls": { "type": "array", "items": { "type": "string" }, "description": "List of other functions called by this one." },
    "line_number": { "type": "integer", "minimum": 0 },
    "is_async": { "type": "boolean" },
    "parameters": { "type": "array", "items": { "type": "string" } },
    "entry_point_type": { "type": ["string", "null"], "description": "Type of entry point if applicable (e.g., 'fastapi_route_post')." },
    "last_updated": { "type": "string", "format": "date-time" },
    "is_class": { "type": "boolean", "description": "True if the symbol is a class definition." },
    "base_classes": {
      "type": "array",
      "items": { "type": "string" },
      "description": "A list of base classes this symbol inherits from (if it is a class)."
    },
    "entry_point_justification": {
      "type": ["string", "null"],
      "description": "The name of the pattern that identified this symbol as an entry point."
    },
    "parent_class_key": {
      "type": ["string", "null"],
      "description": "The key of the parent class, if this symbol is a method."
    },
    "structural_hash": {
      "type": "string",
      "description": "A SHA256 hash of the symbol's structure, ignoring comments and docstrings."
    },
    "vector": {
      "type": ["array", "null"],
      "description": "A pre-computed semantic vector representing the meaning of the capability's source code.",
      "items": {
        "type": "number"
      }
    },
    "end_line_number": {
      "type": ["integer", "null"],
      "description": "The line number where the symbol's definition ends."
    },
    "source_code": {
      "type": ["string", "null"],
      "description": "The exact, unparsed source code of the symbol."
    }
  },
  "additionalProperties": false
}

--- END OF FILE ./.intent/charter/schemas/code/knowledge_graph_entry_schema.json ---

--- START OF FILE ./.intent/charter/schemas/constitutional/intent_bundle_schema.json ---
{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "Intent Bundle",
    "description": "A schema for the structured data package representing a single, reasoned action by the CORE system.",
    "type": "object",
    "required": [
        "bundle_id",
        "initiator",
        "created_at",
        "goal",
        "justification",
        "risk_tier",
        "status",
        "evidence"
    ],
    "properties": {
        "bundle_id": {
            "type": "string",
            "description": "A unique identifier for this bundle of work."
        },
        "initiator": {
            "type": "string",
            "description": "The human operator or system agent that initiated the action."
        },
        "created_at": {
            "type": "string",
            "format": "date-time"
        },
        "goal": {
            "type": "string",
            "description": "The high-level goal this bundle is intended to achieve."
        },
        "justification": {
            "type": "string",
            "description": "The constitutional principle(s) this action serves."
        },
        "risk_tier": {
            "type": "string",
            "enum": ["low", "medium", "high"],
            "description": "The assessed risk level of the proposed change."
        },
        "status": {
            "type": "string",
            "enum": ["draft", "planned", "validated", "approved", "executed", "archived", "failed"],
            "description": "The current state in the lifecycle of the bundle."
        },
        "evidence": {
            "type": "object",
            "description": "A collection of links to artifacts that support this action.",
            "properties": {
                "plan_id": { "type": "string" },
                "validation_report_id": { "type": "string" },
                "canary_report_id": { "type": "string" },
                "test_report_id": { "type": "string" },
                "approval_signature_ids": {
                    "type": "array",
                    "items": { "type": "string" }
                }
            }
        }
    }
}
--- END OF FILE ./.intent/charter/schemas/constitutional/intent_bundle_schema.json ---

--- START OF FILE ./.intent/charter/schemas/constitutional/intent_crate_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://core.local/schemas/intent_crate_schema.json",
  "title": "Intent Crate Manifest",
  "description": "The constitutional schema for a manifest.yaml file within an Intent Crate. This defines a formal, auditable request for change.",
  "type": "object",
  "required": ["crate_id", "author", "intent", "type"],
  "properties": {
    "crate_id": {
      "type": "string",
      "description": "A unique identifier for this crate, typically matching the directory name.",
      "pattern": "^[a-zA-Z0-9_-]+$"
    },
    "author": {
      "type": "string",
      "description": "The identity of the human or system that created the crate (e.g., an email address)."
    },
    "intent": {
      "type": "string",
      "description": "A clear, one-sentence justification for the proposed change.",
      "minLength": 20
    },
    "type": {
      "type": "string",
      "description": "The type of change being proposed.",
      "enum": ["CONSTITUTIONAL_AMENDMENT", "CODE_MODIFICATION"]
    },
    "payload_files": {
        "type": "array",
        "description": "A list of the files included in this crate that are part of the change.",
        "items": {
            "type": "string"
        }
    }
  },
  "additionalProperties": false
}
--- END OF FILE ./.intent/charter/schemas/constitutional/intent_crate_schema.json ---

--- START OF FILE ./.intent/charter/schemas/constitutional/proposal_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://core.local/schemas/proposal.schema.json",
  "title": "CORE Proposal (v1)",
  "type": "object",
  "additionalProperties": false,
  "required": ["target_path", "action", "justification", "content"],
  "properties": {
    "target_path": {
      "type": "string",
      "description": "Repo-relative path to the file to be replaced. Must not be inside .intent/proposals/.",
      "pattern": "^(?!\\.intent\\/proposals\\/)[\\w\\-\\.\\/]+$",
      "$comment": "Allows any path as long as it's not writing into the proposals directory itself."
    },
    "action": {
      "type": "string",
      "enum": ["replace_file"],
      "description": "Currently only full file replacement is supported."
    },
    "justification": {
      "type": "string",
      "minLength": 10,
      "description": "Human-readable rationale for the change.",
      "pattern": "\\S"
    },
    "content": {
      "type": "string",
      "minLength": 1
    },
    "signatures": {
      "type": "array",
      "description": "Optional array of signature objects.",
      "items": { "$ref": "#/$defs/signature" }
    }
  },
  "$defs": {
    "signature": {
      "type": "object",
      "additionalProperties": false,
      "required": ["identity", "signature_b64", "token", "timestamp"],
      "properties": {
        "identity": { "type": "string" },
        "signature_b64": { "type": "string", "contentEncoding": "base64" },
        "token": {
          "type": "string",
          "pattern": "^core-proposal-v[0-9]+:[a-f0-9]{64}$",
          "$comment": "Allows any version number for the token, e.g., v1, v6."
        },
        "timestamp": { "type": "string", "format": "date-time" }
      }
    }
  }
}
--- END OF FILE ./.intent/charter/schemas/constitutional/proposal_schema.json ---

--- START OF FILE ./.intent/charter/schemas/data/database_policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "Database Policy Schema",
  "type": "object",
  "required": ["id", "version", "title", "engine", "migrations", "rules", "drift"],
  "properties": {
    "id": { "const": "database_policy" },
    "version": { "type": "string" },
    "title": { "type": "string" },
    "engine": {
      "type": "object",
      "required": ["type", "schema"],
      "properties": {
        "type": { "type": "string", "enum": ["postgresql"] },
        "schema": { "type": "string", "minLength": 1 }
      }
    },
    "migrations": {
      "type": "object",
      "required": ["directory", "order"],
      "properties": {
        "directory": { "type": "string" },
        "order": {
          "type": "array",
          "items": { "type": "string", "pattern": "^\\d{3}_.+\\.sql$" },
          "minItems": 1
        }
      }
    },
    "rules": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["id", "statement", "enforcement"],
        "properties": {
          "id": { "type": "string" },
          "statement": { "type": "string" },
          "enforcement": { "enum": ["error", "warn", "info"] }
        },
        "additionalProperties": false
      }
    },
    "retention": {
      "type": "object",
      "properties": {
        "audit_runs_days": { "type": "integer", "minimum": 1 },
        "proposals_days": { "type": "integer", "minimum": 1 }
      },
      "additionalProperties": true
    },
    "drift": {
      "type": "object",
      "required": ["development", "production"],
      "properties": {
        "development": { "type": "string", "enum": ["warn", "block"] },
        "production": { "type": "string", "enum": ["warn", "block"] }
      }
    },
    "backup_restore": {
      "type": "object",
      "properties": {
        "cadence": { "type": "string" },
        "test_restore_quarterly": { "type": "boolean" }
      }
    },
    "quorum": {
      "type": "object",
      "properties": {
        "changes_require_critical_paths": { "type": "boolean" }
      }
    }
  },
  "additionalProperties": true
}
--- END OF FILE ./.intent/charter/schemas/data/database_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/data/database_schema.yaml ---
version: 1
description: >
  Initial schema for CORE's operational database.
  Stores auditable history of events, not constitutional truth.

tables:
  capabilities:
    description: >
      Current catalog of capabilities with their owners and tags.
      Mirrors .intent/knowledge/domains but may include runtime metadata.
    columns:
      - name: key
        type: text
        constraints: [primary_key]
      - name: title
        type: text
      - name: description
        type: text
      - name: owner
        type: text
      - name: tags
        type: jsonb
      - name: updated_at
        type: timestamptz

  capability_history:
    description: Versioned history of capability changes.
    columns:
      - name: id
        type: bigserial
        constraints: [primary_key]
      - name: capability_key
        type: text
      - name: change_type
        type: text   # created, updated, deleted
      - name: diff
        type: jsonb
      - name: changed_at
        type: timestamptz

  cli_runs:
    description: >
      Each execution of a core-admin command with timestamp and result.
    columns:
      - name: id
        type: bigserial
        constraints: [primary_key]
      - name: command
        type: text
      - name: args
        type: jsonb
      - name: result
        type: text   # success, fail
      - name: run_at
        type: timestamptz

  audits:
    description: >
      Records every constitutional audit or validation run.
    columns:
      - name: id
        type: bigserial
        constraints: [primary_key]
      - name: scope
        type: text
      - name: result
        type: jsonb
      - name: run_at
        type: timestamptz

migrations:
  - id: 0001-initial
    description: Initial schema creation for capabilities, capability_history, cli_runs, audits.
    created_at: "2025-09-18"
    approved_by: TBD


--- END OF FILE ./.intent/charter/schemas/data/database_schema.yaml ---

--- START OF FILE ./.intent/charter/schemas/governance/available_actions_policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "Available Actions Policy",
  "description": "Defines the complete set of actions available to the PlannerAgent.",
  "type": "object",
  "allOf": [{ "$ref": "../policy_schema.json" }],
  "properties": {
    "id": { "const": "available_actions_policy" },
    "actions": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["name", "description"],
        "properties": {
          "name": { "type": "string" },
          "description": { "type": "string" },
          "required_parameters": { "type": "array", "items": { "type": "string" } }
        }
      }
    }
  },
  "required": ["actions"]
}
--- END OF FILE ./.intent/charter/schemas/governance/available_actions_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/governance/cli_registry_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "title": "CLI Registry Policy",
  "description": "The constitutional policy that serves as the single source of truth for all registered core-admin CLI commands.",
  "type": "object",
  "allOf": [{ "$ref": "../policy_schema.json" }],
  "properties": {
    "id": { "const": "cli_registry_policy" },
    "commands": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["name", "summary", "entrypoint", "category"],
        "properties": {
          "name": { "type": "string" },
          "module": { "type": "string" },
          "entrypoint": { "type": "string" },
          "summary": { "type": "string" },
          "category": { "type": "string" }
        }
      }
    }
  },
  "required": ["commands"]
}
--- END OF FILE ./.intent/charter/schemas/governance/cli_registry_schema.json ---

--- START OF FILE ./.intent/charter/schemas/governance/enforcement_model_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Enforcement Model Policy Schema",
  "description": "Schema for the canonical enforcement model policy.",
  "type": "object",
  "required": [
    "version",
    "title",
    "purpose",
    "levels",
    "rules"
  ],
  "properties": {
    "version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "title": { "type": "string" },
    "purpose": { "type": "string" },
    "scope": { "type": "object" },
    "owners": { "type": "object" },
    "review": { "type": "object" },
    "levels": {
      "type": "object",
      "required": ["error", "warn", "info"],
      "properties": {
        "error": { "$ref": "#/definitions/level" },
        "warn": { "$ref": "#/definitions/level" },
        "info": { "$ref": "#/definitions/level" }
      },
      "additionalProperties": false
    },
    "rules": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["id", "statement", "enforcement"],
        "properties": {
          "id": { "type": "string" },
          "statement": { "type": "string" },
          "enforcement": { "enum": ["error", "warn", "info"] }
        }
      }
    }
  },
  "additionalProperties": false,
  "definitions": {
    "level": {
      "type": "object",
      "required": ["description", "ci_behavior", "runtime_behavior"],
      "properties": {
        "description": { "type": "string" },
        "ci_behavior": { "type": "string" },
        "runtime_behavior": { "type": "string" }
      },
      "additionalProperties": false
    }
  }
}
--- END OF FILE ./.intent/charter/schemas/governance/enforcement_model_schema.json ---

--- START OF FILE ./.intent/charter/schemas/governance/intent_guard_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Intent Guard Policy",
  "description": "Schema for the core IntentGuard rules that prevent unauthorized system modifications.",
  "type": "object",
  "required": ["rules"],
  "properties": {
    "rules": {
      "type": "array",
      "minItems": 1,
      "items": {
        "type": "object",
        "required": ["id", "description", "enforcement"],
        "properties": {
          "id": { "type": "string" },
          "description": { "type": "string" },
          "enforcement": {
            "type": "string",
            "enum": ["error", "warn", "info"]
          },
          "applies_to": {
            "type": "object",
            "properties": {
              "paths": { "type": "array", "items": { "type": "string" } }
            }
          },
          "exclude": {
            "type": "object",
            "properties": {
              "paths": { "type": "array", "items": { "type": "string" } }
            }
          }
        }
      }
    }
  },
  "additionalProperties": false
}
--- END OF FILE ./.intent/charter/schemas/governance/intent_guard_schema.json ---

--- START OF FILE ./.intent/charter/schemas/governance/reporting_policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://core.local/schemas/reporting_policy.schema.json",
  "title": "Reporting Policy",
  "description": "Constitutional schema for governing generated artifacts and reports.",
  "type": "object",
  "required": ["id", "version", "purpose", "rules", "definitions"],
  "additionalProperties": false,
  "properties": {
    "id": { "const": "reporting_policy" },
    "version": { "type": "integer" },
    "title": { "type": "string" },
    "status": { "enum": ["active", "draft"] },
    "purpose": { "type": "string" },
    "scope": { "type": "object" },
    "owners": { "type": "object" },
    "review": { "type": "object" },
    "rules": {
      "type": "array",
      "items": {
        "type": "object",
        "required": ["id", "statement", "enforcement"],
        "properties": {
          "id": { "type": "string" },
          "statement": { "type": "string" },
          "enforcement": { "enum": ["info", "warn", "error"] }
        }
      }
    },
    "definitions": {
      "type": "object",
      "required": ["output_directory", "header_template"],
      "properties": {
        "output_directory": { "type": "string" },
        "header_template": { "type": "string" }
      }
    }
  }
}
--- END OF FILE ./.intent/charter/schemas/governance/reporting_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/operations/canary_policy_schema.json ---
{
"$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "canary_policy.schema.json",
  "title": "Canary Policy",
  "type": "object",
  "required": ["id", "version", "title", "owners", "review", "canary"],
  "properties": {
    "id": { "type": "string", "pattern": "^[a-z0-9_.-]+$" },
    "version": { "type": "string", "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$" },
    "title": { "type": "string" },
    "status": { "type": "string", "enum": ["draft", "active", "deprecated"] },
    "owners": { "type": "array", "items": { "type": "string" }, "minItems": 1 },
    "review": {
      "type": "object",
      "required": ["frequency"],
      "properties": {
        "frequency": { "type": "string", "enum": ["monthly", "quarterly", "semiannual", "annual"] },
        "last_reviewed": { "type": "string", "format": "date" }
      },
      "additionalProperties": false
    },
    "canary": {
      "type": "object",
      "required": ["enabled", "scope", "abort_conditions"],
      "properties": {
        "enabled": { "type": "boolean" },
        "scope": {
          "type": "object",
          "properties": {
            "paths": { "type": "array", "items": { "type": "string" } },
            "modes": { "type": "array", "items": { "type": "string", "enum": ["development", "staging", "production"] } }
          },
          "additionalProperties": false
        },
        "abort_conditions": { "type": "array", "items": { "type": "string" }, "minItems": 1 },
        "metrics": {
          "type": "array",
          "items": {
            "type": "object",
            "required": ["name", "threshold", "direction"],
            "properties": {
              "name": { "type": "string" },
              "threshold": { "type": "number" },
              "direction": { "type": "string", "enum": ["greater", "less"] }
            },
            "additionalProperties": false
          }
        }
      },
      "additionalProperties": false
    }
  },
  "additionalProperties": false
}

--- END OF FILE ./.intent/charter/schemas/operations/canary_policy_schema.json ---

--- START OF FILE ./.intent/charter/schemas/operations/config_schema.yaml ---
# .intent/schemas/config_schema.yaml
git:
  ignore_validation:
    type: boolean
    default: false
    description: >
      If true, skips Git pre-write checks. MUST be false in production or fallback modes
      to maintain rollback safety. Only for emergency recovery.
--- END OF FILE ./.intent/charter/schemas/operations/config_schema.yaml ---

--- START OF FILE ./.intent/charter/schemas/operations/runtime_requirements_schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "title": "Runtime Requirements",
  "type": "object",
  "required": ["id", "version", "title", "status", "variables", "owners", "review"],
  "properties": {
    "id": { "const": "runtime_requirements" },
    "version": { "type": "integer", "minimum": 1 },
    "title": { "type": "string" },
    "status": { "enum": ["active", "draft", "archived"] },
    "owners": { "type": "object" },
    "review": { "type": "object" },
    "variables": {
      "type": "object",
      "minProperties": 1,
      "patternProperties": {
        "^[A-Z0-9_]+$": {
          "type": "object",
          "required": ["description", "source", "required", "type", "used_by"],
          "properties": {
            "description": { "type": "string" },
            "source": { "enum": ["env", "secret", "cli"] },
            "required": { "type": "boolean" },
            "type": { "enum": ["string", "integer", "bool", "enum", "uri", "path"] },
            "allowed": { "type": "array", "items": { "type": "string" } },
            "default": {},
            "used_by": { "type": "array", "items": { "type": "string" } },
            "required_when": { "type": "string" }
          }
        }
      },
      "additionalProperties": false
    }
  },
  "additionalProperties": false
}
--- END OF FILE ./.intent/charter/schemas/operations/runtime_requirements_schema.json ---

--- START OF FILE ./.intent/charter/schemas/policy_schema.json ---
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://core.local/schemas/policy_schema.json",
  "title": "CORE Policy",
  "description": "The canonical schema for all constitutional policy files in .intent/charter/policies/.",
  "type": "object",
  "required": ["policy_id", "id", "version", "title", "purpose", "status", "owners", "review"],
  "properties": {
    "policy_id": {
      "type": "string",
      "description": "A unique and stable UUID for this policy document.",
      "pattern": "^[0-9a-fA-F]{8}-([0-9a-fA-F]{4}-){3}[0-9a-fA-F]{12}$"
    },
    "id": {
      "type": "string",
      "description": "The unique, snake_case identifier for the policy, matching the file name (e.g., 'agent_policy').",
      "pattern": "^[a-z0-9_]+_policy$"
    },
    "version": {
      "type": "string",
      "description": "The semantic version of the policy document.",
      "pattern": "^[0-9]+\\.[0-9]+\\.[0-9]+$"
    },
    "title": {
      "type": "string",
      "description": "A human-readable, Title Case name for the policy."
    },
    "purpose": {
      "type": "string",
      "description": "A concise, one or two-sentence explanation of why this policy exists."
    },
    "status": {
      "type": "string",
      "description": "The current lifecycle status of the policy.",
      "enum": ["active", "draft", "deprecated"]
    },
    "owners": {
      "type": "object",
      "description": "Defines the roles responsible for maintaining this policy.",
      "properties": {
        "primary": { "type": "string" },
        "reviewers": { "type": "array", "items": { "type": "string" } }
      },
      "required": ["primary"]
    },
    "review": {
      "type": "object",
      "description": "Specifies the review cadence for this policy.",
      "properties": {
        "frequency": { "type": "string", "description": "e.g., '12 months', 'quarterly'" },
        "last_reviewed": { "type": "string", "format": "date" }
      },
      "required": ["frequency"]
    }
  },
  "additionalProperties": true
}
--- END OF FILE ./.intent/charter/schemas/policy_schema.json ---

--- START OF FILE ./.intent/meta.yaml ---
version: "0.7.0" # Ratification of the Final Constitutional Alignment
# PURPOSE: This is the master index for the entire CORE constitution. It maps
# abstract concepts to their concrete file paths, fully embracing the new
# hierarchical policy structure for maximum clarity and governance.

charter:
  constitution:
    active_version: "charter/constitution/ACTIVE"
    amendment_process: "charter/constitution/amendment_process.md"
    approvers: "charter/constitution/approvers.yaml"
    critical_paths: "charter/constitution/critical_paths.yaml"
    operator_lifecycle: "charter/constitution/operator_lifecycle.md"

  mission:
    manifesto: "charter/mission/manifesto.md"
    northstar: "charter/mission/northstar.yaml"
    principles: "charter/mission/principles.yaml"

  policies:
    safety_policy: "charter/policies/safety_policy.yaml"

    agent:
      agent_policy: "charter/policies/agent/agent_policy.yaml"
      micro_proposal_policy: "charter/policies/agent/micro_proposal_policy.yaml"

    code:
      capability_linter_policy: "charter/policies/code/capability_linter_policy.yaml"
      code_health_policy: "charter/policies/code/code_health_policy.yaml"
      code_style_policy: "charter/policies/code/code_style_policy.yaml"
      naming_conventions_policy: "charter/policies/code/naming_conventions_policy.yaml"
      refactoring_patterns_policy: "charter/policies/code/refactoring_patterns_policy.yaml"

    data:
      database_policy: "charter/policies/data/database_policy.yaml"
      secrets_management_policy: "charter/policies/data/secrets_management_policy.yaml"

    governance:
      audit_ignore_policy: "charter/policies/governance/audit_ignore_policy.yaml"
      auditor_policy: "charter/policies/governance/auditor_policy.yaml"
      available_actions_policy: "charter/policies/governance/available_actions_policy.yaml"
      cli_governance_policy: "charter/policies/governance/cli_governance_policy.yaml"
      enforcement_model_policy: "charter/policies/governance/enforcement_model_policy.yaml"
      intent_crate_policy: "charter/policies/governance/intent_crate_policy.yaml"
      intent_guard_policy: "charter/policies/governance/intent_guard_policy.yaml"
      knowledge_source_policy: "charter/policies/governance/knowledge_source_policy.yaml"
      logging_policy: "charter/policies/governance/logging_policy.yaml"
      reporting_policy: "charter/policies/governance/reporting_policy.yaml"
      tooling_policy: "charter/policies/governance/tooling_policy.yaml"

    operations:
      canary_policy: "charter/policies/operations/canary_policy.yaml"
      dev_fastpath_policy: "charter/policies/operations/dev_fastpath_policy.yaml"
      incident_response_policy: "charter/policies/operations/incident_response_policy.yaml"

  schemas:
    policy_schema: "charter/schemas/policy_schema.json"
    
    agent:
      agent_policy_schema: "charter/schemas/agent/agent_policy_schema.json"
      cognitive_roles_schema: "charter/schemas/agent/cognitive_roles_schema.json"
      micro_proposal_policy_schema: "charter/schemas/agent/micro_proposal_policy_schema.json"
      resource_manifest_policy_schema: "charter/schemas/agent/resource_manifest_policy_schema.json"

    code:
      capability_tag_schema: "charter/schemas/code/capability_tag_schema.json"
      knowledge_graph_entry_schema: "charter/schemas/code/knowledge_graph_entry_schema.json"
      
    constitutional:
      intent_bundle_schema: "charter/schemas/constitutional/intent_bundle_schema.json"
      intent_crate_schema: "charter/schemas/constitutional/intent_crate_schema.json"
      proposal_schema: "charter/schemas/constitutional/proposal_schema.json"

    data:
      database_policy_schema: "charter/schemas/data/database_policy_schema.json"
      database_schema: "charter/schemas/data/database_schema.yaml"
      
    governance:
      available_actions_policy_schema: "charter/schemas/governance/available_actions_policy_schema.json"
      cli_registry_schema: "charter/schemas/governance/cli_registry_schema.json"
      enforcement_model_schema: "charter/schemas/governance/enforcement_model_schema.json"
      intent_guard_schema: "charter/schemas/governance/intent_guard_schema.json"
      reporting_policy_schema: "charter/schemas/governance/reporting_policy_schema.json"

    operations:
      canary_policy_schema: "charter/schemas/operations/canary_policy_schema.json"
      config_schema: "charter/schemas/operations/config_schema.yaml"
      runtime_requirements_schema: "charter/schemas/operations/runtime_requirements_schema.json"

mind:
  project_manifest: "mind/project_manifest.yaml"

  config:
    local_mode: "mind/config/local_mode.yaml"
    runtime_requirements: "mind/config/runtime_requirements.yaml"

  evaluation:
    score_policy: "mind/evaluation/score_policy.yaml"
    audit_checklist: "mind/evaluation/audit_checklist.yaml"

  knowledge:
    entry_point_patterns: "mind/knowledge/entry_point_patterns.yaml"
    file_handlers: "mind/knowledge/file_handlers.yaml"
    source_structure: "mind/knowledge/source_structure.yaml"

  prompts:
    capability_definer: "mind/prompts/capability_definer.prompt"
    code_peer_review: "mind/prompts/code_peer_review.prompt"
    constitutional_review: "mind/prompts/constitutional_review.prompt"
    fix_capability_manifest: "mind/prompts/fix_capability_manifest.prompt"
    fix_function_docstring: "mind/prompts/fix_function_docstring.prompt"
    fix_header: "mind/prompts/fix_header.prompt"
    fix_line_length: "mind/prompts/fix_line_length.prompt"
    goal_assessor: "mind/prompts/goal_assessor.prompt"
    intent_translator: "mind/prompts/intent_translator.prompt"
    module_docstring_writer: "mind/prompts/module_docstring_writer.prompt"
    new_capability_generator: "mind/prompts/new_capability_generator.prompt"
    planner_agent: "mind/prompts/planner_agent.prompt"
    refactor_for_clarity: "mind/prompts/refactor_for_clarity.prompt"
    refactor_outlier: "mind/prompts/refactor_outlier.prompt"
    standard_task_generator: "mind/prompts/standard_task_generator.prompt"
    vectorizer: "mind/prompts/vectorizer.prompt"

--- END OF FILE ./.intent/meta.yaml ---

--- START OF FILE ./.intent/mind/config/local_mode.yaml ---
# .intent/mind/config/local_mode.yaml

mode: local_fallback
apis:
  llm:
    enabled: false
    fallback: local_validator
  git:
    ignore_validation: false

# Development-specific overrides
dev_fastpath: true        # allow auto-sign in dev env only
--- END OF FILE ./.intent/mind/config/local_mode.yaml ---

--- START OF FILE ./.intent/mind/config/runtime_requirements.yaml ---
# .intent/mind/config/runtime_requirements.yaml
id: runtime_requirements
version: 1
title: "Runtime Requirements"
status: active
owners:
  accountable: "Platform SRE"
  responsible: ["Core Maintainer"]
review:
  frequency: "6 months"

variables:
  MIND:
    description: "The relative path to the system's declarative 'mind' (.intent directory)."
    source: env
    required: true
    type: path
    used_by: ["system", "auditor"]
  BODY:
    description: "The relative path to the system's executable 'body' (src directory)."
    source: env
    required: true
    type: path
    used_by: ["system"]
  REPO_PATH:
    description: "The absolute path to the root of the repository."
    source: env
    required: true
    type: path
    used_by: ["system","auditor"]
  LLM_ENABLED:
    description: "Master flag to enable or disable all LLM-related capabilities."
    source: env
    required: true
    type: bool
    allowed: ["true","false"]
    used_by: ["agents"]
  KEY_STORAGE_DIR:
    description: "The secure directory for storing operator private keys."
    source: env
    required: true
    type: path
    default: ".intent/keys"
    used_by: ["system"]
  CORE_ACTION_LOG_PATH:
    description: "Path to the action/change log file, required for the safety policy 'change_must_be_logged'."
    source: env
    required: true
    type: path
    used_by: ["auditor", "system"]
  CORE_ENV:
    description: "Runtime mode: 'development' or 'production'."
    source: env
    required: true
    type: enum
    allowed: ["development","production"]
    used_by: ["system"]
  LOG_LEVEL:
    description: "Logging level."
    source: env
    required: true
    type: enum
    allowed: ["DEBUG","INFO","WARNING","ERROR"]
    used_by: ["system"]
  CORE_DEV_FASTPATH:
    description: "Enable development fastpath."
    source: env
    required: false
    type: bool
    used_by: ["system"]
    required_when: "CORE_ENV == 'development'"
  CORE_MAX_CONCURRENT_REQUESTS:
    description: "The maximum number of simultaneous outbound LLM requests to prevent rate-limiting."
    source: env
    required: false
    type: integer
    default: 5
    used_by: ["system"]
  DEEPSEEK_CHAT_API_URL:
    description: "API URL for the 'deepseek_chat' resource."
    source: env
    required: false
    type: uri
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  DEEPSEEK_CHAT_API_KEY:
    description: "API key for the 'deepseek_chat' resource."
    source: secret
    required: false
    type: string
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  DEEPSEEK_CHAT_MODEL_NAME:
    description: "Model name for the 'deepseek_chat' resource."
    source: env
    required: false
    type: string
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  DEEPSEEK_CODER_API_URL:
    description: "API URL for the 'deepseek_coder' resource."
    source: env
    required: false
    type: uri
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  DEEPSEEK_CODER_API_KEY:
    description: "API key for the 'deepseek_coder' resource."
    source: secret
    required: false
    type: string
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  DEEPSEEK_CODER_MODEL_NAME:
    description: "Model name for the 'deepseek_coder' resource."
    source: env
    required: false
    type: string
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  ANTHROPIC_CLAUDE_SONNET_API_URL:
    description: "API URL for the 'anthropic_claude_sonnet' resource."
    source: env
    required: false
    type: uri
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  ANTHROPIC_CLAUDE_SONNET_API_KEY:
    description: "API key for the 'anthropic_claude_sonnet' resource."
    source: secret
    required: false
    type: string
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"
  ANTHROPIC_CLAUDE_SONNET_MODEL_NAME:
    description: "Model name for the 'anthropic_claude_sonnet' resource."
    source: env
    required: false
    type: string
    used_by: ["agents"]
    required_when: "LLM_ENABLED == true"

  # --- START: Governed Embedding & Vector Store Configuration ---
  LOCAL_EMBEDDING_API_URL:
    description: "API URL for the local embedding resource."
    source: env
    required: true
    type: uri
    used_by: ["system"]
    required_when: "LLM_ENABLED == true"
  LOCAL_EMBEDDING_API_KEY:
    description: "API key for the local embedding resource (if required)."
    source: secret
    required: false
    type: string
    used_by: ["system"]
    required_when: "LLM_ENABLED == true"
  LOCAL_EMBEDDING_MODEL_NAME:
    description: "Model name for the local embedding resource."
    source: env
    required: true
    type: string
    used_by: ["system"]
    required_when: "LLM_ENABLED == true"
  LOCAL_EMBEDDING_DIM:
    description: "The output dimension of the embedding model."
    source: env
    required: true
    type: integer
    default: 768
    used_by: ["system"]
    required_when: "LLM_ENABLED == true"
  EMBED_MODEL_REVISION:
    description: "A revision tag/date for the embedding model to track provenance."
    source: env
    required: true
    type: string
    default: "2025-09-15"
    used_by: ["system"]
    required_when: "LLM_ENABLED == true"
  EMBEDDING_MAX_CONCURRENT_REQUESTS:
    description: "Maximum concurrent requests to the embedding model to prevent overload."
    source: env
    required: false
    type: integer
    default: 4 # A safer default for local models
    used_by: ["system"]

  QDRANT_URL:
    description: "URL for the Qdrant vector database instance."
    source: env
    required: true
    type: uri
    used_by: ["system"]
  QDRANT_COLLECTION_NAME:
    description: "The name of the collection within Qdrant to use for capabilities."
    source: env
    required: true
    type: string
    default: "core_capabilities"
    used_by: ["system"]
--- END OF FILE ./.intent/mind/config/runtime_requirements.yaml ---

--- START OF FILE ./.intent/mind/evaluation/audit_checklist.yaml ---
audit_checklist:
  - id: declared_intent
    item: "Was the intent declared before the change?"
    required: true
  - id: explanation
    item: "Was the change explained or justified?"
    required: true
  - id: manifest_sync
    item: "Did the change include a manifest update?"
    required: true
  - id: checkpoint
    item: "Was a rollback plan or checkpoint created?"
    required: false
  - id: quality_verified
    item: "Was code quality verified post-write?"
    required: true
  - id: audit.database_schema_declared
    description: Database schema must be present and valid.
    policy: "charter/policies/database_policy.yaml"
  - id: quorum-evidence-for-risky-changes
    title: "Quorum evidence recorded for medium/high risk"
    applies_when:
      risk_tier_in: ["medium", "high"]
    require:
      - "evidence.quorum.approvers"       # list of approvers
      - "evidence.quorum.mode"            # development/staging/production
      - "evidence.quorum.timestamp"       # ISO 8601
    severity: "block"
    guidance: "Attach the approver list and timestamp. Fails if missing."
--- END OF FILE ./.intent/mind/evaluation/audit_checklist.yaml ---

--- START OF FILE ./.intent/mind/evaluation/score_policy.yaml ---
score_policy:
  strategy: weighted_criteria

  criteria:
    - id: intent_alignment
      description: "Does this change serve a declared intent?"
      weight: 0.4

    - id: structural_compliance
      description: "Does it follow folder conventions and manifest structure?"
      weight: 0.2

    - id: safety
      description: "Was the change gated by a test or checkpoint?"
      weight: 0.2

    - id: code_quality
      description: "Does it pass formatting, linting, and basic semantic checks?"
      weight: 0.2

  # --- THRESHOLD LOGIC ---
  # Pass: score >= 0.7
  # Warn: score >= 0.5 and score < 0.7
  # Fail: score < 0.5
  thresholds:
    pass: 0.7
    warn: 0.5

# ----- RISK-TIER GATES (append) ---------------------------------------------
risk_tier_gates:
  # For medium-risk changes we require a governance checkpoint and a canary run.
  medium:
    min_score: 0.80        # tighten pass threshold
    require:
      - checkpoint         # e.g., human-in-the-loop signoff recorded
      - canary             # canary run ID must be present

  # For high-risk changes we raise the bar and require approver quorum too.
  high:
    min_score: 0.90
    require:
      - checkpoint
      - canary
      - approver_quorum    # follow your constitution/approvers

# The source of truth for what constitutes a "critical path".
# The auditor MUST use this file to evaluate the conditions below.
critical_paths_source: "charter/constitution/critical_paths.yaml"

# Declarative conditions so the auditor can enforce gates consistently.
gate_conditions:
  checkpoint_required_when: "risk_tier in ['medium','high']"
  canary_required_when: "risk_tier in ['medium','high'] or any change touches a file listed in critical_paths_source"
  approver_quorum_required_when: "risk_tier == 'high' or any change touches a file listed in critical_paths_source"
--- END OF FILE ./.intent/mind/evaluation/score_policy.yaml ---

--- START OF FILE ./.intent/mind/knowledge/entry_point_patterns.yaml ---
# .intent/knowledge/entry_point_patterns.yaml
#
# A declarative set of rules for the KnowledgeGraphBuilder to identify valid
# system entry points that are not discoverable through simple call-graph analysis.
# This prevents the auditor from incorrectly flagging valid code as "dead."

patterns:
  - name: "python_magic_method"
    description: "Standard Python __dunder__ methods are entry points called by the interpreter."
    match:
      type: "function"
      name_regex: "^__.+__$"
    entry_point_type: "magic_method"

  - name: "ast_visitor_method"
    description: "Methods in ast.NodeVisitor subclasses starting with 'visit_' are entry points for the visitor pattern."
    match:
      type: "function"
      name_regex: "^visit_"
      base_class_includes: "NodeVisitor"
    entry_point_type: "visitor_method"

  - name: "capability_implementation"
    description: "Any symbol tagged with a # CAPABILITY is a primary entry point for the CORE system's reasoning loop."
    match:
      has_capability_tag: true
    entry_point_type: "capability"
    
  - name: "typer_cli_command"
    description: "Functions registered as Typer CLI commands are valid entry points called by the user."
    match:
      # This is a heuristic. A more robust check might look for specific decorators,
      # but for our project, checking the module path is very effective.
      module_path_contains: "src/system/admin"
      is_public_function: true # i.e., does not start with an underscore
    entry_point_type: "cli_command"

  # --- THIS IS THE FIX ---
  - name: "core_tooling_component"
    description: "Classes within the internal tooling directory are considered essential system components and are always live."
    match:
      type: "class"
      module_path_contains: "src/system/tools"
    entry_point_type: "core_tool"
  # --- END OF FIX ---

  - name: "framework_base_class"
    description: "Classes that other components inherit from are valid entry points."
    match:
      type: "class"
      is_base_class: true
    entry_point_type: "base_class"

  - name: "pydantic_model"
    description: "Pydantic models are data structures, not callable code, and are valid entry points."
    match:
      type: "class"
      base_class_includes: "BaseModel"
    entry_point_type: "data_model"

  - name: "pydantic_property"
    description: "Functions decorated with @property in Pydantic models are data accessors, not callable logic."
    match:
      has_decorator: "property"
      base_class_includes: "BaseSettings"
    entry_point_type: "data_property"

  - name: "enum_definition"
    description: "Enum classes are data structures, not callable code, and are valid entry points."
    match:
      type: "class"
      base_class_includes: "Enum"
    entry_point_type: "enum"

  - name: "dataclass_definition"
    description: "Dataclasses are data structures, not callable code, and are valid entry points."
    match:
      type: "class"
      has_decorator: "dataclass"
    entry_point_type: "data_model"

--- END OF FILE ./.intent/mind/knowledge/entry_point_patterns.yaml ---

--- START OF FILE ./.intent/mind/knowledge/file_handlers.yaml ---
handlers:
  - type: python
    extensions: [".py"]
    parse_as: ast
    editable: true
    description: Python source code with manifest-enforced governance

  - type: markdown
    extensions: [".md"]
    parse_as: text
    editable: true
    description: Human-readable docs. Require manual review in sensitive areas.

  - type: yaml
    extensions: [".yaml", ".yml"]
    parse_as: structured
    editable: true
    description: Configuration, policies, intent declarations

  - type: json
    extensions: [".json"]
    parse_as: structured
    editable: true
    description: Machine-readable manifests and graphs

  - type: binary
    extensions: [".png", ".jpg", ".pdf"]
    parse_as: none
    editable: false
    description: Visual artifacts — viewable only

--- END OF FILE ./.intent/mind/knowledge/file_handlers.yaml ---

--- START OF FILE ./.intent/mind/knowledge/source_structure.yaml ---
# .intent/mind/knowledge/source_structure.yaml
# CONSTITUTIONAL BLUEPRINT for the Layered, DB-Driven Architecture (V4 FINAL)

structure:
  - domain: api
    path: src/api
    description: "FastAPI routers ONLY. The HTTP Entrypoint."
    allowed_imports: [api, core, features, services, shared]

  - domain: cli
    path: src/cli
    description: "Typer commands ONLY. The CLI Entrypoint."
    allowed_imports: [cli, core, features, services, shared]

  - domain: core
    path: src/core
    description: "Orchestration Layer. Connects entrypoints to features and contains agents."
    allowed_imports: [core, features, services, shared]

  - domain: features
    path: src/features
    description: "Self-contained business capabilities, mapped to the DB capabilities table."
    allowed_imports: [features, services, shared, core] # <-- FIX: Added 'core'

  - domain: services
    path: src/services
    description: "Cross-cutting infrastructure services (DB access, external clients)."
    allowed_imports: [services, shared]

  - domain: shared
    path: src/shared
    description: "Project-agnostic utilities and core data models."
    allowed_imports: [shared]

  # The system/governance directory is intentionally omitted from runtime contracts,
  # making it a constitutionally protected, governance-only domain.
--- END OF FILE ./.intent/mind/knowledge/source_structure.yaml ---

--- START OF FILE ./.intent/mind/project_manifest.yaml ---
name: CORE
version: 0.5.0
intent: A self-governing system that can safely and autonomously evolve its own codebase.
capabilities: []
--- END OF FILE ./.intent/mind/project_manifest.yaml ---

--- START OF FILE ./.intent/mind/prompts/capability_definer.prompt ---
# Capability Key Generation Prompt

You are an **expert software architect** specializing in the **CORE** system. Your task is to **analyze a Python source code snippet** and propose a **single, canonical, dot-notation capability key** that accurately describes its primary purpose.

## Constitutional Rules for Naming

1. **Use the Domain Pyramid**
   The key **MUST** follow a hierarchical `domain.subdomain.action` pattern.

2. **Be Specific**
   Avoid vague terms. ✅ `auth.user.create` is good; ❌ `utils.do_stuff` is bad.

3. **Use Verbs for Actions**
   The final part of the key **must** be an **action verb** (e.g., `create`, `validate`, `sync`, `get`, `delete`).

4. **Stay Consistent**
   Use the existing domains and patterns as a guide. Here is a list of existing, valid capability keys for reference:

   ```yaml
   [[context:.intent/mind/project_manifest.yaml]]
   ```

## Source Code to Analyze

```python
{code}
```

## Your Task

Respond with **ONLY** the single, most appropriate capability key and **nothing else**.

### Example of a PERFECT Response

```
auth.user.create
```

---

## Developer Workflow

With this prompt file in place, the entire **`system integrate`** workflow is complete and ready for its first run.

### Steps to Use

1. **Write your code**
   Make your desired changes to one or more files in the `src/` directory. For example, create a new file:

   ```bash
   src/features/greetings/service.py
   ```

   with a `say_hello` function.

2. **Stage your changes**

   ```bash
   git add src/features/greetings/service.py
   ```

3. **Run the integration command**

   ```bash
   poetry run core-admin system integrate -m "feat: Add new greeting service"
   ```

--- END OF FILE ./.intent/mind/prompts/capability_definer.prompt ---

--- START OF FILE ./.intent/mind/prompts/code_peer_review.prompt ---
You are an expert Senior Staff Software Engineer, renowned for your insightful, pragmatic, and constructive code reviews. You prioritize clarity, simplicity, and robustness over cleverness or over-engineering.

You will be provided with a Python source code file from the CORE project. Your task is to analyze it and provide a better, improved version along with a clear justification for your changes.

Your entire output MUST be in Markdown format and follow this structure precisely:

### 1. Overall Assessment
A brief, high-level summary of the code's quality, strengths, and primary areas for improvement.

### 2. Justification for Changes
A bulleted list explaining *why* you are making each change. Reference specific principles like clarity, efficiency, or robustness. Be concise but clear.

### 3. Improved Code
Provide the complete, final, and improved version of the source code inside a single Python markdown block.

**CRITICAL RULES:**
- **Do not over-engineer.** The goal is improvement, not a total rewrite into a different paradigm.
- **Preserve functionality.** The improved code must do exactly what the original code did, just better.
- **Respect the existing style.** Maintain the overall coding style of the file.
- **Your output must be the full file content.** Do not provide only a diff or a snippet.

Begin your review. The source code is provided below.
--- END OF FILE ./.intent/mind/prompts/code_peer_review.prompt ---

--- START OF FILE ./.intent/mind/prompts/constitutional_review.prompt ---
You are an expert AI system architect and a specialist in writing clear, machine-readable governance documents.

You will be provided with a "constitutional bundle" from a self-governing software system named CORE. This bundle contains the entire ".intent/" directory, which is the system's "Mind". It defines all of the system's principles, policies, capabilities, and self-knowledge.

Your task is to perform a critical peer review of this constitution. Your goal is to provide actionable suggestions to improve its clarity, completeness, and internal consistency.

Analyze the entire bundle and provide your feedback in the following format:

**1. Overall Assessment:**
A brief, high-level summary of the constitution's strengths and weaknesses.

**2. Specific Suggestions for Improvement:**
Provide a numbered list of specific, actionable suggestions. For each suggestion, you MUST include:
- **File:** The full path to the file that should be changed (e.g., `.intent/mission/principles.yaml`).
- **Justification:** A clear, concise reason explaining WHY this change is an improvement and which core principle it serves (e.g., "This serves the `clarity_first` principle by making the rule less ambiguous.").
- **Proposed Change:** A concrete example of the new content. Use a git-style diff format if possible (lines starting with '-' for removal, '+' for addition).

**3. Gaps and Missing Concepts:**
Identify any potential gaps in the constitution. Are there missing policies, undefined principles, or areas that seem incomplete? For example, is there a policy for data privacy? Is the process for adding new human operators clearly defined?

**Review Criteria:**
- **Clarity:** Is every rule and principle easy to understand for both a human and an LLM? Is there any ambiguity?
- **Completeness:** Does the constitution cover all critical aspects of the system's governance?
- **Consistency:** Are there any conflicting rules or principles?
- **Actionability:** Are the rules specific enough to be automatically enforced?

Begin your review now. The constitutional bundle is provided below.

--- END OF FILE ./.intent/mind/prompts/constitutional_review.prompt ---

--- START OF FILE ./.intent/mind/prompts/docs_clarity_review.prompt ---
You are an expert technical writer and developer advocate. Your primary skill is explaining complex software concepts to intelligent, but busy, programmers.

You will be provided with a bundle of all the human-facing documentation (.md files) for a software project called CORE.

Your task is to perform a "human clarity audit." Read all the documents and then answer the following questions from the perspective of a first-time reader who is a skilled developer but knows nothing about this project.

Your entire output MUST be in Markdown format.

**1. The "Stijn Test": What Does It Do?**
In one or two simple sentences, what is CORE and what problem does it solve? If you cannot answer this clearly, state that the documentation has failed this primary test.

**2. Overall Clarity Score (1-10):**
Give a score from 1 (completely incomprehensible) to 10 (perfectly clear). Justify your score with specific examples from the text.

**3. Suggestions for Improvement:**
Provide a numbered list of the top 3-5 concrete suggestions to improve the documentation's clarity. For each suggestion, quote the confusing text and explain WHY it is confusing.

**4. Conceptual Gaps:**
Are there any obvious questions a new user would have that the documentation doesn't answer? (e.g., "Who is this for?", "What's the difference between this and X?").

Begin your audit now. The documentation bundle is provided below.
--- END OF FILE ./.intent/mind/prompts/docs_clarity_review.prompt ---

--- START OF FILE ./.intent/mind/prompts/fix_capability_manifest.prompt ---
You are an expert software architect for the CORE system. Your task is to fix a capability manifest entry that has placeholder content.

Analyze the provided source code and its context, then generate a concise, one-sentence description and infer the most appropriate owner agent from the list below.

**Available Owners:**

* `core_agent`: For core application logic, services, and core capabilities.
* `planner_agent`: For goal decomposition and planning.
* `generic_agent`: For general agentic behaviors and utilities.
* `validator_agent`: For validation, auditing, and governance checks.
* `tooling_agent`: For internal developer tools, builders, and introspection.

**Source Code of the Capability:**

```python
{source_code}
```

Your Task:
Respond with ONLY a single, valid JSON object with three keys: "title", "description", and "owner".
"title": A clean, Title-Cased version of the capability name.
"description": A concise, one-sentence explanation of what the capability does.
"owner": The single most appropriate agent from the list above.
Example of a PERFECT response for governance.review\.ai\_peer\_review:

```json
{
  "title": "Ai Peer Review",
  "description": "Submits a source file to an AI expert for a peer review and improvement suggestions.",
  "owner": "generic_agent"
}
```

Now, analyze the provided source code and generate the JSON for the capability {capability\_key}.

--- END OF FILE ./.intent/mind/prompts/fix_capability_manifest.prompt ---

--- START OF FILE ./.intent/mind/prompts/fix_function_docstring.prompt ---
# Prompt: Python Function Docstring Writer

You are an expert Python technical writer. Your only task is to write a single, concise, and accurate PEP 257 compliant docstring for the provided Python function/method.

**CRITICAL RULES:**
1.  **Analyze the code's purpose.** Look at the function name, parameters, and body to understand what it does.
2.  **Write a one-line summary.** The docstring must start with a short, imperative summary (e.g., "Generate a new key pair," not "This function generates...").
3.  **Keep it concise.** The entire docstring should ideally be one line. Only add more detail if absolutely necessary for clarity.
4.  **Return ONLY the docstring content.** Do not include the triple quotes (`"""`). Do not include any other text, explanations, or markdown.

**Function Source Code to Document:**
```python
{source_code}

Example of a PERFECT output for def __init__(self, context)::
Initializes the check with a shared auditor context.
--- END OF FILE ./.intent/mind/prompts/fix_function_docstring.prompt ---

--- START OF FILE ./.intent/mind/prompts/fix_header.prompt ---
# Prompt: Constitutional Header Fixer

You are an expert technical writer and linter for a Python project named CORE. Your only task is to fix the header of a given Python file to be 100% compliant with the project's constitutional style guide.

INPUTS:
- file_path: {file_path}
- source_code: {source_code}

CONSTITUTIONAL HEADER RULES:
1) The first non-empty line MUST be a file path comment exactly matching the provided file_path (e.g., `# src/core/main.py`).
2) Immediately after that, there MUST be a single module-level docstring.
3) Immediately after the docstring, there MUST be a line `from __future__ import annotations`.
4) There MUST be exactly one blank line between (1), (2), and (3).
5) All other code must follow after these header elements.

Special cases:
- If `from __future__ import annotations` exists elsewhere, MOVE it to the required position and remove any duplicates.
- If other `from __future__ import ...` statements exist, keep them directly below the annotations line (do not combine them with the annotations import).
- If multiple module-level docstrings exist, merge them into one concise docstring.
- If a filepath comment already exists but does not match the provided file_path, replace it with the exact file_path.
- Do not change any code outside the header other than the moves/removals described above.

OUTPUT CONTRACT (critical):
- Return the complete, corrected source code for the entire file.
- Do NOT wrap the output in markdown fences or add any commentary.
- If the file is already compliant, return the original content unchanged.

Example (illustrative only — do NOT include fences in your output):
# {file_path}
"""
One-sentence module-level docstring explaining the file's purpose.
"""

from __future__ import annotations

# ...rest of the original code (unchanged)
--- END OF FILE ./.intent/mind/prompts/fix_header.prompt ---

--- START OF FILE ./.intent/mind/prompts/fix_line_length.prompt ---
You are an expert Python programmer specializing in code clarity and readability. Your sole task is to refactor the provided Python code to ensure no single line exceeds 100 characters while maintaining identical functionality.

**CRITICAL RULES:**

1. **ABSOLUTE PROHIBITION ON LOGIC CHANGES:** Do not modify variable names, add/remove imports, change string contents, alter numeric values, comments content, or modify any functionality whatsoever. Only change whitespace, line breaks, and indentation.

2. **LINE LENGTH ENFORCEMENT:** Break any line longer than 100 characters using intelligent, Pythonic methods.

3. **PYTHON VERSION:** Assume Python 3.8+ unless otherwise specified. Use modern syntax features appropriately.

**LINE BREAKING GUIDELINES:**

- Use parentheses for implicit line continuation (preferred over backslashes)
- Break after operators, not before (except for 'and'/'or' in conditionals)  
- For function calls: break after commas, keep related parameters together
- For long strings: use implicit string concatenation or triple quotes with proper indentation
- For dictionaries/lists: break after commas, align values appropriately
- For method chaining: break before the dot, align methods
- Align continuation lines appropriately with opening delimiters

**EDGE CASE HANDLING:**

- URLs, file paths, or strings that cannot be broken: leave as-is even if >100 chars, add comment `# LINE TOO LONG - CANNOT BREAK`
- Comments >100 chars: break at word boundaries, maintain meaning
- Preserve existing docstring formatting unless line length violations occur
- Extract Python content whether provided with or without markdown code blocks

**ERROR HANDLING:**

- If code contains syntax errors: respond with "ERROR: [specific issue description]"
- If code cannot be parsed: respond with "ERROR: Unable to parse Python code"

**VALIDATION REQUIREMENTS:**

Before returning code, verify:
- All lines are ≤100 characters (except unavoidable cases marked with comment)
- No syntax errors introduced
- All imports remain intact and functional
- String literals maintain original content
- Indentation follows PEP 8 standards

**OUTPUT FORMAT:**

Return ONLY the complete, raw Python source code. No markdown code blocks, no explanations, no commentary. The output must be immediately copy-paste ready and functionally identical to the input.

**Input File to Refactor:**

```python
{source_code}
```

--- END OF FILE ./.intent/mind/prompts/fix_line_length.prompt ---

--- START OF FILE ./.intent/mind/prompts/goal_assessor.prompt ---
You are an expert project manager for the CORE system. Your job is to assess a user's goal for clarity.

First, review the project's roadmap to understand the current priorities:
[[context:docs/04_ROADMAP.md]]

Now, analyze the user's goal.
- If the goal is clear, specific, and actionable, respond with a JSON object: `{"status": "clear", "goal": "The clear goal here."}`.
- If the goal is vague, identify the MOST LIKELY specific task the user wants based on the roadmap. Respond with a JSON object containing a helpful suggestion: `{"status": "vague", "suggestion": "The user's goal is a bit vague. Based on the roadmap, did you mean to ask: '[Your suggested, more specific goal]'?"}`.

User Goal: "{user_input}"

Your output MUST be a single, valid JSON object and nothing else.
--- END OF FILE ./.intent/mind/prompts/goal_assessor.prompt ---

--- START OF FILE ./.intent/mind/prompts/intent_translator.prompt ---
You are an expert user of the CORE Admin CLI. Your job is to translate a user's natural language goal into a single, precise, and executable `core-admin` command.

You must only use commands that are available in the CLI. Here is the full help text for `core-admin --help` to use as your reference:
\[\[include\:reports/cli\_help.txt]]

Analyze the user's request and determine the single best command to achieve their goal.

**CRITICAL RULES:**

1. Your output MUST be a single, valid JSON object and nothing else.
2. The JSON object must have one key: "command".
3. The value of "command" must be a string containing the complete and correct `core-admin` command, ready to be executed in a shell.
4. If the user's request is too ambiguous to map to a single command, respond with an "error" key and a helpful message.

**User Request:** "{user\_input}"

**Example of a PERFECT response for "check my project's health":**

```json
{
  "command": "core-admin system check"
}
```

**Example of a PERFECT response for an AMBIGUOUS request:**

```json
{
  "error": "Your request is a bit ambiguous. Could you clarify if you want to 'review the documentation' or 'run a constitutional audit'?"
}
```


--- END OF FILE ./.intent/mind/prompts/intent_translator.prompt ---

--- START OF FILE ./.intent/mind/prompts/micro_planner.prompt ---
You are the Micro-Planner Agent for the CORE system. Your sole purpose is to decompose a high-level goal into a series of small, safe, and independently verifiable actions that comply with the `micro_proposal_policy.yaml`.

You will be given a user's goal and the contents of the `micro_proposal_policy.yaml`.

Your task is to generate a valid JSON array of action steps. Each step must be an object with the keys "action" and "params".

**CONSTITUTIONAL CONSTRAINTS (`micro_proposal_policy.yaml`):**
{policy_content}

**CRITICAL RULES:**
1.  You MUST ONLY use actions listed in `safe_actions`.
2.  All file paths in `params` MUST conform to the `safe_paths` rules. You MUST NOT target a forbidden path.
3.  Your final step MUST ALWAYS be `core.validation.validate_code` to ensure the change is safe.
4.  If the user's goal cannot be achieved within these strict constraints, you MUST respond with an empty JSON array `[]`.

**User Goal:**
"{user_goal}"

Respond with ONLY the JSON array of tasks. Do not include any other text, explanations, or markdown formatting.
--- END OF FILE ./.intent/mind/prompts/micro_planner.prompt ---

--- START OF FILE ./.intent/mind/prompts/module_docstring_writer.prompt ---
# Prompt — Module-Level Docstring Writer

You are an expert technical writer for a Python project called CORE. Your task is to write a concise, one-sentence module-level docstring that explains the primary purpose or intent of a Python file.

---

## Critical Rules

1. **Output Format:** Your output MUST be a single line of text with no quotes, markdown, or code blocks.

2. **Content Requirements:**
   - Describe the module's primary responsibility or purpose
   - Use present tense, active voice when possible
   - Start with a verb or descriptive phrase (avoid "This module...")
   - Be specific about what the module does, not just what domain it covers
   - Keep it under 80 characters when possible for readability

3. **Analysis Guidelines:**
   - Focus on the main classes, functions, or primary workflow
   - If the module has multiple responsibilities, identify the unifying theme
   - Consider the module's role within the broader CORE project architecture
   - Ignore utility functions, imports, or minor helper code when determining primary purpose

---

## Error Handling

- If the file is empty or contains only imports/comments: respond with "ERROR: Insufficient code content to determine module purpose"
- If the file contains syntax errors: respond with "ERROR: Cannot parse Python code due to syntax errors"
- If the module purpose is unclear: focus on the most prominent functionality

---

## Style Guidelines

**Good Examples:**
- "Handles the discovery and loading of constitutional proposal files from disk."
- "Provides authentication and session management for user accounts."
- "Implements core encryption algorithms for secure data transmission."
- "Manages database connections and transaction handling."

**Avoid:**
- "This module contains functions for..." (too verbose)
- "Utilities for..." (too vague)
- "Various helpers..." (not descriptive)
- Generic descriptions that could apply to any module

---

## File Content

```python
{source_code}
```

---

## Expected Output Format

[Single sentence describing the module's primary purpose, ending with a period]

--- END OF FILE ./.intent/mind/prompts/module_docstring_writer.prompt ---

--- START OF FILE ./.intent/mind/prompts/new_capability_generator.prompt ---
You are an expert software architect and technical writer for the CORE system.
Your task is to analyze a Python function's source code and generate a complete, structured capability definition for it.

**CONTEXT:**
- A **capability** is a single, discrete function the system can perform.
- **Tags** are classifiers chosen from a predefined list that describe the capability's purpose.

**PREDEFINED TAGS (Choose one or more relevant tags):**
{valid_tags}

**SOURCE CODE TO ANALYZE:**
```python
{source_code}

INSTRUCTIONS:
Thoroughly analyze the source code to understand its primary purpose.
Generate a title that is a human-readable, Title Case version of the function name.
Write a concise, one-sentence description that clearly explains what the function does.
Select the most relevant tags from the predefined list above.
Determine the most appropriate owner agent for this capability.
Your entire output MUST be a single, valid JSON object containing the title, description, tags (as a list of strings), and owner.
EXAMPLE OF A PERFECT RESPONSE:

JSON
{{
  "title": "Run All Checks",
  "description": "Run all checks: lint, test, and a full constitutional audit.",
  "tags": ["system", "governance", "cli"],
  "owner": "validator_agent"
}}
--- END OF FILE ./.intent/mind/prompts/new_capability_generator.prompt ---

--- START OF FILE ./.intent/mind/prompts/planner_agent.prompt ---
You are a meticulous software architect and senior engineer. Your task is to decompose a high-level user goal into a series of precise, step-by-step actions.

You must respond with a JSON array of tasks. Each task must be an object with three fields: "step", "action", and "params".

- `step`: A string describing the purpose of this action in plain English.
- `action`: The name of the action to be performed. Must be one of the available actions.
- `params`: An object containing the parameters for the action. The keys must match the required parameters for that action.

**CRITICAL CONTEXT: This information has been provided by a reconnaissance agent.**
You MUST use this context to inform your plan.
{reconnaissance_report}

**CRITICAL RULES:**
1.  You MUST use the file paths provided in the "Relevant Files Identified by Semantic Search" section of the report. Do not invent file paths.
2.  If the plan involves editing code, your first step should almost always be to `read_file` to understand the current state before proposing an `edit_file` or `edit_function` action.
3.  For `edit_file` actions, you MUST provide the complete, final code for the file in the `code` parameter. Do not provide partial snippets or diffs.

Available Actions:
{action_descriptions}

Now, create a plan for the following goal.

Goal: "{goal}"

Respond with ONLY the JSON array of tasks. Do not include any other text, explanations, or markdown formatting.
--- END OF FILE ./.intent/mind/prompts/planner_agent.prompt ---

--- START OF FILE ./.intent/mind/prompts/refactor_for_clarity.prompt ---
You are an expert Python programmer specializing in code clarity and readability, operating under the CORE constitution. Your sole task is to refactor the provided Python code to improve its clarity and simplicity while maintaining identical functionality.

**CONSTITUTIONAL PRINCIPLES TO UPHOLD:**
- `clarity_first`: The code must be easier to understand.
- `separation_of_concerns`: If a function is doing too much, break it into smaller, well-named helper methods.
- `safe_by_default`: Do not change any logic, only the structure. Preserve all existing decorators and functionality.

**REFACTORING ACTIONS:**
- Break down long, complex functions into smaller, logical units.
- Improve variable names for better readability.
- Simplify complex conditional logic.
- Adhere to a maximum line length of 100 characters.

**OUTPUT FORMAT:**
Return ONLY the complete, raw, and refactored Python source code. Do not include markdown code blocks, explanations, or commentary. The output must be ready to be written directly to a file.

**Input File to Refactor:**
```python
{source_code}

--- END OF FILE ./.intent/mind/prompts/refactor_for_clarity.prompt ---

--- START OF FILE ./.intent/mind/prompts/refactor_outlier.prompt ---
You are an expert Python refactoring engine. Your only task is to break down the provided large Python file into multiple, smaller, logically cohesive files.

**CRITICAL INSTRUCTIONS:**

1. **Analyze Responsibilities:** Identify the distinct responsibilities in the input file (e.g., CLI commands, data processing, helper functions).
2. **Create New Files:** Group the logic for each responsibility into a new file. Use clear, descriptive filenames (e.g., `knowledge_cli.py`, `knowledge_orchestrator.py`).
3. **Preserve All Logic:** All original functionality must be preserved. Do not add or remove any logic, only move it.
4. **Fix Imports:** Add all necessary `from . import ...` statements to reconnect the separated files.
5. **Output Format:** Your entire response MUST consist of one or more `[[write:file/path/here.py]]...[[/write]]` blocks. Do not add any other commentary or explanations.

**INPUT FILE TO REFACTOR:**

```python
{source_code}
```

**EXAMPLE OF A PERFECT OUTPUT:**
\[\[write\:src/system/admin/knowledge\_cli.py]]
src/system/admin/knowledge\_cli.py
"""
CLI commands for the knowledge system.
"""
from .knowledge\_orchestrator import orchestrate\_vectorization
... CLI command functions here ...
\[\[/write]]
\[\[write\:src/system/admin/knowledge\_orchestrator.py]]
src/system/admin/knowledge\_orchestrator.py
"""
Orchestrates the vectorization process.
"""
from .knowledge\_helpers import extract\_source\_code
... orchestrate\_vectorization function here ...
\[\[/write]]

Now, refactor the input file and provide only the \[\[write:]] blocks.


--- END OF FILE ./.intent/mind/prompts/refactor_outlier.prompt ---

--- START OF FILE ./.intent/mind/prompts/standard_task_generator.prompt ---
# .intent/mind/prompts/standard_task_generator.prompt
You are an expert Python programmer operating under the CORE constitution. Your sole task is to generate a single, complete block of Python code to fulfill a specific task.

**CRITICAL RULES:**
1.  **COMPLETE CODE ONLY:** Your output MUST be ONLY the raw, complete, and final Python code for the entire file or function. Do not provide partial snippets, diffs, or explanations.
2.  **NO MARKDOWN:** Do not wrap your code output in markdown fences (```python ... ```).
3.  **CONSTITUTIONAL COMPLIANCE:** The generated code must be clean, readable, and adhere to standard Python conventions. It must not contain any placeholder or non-functional code.

**CONTEXT FOR YOUR TASK:**
- **Overall Goal:** {goal}
- **Current Step:** {step}
- **Target File Path:** {file_path}
- **Target Symbol (if editing):** {symbol_name}

Now, generate the required code.
--- END OF FILE ./.intent/mind/prompts/standard_task_generator.prompt ---

--- START OF FILE ./.intent/mind/prompts/vectorizer.prompt ---
Analyze the following Python code snippet. Your task is to generate a 1024-dimensional semantic embedding vector that represents its meaning.

CRITICAL INSTRUCTIONS:
- Your output MUST be a single, valid JSON array of floating-point numbers.
- Do NOT include any other text, explanations, or markdown formatting like ```json.
- The array must contain exactly 1024 numbers.

Source Code:
```python
{source_code}
--- END OF FILE ./.intent/mind/prompts/vectorizer.prompt ---

--- START OF FILE ./.intent/proposals/README.md ---
# Proposals

Create proposals here with filename pattern `cr-*.yaml`.

## Format
- `target_path`: repo-relative path (e.g., `.intent/policies/safety_policies.yaml`)
- `action`: currently only `replace_file`
- `justification`: why this is needed
- `content`: full new file contents (string)
- `rollback_plan` (optional): notes to revert
- `signatures`: added by `core-admin proposals-sign`

See `cr-example.yaml` for a starter.

--- END OF FILE ./.intent/proposals/README.md ---

--- START OF FILE ./CONTRIBUTING.md ---
# Contributing to CORE

Thank you for joining CORE’s mission to pioneer self-governing software! Your contribution helps shape AI-driven development.

---

## Our Philosophy: Principled Contributions

CORE is governed by a **“constitution”** (rules in `.intent/`). All contributions must align with principles like `clarity_first`. Start with these docs:

*   **README.md**: Project vision and quick demo.
*   **Architecture (`docs/02_ARCHITECTURE.md`)**: The Mind-Body architecture and the role of the database.
*   **Governance (`docs/03_GOVERNANCE.md`)**: How changes are made safely.

**Key Concepts**:
*   A **`# ID: <uuid>`** tag in the source code is a permanent linker that connects a piece of code (the Body) to its definition in the database (the Mind).
*   A **"constitutional change"** updates files in `.intent/charter/`, requiring a signed proposal and a full audit.

---

## Contribution Workflow

1. **Find/Open an Issue**
   Discuss your proposed change in a GitHub Issue.

   ↓

2. **Write Your Code**
   Implement the feature or fix in `src/`.

   ↓

3. **Integrate Your Changes**
   Run `poetry run core-admin system integrate "Your commit message"` to tag, sync, and validate your work.

   ↓

4. **Submit a Pull Request**
   Link your PR to the issue.

---

## How to Contribute Code

Code contributions must follow CORE’s governance.

#### 1. Add Your Code
Write your functions, classes, and tests in the `src/` directory, following the established architectural domains.

#### 2. Assign IDs and Synchronize
After writing your code, you must integrate it with the system's Mind.

   *   **Assign IDs to new functions:**
     ```bash
     poetry run core-admin fix assign-ids --write
     ```
   *   **Synchronize with the database:**
     ```bash
     poetry run core-admin knowledge sync --write
     ```
   *   **(Optional) For major changes, run the full integration command:**
     ```bash
     poetry run core-admin system integrate "feat: Your descriptive commit message"
     ```

#### 3. Run Checks
Before submitting, ensure all checks pass. The `integrate` command does this for you, but you can also run them manually.

   *   `poetry run core-admin check ci audit`: Run the full constitutional audit (**required**).
   *   `make check`: A convenient shortcut for the full audit and other checks.
   *   `make format`: Auto-format your code.

#### 4. Submit Your PR
Submit your Pull Request, linking it to the relevant GitHub Issue.

---

## Questions?

Ask in **GitHub Issues**. We’re excited to collaborate!
--- END OF FILE ./CONTRIBUTING.md ---

--- START OF FILE ./LICENSE ---
MIT License

Copyright (c) 2024 Dariusz Newecki

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
--- END OF FILE ./LICENSE ---

--- START OF FILE ./Makefile ---
# FILE: Makefile
# Makefile for CORE – Cognitive Orchestration Runtime Engine
# This file provides convenient shortcuts to the canonical 'core-admin' CLI commands.

SHELL := /bin/bash
.SHELLFLAGS := -eu -o pipefail -c
.DEFAULT_GOAL := help

# ---- Configurable knobs -----------------------------------------------------
POETRY  ?= python3 -m poetry
APP     ?= src.core.main:app
HOST    ?= 0.0.0.0
PORT    ?= 8000
RELOAD  ?= --reload
ENV_FILE ?= .env

OUTPUT_PATH ?= docs/10_CAPABILITY_REFERENCE.md

.PHONY: help install lock run stop audit lint format test check fast-check clean distclean nuke docs check-docs cli-tree

help:
	@echo "CORE Development Makefile"
	@echo "-------------------------"
	@echo "This Makefile provides shortcuts to the main CLI."
	@echo "For all commands, see: 'poetry run core-admin --help'"
	@echo ""
	@echo "Common Shortcuts:"
	@echo "make install       - Install dependencies"
	@echo "make fast-check    - Run linting and tests (RECOMMENDED FOR LOCAL DEV)"
	@echo "make check         - Run all checks including vectorization (for CI)"
	@echo "make lint          - Check code format and quality (read-only)"
	@echo "make format        - Fix code format and quality issues"
	@echo "make test          - Run tests via 'core-admin check ci test'"
	@echo "make run           - Start the API server"
	@echo "make cli-tree      - Display the full CLI command tree"
	@echo "make clean         - Remove temporary files"
	@echo "make docs          - Generate capability documentation"

install:
	@echo "📦 Installing dependencies..."
	$(POETRY) install

lock:
	@echo "🔒 Resolving and locking dependencies..."
	$(POETRY) lock

run:
	@echo "🚀 Starting FastAPI server at http://$(HOST):$(PORT)"
	$(POETRY) run uvicorn $(APP) --host $(HOST) --port $(PORT) $(RELOAD) --env-file $(ENV_FILE)

stop:
	@echo "🛑 Stopping any process on port $(PORT)..."
	@lsof -t -i:$(PORT) | xargs kill -9 2>/dev/null || true


# --- START: CORRECTED COMMANDS ---
audit:
	$(POETRY) run core-admin check ci audit

lint:
	$(POETRY) run core-admin check ci lint

format:
	$(POETRY) run core-admin fix format

test:
	$(POETRY) run core-admin check ci test

cli-tree:
	@echo "🌳 Generating CLI command tree..."
	$(POETRY) run core-admin check diagnostics cli-tree

fast-check:
	$(POETRY) run core-admin check ci lint
	$(POETRY) run core-admin check ci test
# --- END: CORRECTED COMMANDS ---
	
fix-lines:
	@echo "📏 Fixing long lines with AI assistant..."
	$(POETRY) run core-admin fix line-lengths --write
	
fix-docs:
	@echo "✍️  Adding missing docstrings with AI assistant..."
	$(POETRY) run core-admin fix docstrings --write

build-graph:
	@echo "🏗️  Building knowledge graph..."
	$(POETRY) run core-admin build graph

vectorize: build-graph
	@echo "🧠 Vectorizing knowledge graph..."
	$(POETRY) run core-admin run vectorize

check:
	@echo "🤝 Running full constitutional audit and documentation check..."
	$(MAKE) lint
	$(MAKE) test
	$(MAKE) audit
	@$(MAKE) check-docs

docs:
	@echo "📚 Generating capability documentation..."
	$(POETRY) run core-admin build docs

check-docs: docs
	@echo "🔎 Checking for documentation drift..."
	@git diff --exit-code --quiet $(OUTPUT_PATH) || (echo "❌ ERROR: Documentation is out of sync. Please run 'make docs' and commit the changes." && exit 1)
	@echo "✅ Documentation is up to date."

# ---- Clean targets ---------------------------------------------------------

clean:
	@echo "🧹 Cleaning up temporary files and caches..."
	find . -type f -name '*.pyc' -delete
	find . -type d -name '__pycache__' -prune -exec rm -rf {} +
	rm -rf .pytest_cache .ruff_cache .mypy_cache .cache
	rm -f .coverage
	rm -rf htmlcov
	rm -rf build dist *.egg-info
	rm -rf pending_writes sandbox
	@echo "✅ Clean complete."

distclean: clean
	@echo "🧨 Distclean: removing virtual environments and build leftovers..."
	rm -rf .venv
	@echo "✅ Distclean complete."

nuke:
	@echo "☢️  Running 'git clean -fdx' in 3s (CTRL+C to cancel)..."
	@sleep 3
	git clean -fdx
	@echo "✅ Repo nuked (untracked files/dirs removed)."
--- END OF FILE ./Makefile ---

--- START OF FILE ./README.md ---
# CORE — The Self-Improving System Architect

> **Where Intelligence Lives.**

[![Status: Architectural Prototype](https://img.shields.io/badge/status-architectural%20prototype-blue.svg)](#-project-status)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![codecov](https://codecov.io/gh/DariuszNewecki/CORE/graph/badge.svg)](https://codecov.io/gh/DariuszNewecki/CORE)

CORE is a self-governing, constitutionally aligned AI development framework that can plan, write, validate, and evolve software systems — autonomously and safely. It is designed for environments where **trust, traceability, and governance matter**.

---

## 🏛️ Project Status: Architectural Prototype

The core self-governance and constitutional amendment loop is complete and stable. The system can audit and modify its own constitution via a human-in-the-loop, cryptographically signed approval process.

The next phase is to expand agent capabilities so CORE can generate and manage entirely new applications based on user intent. We’re making the project public now to invite collaboration on this foundational architecture.

---

## 🧠 What is CORE?

Traditional codebases often suffer from **architectural drift** — the code no longer matches the original design. Linters catch syntax errors, but architectural mistakes slip through.

CORE solves this by using a **“constitution”** (a set of machine-readable rules in `.intent/`) and an AI-powered **`ConstitutionalAuditor`** to ensure your code stays true to its design.

It’s built on a simple **Mind–Body–Will** philosophy:

* **Mind (`.intent/`)**: The Constitution. You declare your project's rules and goals here.
* **Body (`src/`)**: The Machinery. Simple, reliable tools that act on the code.
* **Will (AI Agents)**: The Reasoning Layer. AI agents that read the Mind and use the Body's tools to achieve your goals, while the Auditor ensures they never break the rules.

---

## 🚀 Getting Started (5-Minute Demo)

See CORE in action by running the worked example: create a simple API, intentionally break an architectural rule, and watch CORE's auditor catch it.

👉 **[Run the Worked Example (`docs/09_WORKED_EXAMPLE.md`)](docs/09_WORKED_EXAMPLE.md)**

---

## 📖 Documentation Portal

* **[What is CORE? (`docs/00_WHAT_IS_CORE.md`)](docs/00_WHAT_IS_CORE.md)** — The vision and philosophy.
* **[Architecture (`docs/02_ARCHITECTURE.md`)](docs/02_ARCHITECTURE.md)** — Technical details of the Mind and Body.
* **[Governance (`docs/03_GOVERNANCE.md`)](docs/03_GOVERNANCE.md)** — How changes are made safely.
* **[Roadmap (`docs/04_ROADMAP.md`)](docs/04_ROADMAP.md)** — See where we're going.
* **[Technical Debt Log (`docs/05_TECHNICAL_DEBT.md`)](docs/05_TECHNICAL_DEBT.md)** — Our formal plan for architectural improvements.
* **[Contributing (`CONTRIBUTING.md`)](CONTRIBUTING.md)** — Join our mission!

---

## ⚙️ Installation & Quick Start

**Requirements**: Python 3.12+, Poetry

```bash
# Clone and install
git clone https://github.com/DariuszNewecki/CORE.git
cd CORE
poetry install

# Set up environment
cp .env.example .env
# Edit .env with your LLM API keys

# Verify setup is clean by running the full system check
poetry run core-admin system check

# Try the conversational command!
poetry run core-admin chat "make me a simple command-line tool that prints a random number"

# 🌱 Contributing
We welcome all contributors! The best place to start is our Contributing Guide.

Check the Project Roadmap for "Next Up" tasks and see our open issues on GitHub.
# 📄 License
Licensed under the MIT License. See LICENSE.

--- END OF FILE ./README.md ---

--- START OF FILE ./assesment.prompt ---
# assesment.prompt
# This is the canonical prompt for a full architectural and constitutional review of the CORE project.

**You are an expert AI Systems Architect specializing in self-governing software and constitutional design. You have been retained to conduct a comprehensive architectural and constitutional review of a project named CORE.**

### Project Philosophy & Context

Before you begin, you must understand CORE's fundamental principles. CORE is not a typical software project; it is a self-governing system designed to evolve safely under a machine-readable "constitution."

Your entire assessment must be grounded in this philosophy.

1.  **The Architectural Trinity:** The system is strictly divided into three parts:
    *   🏛️ **The Mind (`.intent/`):** The Constitution. This is the single source of truth, divided into two parts:
        *   **The Charter (`.intent/charter/`):** The immutable, human-governed laws, principles, and schemas.
        *   **The Working Mind (`.intent/mind/`):**  The dynamic, system-maintained knowledge, with the database as the primary source of truth and .intent/mind/ files acting as human-readable sources for that truth.
    *   🦾 **The Body (`src/`):** The Machinery. The complete, implemented source code and tools that perform actions but do not make decisions.
    *   🧠 **The Will (AI Agents):** The Reasoning Layer. AI agents that read the Mind and use the Body's tools to achieve goals. Their actions are policed by the `ConstitutionalAuditor`.

2.  **Key Constitutional Principles:** Your review must be based on these values:
    *   **`clarity_first`**: Is the system's purpose and structure easy to understand?
    *   **`safe_by_default`**: Are changes validated and reversible? Is the system resilient?
    *   **`separation_of_concerns`**: Does the code respect the Mind-Body architecture? Is logic in the correct domain?
    *   **`dry_by_design`**: Is there duplicated logic or configuration that should be centralized?
    *   **`evolvable_structure`**: Can the system's constitution and code be changed safely and formally?

3.  **Project Goal: The Autonomy Ladder:** CORE's goal is to climb a ladder of self-governance, from observing code (A0) to autonomously generating new applications (A4). The project has recently completed a major constitutional refactoring ("The Great Simplification") and is stabilizing its foundation for the A1/A2 autonomy levels.

### Your Task

You will be provided with a complete snapshot of the CORE project. Your task is to perform a deep analysis and provide a strategic report to **identify the highest-leverage next steps to accelerate its progress toward greater autonomy.**

Your report must follow this exact structure:

---

### 1. Executive Summary

Provide a brief, high-level assessment of the project's current state post-refactoring. What is its greatest strength and its most significant remaining architectural weakness?

### 2. Architectural Scorecard (1-5)

Score each of the following dimensions on a scale of 1 (poor) to 5 (excellent). For each score, provide a concise one-sentence justification.

*   **Constitutional Integrity:** [Score] - Justification:
*   **Clarity & Simplicity:** [Score] - Justification:
*   **Architectural Purity (SoC & DRY):** [Score] - Justification:
*   **Safety & Governance:** [Score] - Justification:
*   **Readiness for Autonomy (A1/A2):** [Score] - Justification:

### 3. Strategic Gaps & Misalignments

Identify the top 3 high-level gaps or architectural misalignments that are holding the project back. **Focus on issues that prevent the system from becoming more autonomous.**

*   **Gap/Misalignment 1:** (e.g., Stale Operational Tooling)
    *   **Problem:** ...
    *   **Risk:** ...
*   **Gap/Misalignment 2:** (e.g., Implicit Service Dependencies)
    *   **Problem:** ...
    *   **Risk:** ...

### 4. Actionable Roadmap to A1 Autonomy

This is the most critical section. Provide a prioritized, actionable roadmap of tasks to address the issues you've identified. The goal is to make CORE capable of proposing and executing simple, safe changes to its own codebase (A1).

| Priority | Task Description | Constitutional Principle Served | Suggested First Step |
| :--- | :--- | :--- | :--- |
| **High** | *e.g., Consolidate all tooling into the `src/system/` domain.* | `separation_of_concerns` | *e.g., Create a migration plan in `docs/migrations/` for the `tools/` directory.* |
| **Medium** | *e.g., Implement a formal Dependency Injection container for core services.* | `clarity_first`, `evolvable_structure` | *e.g., Refactor `src/system/admin/__init__.py` to create a single context object.* |
| **Low** | *e.g., Create a self-healing agent to fix documentation drift.* | `reason_with_purpose` | *e.g., Draft a new prompt in `.intent/mind/prompts/` for a `docs_linter_agent`.* |

---

**Final Instruction:** Ground all your feedback in CORE's established principles. Your goal is not to suggest generic best practices, but to help this unique system become a better version of itself.

**The codebase bundle to review is provided below:**
--- END OF FILE ./assesment.prompt ---

--- START OF FILE ./docker-compose.yml ---
# docker-compose.yml
version: '3.8'

services:
  qdrant:
    image: qdrant/qdrant:v1.15.1
    container_name: core_qdrant_db
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - /mnt/vector_db/qdrant-core:/qdrant/storage
    restart: always

--- END OF FILE ./docker-compose.yml ---

--- START OF FILE ./pyproject.toml ---
# pyproject.toml
[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.poetry]
name = "core"
version = "0.1.0"
description = "CORE: A self-governing, intent-driven software development system."
authors = ["Dariusz Newecki <d.newecki@gmail.com>"]
license = "MIT"
readme = "README.md"
packages = [
    { include = "api", from = "src" },
    { include = "cli", from = "src" },
    { include = "core", from = "src" },
    { include = "features", from = "src" },
    { include = "services", from = "src" },
    { include = "shared", from = "src" },
]

[tool.poetry.dependencies]
python = ">=3.12"
fastapi = ">=0.95.0"
uvicorn = {extras = ["standard"], version = ">=0.21.0"}
pyyaml = ">=6.0"
httpx = ">=0.25.0"
python-dotenv = ">=1.0.0"
pydantic = ">=2.11"
pydantic-settings = "^2.10.1"
cryptography = ">=42.0.0"
rich = "^13"
black = "^24"
jsonschema = "^4"
typer = {extras = ["rich"], version = "^0.16.1"}
radon = ">=5.1.0"
filelock = "^3.13.0"
ruamel-yaml = "^0.18.6"
qdrant-client = "^1.9.2"
numpy = "^2.3.2"
scikit-learn = "^1.5.1"
scipy = "^1.14.0"
sqlalchemy = ">=2.0"
asyncpg = "^0.30.0"
sqlparse = "^0.5.3"

[tool.poetry.group.dev.dependencies]
pytest = ">=7.0,<8.0"
pytest-asyncio = "==0.21.0"
pytest-mock = "^3.12.0"
pytest-cov = "^6.2"
pytest-dotenv = "^0.5.2"

[tool.poetry.scripts]
core-admin = "cli.admin_cli:app"

[tool.black]
line-length = 88

[tool.ruff]
line-length = 88

[tool.ruff.lint]
select = ["E", "W", "F", "I"]
ignore = ["E402", "E501"]

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"
# --- START OF FIX ---
# This line tells pytest to add the 'src' directory to the Python path
# so that imports like 'from core.knowledge_service' work correctly.
pythonpath = ["src"]
# --- END OF FIX ---
addopts = ["-c", "pyproject.toml"]
env_files = [
    ".env"
]
--- END OF FILE ./pyproject.toml ---

--- START OF FILE ./scripts/build_llm_context.py ---
#!/usr/-bin/env python3
# tools/build_llm_context.py
import argparse, hashlib, json, os, sys, time, fnmatch, subprocess
from pathlib import Path

TEXT_EXTS = {
    ".py",".pyi",".md",".txt",".yaml",".yml",".toml",".ini",".cfg",".json",".sql",
    ".sh",".bash",".zsh",".ps1",".bat",".gitignore",".dockerignore",".env.example",
    ".rst",".csv"
}
BINARY_EXTS = {
    ".png",".jpg",".jpeg",".gif",".webp",".ico",".bmp",".tiff",".svg",
    ".mp3",".wav",".flac",".ogg",".mp4",".webm",".mov",".avi",
    ".pdf",".zip",".tar",".gz",".xz",".7z",".rar",".whl",".so",".dll",".dylib",
    ".pyc",".pyo"
}
DEFAULT_EXCLUDE_DIRS = {
    ".git",".venv","venv","__pycache__",".pytest_cache",".ruff_cache",".mypy_cache",
    "logs","sandbox","pending_writes","dist","build",".idea",".vscode","demo","work"
}
ROOT_DEFAULTS = ["pyproject.toml","poetry.lock","README.md","LICENSE","Makefile",".gitignore"]

# --- START OF MODIFICATION ---
# We are adding the 'sql' directory to the developer and full profiles
# to ensure the database schema is included in the AI context.
PROFILES = {
    "minimal": {
        "include_dirs": ["src", ".intent", "docs"],
        "root_files": ROOT_DEFAULTS,
    },
    "dev": {
        "include_dirs": ["src", ".intent", "docs", "tests", "sql"], # <-- ADDED 'sql'
        "root_files": ROOT_DEFAULTS,
    },
    "full": {
        "include_dirs": ["src", ".intent", "docs", "tests", "scripts", "tools", "sql"], # <-- ADDED 'sql'
        "root_files": ROOT_DEFAULTS,
    },
    "intent-only": {
        "include_dirs": [".intent"],
        "root_files": [],
    },
}
# --- END OF MODIFICATION ---

def is_probably_binary(path: Path) -> bool:
    if path.suffix.lower() in BINARY_EXTS:
        return True
    try:
        with path.open("rb") as f:
            chunk = f.read(4096)
        if b"\x00" in chunk:
            return True
    except Exception:
        return True
    return False

def sha256_of_bytes(b: bytes) -> str:
    h = hashlib.sha256()
    h.update(b)
    return h.hexdigest()

def read_text_head(path: Path, max_bytes: int) -> bytes:
    with path.open("rb") as f:
        data = f.read(max_bytes)
    try:
        size = path.stat().st_size
    except Exception:
        size = len(data)
    trailer = b""
    if size > len(data):
        trailer = f"\n[... TRUNCATED: kept first {len(data)} bytes of {size} ...]\n".encode("utf-8")
    return data + trailer

def collect_files(root: Path, include_dirs, extra_paths, exclude_dirs, allow_exts,
                  include_root_files, name_excludes: list[str]):
    files = []
    # add root files if present
    for rf in include_root_files:
        p = root / rf
        if p.exists() and p.is_file():
            files.append(p)

    todo_dirs = []
    for d in include_dirs:
        p = root / d
        if p.exists() and p.is_dir():
            todo_dirs.append(p)

    for extra in extra_paths:
        p = root / extra
        if p.exists():
            if p.is_file():
                files.append(p)
            elif p.is_dir():
                todo_dirs.append(p)

    # Walk allowlisted dirs
    for base in todo_dirs:
        for dirpath, dirnames, filenames in os.walk(base, followlinks=False):
            # prune excluded dirs
            dirnames[:] = [dn for dn in dirnames if dn not in exclude_dirs]
            for fn in filenames:
                # skip by name globs if requested
                if any(fnmatch.fnmatch(fn, pat) for pat in name_excludes):
                    continue
                p = Path(dirpath) / fn
                if p.suffix.lower() in BINARY_EXTS:
                    continue
                if p.suffix.lower() in allow_exts or p.suffix.lower() == "":
                    files.append(p)
                elif p.name in (".env",):
                    # avoid secrets by default
                    continue
    # de-dup + sort deterministically
    uniq = sorted({str(p) for p in files})
    return [Path(u) for u in uniq]

def git_changed_files(since: str) -> set:
    try:
        r = subprocess.run(
            ["git", "diff", "--name-only", since, "HEAD"],
            check=True, capture_output=True, text=True
        )
        return {line.strip() for line in r.stdout.splitlines() if line.strip()}
    except Exception:
        return set()

def write_chunks(outdir: Path, entries, max_chunk_bytes: int):
    outdir.mkdir(parents=True, exist_ok=True)
    chunk_idx = 1
    current = bytearray()
    paths = []

    def flush():
        nonlocal current, chunk_idx, paths
        if not current:
            return None
        name = f"context_{chunk_idx:04d}.txt"
        (outdir / name).write_bytes(current)
        paths.append(name)
        chunk_idx += 1
        current = bytearray()
        return name

    for e in entries:
        block = (
            f"--- START OF FILE {e['path']} ---\n".encode("utf-8")
            + e["bytes"]
            + f"\n--- END OF FILE {e['path']} ---\n\n".encode("utf-8")
        )
        if len(current) + len(block) > max_chunk_bytes and current:
            flush()
        if len(block) > max_chunk_bytes:
            if current:
                flush()
            current.extend(block[:max_chunk_bytes])
            current.extend(b"\n[... CHUNK TRUNCATED ...]\n")
            flush()
        else:
            current.extend(block)
    flush()

    return paths

def main():
    ap = argparse.ArgumentParser(description="Build compact, chunked LLM context from a repo.")
    ap.add_argument("--profile", choices=PROFILES.keys(), default="minimal")
    ap.add_argument("--paths", help="Comma-separated extra paths to include (files or dirs).", default="")
    ap.add_argument("--exclude-dirs", help="Comma-separated dirs to exclude in addition to defaults.", default="")
    ap.add_argument("--names-exclude", help="Comma-separated filename globs to exclude (e.g. '*.md,*.csv')", default="")
    ap.add_argument("--max-file-bytes", type=int, default=300_000, help="Max bytes per file to capture.")
    ap.add_argument("--max-chunk-bytes", type=int, default=12_000_000, help="Max bytes per output chunk.")
    ap.add_argument("--max-files", type=int, default=0, help="Stop after N files (0 = no limit).")
    ap.add_argument("--outdir", default="llm_context", help="Output directory.")
    ap.add_argument("--since", help="Only include files changed since this git ref (e.g. v0.2.0)", default=None)
    ap.add_argument("--print-summary", action="store_true")
    args = ap.parse_args()

    root = Path.cwd()
    prof = PROFILES[args.profile]
    include_dirs = prof["include_dirs"]
    include_root_files = prof["root_files"]

    extra_paths = [p.strip() for p in args.paths.split(",") if p.strip()]
    exclude_dirs = set(DEFAULT_EXCLUDE_DIRS)
    exclude_dirs |= {d.strip() for d in args.exclude_dirs.split(",") if d.strip()}
    name_excludes = [p.strip() for p in args.names_exclude.split(",") if p.strip()]

    candidates = collect_files(
        root, include_dirs, extra_paths, exclude_dirs, TEXT_EXTS, include_root_files, name_excludes
    )

    if args.since:
        changed = git_changed_files(args.since)
        if changed:
            candidates = [p for p in candidates if str(p.relative_to(root)) in changed]
        else:
            candidates = []

    # Deterministic order, then cap if needed
    candidates = sorted(candidates, key=lambda p: str(p))
    if args.max_files and args.max_files > 0:
        candidates = candidates[: args.max_files]

    entries = []
    total_bytes = 0
    total_files = 0
    skipped_binaries = []
    unreadable = 0
    for p in candidates:
        try:
            if is_probably_binary(p):
                skipped_binaries.append(str(p))
                continue
            data = read_text_head(p, args.max_file_bytes)
            total_bytes += len(data)
            total_files += 1
            entries.append({
                "path": str(p.relative_to(root)),
                "sha256": sha256_of_bytes(data),
                "size_bytes_captured": len(data),
                "bytes": data,
            })
        except Exception:
            unreadable += 1
            continue

    entries.sort(key=lambda e: e["path"])
    outdir = Path(args.outdir)
    chunk_paths = write_chunks(outdir, entries, args.max_chunk_bytes)

    manifest = {
        "created_at": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        "root": str(root),
        "profile": args.profile,
        "include_dirs": include_dirs,
        "extra_paths": extra_paths,
        "exclude_dirs": sorted(list(exclude_dirs)),
        "names_exclude": name_excludes,
        "max_file_bytes": args.max_file_bytes,
        "max_chunk_bytes": args.max_chunk_bytes,
        "max_files": args.max_files,
        "total_files": total_files,
        "total_bytes_captured": total_bytes,
        "chunks": chunk_paths,
        "files": [{"path": e["path"], "sha256": e["sha256"], "size_bytes_captured": e["size_bytes_captured"]} for e in entries],
        "skipped_binary_like": skipped_binaries[:200],
        "unreadable_count": unreadable,
    }
    (outdir / "index.json").write_text(json.dumps(manifest, indent=2))

    # Write a brief human summary
    (outdir / "summary.txt").write_text(
        "\n".join([
            f"Created: {manifest['created_at']}",
            f"Profile: {manifest['profile']}",
            f"Files captured: {total_files}",
            f"Bytes captured: {total_bytes}",
            f"Chunks: {len(chunk_paths)}",
            f"Skipped (binary-like): {len(skipped_binaries)}",
            f"Unreadable: {unreadable}",
            f"Outdir: {outdir}",
        ]) + "\n"
    )

    if args.print_summary:
        mb = total_bytes / (1024*1024)
        print(f"[OK] Captured {total_files} files, {mb:.2f} MiB into {len(chunk_paths)} chunk(s):")
        for c in chunk_paths:
            print(f"  - {c}")
        print(f"Manifest: {outdir/'index.json'}")
        print(f"Summary : {outdir/'summary.txt'}")

if __name__ == "__main__":
    sys.exit(main())
--- END OF FILE ./scripts/build_llm_context.py ---

--- START OF FILE ./scripts/concat_intent.sh ---
#!/usr/bin/env bash
#
# concat_bundle.sh
# A constitutionally-aware script to bundle all relevant .intent/ files
# into a single text file for external AI review and analysis.
#
# This script respects the Charter/Mind separation and excludes sensitive or
# irrelevant files to create a clean, focused context bundle.
#

set -euo pipefail

# --- Configuration ---
# The final output file for the bundle.
OUTPUT_FILE="constitutional_bundle.txt"
# The root of the constitution.
INTENT_DIR=".intent"
# --- End Configuration ---

# Ensure we are in the project root where .intent directory exists
if [ ! -d "$INTENT_DIR" ]; then
    echo "❌ Error: This script must be run from the CORE project root directory."
    exit 1
fi

echo "🚀 Generating constitutional bundle for AI review..."
echo "   -> Output will be saved to: $OUTPUT_FILE"

# Start with a clean slate
> "$OUTPUT_FILE"

# Helper function to append a directory's contents to the bundle
# It takes a title and the directory path as arguments.
append_directory() {
    local title="$1"
    local dir_path="$2"
    local file_count=0

    # Check if the directory exists and has files
    if [ -d "$dir_path" ] && [ -n "$(find "$dir_path" -maxdepth 1 -type f)" ]; then
        echo "" | tee -a "$OUTPUT_FILE" > /dev/null
        echo "--- START OF SECTION: $title ---" >> "$OUTPUT_FILE"
        echo "" >> "$OUTPUT_FILE"

        # Use find to handle files gracefully, sorted for deterministic output
        for file in $(find "$dir_path" -maxdepth 1 -type f -name "*.yaml" -o -name "*.yml" -o -name "*.md" -o -name "*.json" | sort); do
            if [ -f "$file" ]; then
                echo "--- START OF FILE $file ---" >> "$OUTPUT_FILE"
                cat "$file" >> "$OUTPUT_FILE"
                echo -e "\n--- END OF FILE $file ---\n" >> "$OUTPUT_FILE"
                file_count=$((file_count + 1))
            fi
        done
        echo "--- END OF SECTION: $title ($file_count files) ---" >> "$OUTPUT_FILE"
    fi
}

# 1. Start with the Master Index
echo "--- START OF FILE $INTENT_DIR/meta.yaml ---" >> "$OUTPUT_FILE"
cat "$INTENT_DIR/meta.yaml" >> "$OUTPUT_FILE"
echo -e "\n--- END OF FILE $INTENT_DIR/meta.yaml ---\n" >> "$OUTPUT_FILE"

# 2. Append the entire Charter
echo "==============================================================================" >> "$OUTPUT_FILE"
echo "                            PART 1: THE CHARTER" >> "$OUTPUT_FILE"
echo " (The Immutable Laws, Mission, and Foundational Principles of the System)" >> "$OUTPUT_FILE"
echo "==============================================================================" >> "$OUTPUT_FILE"
append_directory "Constitution" "$INTENT_DIR/charter/constitution"
append_directory "Mission" "$INTENT_DIR/charter/mission"
append_directory "Policies" "$INTENT_DIR/charter/policies"
append_directory "Schemas" "$INTENT_DIR/charter/schemas"

# 3. Append the entire Working Mind
echo "" >> "$OUTPUT_FILE"
echo "==============================================================================" >> "$OUTPUT_FILE"
echo "                            PART 2: THE WORKING MIND" >> "$OUTPUT_FILE"
echo " (The Dynamic Knowledge, Configuration, and Evaluation Logic of the System)" >> "$OUTPUT_FILE"
echo "==============================================================================" >> "$OUTPUT_FILE"
append_directory "Configuration" "$INTENT_DIR/mind/config"
append_directory "Evaluation" "$INTENT_DIR/mind/evaluation"
append_directory "Knowledge" "$INTENT_DIR/mind/knowledge"

# Note: We intentionally exclude prompts/ as they are often very large and context-specific.
# We also exclude generated artifacts like knowledge_graph.json and sensitive files like keys/.

TOTAL_SIZE=$(wc -c < "$OUTPUT_FILE")
echo ""
echo "✅ Constitutional bundle successfully generated!"
echo "   -> Total size: $TOTAL_SIZE bytes."
echo "   -> You can now copy the content of '$OUTPUT_FILE' and provide it to an external AI for review."
--- END OF FILE ./scripts/concat_intent.sh ---

--- START OF FILE ./scripts/concat_project.sh ---
#!/usr/bin/env python3
# scripts/create_project_bundle.py
"""
A constitutionally-aware script to bundle the CORE project's essence for AI review.
It includes the Mind, Body, and operational tooling while excluding transient state,
sensitive data, and generated artifacts. It produces a structured output for clarity.
"""
from __future__ import annotations

import argparse
from pathlib import Path

# --- Configuration ---
# The final output file for the bundle.
OUTPUT_FILE = "project_context.txt"
# The marker for the project root.
ROOT_MARKER = "pyproject.toml"

# --- CHANGE: Simplified and corrected include lists ---
# All directories to be included are now in a single list.
INCLUDE_DIRS = [
    ".intent",
    "src",
    "tests",
    "scripts",
    ".github",
    "sql",  # <-- CRITICAL FIX: Added the sql directory
]
# All individual files at the root level are in this list.
INCLUDE_ROOT_FILES = [
    "pyproject.toml", "README.md", "CONTRIBUTING.md", "LICENSE", "Makefile",
    ".gitignore", "assesment.prompt", "docker-compose.yml"
]
# --- END CHANGE ---

# Define what to exclude, based on our architectural principles.
EXCLUDE_PATTERNS = [
    # General exclusions
    ".git", ".venv", "__pycache__", ".pytest_cache", ".ruff_cache",
    "logs", "sandbox", "pending_writes", "demo", "work", "dist", "build",
    # Sensitive files
    ".env", ".intent/keys",
    # Generated or large artifacts
    "poetry.lock",
    # --- CHANGE: Removed 'reports/' as we only need to exclude the output file ---
    # Binary file extensions
    "*.png", "*.jpg", "*.jpeg", "*.gif", "*.webp", "*.ico", "*.pyc", "*.so",
    "*.DS_Store", "Thumbs.db",
]
# --- End Configuration ---


def is_excluded(path: Path, root: Path, exclude_patterns: list[str]) -> bool:
    """Check if a path should be excluded based on the patterns."""
    relative_path_str = str(path.relative_to(root))
    for pattern in exclude_patterns:
        if path.match(pattern) or relative_path_str.startswith(pattern):
            return True
    return False


def is_likely_binary(path: Path) -> bool:
    """Heuristic to check if a file is binary by looking for null bytes."""
    try:
        with path.open("rb") as f:
            return b"\x00" in f.read(1024)
    except Exception:
        return True


def main():
    """Main execution function."""
    parser = argparse.ArgumentParser(description="Generate Project Context Bundle for AI review.")
    parser.add_argument(
        "--output", default=OUTPUT_FILE, help="Path for the output bundle file."
    )
    args = parser.parse_args()
    output_path = Path(args.output).resolve()

    # 1. Ensure the script is run from the project root.
    root_path = Path.cwd()
    if not (root_path / ROOT_MARKER).exists():
        print(f"❌ Error: This script must be run from the CORE project root directory.")
        return 1

    print(f"🚀 Generating Project Context Bundle for AI review...")
    print(f"   -> Output will be saved to: {output_path}")

    # Exclude the output file itself
    final_exclude_patterns = EXCLUDE_PATTERNS + [str(output_path)]

    files_to_bundle = []
    # Gather all files from included directories
    for dir_name in INCLUDE_DIRS:
        dir_path = root_path / dir_name
        if dir_path.is_dir():
            files_to_bundle.extend(dir_path.rglob("*"))

    # Add root files
    for file_name in INCLUDE_ROOT_FILES:
        file_path = root_path / file_name
        if file_path.is_file():
            files_to_bundle.append(file_path)

    # 2. Filter, sort, and process files
    output_path.parent.mkdir(parents=True, exist_ok=True)
    file_count = 0
    with output_path.open("w", encoding="utf-8") as outfile:
        outfile.write("--- START OF FILE project_context.txt ---\n\n")
        outfile.write("--- START OF PROJECT CONTEXT BUNDLE ---\n\n")

        # Use a set for efficient deduplication, then sort for deterministic order
        unique_files = sorted(list(set(files_to_bundle)))

        for file in unique_files:
            if (
                not file.is_file()
                or is_excluded(file, root_path, final_exclude_patterns)
                or is_likely_binary(file)
            ):
                continue

            file_count += 1
            relative_path = file.relative_to(root_path)
            outfile.write(f"--- START OF FILE ./{relative_path} ---\n") # <-- Added './' for clarity
            try:
                content = file.read_text("utf-8")
                if content:
                    outfile.write(content)
                else:
                    outfile.write("[EMPTY FILE]")
            except Exception as e:
                outfile.write(f"[ERROR READING FILE: {e}]")
            outfile.write(f"\n--- END OF FILE ./{relative_path} ---\n\n") # <-- Added './' for clarity

        outfile.write("--- END OF PROJECT CONTEXT BUNDLE ---\n")

    print(f"\n✅ Done. Concatenated {file_count} files into {output_path}.")
    return 0

if __name__ == "__main__":
    exit(main())
--- END OF FILE ./scripts/concat_project.sh ---

--- START OF FILE ./scripts/create_qdrant_collection.py ---
import asyncio
from qdrant_client import AsyncQdrantClient, models

# --- Your Configuration ---
# These should match your .env file
QDRANT_URL = "http://192.168.20.22:6333"
COLLECTION_NAME = "core_capabilities"
VECTOR_DIMENSION = 768  # This must match your embedding model's output size
# --- End Configuration ---

async def create_collection():
    """
    Connects to Qdrant and idempotently creates the specified collection.
    """
    print(f"Connecting to Qdrant at {QDRANT_URL}...")
    client = AsyncQdrantClient(url=QDRANT_URL)

    try:
        # Check if the collection already exists
        collections_response = await client.get_collections()
        existing_collections = [c.name for c in collections_response.collections]
        
        if COLLECTION_NAME in existing_collections:
            print(f"✅ Collection '{COLLECTION_NAME}' already exists. Nothing to do.")
            return

        # If it doesn't exist, create it
        print(f"Collection '{COLLECTION_NAME}' not found. Creating it now...")
        await client.recreate_collection(
            collection_name=COLLECTION_NAME,
            vectors_config=models.VectorParams(
                size=VECTOR_DIMENSION,
                distance=models.Distance.COSINE,
            ),
        )
        print(f"✅ Successfully created collection '{COLLECTION_NAME}'.")

    except Exception as e:
        print(f"❌ An error occurred: {e}")
        print("\nPlease ensure your Qdrant Docker container is running and accessible.")
    finally:
        await client.close()


if __name__ == "__main__":
    asyncio.run(create_collection())
--- END OF FILE ./scripts/create_qdrant_collection.py ---

--- START OF FILE ./scripts/gh_status_report.sh ---
#!/usr/bin/env bash
set -euo pipefail
OWNER="${OWNER:-DariuszNewecki}"
REPO="${REPO:-CORE}"

has_jq() { command -v jq >/dev/null 2>&1; }

out="GH_STATUS.md"
echo "# GitHub Status Report — $OWNER/$REPO" > "$out"
echo "" >> "$out"
echo "Generated: $(date -u +"%Y-%m-%d %H:%M:%SZ")" >> "$out"
echo "" >> "$out"

echo "## Repository" >> "$out"
gh api repos/$OWNER/$REPO > /tmp/repo.json
if has_jq; then
  jq '{name,visibility,default_branch,open_issues_count,description}' /tmp/repo.json >> "$out"
else
  cat /tmp/repo.json >> "$out"
fi
echo "" >> "$out"

echo "## Milestones" >> "$out"
gh api repos/$OWNER/$REPO/milestones --paginate > /tmp/miles.json || echo "[]">/tmp/miles.json
if has_jq; then
  jq '.[] | {number,title,state,due_on,open_issues,closed_issues,description}' /tmp/miles.json >> "$out"
else
  cat /tmp/miles.json >> "$out"
fi
echo "" >> "$out"

# --- THIS IS THE MODIFIED SECTION ---

echo "## Open Issues" >> "$out"
gh issue list --repo $OWNER/$REPO --state open --limit 200 \
  --json number,title,labels,milestone,url,createdAt > /tmp/issues_open.json
if has_jq; then
  jq '.[] | {number,title,milestone: .milestone.title,labels: [.labels[].name],url,createdAt}' /tmp/issues_open.json >> "$out"
else
  cat /tmp/issues_open.json >> "$out"
fi
echo "" >> "$out"

echo "## Recently Closed Issues" >> "$out"
gh issue list --repo $OWNER/$REPO --state closed --limit 30 \
  --json number,title,labels,milestone,url,closedAt > /tmp/issues_closed.json
if has_jq; then
  jq '.[] | {number,title,milestone: .milestone.title,labels: [.labels[].name],url,closedAt}' /tmp/issues_closed.json >> "$out"
else
  cat /tmp/issues_closed.json >> "$out"
fi
echo "" >> "$out"

# --- END OF MODIFIED SECTION ---

echo "## Labels" >> "$out"
gh label list --repo $OWNER/$REPO --json name,color,description > /tmp/labels.json
if has_jq; then
  jq '.[] | {name,color,description}' /tmp/labels.json >> "$out"
else
  cat /tmp/labels.json >> "$out"
fi
echo "" >> "$out"

echo "## Projects (Projects v2)" >> "$out"
gh project list --owner $OWNER > /tmp/projects.txt || true
cat /tmp/projects.txt >> "$out"
echo "" >> "$out"
if grep -Eo '#[0-9]+' /tmp/projects.txt >/dev/null 2>&1; then
  while read -r num; do
    pnum="${num//#/}"
    echo "### Project $pnum" >> "$out"
    gh project view "$pnum" --owner $OWNER --format json >> "$out" || true
    echo "" >> "$out"
  done < <(grep -Eo '#[0-9]+' /tmp/projects.txt | sort -u)
fi

echo "## Releases" >> "$out"
gh release list --repo $OWNER/$REPO >> "$out" || true
echo "" >> "$out"

echo "Report written to $out"
--- END OF FILE ./scripts/gh_status_report.sh ---

--- START OF FILE ./scripts/register_all_capabilities.py ---
#!/usr/bin/env python3
# scripts/register_all_capabilities.py
"""
A helper script to automatically register all unassigned capabilities
found in the knowledge graph.
"""

import json
import subprocess
import sys
from pathlib import Path

from rich.console import Console
from rich.progress import track

# --- Configuration ---
REPO_ROOT = Path(__file__).resolve().parents[1]
KNOWLEDGE_GRAPH_PATH = REPO_ROOT / ".intent" / "knowledge" / "knowledge_graph.json"
# --- End Configuration ---

console = Console()


def main():
    """Main execution function."""
    console.print(
        "[bold cyan]🚀 Batch Registering All Unassigned Capabilities...[/bold cyan]"
    )

    if not KNOWLEDGE_GRAPH_PATH.exists():
        console.print(
            f"[bold red]❌ Error: Knowledge graph not found at {KNOWLEDGE_GRAPH_PATH}[/bold red]"
        )
        sys.exit(1)

    with KNOWLEDGE_GRAPH_PATH.open("r", encoding="utf-8") as f:
        graph = json.load(f)

    symbols = graph.get("symbols", {}).values()

    # --- THIS IS THE DEFINITIVE FIX ---
    # The script now uses the same, correct logic as the auditor to identify
    # only the PUBLIC symbols that are unassigned.
    unassigned_symbols = [
        s
        for s in symbols
        if s.get("capability") == "unassigned" and not s.get("name", "").startswith("_")
    ]
    # --- END OF FIX ---

    if not unassigned_symbols:
        console.print(
            "[bold green]✅ Success! No unassigned public capabilities found.[/bold green]"
        )
        sys.exit(0)

    console.print(
        f"   -> Found {len(unassigned_symbols)} unassigned public capabilities to register."
    )
    console.print(
        "[yellow]This will make multiple calls to the LLM and will take some time.[/yellow]"
    )
    if input("Proceed? (y/N): ").lower() != "y":
        console.print("[bold red]Aborted.[/bold red]")
        sys.exit(0)

    success_count = 0
    fail_count = 0

    for symbol in track(
        unassigned_symbols, description="Registering capabilities..."
    ):
        symbol_key = symbol.get("key")
        if not symbol_key:
            continue

        command = [
            "poetry",
            "run",
            "core-admin",
            "capability",
            "new",
            symbol_key,
        ]

        try:
            subprocess.run(
                command,
                check=True,
                capture_output=True,
                text=True,
                cwd=REPO_ROOT,
            )
            success_count += 1
        except subprocess.CalledProcessError as e:
            console.print(
                f"\n[bold red]❌ Failed to register '{symbol_key}':[/bold red]"
            )
            console.print(e.stderr)
            fail_count += 1

    console.print("\n--- Batch Registration Summary ---")
    console.print(
        f"[bold green]✅ Successfully registered: {success_count}[/bold green]"
    )
    if fail_count > 0:
        console.print(f"[bold red]❌ Failed to register: {fail_count}[/bold red]")
    
    console.print("\n[bold cyan]🧠 Rebuilding knowledge graph to reflect all changes...[/bold cyan]")
    try:
        subprocess.run(
            ["poetry", "run", "core-admin", "knowledge", "build-graph"],
            check=True,
            capture_output=True,
            text=True,
            cwd=REPO_ROOT,
        )
        console.print("[bold green]✅ Knowledge graph successfully updated.[/bold green]")
    except subprocess.CalledProcessError as e:
        console.print("[bold red]❌ Failed to rebuild knowledge graph:[/bold red]")
        console.print(e.stderr)
        sys.exit(1)
    
    if fail_count > 0:
        sys.exit(1)


if __name__ == "__main__":
    main()
    
--- END OF FILE ./scripts/register_all_capabilities.py ---

--- START OF FILE ./sql/001_init.sql ---
CREATE SCHEMA IF NOT EXISTS core;

-- proposals (evidence of constitutional change attempts)
CREATE TABLE IF NOT EXISTS core.proposals (
  id               BIGSERIAL PRIMARY KEY,
  target_path      TEXT NOT NULL,
  content_sha256   CHAR(64) NOT NULL,
  justification    TEXT NOT NULL,
  risk_tier        TEXT CHECK (risk_tier IN ('low','medium','high')) DEFAULT 'low',
  is_critical      BOOLEAN NOT NULL DEFAULT FALSE,
  status           TEXT CHECK (status IN ('open','approved','rejected','superseded')) NOT NULL DEFAULT 'open',
  created_at       TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  created_by       TEXT NOT NULL
);

CREATE TABLE IF NOT EXISTS core.proposal_signatures (
  proposal_id       BIGINT NOT NULL REFERENCES core.proposals(id) ON DELETE CASCADE,
  approver_identity TEXT NOT NULL,
  signature_base64  TEXT NOT NULL,
  signed_at         TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  is_valid          BOOLEAN NOT NULL DEFAULT TRUE,
  PRIMARY KEY (proposal_id, approver_identity)
);

-- audit runs (scores + pass/fail over time)
CREATE TABLE IF NOT EXISTS core.audit_runs (
  id         BIGSERIAL PRIMARY KEY,
  source     TEXT NOT NULL,           -- 'nightly' | 'pr' | 'manual'
  commit_sha CHAR(40),
  score      NUMERIC(4,3),
  passed     BOOLEAN NOT NULL,
  started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  finished_at TIMESTAMPTZ
);

--- END OF FILE ./sql/001_init.sql ---

--- START OF FILE ./sql/002_capability_domains.sql ---
-- FILE: sql/002_capability_domains.sql

-- 1) Capabilities can be multi-domain via a junction; keep the column
--    but make it nullable for backward-compat/exports.
ALTER TABLE core.capabilities
  ALTER COLUMN domain DROP NOT NULL;

-- 2) Junction table for capability <-> domain
CREATE TABLE IF NOT EXISTS core.capability_domains (
  capability_key TEXT NOT NULL
    REFERENCES core.capabilities(key) ON DELETE CASCADE,
  domain_key TEXT NOT NULL
    REFERENCES core.domains(key) ON DELETE RESTRICT,
  is_primary BOOLEAN NOT NULL DEFAULT FALSE,
  PRIMARY KEY (capability_key, domain_key)
);

-- 3) At most one primary domain per capability (optional but helpful).
CREATE UNIQUE INDEX IF NOT EXISTS uq_capability_primary_domain
  ON core.capability_domains (capability_key)
  WHERE is_primary = TRUE;

-- 4) Seed the junction from the legacy single-column if present.
INSERT INTO core.capability_domains (capability_key, domain_key, is_primary)
SELECT c.key, c.domain, TRUE
FROM core.capabilities c
JOIN core.domains d ON d.key = c.domain
WHERE c.domain IS NOT NULL
ON CONFLICT DO NOTHING;

--- END OF FILE ./sql/002_capability_domains.sql ---

--- START OF FILE ./sql/002_catalog.sql ---
-- Minimal catalog tables for domains + capabilities (DB = SSOT)
create table if not exists core.domains (
  key          text primary key,
  title        text not null,
  description  text,
  parent_key   text references core.domains(key),
  status       text check (status in ('active','deprecated')) not null default 'active',
  last_seen_at timestamptz not null default now()
);

create table if not exists core.capabilities (
  key          text primary key,
  title        text not null,
  domain       text not null references core.domains(key) on update cascade,
  owner        text not null default 'unassigned',
  status       text check (status in ('active','deprecated')) not null default 'active',
  last_seen_at timestamptz not null default now()
);

create index if not exists idx_capabilities_domain on core.capabilities(domain);

--- END OF FILE ./sql/002_catalog.sql ---

--- START OF FILE ./sql/003_capability_domains_idx.sql ---
-- FILE: sql/003_capability_domains_idx.sql

-- Helpful indexes for common lookups
CREATE INDEX IF NOT EXISTS idx_capability_domains_domain
  ON core.capability_domains(domain_key);

CREATE INDEX IF NOT EXISTS idx_capability_domains_cap_primary
  ON core.capability_domains(capability_key)
  WHERE is_primary = TRUE;

--- END OF FILE ./sql/003_capability_domains_idx.sql ---

--- START OF FILE ./sql/003_implementations.sql ---
--- START OF FILE sql/003_implementations.sql ---
-- FILE: sql/003_implementations.sql

CREATE TABLE IF NOT EXISTS core.implementations (
  capability_key TEXT NOT NULL REFERENCES core.capabilities(key) ON DELETE CASCADE,
  file_path TEXT NOT NULL,
  symbol_path TEXT NOT NULL,
  structural_hash CHAR(64) NOT NULL,
  PRIMARY KEY (capability_key, file_path, symbol_path)
);
--- END OF FILE sql/003_implementations.sql ---
--- END OF FILE ./sql/003_implementations.sql ---

--- START OF FILE ./sql/004_refactor_to_symbols.sql ---
-- FILE: sql/004_refactor_to_symbols.sql

-- Step 1: Create a temporary mapping table to hold the old implementation data.
-- This block is wrapped in a DO statement to execute conditionally, making the script safe to re-run.
DO $$
BEGIN
   IF EXISTS (SELECT FROM pg_tables WHERE schemaname = 'core' AND tablename  = 'implementations') THEN
      -- Create the temp table only if the source table exists
      CREATE TABLE core.implementations_temp AS TABLE core.implementations;
   END IF;
END $$;

-- Step 2: Explicitly drop the dependent objects first.
DROP TABLE IF EXISTS core.capability_domains;
DROP VIEW IF EXISTS core.knowledge_graph;
DROP VIEW IF EXISTS core.capabilities_view;

-- Step 3: Now it is safe to drop the old tables.
DROP TABLE IF EXISTS core.implementations;
DROP TABLE IF EXISTS core.capabilities;
DROP TABLE IF EXISTS core.domains;

-- Step 4: Create the new, universal symbols table.
CREATE TABLE core.symbols (
    uuid            TEXT PRIMARY KEY,
    symbol_path     TEXT NOT NULL UNIQUE,
    file_path       TEXT NOT NULL,
    is_public       BOOLEAN NOT NULL DEFAULT FALSE,
    title           TEXT,
    description     TEXT,
    owner           TEXT NOT NULL DEFAULT 'unassigned_agent',
    status          TEXT NOT NULL DEFAULT 'active',
    structural_hash CHAR(64),
    vector_id       TEXT,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at      TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

-- Add indexes for performance
CREATE INDEX idx_symbols_filepath ON core.symbols (file_path);
CREATE INDEX idx_symbols_is_public ON core.symbols (is_public);

-- NOTE: Data migration from the temp table will be handled by the new 'knowledge sync' command.
--- END OF FILE ./sql/004_refactor_to_symbols.sql ---

--- START OF FILE ./sql/005_add_symbol_key.sql ---
-- FILE: sql/005_add_symbol_key.sql
--
-- CONSTITUTIONAL AMENDMENT: Add a canonical, human-readable key to the symbols table.
--
-- Justification: This amendment forges the missing link between the human-readable
-- capabilities declared in .intent/mind/project_manifest.yaml and their concrete
-- implementations tracked in the database. It is a critical step to making the
-- ConstitutionalAuditor's 'check_capability_coverage' function correctly and
-- serves the 'clarity_first' principle.

-- Step 1: Add the new 'key' column. It is nullable for now to allow a phased data migration.
ALTER TABLE core.symbols
ADD COLUMN key TEXT;

-- Step 2: Create a unique index to ensure that each human-readable key can only
-- be assigned to one symbol, enforcing the single_source_of_truth principle.
-- The index is created on non-null values only.
CREATE UNIQUE INDEX IF NOT EXISTS uq_symbols_key
ON core.symbols (key)
WHERE key IS NOT NULL;
--- END OF FILE ./sql/005_add_symbol_key.sql ---

--- START OF FILE ./sql/006_knowledge_graph_view.sql ---
-- FILE: sql/006_knowledge_graph_view.sql
--
-- CONSTITUTIONAL AMENDMENT: Create a database view to act as a stable,
-- queryable interface to the system's knowledge graph.
--
-- Justification: This view provides a drop-in replacement for the legacy
-- knowledge_graph.json file, serving the 'evolvable_structure' and 'clarity_first'
-- principles by abstracting the underlying table structure from consumers
-- like the ConstitutionalAuditor.

CREATE OR REPLACE VIEW core.knowledge_graph AS
SELECT
    s.uuid,
    s.key AS capability, -- Alias 'key' to 'capability' for backward compatibility
    s.symbol_path,
    s.file_path AS file,
    s.title,
    s.description AS intent,
    s.owner,
    s.status,
    s.is_public,
    s.structural_hash,
    s.vector_id,
    s.updated_at AS last_updated,
    -- NOTE: These fields are placeholders to match the old schema for now.
    '[]'::jsonb AS tags,
    '[]'::jsonb AS calls,
    '[]'::jsonb AS parameters,
    '[]'::jsonb AS base_classes,
    (s.symbol_path LIKE '%__init__') AS is_class,
    (s.symbol_path LIKE '%Test%') AS is_test,
    -- --- THIS IS THE FIX ---
    -- Add the missing columns that downstream tools rely on.
    -- For now, we use placeholders or simple derivations.
    0 AS line_number, -- Placeholder
    0 AS end_line_number, -- Placeholder
    NULL AS source_code, -- Placeholder
    NULL AS docstring, -- Placeholder
    NULL AS entry_point_type, -- Placeholder
    NULL AS entry_point_justification, -- Placeholder
    NULL AS parent_class_key, -- Placeholder
    FALSE AS is_async -- Placeholder
    -- --- END OF FIX ---
FROM
    core.symbols s;
--- END OF FILE ./sql/006_knowledge_graph_view.sql ---

--- START OF FILE ./sql/007_capabilities_registry.sql ---
-- FILE: sql/007_capabilities_registry.sql
CREATE TABLE IF NOT EXISTS core.capabilities (
  id TEXT PRIMARY KEY,          -- The canonical key, e.g., 'introspection.vectorize'
  title TEXT NOT NULL,
  owner TEXT NOT NULL,
  implementing_files JSONB,     -- A JSON array of file paths like ["src/features/introspection/service.py"]
  created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
--- END OF FILE ./sql/007_capabilities_registry.sql ---

--- START OF FILE ./sql/008_operational_tables.sql ---
-- FILE: sql/008_operational_tables.sql
--
-- CONSTITUTIONAL AMENDMENT: Make the database the Single Source of Truth for operational knowledge.
--
-- Justification: This migration creates tables to house runtime operational knowledge
-- that was previously stored in difficult-to-manage YAML files. This serves the
-- 'single_source_of_truth' principle by centralizing configuration, making it
-- transactionally safe, and queryable by all system components.

-- Table for LLM Resources, replacing resource_manifest_policy.yaml
CREATE TABLE IF NOT EXISTS core.llm_resources (
    name TEXT PRIMARY KEY,
    provided_capabilities JSONB NOT NULL DEFAULT '[]'::jsonb,
    env_prefix TEXT NOT NULL UNIQUE,
    performance_metadata JSONB
);

-- Table for Cognitive Roles, replacing cognitive_roles_policy.yaml
CREATE TABLE IF NOT EXISTS core.cognitive_roles (
    "role" TEXT PRIMARY KEY,
    description TEXT,
    assigned_resource TEXT REFERENCES core.llm_resources(name),
    required_capabilities JSONB NOT NULL DEFAULT '[]'::jsonb
);

-- Table for Runtime Services, replacing runtime_services.yaml
CREATE TABLE IF NOT EXISTS core.runtime_services (
    name TEXT PRIMARY KEY,
    implementation TEXT NOT NULL UNIQUE
);

-- Table for CLI Commands, replacing cli_registry_policy.yaml
CREATE TABLE IF NOT EXISTS core.cli_commands (
    name TEXT PRIMARY KEY,
    module TEXT NOT NULL,
    entrypoint TEXT NOT NULL,
    summary TEXT,
    category TEXT
);
--- END OF FILE ./sql/008_operational_tables.sql ---

--- START OF FILE ./sql/009_domain_and_vector_tables.sql ---
-- Migration to make the database the single source of truth for domains.
-- This aligns with the 'single_source_of_truth' and 'evolvable_structure' principles.

-- Step 1: Create the new 'domains' table.
-- This table will store the canonical list of all architectural domains.
CREATE TABLE IF NOT EXISTS core.domains (
    key          TEXT PRIMARY KEY,
    title        TEXT NOT NULL,
    description  TEXT,
    created_at   TIMESTAMPTZ NOT NULL DEFAULT NOW()
);
CREATE INDEX IF NOT EXISTS idx_domains_key ON core.domains (key);


-- Step 2: Add a 'domain' column to the 'symbols' table.
-- This creates the formal link between a piece of code (a symbol) and its
-- architectural domain. It is nullable to support symbols that are not
-- yet classified.
ALTER TABLE core.symbols
ADD COLUMN domain_key TEXT REFERENCES core.domains(key) ON DELETE SET NULL;
CREATE INDEX IF NOT EXISTS idx_symbols_domain_key ON core.symbols (domain_key);


-- Step 3: Add a 'vector' column to the 'symbols' table.
-- This makes the database the single source of truth for embeddings, directly
-- associating a vector with the symbol it represents. We use JSONB for
-- portability instead of a vendor-specific VECTOR type.
ALTER TABLE core.symbols
ADD COLUMN vector JSONB;
CREATE INDEX IF NOT EXISTS idx_symbols_vector_gin ON core.symbols USING GIN (vector);


-- Step 4: Create a junction table for many-to-many relationships between symbols and capabilities.
-- This is a forward-looking change to support future scenarios where a single
-- function might implement multiple, distinct capabilities.
CREATE TABLE IF NOT EXISTS core.symbol_capabilities (
    symbol_uuid TEXT NOT NULL REFERENCES core.symbols(uuid) ON DELETE CASCADE,
    capability_key TEXT NOT NULL, -- This will be validated by the application layer
    PRIMARY KEY (symbol_uuid, capability_key)
);
CREATE INDEX IF NOT EXISTS idx_symbol_capabilities_capability_key ON core.symbol_capabilities (capability_key);

--- END OF FILE ./sql/009_domain_and_vector_tables.sql ---

--- START OF FILE ./src/api/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/api/__init__.py ---

--- START OF FILE ./src/api/v1/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/api/v1/__init__.py ---

--- START OF FILE ./src/cli/admin_cli.py ---
# src/cli/admin_cli.py
"""
The single, canonical entry point for the core-admin CLI.
This module assembles all command groups into a single Typer application.
"""

from __future__ import annotations

import typer
from rich.console import Console

# --- Command Group Imports ---
# These imports bring in the modules that contain the 'register' functions.
from cli.commands import (
    agent,
    build,
    byor,
    capability,
    chat,
    check,
    db,
    fixer,
    guard,
    interactive,
    knowledge,
    knowledge_sync,
    new,
    proposal_service,
    run,
    system,
    tools,
)
from features.governance import key_management_service
from features.project_lifecycle import bootstrap_service

console = Console()

# --- Main Application ---
app = typer.Typer(
    name="core-admin",
    help="""
    CORE: The Self-Improving System Architect's Toolkit.

    This CLI is the primary interface for operating and governing the CORE system.
    Run with no arguments to enter the interactive menu.
    """,
    no_args_is_help=False,  # We want to launch the interactive menu by default
)


# --- Command Registration ---
# <-- RESTORED STATIC REGISTRATION TO FIX BOOTSTRAPPING PARADOX
# The order here determines the order in the --help output.
system.register(app)
check.register(app)
fixer.register(app)
db.register(app)
knowledge.register(app)
knowledge_sync.register(app)
run.register(app)
build.register(app)
tools.register(app)
agent.register(app)
proposal_service.register(app)
key_management_service.register(app)
new.register(app)
bootstrap_service.register(app)
byor.register(app)
guard.register(app)
capability.register(app)
chat.register(app)


@app.callback(invoke_without_command=True)
# ID: 25555fd8-2556-4a77-b222-a68988ef2b01
def main(ctx: typer.Context):
    """
    If no command is specified, launch the interactive menu.
    """
    if ctx.invoked_subcommand is None:
        console.print(
            "[bold green]No command specified. Launching interactive menu...[/bold green]"
        )
        interactive.launch_interactive_menu()


if __name__ == "__main__":
    app()

--- END OF FILE ./src/cli/admin_cli.py ---

--- START OF FILE ./src/cli/commands/__init__.py ---
# src/cli/commands/__init__.py
"""
This file marks the 'commands' directory as a Python package,
allowing command modules to be imported from here.
"""
from __future__ import annotations

--- END OF FILE ./src/cli/commands/__init__.py ---

--- START OF FILE ./src/cli/commands/agent.py ---
# src/system/admin/agent.py
"""
Provides a CLI interface for human operators to directly invoke autonomous agent capabilities like application scaffolding.
"""

from __future__ import annotations

import json
import subprocess
import textwrap

import typer

# --- FIX: Import the new service, not the old client ---
from core.cognitive_service import CognitiveService
from core.file_handler import FileHandler
from core.git_service import GitService
from features.project_lifecycle.scaffolding_service import Scaffolder
from shared.logger import getLogger
from shared.path_utils import get_repo_root

log = getLogger("core_admin.agent")
CORE_ROOT = get_repo_root()

agent_app = typer.Typer(help="Directly invoke autonomous agent capabilities.")


def _extract_json_from_response(text: str):
    """Helper to extract JSON from LLM responses for scaffolding."""
    import re

    match = re.search(r"```json\s*(\{[\s\S]*?\}|\[[\s\S]*?\])\s*```", text, re.DOTALL)
    if match:
        return json.loads(match.group(1))
    return json.loads(text)


# ID: 610428b9-0edd-43be-ae98-8077f1444ad9
def scaffold_new_application(
    project_name: str,
    goal: str,
    cognitive_service: CognitiveService,  # <-- FIX: Takes the service now
    file_handler: FileHandler,
    initialize_git: bool = False,
) -> tuple[bool, str]:
    """Uses an LLM to plan and generate a new, multi-file application."""
    log.info(f"🌱 Starting to scaffold new application '{project_name}'...")
    prompt_template = textwrap.dedent(
        """
        You are a senior software architect. Your task is to design the file structure and content for a new Python application based on a high-level goal.

        **Goal:** "{goal}"

        **Instructions:**
        1.  Think step-by-step about the necessary files for a minimal, working version.
        2.  Your output MUST be a single, valid JSON object with file paths as keys and content as values.
        3.  Include a `pyproject.toml` and a simple `src/main.py`.
        4.  Keep the code simple, clean, and functional.
        """
    ).strip()

    final_prompt = prompt_template.format(goal=goal)
    try:
        # --- FIX: Use the CognitiveService to get the correct client for the job ---
        planner_client = cognitive_service.get_client_for_role("Planner")
        response_text = planner_client.make_request(
            final_prompt, user_id="scaffolding_agent"
        )
        file_structure = _extract_json_from_response(response_text)

        if not isinstance(file_structure, dict):
            raise ValueError("LLM did not return a valid JSON object of files.")

        log.info(f"   -> LLM planned a structure with {len(file_structure)} files.")

        scaffolder = Scaffolder(project_name=project_name)
        scaffolder.scaffold_base_structure()

        for rel_path, content in file_structure.items():
            scaffolder.write_file(rel_path, content)

        log.info("   -> Adding starter test and CI workflow...")
        test_template_path = scaffolder.starter_kit_path / "test_main.py.template"
        ci_template_path = scaffolder.starter_kit_path / "ci.yml.template"

        if test_template_path.exists():
            test_content = test_template_path.read_text(encoding="utf-8").format(
                project_name=project_name
            )
            scaffolder.write_file("tests/test_main.py", test_content)

        if ci_template_path.exists():
            ci_content = ci_template_path.read_text(encoding="utf-8")
            scaffolder.write_file(".github/workflows/ci.yml", ci_content)

        if initialize_git:
            log.info(
                f"   -> Initializing new Git repository in {scaffolder.project_root}..."
            )
            subprocess.run(
                ["git", "init"],
                cwd=scaffolder.project_root,
                check=True,
                capture_output=True,
            )
            new_repo_git = GitService(str(scaffolder.project_root))
            new_repo_git.add(".")
            new_repo_git.commit(f"feat(scaffold): Initial commit for '{project_name}'")

        return (
            True,
            f"✅ Successfully scaffolded '{project_name}' in '{scaffolder.workspace.relative_to(file_handler.repo_path)}'.",
        )

    except Exception as e:
        log.error(f"❌ Scaffolding failed: {e}", exc_info=True)
        return False, f"Scaffolding failed: {str(e)}"


@agent_app.command("scaffold")
# ID: 4c4f91d1-2327-4551-b2e5-578150dac337
def agent_scaffold(
    name: str = typer.Argument(..., help="The directory name for the new application."),
    goal: str = typer.Argument(..., help="A high-level goal for the application."),
    git_init: bool = typer.Option(
        True, "--git/--no-git", help="Initialize a Git repository."
    ),
):
    """Uses an LLM agent to autonomously scaffold a new application."""
    log.info(f"🤖 Invoking Agent to scaffold application '{name}'...")
    log.info(f"   -> Goal: '{goal}'")

    try:
        # --- FIX: Instantiate the service, not the client ---
        cognitive_service = CognitiveService(CORE_ROOT)
        file_handler = FileHandler(str(CORE_ROOT))
        success, message = scaffold_new_application(
            project_name=name,
            goal=goal,
            cognitive_service=cognitive_service,
            file_handler=file_handler,
            initialize_git=git_init,
        )
    except Exception as e:
        log.error(f"❌ Failed to initialize agent tools: {e}", exc_info=True)
        raise typer.Exit(code=1)

    if success:
        typer.secho(f"\n{message}", fg=typer.colors.GREEN)
    else:
        typer.secho(f"\n{message}", fg=typer.colors.RED)
        raise typer.Exit(code=1)


# ID: 66b13d7f-e392-4742-b59f-9f3be3e1f118
def register(app: typer.Typer):
    """Register the 'agent' command group with the main CLI app."""
    app.add_typer(agent_app, name="agent")

--- END OF FILE ./src/cli/commands/agent.py ---

--- START OF FILE ./src/cli/commands/audit_capability_domains.py ---
# src/system/admin/commands/db/audit_capability_domains.py
"""
Provides functionality for the audit_capability_domains module.
"""

from __future__ import annotations

import typer
from sqlalchemy import text

# --- CORRECTED IMPORT ---
from core.db.engine import get_session


async def _audit_queries(limit: int):
    """Audit capabilities database for data quality issues,
    returning counts of total capabilities and lists of keys with
    zero tags, multiple primary domains, legacy domain mismatches,
    and inactive domain tags."""
    # --- CORRECTED USAGE ---
    async with get_session() as session:
        total = (
            await session.execute(text("select count(*) as c from core.capabilities"))
        ).scalar_one()

        zero_tags_stmt = text(
            """
            select c.key
            from core.capabilities c
            where not exists (
              select 1 from core.capability_domains d
              where d.capability_key = c.key
            )
            limit :lim
            """
        ).bindparams(lim=limit)
        zero_tags_rows = (await session.execute(zero_tags_stmt)).scalars().all()

        multi_primary_stmt = text(
            """
            select capability_key
            from core.capability_domains
            group by capability_key
            having sum(case when is_primary then 1 else 0 end) > 1
            limit :lim
            """
        ).bindparams(lim=limit)
        multi_primary_rows = (await session.execute(multi_primary_stmt)).scalars().all()

        legacy_mismatch_stmt = text(
            """
            select c.key
            from core.capabilities c
            where c.domain is not null
              and not exists (
                select 1 from core.capability_domains d
                where d.capability_key = c.key
                  and d.domain_key = c.domain
              )
            limit :lim
            """
        ).bindparams(lim=limit)
        legacy_mismatch_rows = (
            (await session.execute(legacy_mismatch_stmt)).scalars().all()
        )

        inactive_domain_tags_stmt = text(
            """
            select distinct d.capability_key
            from core.capability_domains d
            join core.domains dm on dm.key = d.domain_key
            where dm.status != 'active'
            limit :lim
            """
        ).bindparams(lim=limit)
        inactive_tag_rows = (
            (await session.execute(inactive_domain_tags_stmt)).scalars().all()
        )

        return (
            total,
            zero_tags_rows,
            multi_primary_rows,
            legacy_mismatch_rows,
            inactive_tag_rows,
        )

    """Audit capability domains for common tagging issues and display findings with sample keys."""


# ID: a2d0d438-253f-49ba-82be-10eb2a2a7749
def audit_capability_domains(
    limit: int = typer.Option(
        20, "--limit", help="Max sample keys to show for each finding"
    )
):
    total, zero_tags, multi_primary, legacy_mismatch, inactive_tags = typer.run(
        _audit_queries, limit
    )

    typer.echo(f"Total capabilities: {total}")
    typer.echo(f"Zero tags: {len(zero_tags)}  {zero_tags}")
    typer.echo(f"Multiple primary tags: {len(multi_primary)}  {multi_primary}")
    typer.echo(
        """Register an 'audit-capability-domains' command with the Typer app."""
        f"Legacy domain not among tags: {len(legacy_mismatch)}  {legacy_mismatch}"
    )
    typer.echo(f"Tags on INACTIVE domains: {len(inactive_tags)}  {inactive_tags}")


# ID: d5c37027-bdad-4c56-8c4b-ce4b8ff9467c
def register(app: typer.Typer) -> None:
    app.command("audit-capability-domains")(audit_capability_domains)

--- END OF FILE ./src/cli/commands/audit_capability_domains.py ---

--- START OF FILE ./src/cli/commands/build.py ---
# src/cli/commands/build.py
"""
Registers and implements the 'build' command group for generating
artifacts from the database or constitution.
"""
from __future__ import annotations

import typer

# The old codegraph_builder is no longer a primary artifact.
# It's now implicitly run by 'knowledge sync'.
from features.introspection.generate_capability_docs import (
    main as generate_capability_docs,
)

build_app = typer.Typer(
    help="Commands to build artifacts (e.g., documentation) from the database."
)

build_app.command(
    "capability-docs",
    help="Generate the capability reference documentation from the DB.",
)(generate_capability_docs)


# ID: 2e170c82-210d-401c-a721-6f9d27239a6d
def register(app: typer.Typer) -> None:
    """Register the 'build' command group with the main CLI app."""
    app.add_typer(build_app, name="build")

--- END OF FILE ./src/cli/commands/build.py ---

--- START OF FILE ./src/cli/commands/byor.py ---
# src/system/admin/byor.py
"""
Implements the 'byor-init' command to analyze external repositories and scaffold minimal CORE governance structures.
"""

from __future__ import annotations

from pathlib import Path

import typer
import yaml

from features.introspection.knowledge_graph_service import KnowledgeGraphBuilder
from shared.logger import getLogger

log = getLogger("core_admin.byor")

# --- THIS IS THE FIX ---
# We now point to the 'starter_kits/default' directory as the single
# source of truth for all project scaffolding templates.
CORE_ROOT = Path(__file__).resolve().parents[2]
TEMPLATES_DIR = CORE_ROOT / "system" / "starter_kits" / "default"
# --- END OF FIX ---


# ID: 2c141c77-c07b-48a3-b001-d607d6ed9a39
def initialize_repository(
    path: Path = typer.Argument(
        ...,
        help="The path to the external repository to analyze.",
        exists=True,
        file_okay=False,
        dir_okay=True,
        resolve_path=True,
    ),
    dry_run: bool = typer.Option(
        True,
        "--dry-run/--write",
        help="Show the proposed .intent/ scaffold without writing files. Use --write to apply.",
    ),
):
    """
    Analyzes an external repository and scaffolds a minimal `.intent/` constitution.
    """
    log.info(f"🚀 Starting analysis of repository at: {path}")

    # Step 1: Build the Knowledge Graph.
    log.info("   -> Step 1: Building Knowledge Graph of the target repository...")
    try:
        builder = KnowledgeGraphBuilder(root_path=path)
        graph = builder.build()
        total_symbols = len(graph.get("symbols", {}))
        log.info(
            f"   -> ✅ Knowledge Graph built successfully. Found {total_symbols} symbols."
        )
    except Exception as e:
        log.error(f"   -> ❌ Failed to build Knowledge Graph: {e}", exc_info=True)
        raise typer.Exit(code=1)

    # Step 2: Generate the content for the new constitutional files.
    log.info("   -> Step 2: Generating starter constitution from analysis...")

    # File 1: source_structure.yaml
    domains = builder.domain_map
    source_structure_content = {
        "structure": [
            {
                "domain": name,
                "path": path_str,
                "description": f"Domain for '{name}' inferred by CORE.",
                "allowed_imports": [name, "shared"],
            }
            for path_str, name in domains.items()
        ]
    }

    # File 2: project_manifest.yaml
    discovered_capabilities = sorted(
        list(
            set(
                s["capability"]
                for s in graph.get("symbols", {}).values()
                if s.get("capability") != "unassigned"
            )
        )
    )
    project_manifest_content = {
        "name": path.name,
        "version": "0.1.0-core-scaffold",
        "intent": "A high-level description of what this project is intended to do.",
        "required_capabilities": discovered_capabilities,
    }

    # File 3: capability_tags.yaml (dynamically populated)
    # The content is read from the now-consolidated template file.
    (TEMPLATES_DIR / "capability_tags.yaml.template").read_text()
    capability_tags_content = {
        "tags": [
            {
                "name": cap,
                "description": "A clear explanation of what this capability does.",
            }
            for cap in discovered_capabilities
        ]
    }

    # The files we will create and their content.
    files_to_generate = {
        ".intent/knowledge/source_structure.yaml": source_structure_content,
        ".intent/project_manifest.yaml": project_manifest_content,
        ".intent/knowledge/capability_tags.yaml": capability_tags_content,
        ".intent/mission/principles.yaml": (
            TEMPLATES_DIR / "principles.yaml"
        ).read_text(),
        ".intent/policies/safety_policies.yaml": (
            TEMPLATES_DIR / "safety_policies.yaml"
        ).read_text(),
    }

    # Step 3: Write the files or display the dry run.
    if dry_run:
        log.info("\n💧 Dry Run Mode: No files will be written.")
        for rel_path, content in files_to_generate.items():
            typer.secho(f"\n📄 Proposed `{rel_path}`:", fg=typer.colors.YELLOW)
            if isinstance(content, dict):
                typer.echo(yaml.dump(content, indent=2))
            else:
                typer.echo(content)
    else:
        log.info("\n💾 **Write Mode:** Applying changes to disk.")
        for rel_path, content in files_to_generate.items():
            target_path = path / rel_path
            target_path.parent.mkdir(parents=True, exist_ok=True)
            if isinstance(content, dict):
                target_path.write_text(yaml.dump(content, indent=2))
            else:
                target_path.write_text(content)
            typer.secho(
                f"   -> ✅ Wrote starter file to {target_path}", fg=typer.colors.GREEN
            )

    log.info("\n🎉 BYOR initialization complete.")


# ID: 906f56e6-46e0-4ff1-bd94-3c8dfe8afa10
def register(app: typer.Typer) -> None:
    """Register BYOR commands (e.g., `byor-init`) under the admin CLI."""
    app.command("byor-init")(initialize_repository)

--- END OF FILE ./src/cli/commands/byor.py ---

--- START OF FILE ./src/cli/commands/capability.py ---
# src/cli/commands/capability.py
"""
Provides the 'core-admin capability' command group for managing capabilities
in a constitutionally-aligned way. THIS MODULE IS NOW DEPRECATED and will be
removed after the DB-centric migration is complete.
"""

from __future__ import annotations

import typer
from rich.console import Console

# --- FIX: This command is obsolete and its logic has been moved. ---
# We are commenting it out to fix the import error.
# from .commands.capability.migrate import migrate_to_uuids

console = Console()

capability_app = typer.Typer(help="[DEPRECATED] Create and manage capabilities.")


@capability_app.command("new")
# ID: 628f3738-0aca-4abb-a267-0d1c4a890e5d
def capability_new_deprecated():
    """[DEPRECATED] This command is now obsolete. Use 'knowledge sync' instead."""
    console.print(
        "[bold yellow]⚠️  This command is deprecated and will be removed.[/bold yellow]"
    )
    console.print(
        "   -> Please use '[cyan]poetry run core-admin knowledge sync[/cyan]' to synchronize symbols."
    )


# --- FIX: The migrate-tags command is also obsolete. ---
# @capability_app.command(
#     "migrate-tags",
#     help="[DEPRECATED] Migrates legacy string-based capabilities to stable UUIDs in the DB.",
# )(migrate_to_uuids)


# ID: d90ea0b5-b563-4508-9b1c-1c7c58789141
def register(app: typer.Typer):
    """Register the 'capability' command group with the main CLI app."""
    app.add_typer(capability_app, name="capability")

--- END OF FILE ./src/cli/commands/capability.py ---

--- START OF FILE ./src/cli/commands/chat.py ---
# src/system/admin/chat.py
"""
Implements the 'core-admin chat' command for conversational interaction.
"""

from __future__ import annotations

import json
import subprocess

import typer
from dotenv import load_dotenv

from core.agents.intent_translator import IntentTranslator
from core.cognitive_service import CognitiveService
from shared.config import settings
from shared.logger import getLogger
from shared.utils.parsing import extract_json_from_response

log = getLogger("core_admin.chat")
load_dotenv()


# ID: ab5e8f95-ba22-4845-9903-2aa02b618dd2
def chat(user_input: str = typer.Argument(..., help="Your goal in natural language.")):
    """
    Assesses your natural language goal and provides a clear, actionable command.
    """
    if not settings.LLM_ENABLED:
        log.error(
            "❌ The 'chat' command requires LLMs to be enabled in your .env file."
        )
        raise typer.Exit(code=1)

    log.info(f"Translating user goal: '{user_input}'")

    # --- This is the new, architecturally-aligned logic ---
    # It generates the help text, injects it via the pipeline, and uses the agent.
    try:
        # Generate the CLI help text to use as context
        help_text_result = subprocess.run(
            ["poetry", "run", "core-admin", "--help"],
            capture_output=True,
            text=True,
            check=True,
        )
        help_text = help_text_result.stdout
        help_file = settings.REPO_PATH / "reports" / "cli_help.txt"
        help_file.parent.mkdir(exist_ok=True)
        help_file.write_text(help_text, encoding="utf-8")

        cognitive_service = CognitiveService(settings.REPO_PATH)
        translator = IntentTranslator(cognitive_service)
        response_text = translator.translate(user_input)

        response_json = extract_json_from_response(response_text)
        if not response_json:
            raise json.JSONDecodeError(
                "No valid JSON found in response.", response_text, 0
            )

        if "command" in response_json:
            command = response_json["command"]
            typer.secho("\n✅ AI Suggestion:", fg=typer.colors.GREEN)
            typer.echo("Here is the recommended command to achieve your goal:")
            typer.secho(f"\n  {command}\n", fg=typer.colors.CYAN)
        elif "error" in response_json:
            error_message = response_json["error"]
            typer.secho("\n⚠️ AI Assessment:", fg=typer.colors.YELLOW)
            typer.echo(error_message)
        else:
            raise KeyError("AI response missing 'command' or 'error' key.")

    except (json.JSONDecodeError, KeyError) as e:
        log.error(f"Failed to parse the AI's translation: {e}")
        typer.echo("The AI returned a response I couldn't understand. Raw response:")
        typer.echo(response_text)
        raise typer.Exit(code=1)
    except subprocess.CalledProcessError as e:
        log.error(f"Failed to generate CLI help text: {e.stderr}")
        raise typer.Exit(code=1)
    except Exception as e:
        log.error(f"An unexpected error occurred: {e}", exc_info=True)
        raise typer.Exit(code=1)


# ID: 7989df2a-e653-4b38-afde-adaad2385482
def register(app: typer.Typer):
    """Register the 'chat' command with the main CLI app."""
    app.command("chat")(chat)

--- END OF FILE ./src/cli/commands/chat.py ---

--- START OF FILE ./src/cli/commands/check.py ---
# src/cli/commands/check.py
"""
Registers and implements the 'check' command group by composing
sub-groups for CI and diagnostic commands.
"""
from __future__ import annotations

import typer

from cli.commands.ci import ci_app
from cli.commands.diagnostics import diagnostics_app

check_app = typer.Typer(
    help="Read-only checks to validate constitutional and code health."
)

# Add the sub-groups
check_app.add_typer(ci_app, name="ci", help="High-level CI and system health checks.")
check_app.add_typer(
    diagnostics_app, name="diagnostics", help="Deep diagnostic and integrity checks."
)


# ID: 937c0f11-414e-46f3-b658-1c3debdae051
def register(app: typer.Typer) -> None:
    """Register the 'check' command group with the main CLI app."""
    app.add_typer(check_app, name="check")

--- END OF FILE ./src/cli/commands/check.py ---

--- START OF FILE ./src/cli/commands/ci.py ---
# src/cli/commands/ci.py
"""
Implements high-level CI and system health checks.
"""
from __future__ import annotations

import asyncio
import json
from pathlib import Path

import typer
from rich.console import Console
from rich.json import JSON
from rich.panel import Panel
from rich.table import Table

from cli.commands.cli_utils import (
    _run_poetry_command,
    find_test_file_for_capability_async,
)
from core.service_registry import service_registry
from shared.models.audit_models import AuditSeverity

console = Console()
ci_app = typer.Typer(help="High-level CI and system health checks.")


@ci_app.command(
    "lint",
    help="Check code formatting and quality with Black and Ruff without changing files.",
)
# ID: 8afdeab9-fc81-4d7c-b05f-dd27f936b3e6
def lint():
    """Checks code formatting and quality using Black and Ruff."""
    _run_poetry_command(
        "🔎 Checking code format with Black...", ["black", "--check", "src", "tests"]
    )
    _run_poetry_command(
        "🔎 Checking code quality with Ruff...", ["ruff", "check", "src", "tests"]
    )


@ci_app.command("test", help="Run the pytest suite.")
# ID: f4d514f7-e277-446e-98ff-06e881710a99
def test_system(
    target: str | None = typer.Argument(
        None, help="Optional: A specific test file path or a capability ID."
    )
):
    """Run the pytest suite, optionally targeting a specific test file or capability."""

    async def _async_test_system():
        command = ["pytest"]
        description = "🧪 Running all tests with pytest..."
        if isinstance(target, str):
            target_path = Path(target)
            if target_path.exists() and target_path.is_file():
                command.append(str(target_path))
                description = f"🧪 Running tests for file: {target}"
            else:
                test_file = await find_test_file_for_capability_async(target)
                if test_file:
                    command.append(str(test_file))
                    description = (
                        f"🧪 Running tests for ID '{target}' in {test_file.name}..."
                    )
                else:
                    console.print(
                        f"❌ Could not find a test file for target: '{target}'."
                    )
                    raise typer.Exit(code=1)
        _run_poetry_command(description, command)

    asyncio.run(_async_test_system())


@ci_app.command(
    "audit",
    help="Run the full constitutional self-audit and print a summary of findings.",
)
# --- THIS IS THE FIX ---
# ID: f7bc6512-03d2-4bf9-b718-6fb9323e38ea
def audit(
    severity: str = typer.Option(
        "warning",
        "--severity",
        "-s",
        help="Filter findings by minimum severity level (info, warning, error).",
        case_sensitive=False,
    )
):
    """Run a full constitutional self-audit and print a summary of findings."""

    async def _async_audit():
        auditor = await service_registry.get_service("auditor")
        passed, all_findings, unassigned_count = await auditor.run_full_audit_async()

        try:
            min_severity = AuditSeverity[severity.upper()]
        except KeyError:
            console.print(
                f"[bold red]Invalid severity level '{severity}'. Must be 'info', 'warning', or 'error'.[/bold red]"
            )
            raise typer.Exit(code=1)

        filtered_findings = [f for f in all_findings if f.severity >= min_severity]

        summary_table = Table.grid(expand=True, padding=(0, 1))
        summary_table.add_column(justify="left")
        summary_table.add_column(justify="right", style="bold")
        errors = [f for f in all_findings if f.severity.is_blocking]
        warnings = [f for f in all_findings if f.severity == AuditSeverity.WARNING]
        summary_table.add_row("Errors:", f"[red]{len(errors)}[/red]")
        summary_table.add_row("Warnings:", f"[yellow]{len(warnings)}[/yellow]")
        summary_table.add_row("Unassigned Symbols:", f"[cyan]{unassigned_count}[/cyan]")

        title = "✅ AUDIT PASSED" if passed else "❌ AUDIT FAILED"
        style = "bold green" if passed else "bold red"
        console.print(Panel(summary_table, title=title, style=style, expand=False))

        if filtered_findings:
            console.print("\n[bold]Audit Findings:[/bold]")
            findings_table = Table()
            findings_table.add_column("Severity", style="bold")
            findings_table.add_column("Check ID")
            findings_table.add_column("Message")
            findings_table.add_column("File:Line")

            for f in sorted(filtered_findings, key=lambda x: x.severity, reverse=True):
                color = {"error": "red", "warning": "yellow", "info": "cyan"}.get(
                    str(f.severity), "white"
                )
                loc = (
                    f"{f.file_path}:{f.line_number}"
                    if f.file_path and f.line_number
                    else f.file_path or ""
                )
                findings_table.add_row(
                    f"[{color}]{str(f.severity).upper()}[/{color}]",
                    f.check_id,
                    f.message,
                    loc,
                )

            console.print(findings_table)

        if not passed:
            raise typer.Exit(1)

    asyncio.run(_async_audit())


# --- END OF FIX ---


@ci_app.command(
    "report", help="Run a full audit and save the detailed findings to a JSON file."
)
# ID: 745c70cf-6fc7-4b31-aaa0-ef27bcacc695
def audit_report(
    output_path: Path = typer.Option(
        "reports/audit_report.json",
        "--output",
        "-o",
        help="Path to save the JSON report file.",
    ),
    severity: str = typer.Option(
        "info",
        "--severity",
        "-s",
        help="Filter findings by minimum severity level (info, warning, error).",
        case_sensitive=False,
    ),
):
    """Runs a full constitutional audit and saves the detailed findings to a JSON file."""
    console.print(
        f"[bold cyan]🚀 Running full audit and generating report (min-severity: {severity})...[/bold cyan]"
    )

    async def _async_audit_report():
        auditor = await service_registry.get_service("auditor")
        passed, all_findings, unassigned_count = await auditor.run_full_audit_async()

        try:
            min_severity = AuditSeverity[severity.upper()]
        except KeyError:
            console.print(
                f"[bold red]Invalid severity level '{severity}'. Must be 'info', 'warning', or 'error'.[/bold red]"
            )
            raise typer.Exit(code=1)

        filtered_findings = [f for f in all_findings if f.severity >= min_severity]

        report = {
            "passed": passed,
            "summary": {
                "errors": len([f for f in all_findings if f.severity.is_blocking]),
                "warnings": len(
                    [f for f in all_findings if f.severity == AuditSeverity.WARNING]
                ),
                "unassigned_symbols": unassigned_count,
            },
            "findings": [f.as_dict() for f in filtered_findings],
        }

        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(json.dumps(report, indent=2))

        console.print(
            f"[bold green]✅ Audit report saved to: {output_path}[/bold green]"
        )
        console.print(JSON(json.dumps(report["summary"])))

    asyncio.run(_async_audit_report())

--- END OF FILE ./src/cli/commands/ci.py ---

--- START OF FILE ./src/cli/commands/cli_utils.py ---
# src/cli/commands/cli_utils.py
"""
Provides centralized, reusable utilities for standardizing the console output
and execution of all `core-admin` commands.
"""

from __future__ import annotations

import json
import shutil
import subprocess
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional

import typer
import yaml
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import ed25519
from rich.console import Console

from core.knowledge_service import KnowledgeService
from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.cli_utils")
console = Console()


def _run_poetry_command(description: str, command: list[str]):
    """Helper to run a command via Poetry, log it, and handle errors."""
    POETRY_EXECUTABLE = shutil.which("poetry")
    if not POETRY_EXECUTABLE:
        log.error("❌ Could not find 'poetry' executable in your PATH.")
        raise typer.Exit(code=1)

    typer.secho(f"\n{description}", bold=True)
    full_command = [POETRY_EXECUTABLE, "run", *command]
    try:
        result = subprocess.run(
            full_command, check=True, text=True, capture_output=True
        )
        if result.stdout:
            console.print(result.stdout)
        if result.stderr:
            console.print(f"[yellow]{result.stderr}[/yellow]")
    except subprocess.CalledProcessError as e:
        log.error(f"\n❌ Command failed: {' '.join(full_command)}")
        if e.stdout:
            console.print(e.stdout)
        if e.stderr:
            console.print(f"[bold red]{e.stderr}[/bold red]")
        raise typer.Exit(code=1)


# ID: 76d0313a-1d12-4ea2-9c98-e1d44283bb86
async def find_test_file_for_capability_async(capability_key: str) -> Optional[Path]:
    """
    Asynchronously finds the test file corresponding to a given capability key.
    """
    log.debug(f"Searching for test file for capability: '{capability_key}'")
    try:
        knowledge_service = KnowledgeService(settings.REPO_PATH)
        graph = await knowledge_service.get_graph()
        symbols = graph.get("symbols", {})

        source_file_str = None
        for symbol in symbols.values():
            if symbol.get("key") == capability_key:
                source_file_str = symbol.get("file_path")
                break

        if not source_file_str:
            log.warning(f"Capability '{capability_key}' not found in knowledge graph.")
            return None

        p = Path(source_file_str)
        test_file_path = (
            settings.REPO_PATH / "tests" / p.relative_to("src")
        ).with_name(f"test_{p.name}")

        if test_file_path.exists():
            log.debug(f"Found corresponding test file at: {test_file_path}")
            return test_file_path
        else:
            log.warning(f"Conventional test file not found at: {test_file_path}")
            return None
    except Exception as e:
        log.error(f"Error processing knowledge graph: {e}")
        return None


# ID: 2c1e24f9-42a8-4851-92da-c0276e902551
def load_yaml_file(path: Path) -> Dict[str, Any]:
    """Loads a YAML file safely."""
    return yaml.safe_load(path.read_text(encoding="utf-8")) or {}


# ID: 8400dcf6-6bea-4d10-9dd3-4d07416f0366
def save_yaml_file(path: Path, data: Dict[str, Any]) -> None:
    """Saves data to a YAML file with consistent sorting."""
    path.write_text(yaml.dump(data, sort_keys=True), encoding="utf-8")


# ID: ae41777a-644b-4dc7-8f08-f577060af15b
def load_private_key() -> ed25519.Ed25519PrivateKey:
    """Loads the operator's private key."""
    key_path = settings.KEY_STORAGE_DIR / "private.key"
    if not key_path.exists():
        log.error(
            "❌ Private key not found. Please run 'core-admin keygen' to create one."
        )
        raise typer.Exit(code=1)
    return serialization.load_pem_private_key(key_path.read_bytes(), password=None)


# ID: eebbca97-f3ba-46f0-a6dd-af189bfaf93c
def archive_rollback_plan(proposal_name: str, proposal: Dict[str, Any]) -> None:
    """Archives a proposal's rollback plan upon approval."""
    rollback_plan = proposal.get("rollback_plan")
    if not rollback_plan:
        return
    rollbacks_dir = settings.MIND / "constitution" / "rollbacks"
    rollbacks_dir.mkdir(parents=True, exist_ok=True)
    archive_path = (
        rollbacks_dir
        / f"{datetime.utcnow().strftime('%Y%m%d%H%M%S')}-{proposal_name}.json"
    )
    archive_path.write_text(
        json.dumps(
            {
                "proposal_name": proposal_name,
                "target_path": proposal.get("target_path"),
                "justification": proposal.get("justification"),
                "rollback_plan": rollback_plan,
            },
            indent=2,
        ),
        encoding="utf-8",
    )
    log.info(f"📖 Rollback plan archived to {archive_path}")


# ID: 3c3a57ba-7b53-42ab-b544-ffe0fb9f6f24
def should_fail(report: dict, fail_on: str) -> bool:
    """
    Determines if the CLI should exit with an error code based on the drift
    report and the specified fail condition.
    """
    if fail_on == "missing":
        return bool(report.get("missing_in_code"))
    if fail_on == "undeclared":
        return bool(report.get("undeclared_in_manifest"))
    return bool(
        report.get("missing_in_code")
        or report.get("undeclared_in_manifest")
        or report.get("mismatched_mappings")
    )

--- END OF FILE ./src/cli/commands/cli_utils.py ---

--- START OF FILE ./src/cli/commands/db.py ---
# src/cli/commands/db.py
"""
Registers the top-level 'db' command group for managing the CORE operational database.
"""
from __future__ import annotations

import asyncio

import typer
import yaml
from rich.console import Console
from sqlalchemy import text

from cli.commands.migrate import migrate_db
from cli.commands.status import status
from cli.commands.sync_domains import sync_domains
from services.repositories.db.engine import get_session
from shared.config import settings

console = Console()
db_app = typer.Typer(
    help="Commands for managing the CORE operational database (migrations, syncs, status, exports)."
)

# --- NEW EXPORT COMMAND LOGIC ---


async def _export_domains():
    """Fetches domains from the DB and writes them to domains.yaml."""
    console.print("   -> Exporting `core.domains` to YAML...")
    async with get_session() as session:
        result = await session.execute(
            text(
                "SELECT key as name, title, description FROM core.domains ORDER BY key"
            )
        )
        domains_data = [dict(row._mapping) for row in result]

    # --- THIS IS THE FINAL FIX ---
    # Construct the path using settings.MIND, which correctly points to .intent/mind
    output_path = settings.MIND / "knowledge" / "domains.yaml"
    # --- END OF FINAL FIX ---

    output_path.parent.mkdir(parents=True, exist_ok=True)
    # The structure should match the original file for compatibility
    yaml_content = {"version": 2, "domains": domains_data}
    output_path.write_text(yaml.dump(yaml_content, indent=2, sort_keys=False), "utf-8")
    console.print(
        f"      -> Wrote {len(domains_data)} domains to {output_path.relative_to(settings.REPO_PATH)}"
    )


async def _export_vector_metadata():
    """Fetches vector metadata from the DB and writes it to a report."""
    console.print("   -> Exporting vector metadata from `core.symbols` to YAML...")
    async with get_session() as session:
        result = await session.execute(
            text(
                """
            SELECT uuid, symbol_path, vector_id
            FROM core.symbols
            WHERE vector_id IS NOT NULL
            ORDER BY symbol_path
        """
            )
        )
        vector_data = [dict(row._mapping) for row in result]

    output_path = settings.REPO_PATH / "reports" / "vector_metadata_export.yaml"
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(yaml.dump(vector_data, indent=2, sort_keys=False), "utf-8")
    console.print(
        f"      -> Wrote metadata for {len(vector_data)} vectors to {output_path.relative_to(settings.REPO_PATH)}"
    )


@db_app.command(
    "export", help="Export operational data from the database to read-only files."
)
# ID: a226b858-1e99-4443-8d18-a2cf0ecafba3
def export_data():
    """Exports DB tables to their canonical, read-only YAML file representations."""
    console.print(
        "[bold cyan]🚀 Exporting operational data from Database to files...[/bold cyan]"
    )

    async def _run_exports():
        await _export_domains()
        await _export_vector_metadata()

    asyncio.run(_run_exports())
    console.print("[bold green]✅ Export complete.[/bold green]")


# --- EXISTING COMMANDS ---
db_app.command("status")(status)
db_app.command("sync-domains")(sync_domains)
db_app.command("migrate")(migrate_db)


# ID: a2e89177-868c-4a49-9f05-87b9f43f0bfc
def register(app: typer.Typer):
    """Register the 'db' command group with the main CLI app."""
    app.add_typer(db_app, name="db")

--- END OF FILE ./src/cli/commands/db.py ---

--- START OF FILE ./src/cli/commands/db_manage.py ---
from __future__ import annotations

import typer

# Generic DB commands: `core-admin db ...`
from .db import app as db_app

# Knowledge DB sub-commands live under `knowledge db ...`
# We assemble a small "knowledge" group here and mount its `db` sub-app,
# so existing commands like `core-admin knowledge db import-from-graph` keep working.
from .db import app as knowledge_db_app

# Top-level Typer app exposed by this module
app = typer.Typer(help="Database management meta-commands")

# Mount groups
app.add_typer(db_app, name="db")

knowledge_app = typer.Typer(help="Knowledge operations")
knowledge_app.add_typer(knowledge_db_app, name="db")
app.add_typer(knowledge_app, name="knowledge")

__all__ = ["app"]

--- END OF FILE ./src/cli/commands/db_manage.py ---

--- START OF FILE ./src/cli/commands/diagnostics.py ---
# src/cli/commands/diagnostics.py
"""
Implements deep diagnostic checks for system integrity and constitutional alignment.
"""
from __future__ import annotations

import asyncio
import json

import jsonschema
import typer
import yaml
from rich.console import Console
from rich.table import Table
from rich.tree import Tree
from ruamel.yaml import YAML

from features.governance.audit_context import AuditorContext
from features.governance.checks.domain_placement import DomainPlacementCheck
from features.governance.checks.legacy_tag_check import LegacyTagCheck
from features.governance.policy_coverage_service import PolicyCoverageService
from features.introspection.audit_unassigned_capabilities import get_unassigned_symbols
from shared.config import settings
from shared.models import AuditSeverity
from shared.utils.constitutional_parser import get_all_constitutional_paths

console = Console()
yaml_loader = YAML(typ="safe")
diagnostics_app = typer.Typer(help="Deep diagnostic and integrity checks.")


def _add_cli_nodes(tree_node: Tree, cli_app: typer.Typer):
    for cmd_info in sorted(cli_app.registered_commands, key=lambda c: c.name or ""):
        if not cmd_info.name:
            continue
        help_text = cmd_info.help.split("\n")[0] if cmd_info.help else ""
        tree_node.add(
            f"[bold yellow]⚡ {cmd_info.name}[/bold yellow] [dim]- {help_text}[/dim]"
        )
    for group_info in sorted(cli_app.registered_groups, key=lambda g: g.name or ""):
        if not group_info.name:
            continue
        help_text = (
            group_info.typer_instance.info.help.split("\n")[0]
            if group_info.typer_instance.info.help
            else ""
        )
        branch = tree_node.add(
            f"[cyan]📂 {group_info.name}[/cyan] [dim]- {help_text}[/dim]"
        )
        _add_cli_nodes(branch, group_info.typer_instance)


@diagnostics_app.command(
    "cli-tree", help="Displays a hierarchical tree view of all available CLI commands."
)
# ID: f4d5a5e3-1b9c-4e8a-9f7b-6c0d2e1a3b4c
def cli_tree():
    from cli.admin_cli import app as main_app

    console.print("[bold cyan]🚀 Building CLI Command Tree...[/bold cyan]")
    tree = Tree(
        "[bold magenta]🏛️ CORE Admin CLI Commands[/bold magenta]",
        guide_style="bold bright_blue",
    )
    _add_cli_nodes(tree, main_app)
    console.print(tree)


@diagnostics_app.command(
    "policy-coverage", help="Audits the constitution for policy coverage and integrity."
)
# ID: 74d7e7fd-1f68-4c4c-9dfb-285d1d7ee853
def policy_coverage():
    """
    Runs a meta-audit on all .intent/charter/policies/ to ensure they are
    well-formed and covered by the governance model.
    """
    console.print(
        "[bold cyan]🚀 Running Constitutional Policy Coverage Audit...[/bold cyan]"
    )
    service = PolicyCoverageService()
    report = service.run()

    console.print(f"Report ID: [dim]{report.report_id}[/dim]")
    console.print(f"Policies Seen: {report.summary['policies_seen']}")
    console.print(f"Rules Found: {report.summary['rules_found']}")
    console.print(f"Uncovered Rules: {report.summary['uncovered_rules']}")

    if report.summary["uncovered_rules"] > 0:
        table = Table(title="Uncovered Policy Rules")
        table.add_column("Policy", style="cyan")
        table.add_column("Rule ID", style="magenta")
        table.add_column("Enforcement", style="yellow")
        for record in report.records:
            if not record["covered"]:
                table.add_row(
                    record["policy_id"], record["rule_id"], record["enforcement"]
                )
        console.print(table)

    if report.exit_code != 0:
        console.print(
            f"\n[bold red]❌ Audit Failed with exit code: {report.exit_code}[/bold red]"
        )
        raise typer.Exit(code=report.exit_code)
    else:
        console.print(
            "\n[bold green]✅ All active policies are well-formed and covered.[/bold green]"
        )


@diagnostics_app.command(
    "debug-meta", help="Prints the auditor's view of all required constitutional files."
)
# ID: c4dba9d9-6c1a-4328-b473-2e3286e9d291
def debug_meta_paths():
    """A diagnostic tool to debug the constitutional file parser."""
    console.print(
        "[bold yellow]--- Auditor's Interpretation of meta.yaml ---[/bold yellow]"
    )
    intent_dir = settings.REPO_PATH / ".intent"
    required_paths = get_all_constitutional_paths(intent_dir)

    for path in sorted(list(required_paths)):
        console.print(path)


@diagnostics_app.command(
    "unassigned-symbols", help="Finds symbols without a universal # ID tag."
)
# ID: 41fdbad2-2bc4-4a4d-85c8-5f30461a4af0
def unassigned_symbols():
    # This now correctly uses the new ID-based terminology
    unassigned = get_unassigned_symbols()
    if not unassigned:
        console.print(
            "[bold green]✅ Success! All governable symbols have an assigned ID tag.[/bold green]"
        )
        return
    console.print(
        f"\n[bold red]❌ Found {len(unassigned)} symbols with no assigned ID:[/bold red]"
    )
    table = Table(title="Untagged Symbols ('Orphaned Logic')")
    table.add_column("Symbol Key", style="cyan", no_wrap=True)
    table.add_column("File", style="yellow")
    table.add_column("Line", style="magenta")
    for symbol in sorted(unassigned, key=lambda s: s["key"]):
        table.add_row(symbol["key"], symbol["file"], str(symbol["line_number"]))
    console.print(table)
    console.print("\n[bold]Action Required:[/bold] Run 'knowledge sync' to assign IDs.")


@diagnostics_app.command(
    "manifest-hygiene",
    help="Checks for capabilities declared in the wrong domain manifest file.",
)
# ID: a85348ac-fe9e-49d5-8b11-3a105a57a7e3
def manifest_hygiene():
    context = AuditorContext(settings.REPO_PATH)
    check = DomainPlacementCheck(context)
    findings = check.execute()
    if not findings:
        console.print(
            "[bold green]✅ All capabilities correctly placed in domain manifests[/bold green]"
        )
        raise typer.Exit(code=0)
    errors = [f for f in findings if f.severity == AuditSeverity.ERROR]
    if errors:
        console.print(f"[bold red]🚨 {len(errors)} CRITICAL errors found:[/bold red]")
        for f in errors:
            console.print(f"  [red]{f}[/red]")
    if warnings := [f for f in findings if f.severity == AuditSeverity.WARNING]:
        console.print(f"[bold yellow]⚠️  {len(warnings)} warnings found:[/bold yellow]")
        for f in warnings:
            console.print(f"  [yellow]{f}[/yellow]")
    raise typer.Exit(code=1 if errors else 0)


@diagnostics_app.command(
    "cli-registry", help="Validates the CLI registry against its constitutional schema."
)
# ID: 58a9d61e-9899-4a10-bee2-c5473b3a91ba
def cli_registry():
    meta_content = (settings.REPO_PATH / ".intent" / "meta.yaml").read_text("utf-8")
    meta = yaml.safe_load(meta_content) or {}

    knowledge = meta.get("mind", {}).get("knowledge", {})
    schemas = meta.get("charter", {}).get("schemas", {})

    registry_rel = knowledge.get("cli_registry", "mind/knowledge/cli_registry.yaml")
    schema_rel = schemas.get(
        "cli_registry_schema", "charter/schemas/cli_registry_schema.json"
    )

    registry_path = (settings.REPO_PATH / registry_rel).resolve()
    schema_path = (settings.REPO_PATH / schema_rel).resolve()

    if not registry_path.exists():
        typer.secho(
            f"ERROR: CLI registry not found: {registry_path}",
            err=True,
            fg=typer.colors.RED,
        )
        raise typer.Exit(1)
    if not schema_path.exists():
        typer.secho(
            f"ERROR: CLI registry schema not found: {schema_path}",
            err=True,
            fg=typer.colors.RED,
        )
        raise typer.Exit(1)

    registry_content = registry_path.read_text("utf-8")
    registry = yaml.safe_load(registry_content) or {}

    schema_content = schema_path.read_text(encoding="utf-8")
    schema = json.loads(schema_content)

    validator = jsonschema.Draft202012Validator(schema)
    errors = sorted(validator.iter_errors(registry), key=lambda e: e.path)
    if errors:
        typer.secho(
            f"❌ CLI registry failed validation against {schema_rel}",
            err=True,
            fg=typer.colors.RED,
        )
        for idx, err in enumerate(errors, 1):
            loc = "/".join(map(str, err.path)) or "(root)"
            typer.secho(
                f"  {idx}. at {loc}: {err.message}", err=True, fg=typer.colors.RED
            )
        raise typer.Exit(1)
    typer.secho(f"✅ CLI registry is valid: {registry_rel}", fg=typer.colors.GREEN)


@diagnostics_app.command("legacy-tags", help="Scans the codebase for obsolete tags.")
# ID: 2992fdb2-9b35-478d-a8df-28f23a7d605b
def check_legacy_tags():
    """Runs only the LegacyTagCheck to find obsolete capability tags."""

    async def _async_check_legacy_tags():
        console.print(
            "[bold cyan]🚀 Running standalone legacy tag check...[/bold cyan]"
        )

        context = AuditorContext(settings.REPO_PATH)

        check = LegacyTagCheck(context)
        findings = check.execute()

        if not findings:
            console.print("[bold green]✅ Success! No legacy tags found.[/bold green]")
            return

        console.print(
            f"\n[bold red]❌ Found {len(findings)} instance(s) of legacy tags:[/bold red]"
        )

        # --- THIS IS THE FIX ---
        # Instantiate the Table object before using it.
        table = Table(title="Obsolete Tag Violations")
        # --- END OF FIX ---

        table.add_column("File Path", style="cyan", no_wrap=True)
        table.add_column("Line", style="magenta")
        table.add_column("Message", style="red")

        for finding in findings:
            table.add_row(finding.file_path, str(finding.line_number), finding.message)

        console.print(table)
        raise typer.Exit(code=1)

    asyncio.run(_async_check_legacy_tags())

--- END OF FILE ./src/cli/commands/diagnostics.py ---

--- START OF FILE ./src/cli/commands/embeddings_cli.py ---
# src/system/admin/embeddings_cli.py
"""
CLI wiring for embeddings & vectorization commands.
Exposes: `core-admin knowledge vectorize [--write|--dry-run] [--cap capability --cap ...]`
"""

from __future__ import annotations

from pathlib import Path
from typing import Optional, Set

import typer

from core.cognitive_service import CognitiveService
from core.knowledge_service import KnowledgeService
from services.clients.qdrant_client import QdrantService
from shared.logger import getLogger

from .knowledge_orchestrator import run_vectorize

log = getLogger("core_admin.embeddings_cli")

app = typer.Typer(
    name="knowledge", no_args_is_help=True, help="Knowledge graph & embeddings commands"
)


@app.command("vectorize")
# ID: ed834afd-2224-421d-9a8e-a117526fd7b8
def vectorize_cmd(
    write: bool = typer.Option(
        False, "--write", help="Persist changes to knowledge graph after run."
    ),
    dry_run: bool = typer.Option(
        False, "--dry-run", help="Do not upsert to Qdrant, simulate only."
    ),
    verbose: bool = typer.Option(
        False, "--verbose", help="Verbose logging / stack traces."
    ),
    cap: Optional[list[str]] = typer.Option(
        None, "--cap", help="Limit to specific capability keys (repeatable)."
    ),
    flush_every: int = typer.Option(
        10, "--flush-every", help="Flush/save cadence (N processed chunks)."
    ),
):
    """
    Vectorize code chunks into Qdrant with per-chunk idempotency.
    """
    repo_root = Path(".").resolve()

    # --- Load current knowledge graph ---
    ks = KnowledgeService()
    knowledge = ks.load_graph()  # <-- adjust if your service uses a different name
    symbols_map: dict = knowledge.get("symbols", knowledge)  # support both styles

    # --- Resources ---
    cognitive = CognitiveService()
    qdrant = QdrantService()  # relies on your settings/env

    targets: Optional[Set[str]] = set(cap) if cap else None

    # --- Run orchestrator ---
    typer.echo("🚀 Starting capability vectorization process (per-chunk idempotent)…")
    import asyncio

    asyncio.run(
        run_vectorize(
            repo_root=repo_root,
            symbols_map=symbols_map,
            cognitive_service=cognitive,
            qdrant_service=qdrant,
            dry_run=dry_run,
            verbose=verbose,
            target_capabilities=targets,
            flush_every=flush_every,
        )
    )

    # --- Persist knowledge graph only if requested ---
    if write and not dry_run:
        ks.save_graph(knowledge)  # <-- adjust if your service uses a different name
        typer.echo("📝 Saved updated knowledge graph.")
    else:
        typer.echo("ℹ️ Not saving graph (use --write and disable --dry-run to persist).")


# ID: 23050288-a833-419e-a5fd-5cb9d8ec2112
def register(app_root):
    """
    Hook for system.admin.__init__.py to mount this CLI group.
    Usage: app_root.add_typer(app, name="knowledge")
    """
    app_root.add_typer(app, name="knowledge")

--- END OF FILE ./src/cli/commands/embeddings_cli.py ---

--- START OF FILE ./src/cli/commands/fixer.py ---
# src/cli/commands/fixer.py
"""
Registers all self-healing and code quality improvement commands that WRITE changes
to the codebase or constitution. This is the single entry point for all 'fix' commands.
"""
from __future__ import annotations

import asyncio
from pathlib import Path
from typing import Optional

import typer
from rich.console import Console

from cli.commands.cli_utils import _run_poetry_command
from core.agents.tagger_agent import CapabilityTaggerAgent
from core.cognitive_service import CognitiveService
from core.knowledge_service import KnowledgeService
from features.introspection.knowledge_graph_service import KnowledgeGraphBuilder
from features.self_healing.clarity_service import fix_clarity
from features.self_healing.complexity_service import complexity_outliers
from features.self_healing.docstring_service import fix_docstrings
from features.self_healing.header_service import _run_header_fix_cycle
from features.self_healing.id_tagging_service import assign_missing_ids
from features.self_healing.linelength_service import fix_line_lengths
from features.self_healing.policy_id_service import add_missing_policy_ids
from features.self_healing.prune_orphaned_vectors import (
    main_sync as prune_orphaned_vectors,
)
from features.self_healing.prune_private_capabilities import (
    main as prune_private_capabilities,
)
from features.self_healing.purge_legacy_tags_service import purge_legacy_tags
from services.repositories.db.engine import get_session
from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.fix")
console = Console()
REPO_ROOT = settings.REPO_PATH


fix_app = typer.Typer(
    help="Self-healing tools that write changes to fix constitutional violations."
)


@fix_app.command(
    "format", help="Auto-format all code to be constitutionally compliant."
)
# ID: ac0d6bc3-83d5-44c4-8755-222205b77f15
def format_code_wrapper():
    """Format all code in the `src` and `tests` directories using Black and Ruff with automatic fixes."""
    _run_poetry_command("✨ Formatting code with Black...", ["black", "src", "tests"])
    _run_poetry_command(
        "✨ Fixing code with Ruff...", ["ruff", "check", "src", "tests", "--fix"]
    )


@fix_app.command(
    "headers",
    help="Enforces constitutional header conventions on Python files.",
)
# ID: 51be431e-c7b4-4b76-8c32-bd6ce9acad9f
def fix_headers_cmd(
    file_path: Optional[Path] = typer.Argument(
        None,
        help="Optional: A specific file to fix. If omitted, all project files are scanned.",
        exists=True,
        dir_okay=False,
        resolve_path=True,
    ),
    write: bool = typer.Option(
        False, "--write", help="Apply the changes to the files."
    ),
):
    """User-friendly wrapper for the header fixing logic."""
    dry_run = not write
    files_to_process = []
    if file_path:
        log.info(f"🎯 Targeting a single file for header fixing: {file_path}")
        files_to_process.append(str(file_path.relative_to(REPO_ROOT)))
    else:
        log.info("Scanning all Python files in the 'src' directory...")
        src_dir = REPO_ROOT / "src"
        all_py_files = src_dir.rglob("*.py")
        files_to_process = sorted([str(p.relative_to(REPO_ROOT)) for p in all_py_files])

    _run_header_fix_cycle(dry_run, files_to_process)

    if not dry_run:
        log.info("🧠 Rebuilding knowledge graph to reflect all changes...")
        builder = KnowledgeGraphBuilder(REPO_ROOT)
        builder.build_and_sync()
        log.info("✅ Knowledge graph successfully updated.")


@fix_app.command(
    "tags",
    help="Finds unassigned capabilities and registers them in the database.",
)
# ID: 05d13ed4-367f-4ac8-a611-730798157b8c
def fix_tags_cmd_wrapper(
    file_path: Optional[Path] = typer.Argument(
        None, help="Optional: Path to a specific file."
    ),
    write: bool = typer.Option(
        False, "--write", help="Apply the suggested tags to files and DB."
    ),
):
    """Wrapper for the CapabilityTaggerAgent that writes to the database."""

    async def _async_fix_tags():
        knowledge_service = KnowledgeService(settings.REPO_PATH)
        cognitive_service = CognitiveService(settings.REPO_PATH)
        agent = CapabilityTaggerAgent(cognitive_service, knowledge_service)

        suggestions = await agent.suggest_and_apply_tags(
            file_path=file_path.as_posix() if file_path else None
        )

        if not suggestions:
            console.print(
                "[bold green]✅ No new public capabilities to register.[/bold green]"
            )
            return

        if not write:
            console.print(
                "[bold yellow]💧 Dry Run: Run with --write to register new capabilities.[/bold yellow]"
            )
            return

        console.print(
            f"\n[bold green]✅ Applying {len(suggestions)} new capability tags to source code...[/bold green]"
        )

        async with get_session() as session:
            async with session.begin():
                for key, new_info in suggestions.items():
                    suggested_name = new_info["suggestion"]

                    graph = await knowledge_service.get_graph()
                    source_file_path = REPO_ROOT / new_info["file"]
                    lines = source_file_path.read_text("utf-8").splitlines()
                    symbol_data = graph["symbols"][new_info["key"]]
                    line_to_tag = symbol_data["line_number"] - 1

                    original_line = lines[line_to_tag]
                    indentation = len(original_line) - len(original_line.lstrip(" "))
                    tag_line = f"{' ' * indentation}# ID: {suggested_name}"

                    lines.insert(line_to_tag, tag_line)
                    source_file_path.write_text(
                        "\n".join(lines) + "\n", encoding="utf-8"
                    )
                    console.print(
                        f"   -> Tagged '{suggested_name}' in {new_info['file']}"
                    )

        log.info("🧠 Rebuilding knowledge graph to reflect changes...")
        builder = KnowledgeGraphBuilder(REPO_ROOT)
        builder.build_and_sync()
        log.info("✅ Knowledge graph successfully updated.")

    asyncio.run(_async_fix_tags())


fix_app.command(
    "orphaned-vectors", help="Finds and deletes orphaned vectors from Qdrant."
)(prune_orphaned_vectors)
fix_app.command(
    "private-capabilities", help="Removes #CAPABILITY tags from private symbols."
)(prune_private_capabilities)
fix_app.command("complexity", help="Identifies and refactors complexity outliers.")(
    complexity_outliers
)
fix_app.command("line-lengths", help="Refactors files with long lines.")(
    fix_line_lengths
)
fix_app.command("docstrings", help="Adds missing docstrings.")(fix_docstrings)
fix_app.command("clarity", help="Refactors a file for clarity.")(fix_clarity)


@fix_app.command(
    "purge-legacy-tags", help="Finds and removes all obsolete '# CAPABILITY:' tags."
)
# ID: 14aa94ca-ab55-4a91-9507-ca959a894a18
def purge_legacy_tags_command(
    write: bool = typer.Option(
        False,
        "--write",
        help="Apply the changes and permanently delete the legacy tags.",
    ),
):
    """
    CLI wrapper for the legacy tag purging service.
    """
    dry_run = not write
    total_removed = purge_legacy_tags(dry_run=dry_run)

    console.print("\n--- Purge Complete ---")
    if dry_run:
        console.print(f"💧 DRY RUN: Found {total_removed} total legacy tags to remove.")
        console.print("   Run with '--write' to apply these changes.")
    else:
        console.print(f"✅ APPLIED: Successfully removed {total_removed} legacy tags.")
        console.print(
            "\n[bold]NEXT STEP:[/bold] Run 'poetry run core-admin knowledge sync --write' to update the database."
        )


@fix_app.command(
    "assign-ids", help="Assigns a stable '# ID: <uuid>' to all untagged public symbols."
)
# ID: 103780db-c852-4026-a296-3e1c68e19246
def assign_ids_command(
    write: bool = typer.Option(
        False, "--write", help="Apply the changes and add new ID tags to source files."
    ),
):
    """
    CLI wrapper for the symbol ID tagging service.
    """
    dry_run = not write
    total_assigned = assign_missing_ids(dry_run=dry_run)

    console.print("\n--- ID Assignment Complete ---")
    if dry_run:
        console.print(
            f"💧 DRY RUN: Found {total_assigned} public symbols that need an ID."
        )
        console.print("   Run with '--write' to apply these changes.")
    else:
        console.print(f"✅ APPLIED: Successfully assigned {total_assigned} new IDs.")
        console.print(
            "\n[bold]NEXT STEP:[/bold] Run 'poetry run core-admin knowledge sync --write' to update the database."
        )


# --- THIS IS THE NEW COMMAND ---
@fix_app.command(
    "policy-ids", help="Adds a UUID to all policy files that are missing one."
)
# ID: 81a2b3c4-d5e6-f7a8-b9c0-d1e2f3a4b5c6
def fix_policy_ids_command(
    write: bool = typer.Option(
        False, "--write", help="Apply the changes and add new IDs to policy files."
    ),
):
    """CLI wrapper for the policy ID migration service."""
    dry_run = not write
    total_updated = add_missing_policy_ids(dry_run=dry_run)

    console.print("\n--- Policy ID Migration Complete ---")
    if dry_run:
        console.print(f"💧 DRY RUN: Found {total_updated} policies that need a UUID.")
        console.print("   Run with '--write' to apply these changes.")
    else:
        console.print(f"✅ APPLIED: Successfully updated {total_updated} policies.")
        console.print(
            "\n[bold]NEXT STEP:[/bold] Run 'poetry run core-admin check ci audit' to verify constitutional compliance."
        )


# --- END OF NEW COMMAND ---


# ID: a119b740-e2ef-4386-9ef1-ac607e4128e2
def register(app: typer.Typer):
    """Register the consolidated 'fix' command group with the main CLI app."""
    app.add_typer(fix_app, name="fix")

--- END OF FILE ./src/cli/commands/fixer.py ---

--- START OF FILE ./src/cli/commands/guard.py ---
# src/cli/commands/guard.py
"""
Intent: Governance/validation guard commands exposed to the operator.
"""
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
import yaml
from rich import print as rprint
from rich.panel import Panel
from rich.table import Table

from shared.logger import getLogger

log = getLogger("core_admin")


def _find_manifest_path(root: Path, explicit: Optional[Path]) -> Optional[Path]:
    """Locate and return the path to the project manifest file, or None."""
    if explicit and explicit.exists():
        return explicit
    for p in (root / ".intent/project_manifest.yaml", root / ".intent/manifest.yaml"):
        if p.exists():
            return p
    return None


def _load_raw_manifest(root: Path, explicit: Optional[Path]) -> Dict[str, Any]:
    """Loads and parses a YAML manifest file, returning an empty dict if not found."""
    path = _find_manifest_path(root, explicit)
    if not path:
        return {}
    data = yaml.safe_load(path.read_text(encoding="utf-8")) or {}
    return data


def _ux_defaults(root: Path, explicit: Optional[Path]) -> Dict[str, Any]:
    """Extracts and returns UX-related default values from the manifest."""
    raw = _load_raw_manifest(root, explicit)
    ux = raw.get("operator_experience", {}).get("guard", {}).get("drift", {})
    return {
        "default_format": ux.get("default_format", "json"),
        "default_fail_on": ux.get("default_fail_on", "any"),
        "strict_default": bool(ux.get("strict_default", False)),
        "evidence_json": bool(ux.get("evidence_json", True)),
        "evidence_path": ux.get("evidence_path", "reports/drift_report.json"),
        "labels": ux.get(
            "labels",
            {
                "none": "NONE",
                "success": "✅ No capability drift",
                "failure": "🚨 Drift detected",
            },
        ),
    }


def _is_clean(report: dict) -> bool:
    """Determines if a report is clean."""
    return not (
        report.get("missing_in_code")
        or report.get("undeclared_in_manifest")
        or report.get("mismatched_mappings")
    )


def _print_table(report_dict: dict, labels: Dict[str, str]) -> None:
    """Prints a formatted table of the drift report."""
    table = Table(show_header=True, header_style="bold", title="Capability Drift")
    table.add_column("Section", style="bold")
    table.add_column("Values")

    # ID: 184f626b-d8f7-4e85-94be-1ccf11fd1b07
    def row(title: str, items: List[str]):
        """Adds a row with a formatted list of items."""
        if not items:
            table.add_row(title, f"[bold green]{labels['none']}[/bold green]")
        else:
            table.add_row(
                title, f"[yellow]{'\\n'.join(f'- {it}' for it in items)}[/yellow]"
            )

    row("Missing in code", report_dict.get("missing_in_code", []))
    row("Undeclared in manifest", report_dict.get("undeclared_in_manifest", []))

    mismatches = report_dict.get("mismatched_mappings", [])
    if not mismatches:
        table.add_row(
            "Mismatched mappings", f"[bold green]{labels['none']}[/bold green]"
        )
    else:
        lines = [
            f"- {m.get('capability')}: manifest(...) != code(...)" for m in mismatches
        ]
        table.add_row(
            "Mismatched mappings", "[yellow]" + "\n".join(lines) + "[/yellow]"
        )

    status = (
        f"[bold green]{labels['success']}[/bold green]"
        if _is_clean(report_dict)
        else f"[bold red]{labels['failure']}[/bold red]"
    )
    rprint(Panel.fit(table, title=status))


def _print_pretty(report_dict: dict, labels: Dict[str, str]) -> None:
    """Prints a user-friendly summary of the drift report."""
    _print_table(report_dict, labels)


# ID: b9fb9ddf-cf2f-4338-90c1-7db2b6629ddf
def register(app: typer.Typer) -> None:
    """
    Legacy entry point kept for backward compatibility.

    Delegates to the canonical implementation in `cli.commands.guard_cli.register_guard`.
    """
    from cli.commands.guard_cli import register_guard  # lazy import (no cycle)

    return register_guard(app)

--- END OF FILE ./src/cli/commands/guard.py ---

--- START OF FILE ./src/cli/commands/guard_cli.py ---
# src/cli/commands/guard_cli.py
"""
CLI-facing guard registration helpers.
"""
from __future__ import annotations

import asyncio
import json
from pathlib import Path
from typing import Any, Dict, Optional

import typer

from features.introspection.drift_service import run_drift_analysis_async

__all__ = ["register_guard"]


# ID: a083eccb-0f7d-4230-b32c-4f9d9ae80ace
def register_guard(app: typer.Typer) -> None:
    """
    Registers the 'guard' command group with the CLI.
    """
    from cli.commands.cli_utils import should_fail
    from cli.commands.guard import _print_pretty, _ux_defaults
    from features.introspection.drift_detector import write_report

    guard = typer.Typer(help="Governance/validation guards")
    app.add_typer(guard, name="guard")

    @guard.command("drift")
    # ID: 9c69d559-0c4a-4431-918b-14b3d588da91
    def drift(
        root: Path = typer.Option(Path("."), help="Repository root."),
        manifest_path: Optional[Path] = typer.Option(
            None, help="Explicit manifest path (deprecated)."
        ),
        output: Optional[Path] = typer.Option(
            None, help="Path for JSON evidence report."
        ),
        format: Optional[str] = typer.Option(None, help="json|table|pretty"),
        fail_on: Optional[str] = typer.Option(None, help="any|missing|undeclared"),
    ) -> None:
        """Compares manifest vs code to detect capability drift."""
        try:
            ux = _ux_defaults(root, manifest_path)
            fmt = (format or ux["default_format"]).lower()
            fail_policy = (fail_on or ux["default_fail_on"]).lower()

            report = asyncio.run(run_drift_analysis_async(root))
            report_dict: Dict[str, Any] = report.to_dict()

            if ux["evidence_json"]:
                write_report(output or (root / ux["evidence_path"]), report)

            if fmt in ("table", "pretty"):
                _print_pretty(report_dict, ux["labels"])
            else:
                typer.echo(json.dumps(report_dict, indent=2))

            if should_fail(report_dict, fail_policy):
                raise typer.Exit(code=2)
        except FileNotFoundError as e:
            typer.secho(
                f"Error: A required constitutional file was not found: {e}",
                fg=typer.colors.RED,
            )
            raise typer.Exit(code=1)

    # Note: The kg-export command is removed as it's now obsolete. The drift
    # command provides the core functionality in a more robust way.

--- END OF FILE ./src/cli/commands/guard_cli.py ---

--- START OF FILE ./src/cli/commands/init.py ---
from __future__ import annotations

import typer

from .init import init_db as _init_db
from .list_audits import list_audits as _list_audits
from .log_audit import log_audit as _log_audit
from .report import report as _report
from .status import status as _status

app = typer.Typer(help="Generic DB commands (migrations, status, audits).")

# Register commands
app.command("status")(_status)
app.command("init")(_init_db)
app.command("log-audit")(_log_audit)
app.command("list-audits")(_list_audits)
app.command("report")(_report)

--- END OF FILE ./src/cli/commands/init.py ---

--- START OF FILE ./src/cli/commands/interactive.py ---
# src/system/admin/interactive.py
"""
Implements the interactive, menu-driven TUI for the CORE Admin CLI.
This provides a user-friendly way to discover and run commands.
"""

from __future__ import annotations

import subprocess
import sys

from rich.console import Console
from rich.panel import Panel

console = Console()


# ID: 1d651505-1905-41df-85e6-3891b24cca72
def run_command(command: list[str]):
    """Executes a core-admin command as a subprocess."""
    try:
        # We use sys.executable to ensure we're using the python from the correct venv
        subprocess.run([sys.executable, "-m", "poetry", "run", *command], check=True)
    except subprocess.CalledProcessError:
        console.print("[bold red]Command failed. See error output above.[/bold red]")
    except FileNotFoundError:
        console.print("[bold red]Error: 'poetry' command not found.[/bold red]")

    console.print("\n[bold green]Press Enter to return to the menu...[/bold green]")
    input()


# ID: e4f81e87-71c1-41c1-bfed-fdba926db71f
def show_development_menu():
    """Displays the AI Development & Self-Healing submenu."""
    while True:
        console.clear()
        console.print(Panel("[bold cyan]AI Development & Self-Healing[/bold cyan]"))
        console.print("  [1] Chat with CORE (Translate idea to command)")
        console.print("  [2] Develop (Execute a high-level goal)")
        console.print("  [3] Fix Headers (Run AI-powered style fixer)")
        console.print("\n  [b] Back to main menu")
        console.print("  [q] Quit")
        choice = console.input("\nEnter your choice: ")

        if choice == "1":
            goal = console.input("Enter your goal in natural language: ")
            if goal:
                run_command(["core-admin", "chat", goal])
        elif choice == "2":
            goal = console.input("Enter the full development goal: ")
            if goal:
                run_command(["core-admin", "develop", goal])
        elif choice == "3":
            run_command(["core-admin", "fix", "headers", "--write"])
        elif choice.lower() == "b":
            return
        elif choice.lower() == "q":
            sys.exit(0)


# ID: 91af5862-021e-4c3b-ba18-51deb032382c
def show_governance_menu():
    """Displays the Constitutional Governance submenu."""
    while True:
        console.clear()
        console.print(Panel("[bold cyan]Constitutional Governance[/bold cyan]"))
        console.print("  [1] List Proposals")
        console.print("  [2] Sign a Proposal")
        console.print("  [3] Approve a Proposal")
        console.print("  [4] Review Constitution (AI Peer Review)")
        console.print("\n  [b] Back to main menu")
        console.print("  [q] Quit")
        choice = console.input("\nEnter your choice: ")

        if choice == "1":
            run_command(["core-admin", "proposals", "list"])
        elif choice == "2":
            name = console.input("Enter the proposal filename to sign: ")
            if name:
                run_command(["core-admin", "proposals", "sign", name])
        elif choice == "3":
            name = console.input("Enter the proposal filename to approve: ")
            if name:
                run_command(["core-admin", "proposals", "approve", name])
        elif choice == "4":
            run_command(["core-admin", "review", "constitution"])
        elif choice.lower() == "b":
            return
        elif choice.lower() == "q":
            sys.exit(0)


# ID: 38f63e99-7a3d-4734-9aaa-188e99e44846
def show_system_menu():
    """Displays the System Health & CI submenu."""
    while True:
        console.clear()
        console.print(Panel("[bold cyan]System Health & CI[/bold cyan]"))
        console.print("  [1] Run Full Check (lint, test, audit)")
        console.print("  [2] Run Only Tests")
        console.print("  [3] Format All Code")
        console.print("\n  [b] Back to main menu")
        console.print("  [q] Quit")
        choice = console.input("\nEnter your choice: ")

        if choice == "1":
            run_command(["core-admin", "system", "check"])
        elif choice == "2":
            run_command(["core-admin", "system", "test"])
        elif choice == "3":
            run_command(["core-admin", "system", "format"])
        elif choice.lower() == "b":
            return
        elif choice.lower() == "q":
            sys.exit(0)


# ID: b13f7aa2-3d3a-4442-af86-19bfb95ccfb9
def show_project_lifecycle_menu():
    """Displays the Project Lifecycle submenu."""
    while True:
        console.clear()
        console.print(Panel("[bold cyan]Project Lifecycle[/bold cyan]"))
        console.print("  [1] Create New Governed Application")
        console.print("  [2] Onboard Existing Repository (BYOR)")
        console.print("\n  [b] Back to main menu")
        console.print("  [q] Quit")
        choice = console.input("\nEnter your choice: ")

        if choice == "1":
            name = console.input("Enter the name for the new application: ")
            if name:
                run_command(["core-admin", "new", name, "--write"])
        elif choice == "2":
            path = console.input("Enter the path to the existing repository: ")
            if path:
                run_command(["core-admin", "byor-init", path, "--write"])
        elif choice.lower() == "b":
            return
        elif choice.lower() == "q":
            sys.exit(0)


# ID: 0493a7e1-3b54-478c-b22f-490a36be8b61
def launch_interactive_menu():
    """The main entry point for the interactive TUI menu."""
    while True:
        console.clear()
        console.print(
            Panel(
                "[bold green]🏛️ Welcome to the CORE Interactive Shell[/bold green]",
                subtitle="Select a command group",
            )
        )
        console.print("[bold cyan]1.[/bold cyan] AI Development & Self-Healing")
        console.print("[bold cyan]2.[/bold cyan] Constitutional Governance")
        console.print("[bold cyan]3.[/bold cyan] System Health & CI")
        console.print("[bold cyan]4.[/bold cyan] Project Lifecycle")
        console.print("\n[bold red]q.[/bold red] Quit")

        choice = console.input("\nEnter your choice: ")

        if choice == "1":
            show_development_menu()
        elif choice == "2":
            show_governance_menu()
        elif choice == "3":
            show_system_menu()
        elif choice == "4":
            show_project_lifecycle_menu()
        elif choice.lower() == "q":
            break

--- END OF FILE ./src/cli/commands/interactive.py ---

--- START OF FILE ./src/cli/commands/knowledge.py ---
# src/cli/commands/knowledge.py
"""
Registers the 'knowledge' command group for managing the knowledge base and related artifacts.
"""
from __future__ import annotations

import asyncio

import typer
from rich.console import Console
from rich.table import Table

from cli.commands.reconcile import reconcile_from_cli
from cli.commands.sync import sync_knowledge_base
from cli.commands.sync_manifest import sync_manifest
from core.cognitive_service import CognitiveService
from features.introspection.export_vectors import export_vectors
from features.introspection.generate_correction_map import generate_maps
from features.introspection.semantic_clusterer import run_clustering
from shared.config import settings

console = Console()
knowledge_app = typer.Typer(
    help="Commands for managing the CORE knowledge base (DB and artifacts)."
)


@knowledge_app.command(
    "search", help="Performs a semantic search for capabilities in the knowledge base."
)
# ID: a4d3f3b1-3e4c-4e8a-9f6b-7c8d9e0a1b2c
# --- THIS IS THE FIX ---
# ID: 66832289-1bc0-48fa-8f8f-2d83fecfe3d9
def search_knowledge_command(
    query: str = typer.Argument(..., help="The natural language search query."),
    limit: int = typer.Option(5, "--limit", "-l", help="Number of results to return."),
):
    """
    A synchronous wrapper that runs the async search_knowledge function.
    """

    async def _search_knowledge_async():
        """
        Finds relevant capabilities by performing a semantic search on the vector database.
        """
        console.print(
            f"🧠 Searching for capabilities related to: '[cyan]{query}[/cyan]'..."
        )
        try:
            cognitive_service = CognitiveService(settings.REPO_PATH)
            results = await cognitive_service.search_capabilities(query, limit=limit)

            if not results:
                console.print("[yellow]No relevant capabilities found.[/yellow]")
                return

            table = Table(title="Top Matching Capabilities")
            table.add_column("Score", style="magenta", justify="right")
            table.add_column("Capability Key", style="cyan")
            table.add_column("Description", style="green")

            for hit in results:
                payload = hit.get("payload", {})
                key = payload.get("key", "N/A")
                description = (
                    payload.get("description") or "No description provided."
                ).strip()
                score = f"{hit.get('score', 0):.4f}"
                table.add_row(score, key, description)

            console.print(table)

        except Exception as e:
            console.print(
                f"[bold red]❌ An error occurred during the search: {e}[/bold red]"
            )
            raise typer.Exit(code=1)

    asyncio.run(_search_knowledge_async())


# --- END OF FIX ---


# --- Primary Commands ---
knowledge_app.command(
    "sync",
    help="Scans the codebase and syncs all symbols to the database.",
)(sync_knowledge_base)

knowledge_app.command(
    "reconcile-from-cli",
    help="Links capabilities in the DB using the CLI registry as a map.",
)(reconcile_from_cli)

knowledge_app.command(
    "sync-manifest",
    help="Synchronizes project_manifest.yaml with public capabilities from the database.",
)(sync_manifest)

# --- Analysis & Reporting Commands ---
knowledge_app.command(
    "export-vectors", help="Exports all vectors from Qdrant to a JSONL file."
)(export_vectors)
knowledge_app.command(
    "cluster-vectors", help="Clusters exported vectors to find semantic domains."
)(run_clustering)
knowledge_app.command(
    "generate-map",
    help="Generates alias maps from clustering results.",
)(generate_maps)


# ID: c75e151b-1569-46a1-b809-d2c7c46922d9
def register(app: typer.Typer):
    """Register the 'knowledge' command group with the main CLI app."""
    app.add_typer(knowledge_app, name="knowledge")

--- END OF FILE ./src/cli/commands/knowledge.py ---

--- START OF FILE ./src/cli/commands/knowledge_sync.py ---
# src/cli/commands/knowledge_sync.py
"""
CLI command for synchronizing operational knowledge from YAML files to the database.
"""
from __future__ import annotations

import asyncio
import json

import typer
import yaml
from rich.console import Console
from sqlalchemy import JSON, Column, MetaData, String, Table, dialects

from services.repositories.db.engine import get_session
from shared.config import settings

console = Console()


# --- THIS IS THE FIX ---
async def _upsert_data(session, table_name: str, data: list[dict], primary_key: str):
    """Generic upsert function for operational tables."""
    if not data:
        return 0

    meta = MetaData()
    # Reflect the table structure from the database to get columns, or define manually
    # For robustness, we'll define it based on what we know from the YAML and schema.
    columns = [Column(pk, String, primary_key=True) for pk in primary_key.split(",")]
    for key, value in data[0].items():
        if key not in primary_key:
            col_type = JSON if isinstance(value, (dict, list)) else String
            columns.append(Column(key, col_type))

    # Re-serialize JSON fields to strings for the DB driver
    for row in data:
        for key, value in row.items():
            if isinstance(value, (dict, list)):
                row[key] = json.dumps(value)

    table_obj = Table(
        table_name.split(".")[-1], meta, *columns, schema=table_name.split(".")[0]
    )

    stmt = dialects.postgresql.insert(table_obj).values(data)
    update_dict = {c.name: c for c in stmt.excluded if not c.primary_key}

    upsert_stmt = stmt.on_conflict_do_update(
        index_elements=[primary_key],
        set_=update_dict,
    )

    result = await session.execute(upsert_stmt)
    return result.rowcount


# --- END OF FIX ---


async def _sync_operational_knowledge():
    """Reads legacy YAMLs and syncs them to the new DB tables."""
    console.print(
        "[bold cyan]🚀 Syncing operational knowledge from legacy YAMLs to Database...[/bold cyan]"
    )

    repo_root = settings.REPO_PATH

    # Define legacy paths and target tables
    sync_map = {
        "llm_resources": (
            repo_root / ".intent/charter/policies/agent/resource_manifest_policy.yaml",
            "llm_resources",
            "name",
        ),
        "cognitive_roles": (
            repo_root / ".intent/charter/policies/agent/cognitive_roles_policy.yaml",
            "cognitive_roles",
            "role",
        ),
        "runtime_services": (
            repo_root / ".intent/mind/config/runtime_services.yaml",
            "services",
            "name",
        ),
        "cli_commands": (
            repo_root / ".intent/charter/policies/governance/cli_registry_policy.yaml",
            "commands",
            "name",
        ),
    }

    total_upserted = 0
    async with get_session() as session:
        async with session.begin():
            for table, (path, key, pk) in sync_map.items():
                if not path.exists():
                    console.print(
                        f"[yellow]Legacy file not found, skipping: {path.relative_to(repo_root)}[/yellow]"
                    )
                    continue

                content = yaml.safe_load(path.read_text("utf-8"))
                records = content.get(key, [])

                if records:
                    console.print(
                        f"   -> Syncing {len(records)} records to core.{table}..."
                    )
                    upserted_count = await _upsert_data(
                        session, f"core.{table}", records, pk
                    )
                    total_upserted += upserted_count
                else:
                    console.print(
                        f"   -> No records found in {path.name} for key '{key}'."
                    )

    console.print(
        f"[bold green]✅ Sync complete. Acknowledged {total_upserted} records for upsert.[/bold green]"
    )


# ID: 416af662-de55-4da5-8e73-5e8255e842de
def sync_operational(
    write: bool = typer.Option(
        False, "--write", help="Apply the changes to the database."
    )
):
    """
    One-way sync of operational knowledge (CLI, Roles, Resources) from YAML to DB.
    """
    if not write:
        console.print(
            "[bold yellow]-- DRY RUN --[/bold yellow]\n"
            "This command will read operational YAML files and sync their contents to the database.\n"
            "This is a one-way destructive operation for migration.\n"
            "Run with '--write' to apply changes to the database."
        )
        return

    asyncio.run(_sync_operational_knowledge())


# ID: 41e17c9c-abfb-4af2-9421-412f8c688bfc
def register(app: typer.Typer):
    """Register the 'knowledge sync-operational' command."""
    knowledge_app_group = next(
        (g for g in app.registered_groups if g.name == "knowledge"), None
    )

    if knowledge_app_group:
        knowledge_app = knowledge_app_group.typer_instance
        knowledge_app.command("sync-operational")(sync_operational)
    else:
        # Fallback for dynamic loading
        sync_op_app = typer.Typer(help="Sync operational knowledge to the DB.")
        sync_op_app.command("sync-operational")(sync_operational)
        app.add_typer(sync_op_app, name="knowledge")

--- END OF FILE ./src/cli/commands/knowledge_sync.py ---

--- START OF FILE ./src/cli/commands/list_audits.py ---
# src/system/admin/commands/db/list_audits.py
"""
Provides functionality for the list_audits module.
"""

from __future__ import annotations

import asyncio

import typer
from sqlalchemy import text

# --- CORRECTED IMPORT ---
from core.db.engine import get_session


# ID: 09c55085-1d89-46c2-a663-b4e1f2c2c0b5
def list_audits(
    limit: int = typer.Option(
        10, "--limit", help="How many to show (most recent first)"
    ),
) -> None:
    """Show recent rows from core.audit_runs."""

    async def _run():
        stmt = text(
            """
            select id, started_at, source, score, passed
            from core.audit_runs
            order by id desc
            limit :lim
            """
        ).bindparams(lim=limit)

        # --- CORRECTED USAGE ---
        async with get_session() as session:
            result = await session.execute(stmt)
            rows = result.all()

        if not rows:
            typer.echo("— no audit rows yet —")
            return
        for r in rows:
            when = r.started_at.strftime("%Y-%m-%d %H:%M:%S")
            mark = "✅" if r.passed else "❌"
            typer.echo(f"{r.id:>4}  {when}  {r.source:<7}  score={r.score:.3f}  {mark}")

    asyncio.run(_run())

--- END OF FILE ./src/cli/commands/list_audits.py ---

--- START OF FILE ./src/cli/commands/log_audit.py ---
# src/system/admin/commands/db/log_audit.py
"""
Provides functionality for the log_audit module.
"""

from __future__ import annotations

import asyncio

import typer
from sqlalchemy import text

# --- CORRECTED IMPORT ---
from core.db.engine import get_session

from .common import git_commit_sha


# ID: 90625b7b-b201-458d-84a3-895835a005c0
def log_audit(
    score: float = typer.Option(..., "--score", help="Audit score, e.g. 0.92"),
    passed: bool = typer.Option(
        True, "--passed/--failed", help="Mark audit as passed or failed"
    ),
    source: str = typer.Option(
        "manual", "--source", help="Source label: manual|pr|nightly"
    ),
    commit_sha: str = typer.Option(
        "", "--commit", help="Optional git commit SHA (40 chars)"
    ),
) -> None:
    """Insert one row into core.audit_runs."""

    async def _run():
        sha = commit_sha or git_commit_sha()
        stmt = text(
            """
            insert into core.audit_runs (source, commit_sha, score, passed, started_at, finished_at)
            values (:source, :sha, :score, :passed, now(), now())
            returning id
            """
        )
        # --- CORRECTED USAGE ---
        async with get_session() as session:
            async with session.begin():
                result = await session.execute(
                    stmt, dict(source=source, sha=sha, score=score, passed=passed)
                )
                new_id = result.scalar_one()

        typer.echo(
            f"📝 Logged audit id={new_id} (source={source}, score={score}, passed={passed})"
        )

    asyncio.run(_run())

--- END OF FILE ./src/cli/commands/log_audit.py ---

--- START OF FILE ./src/cli/commands/migrate.py ---
# src/cli/commands/migrate.py
"""
Implements the 'db migrate' command for applying SQL schema changes.
"""
from __future__ import annotations

import asyncio
import pathlib

import typer
from rich.console import Console

from services.repositories.db.common import (  # <-- CORRECTED IMPORT
    apply_sql_file,
    ensure_ledger,
    get_applied,
    load_policy,
    record_applied,
)

console = Console()


async def _run_migrations(apply: bool):
    """The core async logic for running migrations."""
    try:
        pol = load_policy()
        # --- THIS IS THE FIX ---
        # Safely get the migration order and directory, providing empty defaults.
        migrations_config = pol.get("migrations", {})
        order = migrations_config.get("order", [])
        migration_dir = migrations_config.get("directory", "sql")
        # --- END OF FIX ---
    except Exception as e:
        console.print(f"[bold red]❌ Error loading database policy: {e}[/bold red]")
        raise typer.Exit(code=1)

    await ensure_ledger()
    applied = await get_applied()
    pending = [m for m in order if m not in applied]

    if not pending:
        console.print("[bold green]✅ DB schema is up to date.[/bold green]")
        return

    console.print(f"[yellow]Pending migrations found: {pending}[/yellow]")
    if not apply:
        console.print("   -> Run with '--apply' to execute them.")
        return

    for mig in pending:
        console.print(f"   -> Applying migration: {mig}...")
        try:
            await apply_sql_file(pathlib.Path(migration_dir) / mig)
            await record_applied(mig)
            console.print("      [green]...success.[/green]")
        except Exception as e:
            console.print(f"[bold red]      ❌ FAILED to apply {mig}: {e}[/bold red]")
            raise typer.Exit(code=1)

    console.print(
        "[bold green]✅ All pending migrations applied successfully.[/bold green]"
    )


# ID: a6d1df0a-ce85-465a-a29b-6ec422488c2a
def migrate_db(
    apply: bool = typer.Option(False, "--apply", help="Apply pending migrations.")
):
    """Checks for and applies pending database schema migrations."""
    asyncio.run(_run_migrations(apply))

--- END OF FILE ./src/cli/commands/migrate.py ---

--- START OF FILE ./src/cli/commands/new.py ---
# src/system/admin/new.py
"""
Handles the 'core-admin new' command for creating new project scaffolds.
Intent: Defines the 'core-admin new' command, a user-facing wrapper
around the Scaffolder tool.
"""

from __future__ import annotations

import typer

from features.project_lifecycle.scaffolding_service import new_project


# ID: aef6ac5d-843a-47f3-b5df-dd7d0aea3621
def register(app: typer.Typer) -> None:
    """Register the 'new' command with the main CLI app."""
    # Directly register the imported new_project function under the name 'new'
    app.command("new")(new_project)

--- END OF FILE ./src/cli/commands/new.py ---

--- START OF FILE ./src/cli/commands/proposal_service.py ---
# src/cli/commands/proposal_service.py
"""
Registers and implements the command-line interface for proposal lifecycle management.
This module now serves as the main entry point for ALL proposal types.
"""

from __future__ import annotations

import base64
import shutil
import tempfile
from datetime import datetime
from pathlib import Path

import typer
from cryptography.hazmat.primitives import serialization

from cli.commands.cli_utils import (
    archive_rollback_plan,
    load_private_key,
    load_yaml_file,
    save_yaml_file,
)
from cli.commands.proposals_micro import micro_app
from features.governance.constitutional_auditor import ConstitutionalAuditor
from shared.config import settings
from shared.logger import getLogger
from shared.utils.crypto import generate_approval_token

log = getLogger("core_admin.proposals")

proposals_app = typer.Typer(
    help="Work with constitutional proposals for governed changes."
)

proposals_app.add_typer(micro_app, name="micro")


@proposals_app.command("list")
# ID: 7dcb045e-19c9-4d84-91fd-70c4de7e8dfe
def proposals_list() -> None:
    """List pending constitutional proposals and display their status."""
    log.info("🔍 Finding pending constitutional proposals...")
    proposals_dir = settings.REPO_PATH / ".intent" / "proposals"
    proposals_dir.mkdir(exist_ok=True)
    proposals = sorted(list(proposals_dir.glob("cr-*.yaml")))

    if not proposals:
        log.info("✅ No pending proposals found.")
        return

    log.info(f"Found {len(proposals)} pending proposal(s):")
    approvers_config = load_yaml_file(
        settings.REPO_PATH / ".intent" / "charter" / "constitution" / "approvers.yaml"
    )

    for prop_path in proposals:
        config = load_yaml_file(prop_path)
        justification = config.get("justification", "No justification provided.")
        target_path = config.get("target_path", "")
        quorum_config = approvers_config.get("quorum", {})
        current_mode = quorum_config.get("current_mode", "development")

        critical_paths_source = approvers_config.get(
            "critical_paths_source", "charter/constitution/critical_paths.yaml"
        )
        critical_paths_file = settings.REPO_PATH / ".intent" / critical_paths_source
        critical_paths_config = load_yaml_file(critical_paths_file)
        critical_paths = critical_paths_config.get("paths", [])

        is_critical = any(target_path == p for p in critical_paths)
        required_sigs = quorum_config.get(current_mode, {}).get(
            "critical" if is_critical else "standard", 1
        )
        current_sigs = len(config.get("signatures", []))
        status = (
            "✅ Ready"
            if current_sigs >= required_sigs
            else f"⏳ {current_sigs}/{required_sigs} sigs"
        )

        log.info(f"\n  - **{prop_path.name}**: {justification.strip()}")
        log.info(f"    Target: {target_path}")
        log.info(f"    Status: {status} ({'Critical' if is_critical else 'Standard'})")


@proposals_app.command("sign")
# ID: e0b15fef-d8d5-4f39-98b3-18d4eedd8bb5
def proposals_sign(
    proposal_name: str = typer.Argument(
        ..., help="Filename of the proposal to sign (e.g., 'cr-new-policy.yaml')."
    ),
) -> None:
    """Sign a proposal with the operator's private key."""
    log.info(f"✍️ Signing proposal: {proposal_name}")
    proposal_path = settings.REPO_PATH / ".intent" / "proposals" / proposal_name
    if not proposal_path.exists():
        log.error(f"❌ Proposal '{proposal_name}' not found.")
        raise typer.Exit(code=1)

    proposal = load_yaml_file(proposal_path)
    private_key = load_private_key()
    token = generate_approval_token(proposal)
    signature = private_key.sign(token.encode("utf-8"))
    identity = typer.prompt(
        "Enter your identity (e.g., name@domain.com) for this signature"
    )

    proposal.setdefault("signatures", [])
    proposal["signatures"] = [
        s for s in proposal["signatures"] if s.get("identity") != identity
    ]
    proposal["signatures"].append(
        {
            "identity": identity,
            "signature_b64": base64.b64encode(signature).decode("utf-8"),
            "token": token,
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }
    )

    save_yaml_file(proposal_path, proposal)
    log.info("✅ Signature added to proposal file.")


@proposals_app.command("approve")
# ID: 9848504e-60ef-44c1-a57c-b7e14edb5809
def proposals_approve(
    proposal_name: str = typer.Argument(
        ..., help="Filename of the proposal to approve."
    ),
) -> None:
    """Verify signatures, run a canary audit, and apply a valid proposal."""
    log.info(f"🚀 Attempting to approve proposal: {proposal_name}")
    proposal_path = settings.REPO_PATH / ".intent" / "proposals" / proposal_name
    if not proposal_path.exists():
        log.error(f"❌ Proposal '{proposal_name}' not found.")
        raise typer.Exit(code=1)

    proposal = load_yaml_file(proposal_path)
    target_rel_path = proposal.get("target_path")
    if not target_rel_path:
        log.error("❌ Proposal is invalid: missing 'target_path'.")
        raise typer.Exit(code=1)

    log.info("🔐 Verifying cryptographic signatures...")
    approvers_config = load_yaml_file(
        settings.REPO_PATH / ".intent" / "charter" / "constitution" / "approvers.yaml"
    )
    approver_keys = {
        a["identity"]: a["public_key"] for a in approvers_config.get("approvers", [])
    }

    expected_token = generate_approval_token(proposal)
    valid_signatures = 0
    for sig in proposal.get("signatures", []):
        identity = sig.get("identity")
        if sig.get("token") != expected_token:
            log.warning(f"   ⚠️ Stale signature from '{identity}'.")
            continue
        pem = approver_keys.get(identity)
        if not pem:
            log.warning(f"   ⚠️ No public key found for signatory '{identity}'.")
            continue
        try:
            pub_key = serialization.load_pem_public_key(pem.encode("utf-8"))
            pub_key.verify(
                base64.b64decode(sig["signature_b64"]), expected_token.encode("utf-8")
            )
            log.info(f"   ✅ Valid signature from '{identity}'.")
            valid_signatures += 1
        except Exception:
            log.warning(f"   ⚠️ Verification failed for signature from '{identity}'.")
            continue

    quorum_config = approvers_config.get("quorum", {})
    mode = quorum_config.get("current_mode", "development")

    critical_paths_source = approvers_config.get(
        "critical_paths_source", "charter/constitution/critical_paths.yaml"
    )
    critical_paths_file = settings.REPO_PATH / ".intent" / critical_paths_source
    critical_paths_config = load_yaml_file(critical_paths_file)
    critical_paths = critical_paths_config.get("paths", [])

    is_critical = any(str(target_rel_path) == p for p in critical_paths)
    required_sigs = quorum_config.get(mode, {}).get(
        "critical" if is_critical else "standard", 1
    )

    if valid_signatures < required_sigs:
        log.error(
            f"❌ Approval failed: Quorum not met ({valid_signatures}/{required_sigs})."
        )
        raise typer.Exit(code=1)

    log.info("\n🐦 Spinning up canary environment for validation...")
    with tempfile.TemporaryDirectory() as tmp:
        tmp_path = Path(tmp)
        log.info(f"   -> Creating a clean copy of the repository at {tmp_path}...")

        shutil.copytree(
            settings.REPO_PATH,
            tmp_path,
            dirs_exist_ok=True,
            ignore=shutil.ignore_patterns(".git", ".venv", "venv", "__pycache__"),
        )

        env_file = settings.REPO_PATH / ".env"
        if env_file.exists():
            shutil.copy(env_file, tmp_path / ".env")
            log.info("   -> Copied environment configuration to canary.")

        canary_target_path = tmp_path / target_rel_path
        canary_target_path.parent.mkdir(parents=True, exist_ok=True)
        canary_target_path.write_text(proposal.get("content", ""), encoding="utf-8")

        log.info("🔬 Commanding canary to perform a self-audit...")
        auditor = ConstitutionalAuditor(repo_root_override=tmp_path)
        success, findings, unassigned_count = auditor.run_full_audit()

        if success:
            log.info("✅ Canary audit PASSED. Change is constitutionally valid.")
            archive_rollback_plan(proposal_name, proposal)
            live_target_path = settings.REPO_PATH / target_rel_path
            live_target_path.parent.mkdir(parents=True, exist_ok=True)
            live_target_path.write_text(proposal.get("content", ""), encoding="utf-8")
            proposal_path.unlink()
            log.info(f"✅ Successfully approved and applied '{proposal_name}'.")
        else:
            log.error(
                "❌ Canary audit FAILED. Proposal rejected; live system untouched."
            )
            raise typer.Exit(code=1)


# ID: b52c497e-f5b6-4f39-af22-f32c1d400362
def register(app: typer.Typer):
    """
    Registers the 'proposals' command group with the main admin CLI application.
    """
    app.add_typer(proposals_app, name="proposals")

--- END OF FILE ./src/cli/commands/proposal_service.py ---

--- START OF FILE ./src/cli/commands/proposals_micro.py ---
# src/cli/commands/proposals_micro.py
from __future__ import annotations

import asyncio
import json
import subprocess
import tempfile
import uuid
from pathlib import Path

import typer
from rich.console import Console

from core.agents.execution_agent import ExecutionAgent
from core.agents.micro_planner import MicroPlannerAgent
from core.agents.plan_executor import PlanExecutor
from core.prompt_pipeline import PromptPipeline
from core.service_registry import service_registry
from features.governance.audit_context import AuditorContext
from features.governance.micro_proposal_validator import MicroProposalValidator
from shared.config import settings
from shared.logger import getLogger

console = Console()
log = getLogger("proposals_micro")

micro_app = typer.Typer(help="Manage low-risk, autonomous micro-proposals.")


# ID: 4f17d3f6-36ab-4683-ad2a-dfd9b8221d80
def micro_propose(
    goal: str = typer.Argument(..., help="The high-level goal to achieve.")
):
    """Uses an agent to create a safe, auto-approvable plan for a goal."""
    console.print(f"🤖 Generating micro-proposal for goal: '[cyan]{goal}[/cyan]'")

    cognitive_service = service_registry.get_service("cognitive_service")
    planner = MicroPlannerAgent(cognitive_service)

    plan = asyncio.run(planner.create_micro_plan(goal))

    if not plan:
        console.print(
            "[bold red]❌ Agent could not generate a safe plan for this goal.[/bold red]"
        )
        raise typer.Exit(code=1)

    proposal = {"proposal_id": str(uuid.uuid4()), "goal": goal, "plan": plan}
    proposal_file = (
        Path(tempfile.gettempdir())
        / f"core-micro-proposal-{proposal['proposal_id']}.json"
    )
    proposal_file.write_text(json.dumps(proposal, indent=2))

    console.print(
        "[bold green]✅ Safe micro-proposal generated successfully![/bold green]"
    )
    console.print("Plan details:")
    console.print(json.dumps(plan, indent=2))
    console.print("To apply this plan, run:")
    console.print(
        f"[bold]poetry run core-admin proposals micro apply {proposal_file}[/bold]"
    )


@micro_app.command("apply")
# ID: 96a9659e-613a-4403-8cbe-623fa793a19f
def micro_apply(
    proposal_path: Path = typer.Argument(
        ..., help="Path to the micro-proposal JSON file.", exists=True
    )
):
    """Validates and applies a micro-proposal."""
    console.print(f"🔵 Loading and applying micro-proposal: {proposal_path.name}")

    try:
        proposal_content = proposal_path.read_text(encoding="utf-8")
        proposal_data = json.loads(proposal_content)
        plan = proposal_data.get("plan", [])
    except Exception as e:
        console.print(f"[bold red]❌ Error loading proposal file: {e}[/bold red]")
        raise typer.Exit(code=1)

    # 1. Zero-Trust Validation
    console.print(
        "[bold]Step 1/3: Validating plan against constitutional policy...[/bold]"
    )
    validator = MicroProposalValidator()
    is_valid, validation_error = validator.validate(plan)
    if not is_valid:
        console.print(
            f"[bold red]❌ Plan is constitutionally invalid: {validation_error}[/bold red]"
        )
        raise typer.Exit(code=1)
    console.print("   -> ✅ Plan is valid.")

    # 2. Gather Evidence via CI Checks
    console.print("[bold]Step 2/3: Gathering evidence via pre-flight checks...[/bold]")
    checks = [
        ("lint", "check ci lint"),
        ("test", "check ci test"),
        ("audit", "check ci audit"),
    ]
    for name, command in checks:
        console.print(f"   -> Running {name} check...")
        result = subprocess.run(
            ["poetry", "run", "core-admin", *command.split()],
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            console.print(
                f"[bold red]❌ Pre-flight '{name}' check failed. Aborting.[/bold red]"
            )
            console.print(result.stderr)
            raise typer.Exit(code=1)
    console.print("   -> ✅ All pre-flight checks passed.")

    # 3. Apply the Change via ExecutionAgent
    console.print("[bold]Step 3/3: Executing the validated plan...[/bold]")
    try:
        cognitive_service = service_registry.get_service("cognitive_service")
        prompt_pipeline = PromptPipeline(settings.REPO_PATH)
        plan_executor = PlanExecutor()
        auditor_context = AuditorContext(repo_path=settings.REPO_PATH)

        execution_agent = ExecutionAgent(
            cognitive_service=cognitive_service,
            prompt_pipeline=prompt_pipeline,
            plan_executor=plan_executor,
            auditor_context=auditor_context,
        )

        success = asyncio.run(
            execution_agent.execute_plan(
                high_level_goal=proposal_data.get("goal", ""), plan=plan
            )
        )

        if success:
            console.print(
                "[bold green]✅ Micro-proposal applied successfully![/bold green]"
            )
        else:
            console.print(
                "[bold red]❌ ExecutionAgent reported failure during plan application.[/bold red]"
            )
            raise typer.Exit(code=1)

    except Exception as e:
        console.print(f"[bold red]❌ Error during plan execution: {e}[/bold red]")
        raise typer.Exit(code=1)


micro_app.command("propose")(micro_propose)

if __name__ == "__main__":
    micro_app()

--- END OF FILE ./src/cli/commands/proposals_micro.py ---

--- START OF FILE ./src/cli/commands/reconcile.py ---
# src/cli/commands/reconcile.py
"""
Implements the 'knowledge reconcile-from-cli' command to link declared
capabilities to their implementations in the database using the CLI registry as the map.
"""
from __future__ import annotations

import asyncio

import typer
import yaml
from rich.console import Console
from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.config import settings

console = Console()
CLI_REGISTRY_PATH = (
    settings.REPO_PATH / ".intent" / "mind" / "knowledge" / "cli_registry.yaml"
)


async def _async_reconcile():
    """
    Reads the CLI registry and updates the 'key' in the symbols table for all
    symbols that implement a registered command.
    """
    console.print(
        "[bold cyan]🚀 Reconciling capabilities from CLI registry to database...[/bold cyan]"
    )

    if not CLI_REGISTRY_PATH.exists():
        console.print(
            f"[bold red]❌ CLI Registry not found at {CLI_REGISTRY_PATH}[/bold red]"
        )
        raise typer.Exit(code=1)

    registry = yaml.safe_load(CLI_REGISTRY_PATH.read_text("utf-8"))
    commands = registry.get("commands", [])

    updates_to_perform = []
    for command in commands:
        entrypoint = command.get("entrypoint")
        capabilities = command.get("implements", [])
        if not entrypoint or not capabilities:
            continue

        module_path, function_name = entrypoint.split("::")
        file_path_str = "src/" + module_path.replace(".", "/") + ".py"
        symbol_path = f"{file_path_str}::{function_name}"
        primary_key = capabilities[0]

        updates_to_perform.append(
            {
                "key": primary_key,
                "symbol_path": symbol_path,
            }
        )

    if not updates_to_perform:
        console.print(
            "[yellow]⚠️ No capabilities with entrypoints found in CLI registry.[/yellow]"
        )
        return

    console.print(
        f"   -> Found {len(updates_to_perform)} capability implementations to link."
    )

    linked_count = 0
    async with get_session() as session:
        async with session.begin():
            for update in updates_to_perform:
                stmt = text(
                    """
                    UPDATE core.symbols SET key = :key, updated_at = NOW()
                    WHERE symbol_path = :symbol_path AND key IS NULL;
                    """
                )
                result = await session.execute(stmt, update)
                if result.rowcount > 0:
                    linked_count += 1

    console.print(
        f"[bold green]✅ Successfully linked {linked_count} capabilities.[/bold green]"
    )


# ID: b43fc6d4-413b-47f2-8a0c-7860836913ab
def reconcile_from_cli():
    """Typer-compatible wrapper for the async reconcile logic."""
    asyncio.run(_async_reconcile())

--- END OF FILE ./src/cli/commands/reconcile.py ---

--- START OF FILE ./src/cli/commands/report.py ---
# src/system/admin/commands/db/report.py
"""
Provides functionality for the report module.
"""

from __future__ import annotations

import asyncio

import typer
from sqlalchemy import text

# --- CORRECTED IMPORT ---
from core.db.engine import get_session


# ID: 27a79c8d-285f-4e79-8de9-a4a5cba424d4
def report() -> None:
    """Summary by source (count, pass rate, avg score)."""

    async def _run():
        stmt = text(
            """
            select
              source,
              count(*) as total,
              sum(case when passed then 1 else 0 end) as passed_count,
              round(avg(score)::numeric, 3) as avg_score
            from core.audit_runs
            group by source
            order by source
            """
        )

        # --- CORRECTED USAGE ---
        async with get_session() as session:
            result = await session.execute(stmt)
            rows = result.all()

        if not rows:
            typer.echo("— no data —")
            return

        typer.echo("source   total  passed  pass_rate  avg_score")
        for r in rows:
            pass_rate = (r.passed_count / r.total) * 100.0 if r.total else 0.0
            typer.echo(
                f"{r.source:<7} {r.total:>5}  {r.passed_count:>6}   {pass_rate:>6.1f}%     {float(r.avg_score):>8.3f}"
            )

    asyncio.run(_run())

--- END OF FILE ./src/cli/commands/report.py ---

--- START OF FILE ./src/cli/commands/reviewer.py ---
# src/cli/commands/reviewer.py
"""
Provides commands for AI-powered review of the constitution, documentation, and source code files.
"""

from __future__ import annotations

import asyncio
from pathlib import Path
from typing import List, Set

import typer
from rich.console import Console
from rich.markdown import Markdown
from rich.panel import Panel

from core.cognitive_service import CognitiveService
from shared.config import settings
from shared.logger import getLogger
from shared.utils.constitutional_parser import get_all_constitutional_paths

log = getLogger("core_admin.review")
console = Console()  # Define console once at the module level

DOCS_IGNORE_DIRS = {"assets", "archive", "migrations", "examples"}


def _get_bundle_content(files_to_bundle: List[Path], root_dir: Path) -> str:
    bundle_parts = []
    for file_path in sorted(list(files_to_bundle)):
        if file_path.exists() and file_path.is_file():
            try:
                content = file_path.read_text(encoding="utf-8")
                rel_path = file_path.resolve().relative_to(root_dir.resolve())
                bundle_parts.append(f"--- START OF FILE ./{rel_path} ---\n")
                bundle_parts.append(content)
                bundle_parts.append(f"\n--- END OF FILE ./{rel_path} ---\n\n")
            except ValueError:
                log.warning(
                    f"Could not determine relative path for {file_path}. Skipping."
                )
    return "".join(bundle_parts)


def _get_constitutional_files() -> List[Path]:
    """
    Discovers all constitutional files by parsing meta.yaml via the settings object.
    """
    meta_content = settings._meta_config
    relative_paths = get_all_constitutional_paths(meta_content, settings.MIND)
    return [settings.REPO_PATH / p for p in relative_paths]


def _get_docs_files() -> List[Path]:
    root_dir = settings.REPO_PATH
    scan_files = [
        root_dir / "README.md",
        root_dir / "CONTRIBUTING.md",
    ]
    docs_dir = root_dir / "docs"
    found_files: Set[Path] = {f for f in scan_files if f.exists()}
    if docs_dir.is_dir():
        for md_file in docs_dir.rglob("*.md"):
            if not any(ignored in md_file.parts for ignored in DOCS_IGNORE_DIRS):
                found_files.add(md_file)
    return list(found_files)


def _orchestrate_review(
    bundle_name: str,
    prompt_key: str,
    file_gatherer_fn,
    output_path: Path,
    no_send: bool,
):
    log.info(f"🤖 Orchestrating review for: {bundle_name}...")
    try:
        prompt_path = settings.get_path(f"mind.prompts.{prompt_key}")
        review_prompt_template = prompt_path.read_text(encoding="utf-8")
    except FileNotFoundError:
        log.error(
            f"❌ Review prompt '{prompt_key}' not found in meta.yaml. Cannot proceed."
        )
        raise typer.Exit(code=1)

    log.info(f"   -> Loaded review prompt: {prompt_key}")
    log.info("   -> Bundling files for review...")
    files_to_bundle = file_gatherer_fn()
    bundle_content = _get_bundle_content(files_to_bundle, settings.REPO_PATH)
    log.info(f"   -> Bundled {len(files_to_bundle)} files.")
    bundle_output_path = settings.REPO_PATH / "reports" / f"{bundle_name}_bundle.txt"
    bundle_output_path.parent.mkdir(parents=True, exist_ok=True)
    bundle_output_path.write_text(bundle_content, encoding="utf-8")
    log.info(f"   -> Saved review bundle to: {bundle_output_path}")

    final_prompt = f"{review_prompt_template}\n\n{bundle_content}"

    if no_send:
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(final_prompt, encoding="utf-8")
        log.info(f"✅ Full prompt bundle for manual review saved to: {output_path}")
        raise typer.Exit()

    log.info("   -> Sending bundle to LLM for analysis. This may take a moment...")
    cognitive_service = CognitiveService(settings.REPO_PATH)
    reviewer = cognitive_service.get_client_for_role("SecurityAnalyst")

    # ID: f666ec25-e399-4b50-a887-afc0b37f048f
    async def run_async_review():
        return await reviewer.make_request_async(
            final_prompt, user_id=f"{bundle_name}_reviewer"
        )

    review_feedback = asyncio.run(run_async_review())

    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(review_feedback, encoding="utf-8")
    log.info(f"✅ Successfully received feedback and saved to: {output_path}")
    console.print(f"\n--- {bundle_name.replace('_', ' ').title()} Review Summary ---")
    console.print(Markdown(review_feedback))


# ID: 791a17b0-8edf-43f0-ab74-7218bc9a4830
def peer_review(
    output: Path = typer.Option(
        Path("reports/constitutional_review.md"), "--output", "-o"
    ),
    no_send: bool = typer.Option(False, "--no-send"),
):
    """Audits the machine-readable constitution (.intent files) for clarity and consistency."""
    _orchestrate_review(
        "constitutional",
        "constitutional_review",
        _get_constitutional_files,
        output,
        no_send,
    )


# ID: cf79cabf-12fc-49e9-8c15-0bfdaae8c301
def docs_clarity_audit(
    output: Path = typer.Option(
        Path("reports/docs_clarity_review.md"), "--output", "-o"
    ),
    no_send: bool = typer.Option(False, "--no-send"),
):
    """Audits the human-readable documentation (.md files) for conceptual clarity."""
    _orchestrate_review(
        "docs_clarity",
        "docs_clarity_review",
        _get_docs_files,
        output,
        no_send,
    )


# ID: 7c2b8cf2-fecf-4ed9-97a7-72f102a5427d
def code_review(
    file_path: Path = typer.Argument(
        ..., exists=True, dir_okay=False, resolve_path=True
    ),
):
    """Submits a source file to an AI expert for a peer review and improvement suggestions."""

    async def _async_code_review():
        log.info(
            f"🤖 Submitting '{file_path.relative_to(settings.REPO_PATH)}' for AI peer review..."
        )
        try:
            source_code = file_path.read_text(encoding="utf-8")
            prompt_path = settings.get_path("mind.prompts.code_peer_review")
            review_prompt_template = prompt_path.read_text(encoding="utf-8")
            final_prompt = f"{review_prompt_template}\n\n```python\n{source_code}\n```"

            with console.status(
                "[bold green]Asking AI expert for review...[/bold green]",
                spinner="dots",
            ):
                cognitive_service = CognitiveService(settings.REPO_PATH)
                reviewer_client = cognitive_service.get_client_for_role("CodeReviewer")
                review_feedback = await reviewer_client.make_request_async(
                    final_prompt, user_id="code_review_operator"
                )
            console.print(
                Panel("AI Peer Review Complete", style="bold green", expand=False)
            )
            console.print(Markdown(review_feedback))
        except FileNotFoundError:
            log.error(f"❌ Error: File not found at '{file_path}'")
            raise typer.Exit(code=1)
        except Exception as e:
            log.error(
                f"❌ An unexpected error occurred during peer review: {e}",
                exc_info=True,
            )
            raise typer.Exit(code=1)

    asyncio.run(_async_code_review())


# ID: dcd2c2bc-4c65-436a-9646-22834c917f41
def register(app: typer.Typer):
    review_app = typer.Typer(help="Tools for constitutional and documentation review.")
    app.add_typer(review_app, name="review")
    review_app.command("constitution")(peer_review)
    review_app.command("docs")(docs_clarity_audit)
    review_app.command("code")(code_review)

    @review_app.command("export")
    # ID: 2e4cea1d-3aca-46ef-a0b9-9361bdb595b5
    def export_bundle():
        _orchestrate_review(
            "constitutional",
            "constitutional_review",
            _get_constitutional_files,
            settings.REPO_PATH / "reports/manual_review_package.txt",
            no_send=True,
        )

--- END OF FILE ./src/cli/commands/reviewer.py ---

--- START OF FILE ./src/cli/commands/run.py ---
# src/cli/commands/run.py
"""
Registers and implements the 'run' command group for executing complex,
multi-step processes and autonomous cycles.
"""
from __future__ import annotations

import asyncio

import typer
from dotenv import load_dotenv

from core.agents.execution_agent import ExecutionAgent
from core.agents.plan_executor import PlanExecutor
from core.agents.planner_agent import PlannerAgent
from core.agents.reconnaissance_agent import ReconnaissanceAgent
from core.cognitive_service import CognitiveService
from core.file_handler import FileHandler
from core.git_service import GitService
from core.knowledge_service import KnowledgeService
from core.prompt_pipeline import PromptPipeline
from features.governance.audit_context import AuditorContext
from features.introspection.vectorization_service import run_vectorize
from shared.config import settings
from shared.logger import getLogger
from shared.models import PlanExecutionError, PlannerConfig
from shared.path_utils import get_repo_root

log = getLogger("core_admin.run")

run_app = typer.Typer(
    help="Commands for executing complex processes and autonomous cycles."
)


# ID: 404982f6-59cd-40a3-862c-282c14225d3e
async def run_development_cycle(
    goal: str, auto_commit: bool = True
) -> tuple[bool, str]:
    """
    Runs the full development cycle for a given goal.
    """
    try:
        log.info(f"🚀 Received new development goal: '{goal}'")
        repo_path = get_repo_root()

        auditor_context = AuditorContext(repo_path)
        git_service = GitService(repo_path=str(repo_path))
        cognitive_service = CognitiveService(repo_path=repo_path)
        knowledge_service = KnowledgeService(repo_path=repo_path)
        file_handler = FileHandler(repo_path=str(repo_path))
        prompt_pipeline = PromptPipeline(repo_path=repo_path)
        planner_config = PlannerConfig()
        plan_executor = PlanExecutor(file_handler, git_service, planner_config)

        knowledge_graph = await knowledge_service.get_graph()

        # --- THIS IS THE FIX ---
        # The Recon Agent now requires the cognitive_service to do its own search
        recon_agent = ReconnaissanceAgent(knowledge_graph, cognitive_service)
        context_report = await recon_agent.generate_report(goal)

        planner = PlannerAgent(cognitive_service)
        # The planner now requires the report to generate an informed plan
        plan = await planner.create_execution_plan(goal, context_report)
        # --- END OF FIX ---

        executor = ExecutionAgent(
            cognitive_service, prompt_pipeline, plan_executor, auditor_context
        )

        if not plan:
            return False, "PlannerAgent failed to create a valid execution plan."

        success, message = await executor.execute_plan(
            high_level_goal=goal, plan=plan, is_micro_proposal=False
        )

        if success and auto_commit:
            commit_message = f"feat(AI): execute plan for goal - {goal}"
            git_service.commit(commit_message)
            log.info(f"   -> Committed changes with message: '{commit_message}'")
        return success, message
    except PlanExecutionError as e:
        return False, f"A critical error occurred during planning: {e}"
    except Exception as e:
        log.error(f"💥 An unexpected error occurred: {e}", exc_info=True)
        return False, f"An unexpected error occurred: {e}"


@run_app.command(
    "develop",
    help="Orchestrates the autonomous development process from a high-level goal.",
)
# ID: b6963057-2c08-4699-94ea-a7f74fe532ff
def develop(
    goal: str = typer.Argument(
        ..., help="The high-level development goal for CORE to achieve."
    )
):
    load_dotenv()
    if not settings.LLM_ENABLED:
        log.error("❌ The 'develop' command requires LLMs to be enabled.")
        raise typer.Exit(code=1)
    success, message = asyncio.run(run_development_cycle(goal))
    if success:
        typer.secho("\n✅ Goal achieved successfully.", fg=typer.colors.GREEN)
    else:
        typer.secho(f"\n❌ Goal execution failed: {message}", fg=typer.colors.RED)
        raise typer.Exit(code=1)


@run_app.command(
    "vectorize",
    help="Scan capabilities from the DB, generate embeddings, and upsert to Qdrant.",
)
# ID: f82043e9-6402-4cfd-8550-12b5feba09de
def vectorize_capabilities(
    dry_run: bool = typer.Option(
        True, "--dry-run/--write", help="Show changes without writing to Qdrant."
    ),
    force: bool = typer.Option(
        False, "--force", help="Force re-vectorization of all capabilities."
    ),
):
    """The CLI wrapper for the database-driven vectorization process."""
    log.info("🚀 Starting capability vectorization process...")
    if not settings.LLM_ENABLED:
        log.error("❌ LLMs must be enabled to generate embeddings.")
        raise typer.Exit(code=1)
    try:
        asyncio.run(run_vectorize(dry_run=dry_run, force=force))
    except Exception as e:
        log.error(f"❌ Orchestration failed: {e}", exc_info=True)
        raise typer.Exit(code=1)


# ID: ec7405ee-fb7c-424c-8d41-239a77a7a24d
def register(app: typer.Typer):
    """Register the 'run' command group with the main CLI app."""
    app.add_typer(run_app, name="run")

--- END OF FILE ./src/cli/commands/run.py ---

--- START OF FILE ./src/cli/commands/status.py ---
# src/cli/commands/status.py
"""
CLI command to check database connectivity and migration status.
"""
from __future__ import annotations

import asyncio

import typer

# --- THIS IS THE FIX ---
# It now imports from the correct 'services' layer, not the 'cli' layer.
from services.repositories.db.common import (
    ensure_ledger,
    get_applied,
    load_policy,
)
from services.repositories.db.engine import ping


# ID: 10235f65-fae8-473a-8a60-f65711b87f43
def status() -> None:
    """Show DB connectivity and migration status."""

    async def _run():
        # 1) connection/ping
        try:
            info = await ping()
            typer.echo(f"✅ Connected: {info['version']}")
        except Exception as e:
            typer.echo(f"❌ Connection failed: {e}", err=True)
            raise

        # 2) policy & migrations
        pol = load_policy()
        order = pol.get("migrations", {}).get("order", [])

        await ensure_ledger()
        applied = await get_applied()
        pending = [m for m in order if m not in applied]

        typer.echo(f"Applied: {sorted(list(applied)) or '—'}")
        typer.echo(f"Pending: {pending or '—'}")

    asyncio.run(_run())

--- END OF FILE ./src/cli/commands/status.py ---

--- START OF FILE ./src/cli/commands/sync.py ---
# src/cli/commands/sync.py
"""
Implements the 'knowledge sync' command, the single source of truth for
synchronizing the codebase state (IDs) with the database.
"""
from __future__ import annotations

import asyncio

import typer
from rich.console import Console

from features.introspection.sync_service import run_sync_with_db

console = Console()


async def _async_sync_knowledge(write: bool):
    """Core async logic for the sync command."""
    console.print(
        "[bold cyan]🚀 Synchronizing codebase state with database using temp table strategy...[/bold cyan]"
    )

    if not write:
        console.print(
            "\n[bold yellow]💧 Dry Run: This command no longer supports a dry run due to its database-centric logic.[/bold yellow]"
        )
        console.print("   Run with '--write' to execute the synchronization.")
        return

    stats = await run_sync_with_db()

    console.print("\n--- Knowledge Sync Summary ---")
    console.print(f"   Scanned from code:  [cyan]{stats['scanned']}[/cyan] symbols")
    console.print(f"   New symbols added:  [green]{stats['inserted']}[/green]")
    console.print(f"   Existing symbols updated: [yellow]{stats['updated']}[/yellow]")
    console.print(f"   Obsolete symbols removed: [red]{stats['deleted']}[/red]")
    console.print(
        "\n[bold green]✅ Database is now synchronized with the codebase.[/bold green]"
    )


# ID: 89517800-0799-476e-8078-a184519a76a1
def sync_knowledge_base(
    write: bool = typer.Option(
        False, "--write", help="Apply the changes to the database."
    )
):
    """Scans the codebase and syncs all symbols and their IDs to the database."""
    asyncio.run(_async_sync_knowledge(write))

--- END OF FILE ./src/cli/commands/sync.py ---

--- START OF FILE ./src/cli/commands/sync_domains.py ---
# src/cli/commands/sync_domains.py
"""
CLI command to synchronize the canonical list of domains to the database.
"""
from __future__ import annotations

import asyncio

import typer
import yaml
from rich.console import Console
from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.config import settings

console = Console()


async def _sync_domains():
    """
    Reads the canonical domains.yaml file and upserts them into the core.domains table.
    """
    domains_path = settings.MIND / "knowledge" / "domains.yaml"
    if not domains_path.exists():
        console.print(
            f"[bold red]❌ Error: Constitutional domains file not found at {domains_path}[/bold red]"
        )
        raise typer.Exit(code=1)

    content = yaml.safe_load(domains_path.read_text("utf-8"))
    domains_to_sync = content.get("domains", [])

    if not domains_to_sync:
        console.print(
            "[yellow]⚠️  No domains found in domains.yaml. Nothing to sync.[/yellow]"
        )
        return

    upserted_count = 0
    async with get_session() as session:
        async with session.begin():  # Start a transaction
            for domain_data in domains_to_sync:
                name = domain_data.get("name")
                description = domain_data.get("description", "")
                if not name:
                    continue

                stmt = text(
                    """
                    INSERT INTO core.domains (key, title, description, status)
                    VALUES (:key, :title, :desc, 'active')
                    ON CONFLICT (key) DO UPDATE SET
                        title = EXCLUDED.title,
                        description = EXCLUDED.description;
                """
                )

                await session.execute(
                    stmt,
                    {
                        "key": name,
                        "title": name.replace("_", " ").title(),
                        "desc": description,
                    },
                )
                upserted_count += 1

    console.print(
        f"[bold green]✅ Successfully synced {upserted_count} domains to the database.[/bold green]"
    )


# ID: 5bee5341-7f72-430e-b310-f174af37de20
def sync_domains():
    """Synchronizes the canonical list of domains from .intent/knowledge/domains.yaml to the database."""
    asyncio.run(_sync_domains())

--- END OF FILE ./src/cli/commands/sync_domains.py ---

--- START OF FILE ./src/cli/commands/sync_manifest.py ---
# src/cli/commands/sync_manifest.py
"""
Implements the 'knowledge sync-manifest' command to synchronize the project
manifest with the public symbols stored in the database.
"""
from __future__ import annotations

import asyncio

import typer
import yaml
from rich.console import Console
from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.sync_manifest")
console = Console()

MANIFEST_PATH = settings.REPO_PATH / ".intent" / "mind" / "project_manifest.yaml"


async def _async_sync_manifest():
    """
    Reads all public symbols from the database and updates project_manifest.yaml
    to make it the single source of truth for all declared capabilities.
    """
    console.print(
        "[bold cyan]🚀 Synchronizing project manifest with database...[/bold cyan]"
    )

    if not MANIFEST_PATH.exists():
        log.error(f"❌ Manifest file not found at {MANIFEST_PATH}")
        raise typer.Exit(code=1)

    console.print("   -> Fetching all public symbols from the database...")
    public_symbol_keys = []
    try:
        async with get_session() as session:
            result = await session.execute(
                text(
                    "SELECT key FROM core.symbols WHERE is_public = TRUE AND key IS NOT NULL ORDER BY key"
                )
            )
            public_symbol_keys = [row[0] for row in result]
    except Exception as e:
        log.error(f"❌ Database query failed: {e}")
        console.print(
            "[bold red]Error connecting to the database. Is it running?[/bold red]"
        )
        raise typer.Exit(code=1)

    console.print(
        f"   -> Found {len(public_symbol_keys)} public capabilities to declare."
    )

    console.print(f"   -> Updating {MANIFEST_PATH.relative_to(settings.REPO_PATH)}...")
    manifest_data = yaml.safe_load(MANIFEST_PATH.read_text("utf-8"))
    manifest_data["capabilities"] = public_symbol_keys

    MANIFEST_PATH.write_text(
        yaml.dump(manifest_data, indent=2, sort_keys=False), "utf-8"
    )

    console.print("[bold green]✅ Manifest synchronization complete.[/bold green]")


# ID: fcf8c754-27d0-4449-a3c4-bd3afbcff6ce
def sync_manifest():
    """Synchronizes project_manifest.yaml with the public capabilities in the database."""
    asyncio.run(_async_sync_manifest())

--- END OF FILE ./src/cli/commands/sync_manifest.py ---

--- START OF FILE ./src/cli/commands/system.py ---
# src/cli/commands/system.py
from __future__ import annotations

import asyncio

import typer
from rich.console import Console

from core.crate_processing_service import process_crates
from features.project_lifecycle.integration_service import integrate_changes

console = Console()
system_app = typer.Typer(
    help="High-level commands for managing the CORE system lifecycle."
)


@system_app.command("integrate", help="Integrates staged code changes into the system.")
# ID: 46b79a8e-3360-4fac-af15-9a52cf0d9a7a
def integrate_command(
    commit_message: str = typer.Option(
        ..., "-m", "--message", help="The git commit message for this integration."
    )
):
    """Orchestrates the full, autonomous integration of staged code changes."""
    asyncio.run(integrate_changes(commit_message))


@system_app.command(
    "process-crates", help="Processes all pending Intent Crates in the inbox."
)
# ID: 1f2c3d4e-5f6a-7b8c-9d0e-1f2a3b4c5d6e
def process_crates_command():
    """Finds, validates, and applies all pending autonomous change proposals."""
    asyncio.run(process_crates())


# ID: e3b37bfa-b8d3-4fd1-83ed-a1b8d063f41d
def register(app: typer.Typer):
    """Register the 'system' command group with the main CLI app."""
    app.add_typer(system_app, name="system")

--- END OF FILE ./src/cli/commands/system.py ---

--- START OF FILE ./src/cli/commands/tools.py ---
# src/cli/commands/tools.py
"""
Registers a 'tools' command group for powerful, operator-focused maintenance tasks.
This is the new, governed home for logic from standalone scripts.
"""
from __future__ import annotations

import typer
from rich.console import Console

from features.maintenance.maintenance_service import rewire_imports

console = Console()
tools_app = typer.Typer(
    help="Governed, operator-focused maintenance and refactoring tools."
)


@tools_app.command(
    "rewire-imports",
    help="Run after major refactoring to fix all Python import statements across 'src/'.",
)
# ID: 4d6a0245-20c9-425e-a0cd-a390c8dd063c
def rewire_imports_cli(
    write: bool = typer.Option(False, "--write", help="Apply the changes to the files.")
):
    """
    CLI wrapper for the import rewiring service.
    """
    dry_run = not write
    console.print("🚀 Starting architectural import re-wiring script...")
    if dry_run:
        console.print("💧 [yellow]DRY RUN MODE[/yellow]: No files will be changed.")
    else:
        console.print("🟢 [bold green]WRITE MODE[/bold green]: Files will be modified.")

    total_changes = rewire_imports(dry_run=dry_run)

    console.print("\n--- Re-wiring Complete ---")
    if dry_run:
        console.print(
            f"💧 DRY RUN: Found {total_changes} potential import changes to make."
        )
        console.print("   Run with '--write' to apply them.")
    else:
        console.print(f"✅ APPLIED: Made {total_changes} import changes.")

    console.print("\n--- NEXT STEPS ---")
    console.print(
        "1.  VERIFY: Run 'make format' and then 'make check' to ensure compliance."
    )


# ID: 4a90a5ee-6b06-4387-be93-fdb39eee443e
def register(app: typer.Typer):
    """Register the 'tools' command group with the main CLI app."""
    app.add_typer(tools_app, name="tools")

--- END OF FILE ./src/cli/commands/tools.py ---

--- START OF FILE ./src/cli/commands/utils_migration.py ---
# src/system/admin/utils_migration.py
"""
Shared utilities for constitutional migration and domain rationalization.
This is the canonical location for logic used by migration-related tools.
"""
from __future__ import annotations

import re
from pathlib import Path
from typing import Dict

from rich.console import Console
from ruamel.yaml import YAML

yaml_handler = YAML()
yaml_handler.preserve_quotes = True
yaml_handler.indent(mapping=2, sequence=4, offset=2)


# ID: 64bb309f-1cf9-4480-afc4-78130e8357e2
def parse_migration_plan(plan_path: Path) -> Dict[str, str]:
    """Parses the markdown migration plan into a mapping dictionary."""
    if not plan_path.exists():
        raise FileNotFoundError(f"Migration plan not found at: {plan_path}")
    content = plan_path.read_text(encoding="utf-8")
    pattern = re.compile(r"\|\s*`([^`]+)`\s*\|\s*`([^`]+)`\s*\|")
    matches = pattern.findall(content)
    if not matches:
        raise ValueError("No valid domain mappings found in the migration plan.")
    return {old.strip(): new.strip() for old, new in matches}


# ID: 80131c72-c024-4823-8226-f63c5d8c4704
def replacer(
    match: re.Match, domain_map: Dict, console: Console, py_file: Path, repo_root: Path
) -> str:
    """Replacement function for re.subn to update capability tags."""
    old_cap = match.group(1)
    for old_domain, new_domain in domain_map.items():
        if old_cap.startswith(old_domain):
            new_cap = old_cap.replace(old_domain, new_domain, 1)
            if old_cap != new_cap:
                console.print(
                    f"   -> In '{py_file.relative_to(repo_root)}': Renaming tag '{old_cap}' -> '[green]{new_cap}[/green]'"
                )
    return match.group(0)

--- END OF FILE ./src/cli/commands/utils_migration.py ---

--- START OF FILE ./src/cli/commands/validate.py ---
# src/system/admin/validate.py
"""
Provides CLI commands for validating constitutional and governance integrity.
This module consolidates and houses the logic from the old src/core/cli tools.
"""
from __future__ import annotations

import ast
import json
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import typer
from jsonschema import ValidationError, validate

from shared.config_loader import load_yaml_file
from shared.logger import getLogger

log = getLogger("core_admin.validate")

validate_app = typer.Typer(help="Commands for validating constitutional integrity.")


def _load_json(path: Path) -> dict:
    """Loads and returns a JSON dictionary from the specified file path."""
    with path.open("r", encoding="utf-8") as f:
        return json.load(f)


def _validate_schema_pair(pair: Tuple[Path, Path]) -> str | None:
    """Validates a YAML file against a JSON Schema, returning an error message or None."""
    yml_path, schema_path = pair
    if not yml_path.exists():
        return f"Missing file: {yml_path}"
    if not schema_path.exists():
        return f"Missing schema: {schema_path}"
    try:
        data = load_yaml_file(yml_path)
        schema = _load_json(schema_path)
        validate(instance=data, schema=schema)
        typer.echo(f"[OK] {yml_path} ✓")
        return None
    except ValidationError as e:
        path = ".".join(map(str, e.path)) or "(root)"
        return f"[FAIL] {yml_path}: {e.message} at {path}"


@validate_app.command("intent-schema")
# ID: 35d3d2a1-f012-4ce6-af61-86ace0f8f37d
def validate_intent_schema(
    intent_path: Path = typer.Option(
        Path(".intent"), "--intent-path", help="Path to the .intent directory."
    ),
):
    """Validate policy YAMLs under .intent/charter using their corresponding JSON Schemas."""
    log.info("Running intent schema validation via core-admin...")
    base = intent_path / "charter"

    # --- THIS IS THE FIX ---
    # The list now points to the correct, consolidated policies and schemas.
    checks: List[Tuple[Path, Path]] = [
        (
            base / "policies" / "agent_policy.yaml",
            base / "schemas" / "agent_policy_schema.json",
        ),
        (
            base / "policies" / "database_policy.yaml",
            base / "schemas" / "database_policy_schema.json",
        ),
        (
            base / "policies" / "canary_policy.yaml",
            base / "schemas" / "canary_policy_schema.json",
        ),
        (
            base / "policies" / "enforcement_model_policy.yaml",
            base / "schemas" / "enforcement_model_schema.json",
        ),
        (
            base / "policies" / "reporting_policy.yaml",
            base / "schemas" / "reporting_policy_schema.json",
        ),
    ]
    # --- END OF FIX ---

    errors = list(filter(None, (_validate_schema_pair(p) for p in checks)))
    if errors:
        typer.echo("\n".join(errors), err=True)
        raise typer.Exit(code=1)
    typer.echo("All checked .intent policy files are valid.")


@dataclass
# ID: cf80ad7c-42cd-4b45-8cf7-6f8d461707b6
class ReviewContext:
    risk_tier: str = "low"
    score: float = 0.0
    touches_critical_paths: bool = False
    checkpoint: bool = False
    canary: bool = False
    approver_quorum: bool = False


_ALLOWED_NODES = {
    ast.Expression,
    ast.BoolOp,
    ast.BinOp,
    ast.UnaryOp,
    ast.Compare,
    ast.Name,
    ast.Load,
    ast.Constant,
    ast.List,
    ast.Tuple,
    ast.And,
    ast.Or,
    ast.Not,
    ast.In,
    ast.Eq,
    ast.NotEq,
}


def _safe_eval(expr: str, ctx: Dict[str, Any]) -> bool:
    """Safely evaluate a boolean expression string against a context dictionary using AST validation."""
    expr = expr.replace(" true", " True").replace(" false", " False")
    tree = ast.parse(expr, mode="eval")
    for node in ast.walk(tree):
        if type(node) not in _ALLOWED_NODES:
            raise ValueError(f"Unsupported expression node: {type(node).__name__}")
        if isinstance(node, ast.Name) and node.id not in ctx:
            raise ValueError(f"Unknown identifier in condition: {node.id}")
    return bool(eval(compile(tree, "<cond>", "eval"), {"__builtins__": {}}, ctx))


def _merge_contexts(a: ReviewContext, b: ReviewContext) -> ReviewContext:
    return ReviewContext(
        risk_tier=b.risk_tier or a.risk_tier,
        score=b.score if b.score != 0.0 else a.score,
        touches_critical_paths=b.touches_critical_paths or a.touches_critical_paths,
        checkpoint=b.checkpoint or a.checkpoint,
        canary=b.canary or a.canary,
        approver_quorum=b.approver_quorum or a.approver_quorum,
    )


@validate_app.command("risk-gates")
# ID: 198e105d-51e8-4c3d-9129-e42c3898356e
def validate_risk_gates(
    mind_path: Path = typer.Option(
        Path(".intent/mind"), "--mind-path", help="Path to the .intent/mind directory."
    ),
    context: Optional[Path] = typer.Option(None, "--context"),
    risk_tier: str = typer.Option("low", "--risk-tier"),
    score: float = typer.Option(0.0, "--score"),
    touches_critical_paths: bool = typer.Option(
        False, "--touches-critical-paths/--no-touches-critical-paths"
    ),
    checkpoint: bool = typer.Option(False, "--checkpoint/--no-checkpoint"),
    canary: bool = typer.Option(False, "--canary/--no-canary"),
    approver_quorum: bool = typer.Option(
        False, "--approver-quorum/--no-approver-quorum"
    ),
):
    """Enforce risk-tier gates from score_policy.yaml."""
    log.info("Running risk gate validation via core-admin...")
    spath = mind_path / "evaluation" / "score_policy.yaml"
    if not spath.exists():
        typer.echo(f"Missing score policy: {spath}", err=True)
        raise typer.Exit(code=2)

    policy = load_yaml_file(spath)
    gates: Dict[str, Any] = policy.get("risk_tier_gates", {})
    conds: Dict[str, str] = policy.get("gate_conditions", {})

    file_ctx = ReviewContext()
    if context and context.exists():
        raw = load_yaml_file(context)
        file_ctx = ReviewContext(**raw)

    cli_ctx = ReviewContext(
        risk_tier, score, touches_critical_paths, checkpoint, canary, approver_quorum
    )
    ctx = _merge_contexts(file_ctx, cli_ctx)

    violations: List[str] = []
    tier = gates.get(ctx.risk_tier, {})
    min_score = float(tier.get("min_score", 0.0))
    required_flags = set(tier.get("require", []))

    if ctx.score < min_score:
        violations.append(
            f"score {ctx.score:.2f} < min_score {min_score:.2f} for tier '{ctx.risk_tier}'"
        )

    cond_env = ctx.__dict__
    for cond_key, flag_name in [
        ("checkpoint_required_when", "checkpoint"),
        ("canary_required_when", "canary"),
        ("approver_quorum_required_when", "approver_quorum"),
    ]:
        expr = conds.get(cond_key)
        if expr and _safe_eval(expr, cond_env):
            required_flags.add(flag_name)

    for flag in sorted(required_flags):
        if not bool(getattr(ctx, flag, False)):
            violations.append(
                f"required '{flag}' is missing/false for tier '{ctx.risk_tier}'"
            )

    if violations:
        typer.echo("Risk gate violations:", err=True)
        for v in violations:
            typer.echo(f" - {v}", err=True)
        raise typer.Exit(code=1)

    typer.echo("Risk gates satisfied ✓")


# ID: 140e067e-54a1-437f-b02b-8a9f0f64a7f2
def register(app: typer.Typer):
    """Register the 'validate' command group with the main CLI app."""
    app.add_typer(validate_app, name="validate")

--- END OF FILE ./src/cli/commands/validate.py ---

--- START OF FILE ./src/core/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/core/__init__.py ---

--- START OF FILE ./src/core/agents/__init__.py ---
# src/agents/__init__.py
# Package marker for src/agents — contains CORE's agent implementations.

--- END OF FILE ./src/core/agents/__init__.py ---

--- START OF FILE ./src/core/agents/code_editor.py ---
# src/agents/code_editor.py
"""
Editing primitives for code manipulation used by agents.

Owns the code-editing capabilities previously defined in agents.utils.
"""

from __future__ import annotations

import ast
import textwrap
from typing import Optional, Tuple


# ID: 034c41cd-f072-4a4f-adf9-9aaecbd7b7e9
class CodeEditor:
    """Provides capabilities to surgically edit code files."""

    def _get_symbol_start_end_lines(
        self, tree: ast.AST, symbol_name: str
    ) -> Optional[Tuple[int, int]]:
        """Finds the 1-based start and end line numbers of a symbol."""
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                if node.name == symbol_name:
                    if hasattr(node, "end_lineno") and node.end_lineno is not None:
                        return node.lineno, node.end_lineno
        return None

    # ID: 39521cc6-f4d0-4236-a0b9-3f5b1eb04312
    def replace_symbol_in_code(
        self, original_code: str, symbol_name: str, new_code_str: str
    ) -> str:
        """
        Replaces a function/method in code with a new version using a line-based strategy.
        """
        try:
            original_tree = ast.parse(original_code)
        except SyntaxError as e:
            raise ValueError(f"Could not parse original code due to syntax error: {e}")

        symbol_location = self._get_symbol_start_end_lines(original_tree, symbol_name)
        if not symbol_location:
            raise ValueError(f"Symbol '{symbol_name}' not found in the original code.")

        start_line, end_line = symbol_location
        start_index = start_line - 1
        end_index = end_line

        lines = original_code.splitlines()

        original_line = lines[start_index]
        indentation = len(original_line) - len(original_line.lstrip(" "))

        clean_new_code = textwrap.dedent(new_code_str).strip()
        new_code_lines = clean_new_code.splitlines()
        indented_new_code_lines = [
            f"{' ' * indentation}{line}" for line in new_code_lines
        ]

        code_before = lines[:start_index]
        code_after = lines[end_index:]

        final_lines = code_before + indented_new_code_lines + code_after
        return "\n".join(final_lines)

--- END OF FILE ./src/core/agents/code_editor.py ---

--- START OF FILE ./src/core/agents/deduction_agent.py ---
# src/agents/deduction_agent.py
"""
Implements the DeductionAgent, responsible for dynamically selecting the most
efficient and effective LLM resource for a given task based on a constitutional policy.
"""

from __future__ import annotations

import asyncio
import json
from typing import Any, Dict

from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.config import settings
from shared.logger import getLogger

log = getLogger("deduction_agent")


# ID: bed143c4-1168-41c1-ac48-9c2ea70ffffb
class DeductionAgent:
    """
    Scores and selects the optimal LLM resource for a given task.
    This agent acts as the reasoning core for the CognitiveService.
    """

    def __init__(self):
        """Initializes the DeductionAgent. Policies are loaded from DB on first use."""
        agent_policy_content = settings.load("charter.policies.agent.agent_policy")
        self.deduction_policy = agent_policy_content.get("resource_selection", {})

        self.resource_manifest: Dict[str, Any] | None = None
        self._lock = asyncio.Lock()

    async def _load_resource_manifest_from_db(self):
        """Lazily loads the LLM resource manifest from the database."""
        async with self._lock:
            if self.resource_manifest is not None:
                return

            log.debug(
                "Loading LLM resource manifest from database for DeductionAgent..."
            )
            async with get_session() as session:
                result = await session.execute(text("SELECT * FROM core.llm_resources"))
                resources = []
                for row in result:
                    # The database driver returns JSONB columns as strings.
                    # We must parse them back into Python dictionaries/lists.
                    row_dict = dict(row._mapping)
                    if isinstance(row_dict.get("performance_metadata"), str):
                        row_dict["performance_metadata"] = json.loads(
                            row_dict["performance_metadata"]
                        )
                    # --- THIS IS THE FIX ---
                    if isinstance(row_dict.get("provided_capabilities"), str):
                        row_dict["provided_capabilities"] = json.loads(
                            row_dict["provided_capabilities"]
                        )
                    # --- END OF FIX ---
                    resources.append(row_dict)

            self.resource_manifest = {"llm_resources": resources}
            log.debug(f"Loaded {len(resources)} LLM resources from DB.")

    def _calculate_score(
        self, resource_metadata: Dict[str, Any], weights: Dict[str, float]
    ) -> float:
        """
        Calculates a weighted score for a single LLM resource.
        Normalizes ratings (1-5 scale) before applying weights.
        """
        score = 0.0
        normalized_cost = (resource_metadata.get("cost_rating", 3) - 1) / 4
        normalized_speed = (resource_metadata.get("speed_rating", 3) - 1) / 4
        normalized_quality = (resource_metadata.get("quality_rating", 3) - 1) / 4
        normalized_reasoning = (resource_metadata.get("reasoning_rating", 3) - 1) / 4

        score += (1 - normalized_cost) * weights.get("cost", 0)
        score += normalized_speed * weights.get("speed", 0)
        score += normalized_quality * weights.get("quality", 0)
        score += normalized_reasoning * weights.get("reasoning", 0)

        return score

    # ID: 01b55061-647f-497e-9865-6fd952556b85
    async def select_best_resource(
        self, task_context: Dict[str, Any] | None = None
    ) -> str:
        """
        Selects the best LLM resource based on the deduction policy and task context.
        """
        await self._load_resource_manifest_from_db()

        task_context = task_context or {}
        role_config = task_context.get("role_config", {})
        role_name = role_config.get("role", "UnknownRole")
        role_description = role_config.get("description", "")

        # --- THIS IS THE FIX for the CognitiveService side ---
        # The required capabilities from the roles table might also be a JSON string
        required_caps_raw = role_config.get("required_capabilities", [])
        if isinstance(required_caps_raw, str):
            required_caps = set(json.loads(required_caps_raw))
        else:
            required_caps = set(required_caps_raw)
        # --- END OF FIX ---

        weights = self.deduction_policy.get("scoring_weights", {})
        overrides = self.deduction_policy.get("task_specific_overrides", [])

        search_text = (role_name + " " + role_description).lower()

        for override in overrides:
            for keyword in override.get("task_keywords", []):
                if keyword.lower() in search_text:
                    weights = override.get("weights", weights)
                    log.debug(
                        f"Applied task-specific scoring weights for role '{role_name}' "
                        f"based on keyword '{keyword}'."
                    )
                    break
            else:
                continue
            break

        resources = self.resource_manifest.get("llm_resources", [])
        if not resources:
            raise ValueError("No LLM resources defined in the database.")

        scored_resources = []
        for resource in resources:
            provided_caps = set(resource.get("provided_capabilities", []))
            if not required_caps.issubset(provided_caps):
                log.debug(
                    f"Skipping resource '{resource['name']}' due to missing "
                    f"capabilities for role '{role_name}'. Required: {required_caps - provided_caps}"
                )
                continue

            metadata = resource.get("performance_metadata")
            if not metadata:
                continue

            score = self._calculate_score(metadata, weights)
            scored_resources.append((resource["name"], score))
            log.debug(f"Scored resource '{resource['name']}': {score:.4f}")

        if not scored_resources:
            raise ValueError(f"No suitable LLM resources found for role '{role_name}'.")

        best_resource = max(scored_resources, key=lambda item: item[1])
        log.info(
            f"Deduction complete. Best resource for role '{role_name}': "
            f"'{best_resource[0]}' (Score: {best_resource[1]:.4f})"
        )
        return best_resource[0]

--- END OF FILE ./src/core/agents/deduction_agent.py ---

--- START OF FILE ./src/core/agents/execution_agent.py ---
# src/core/agents/execution_agent.py
"""
Provides functionality for the execution_agent module.
"""

from __future__ import annotations

from typing import TYPE_CHECKING, List

from core.agents.plan_executor import PlanExecutor
from core.agents.utils import PlanExecutionContext
from core.cognitive_service import CognitiveService
from core.prompt_pipeline import PromptPipeline
from core.self_correction_engine import attempt_correction
from core.validation_pipeline import validate_code
from features.governance.micro_proposal_validator import MicroProposalValidator
from shared.config import settings
from shared.logger import getLogger
from shared.models import ExecutionTask, PlanExecutionError

if TYPE_CHECKING:
    from features.governance.audit_context import AuditorContext


log = getLogger(__name__)


# ID: 3adc833a-41c4-462d-8118-5126e634c57f
class ExecutionAgent:
    """Orchestrates the execution of a plan, including code generation and validation."""

    def __init__(
        self,
        cognitive_service: CognitiveService,
        prompt_pipeline: PromptPipeline,
        plan_executor: PlanExecutor,
        auditor_context: "AuditorContext",
    ):
        """Initializes the ExecutionAgent with its required tools and constitutional policies."""
        self.cognitive_service = cognitive_service
        self.prompt_pipeline = prompt_pipeline
        self.executor = plan_executor
        self.git_service = self.executor.git_service
        self.config = self.executor.config
        self.auditor_context = auditor_context
        self.validator = MicroProposalValidator()

        agent_policy = settings.load("charter.policies.agent.agent_policy")
        self.max_correction_attempts = agent_policy.get("execution_agent", {}).get(
            "max_correction_attempts", 2
        )

    def _verify_plan(self, plan: List[ExecutionTask]) -> None:
        """
        Verifies a micro-proposal plan against the constitution before execution.
        Raises PlanExecutionError if any part of the plan is invalid.
        """
        log.info(
            "🕵️  ExecutionAgent is verifying the received plan against the constitution..."
        )
        is_valid, error_message = self.validator.validate(plan)
        if not is_valid:
            raise PlanExecutionError(f"Plan validation failed: {error_message}")
        log.info("   -> ✅ Plan is constitutionally valid.")

    # ID: 0a9e4ece-68f3-4711-9633-23598d5c7c2a
    async def execute_plan(
        self,
        high_level_goal: str,
        plan: List[ExecutionTask],
        is_micro_proposal: bool = False,
    ) -> tuple[bool, str]:
        if not plan:
            return False, "Plan is empty or invalid."

        try:
            if is_micro_proposal:
                self._verify_plan(plan)
        except PlanExecutionError as e:
            log.error(
                f"❌ CRITICAL: Received an invalid plan. Execution aborted. Reason: {e}"
            )
            return False, str(e)

        log.info("--- Starting Governed Code Generation Phase ---")
        success, error_message = await self._generate_and_validate_all_tasks(
            high_level_goal, plan
        )
        if not success:
            return False, error_message
        log.info("--- Handing off fully validated plan to Executor ---")
        return await self._execute_validated_plan(plan)

    async def _generate_and_validate_all_tasks(
        self, high_level_goal: str, plan: List[ExecutionTask]
    ) -> tuple[bool, str]:
        for task in plan:
            log.info(f"Processing task: '{task.step}'")
            success, error_message = await self._process_single_task(
                task, high_level_goal
            )
            if not success:
                return False, error_message
        return True, ""

    async def _process_single_task(
        self, task: ExecutionTask, high_level_goal: str
    ) -> tuple[bool, str]:
        generated_code = await self._generate_code_for_task_type(task, high_level_goal)
        if not generated_code:
            if task.action not in ["create_file", "edit_function", "create_proposal"]:
                return True, ""
            return False, f"Initial code generation failed for step: '{task.step}'"
        return await self._validate_with_corrections(
            task,
            generated_code,
            high_level_goal,
        )

    async def _generate_code_for_task_type(self, task: ExecutionTask, goal: str) -> str:
        if task.action in ["create_file", "edit_function"]:
            return await self._generate_code_for_standard_task(task, goal)
        if task.action == "create_proposal":
            return await self._generate_code_for_proposal(task, goal)
        return ""

    async def _validate_with_corrections(
        self, task: ExecutionTask, initial_code: str, goal: str
    ) -> tuple[bool, str]:
        current_code = initial_code
        for attempt in range(self.max_correction_attempts + 1):
            log.info(f"  -> Validation attempt {attempt + 1}...")
            validation_result = validate_code(
                task.params.file_path,
                current_code,
                auditor_context=self.auditor_context,
            )
            if validation_result["status"] == "clean":
                log.info("  -> ✅ Code is constitutionally valid.")
                task.params.code = validation_result["code"]
                return True, ""
            if attempt >= self.max_correction_attempts:
                return False, (
                    f"Self-correction failed after {self.max_correction_attempts} "
                    f"attempts for step: '{task.step}'"
                )
            corrected_code = await self._attempt_code_correction(
                task, current_code, validation_result, goal
            )
            if corrected_code is None:
                return (
                    False,
                    "Self-correction failed to produce a valid retry operation.",
                )
            current_code = corrected_code
        return (
            False,
            f"Could not produce valid code for step '{task.step}' after all attempts.",
        )

    async def _attempt_code_correction(
        self, task: ExecutionTask, current_code: str, validation_result: dict, goal: str
    ) -> str | None:
        log.warning("  -> ⚠️ Code failed validation. Preparing for self-correction.")
        log.warning(f"     Violations: {validation_result['violations']}")
        correction_context = {
            "file_path": task.params.file_path,
            "code": current_code,
            "violations": validation_result["violations"],
            "original_prompt": goal,
        }
        log.info("  -> 🧬 Invoking self-correction engine...")
        correction_result = await attempt_correction(
            correction_context, self.cognitive_service
        )
        if correction_result.get("status") == "retry_staged":
            pending_id = correction_result.get("pending_id")
            pending_op = self.executor.file_handler.pending_writes.get(pending_id)
            if pending_op:
                log.info("  -> ✅ Self-correction generated a potential fix.")
                return pending_op["code"]
        return None

    async def _execute_validated_plan(
        self, plan: List[ExecutionTask]
    ) -> tuple[bool, str]:
        with PlanExecutionContext(self.git_service, self.config):
            try:
                await self.executor.execute_plan(plan)
                return True, "✅ Plan executed successfully."
            except PlanExecutionError as e:
                return False, f"Plan execution failed: {str(e)}"
            except Exception as e:
                log.error(
                    "An unexpected error occurred during execution.",
                    exc_info=True,
                )
                return False, f"An unexpected error occurred: {str(e)}"

    async def _generate_code_for_proposal(self, task: ExecutionTask, goal: str) -> str:
        log.info(f"✍️  Generating full file content for proposal: '{task.step}'...")
        file_path_str = task.params.file_path
        if not file_path_str:
            return ""
        original_content = self._read_existing_file(file_path_str)
        prompt_template = settings.load("mind.prompts.proposal_generator")
        final_prompt = prompt_template.format(
            goal=goal,
            step=task.step,
            file_path=file_path_str,
            original_content=original_content,
        )
        generator = await self.cognitive_service.get_client_for_role("Coder")
        return await generator.make_request_async(
            final_prompt, user_id="execution_agent_proposer"
        )

    async def _generate_code_for_standard_task(
        self, task: ExecutionTask, goal: str
    ) -> str:
        log.info(f"✍️  Generating code for task: '{task.step}'...")
        if task.action not in ["create_file", "edit_function"]:
            return ""
        prompt_template = settings.get_path(
            "mind.prompts.standard_task_generator"
        ).read_text()
        final_prompt = prompt_template.format(
            goal=goal,
            step=task.step,
            file_path=task.params.file_path,
            symbol_name=task.params.symbol_name or "",
        )
        enriched_prompt = self.prompt_pipeline.process(final_prompt)
        generator = await self.cognitive_service.get_client_for_role("Coder")
        return await generator.make_request_async(
            enriched_prompt, user_id="execution_agent_coder"
        )

    def _read_existing_file(self, file_path_str: str) -> str:
        try:
            return (settings.REPO_PATH / file_path_str).read_text(encoding="utf-8")
        except FileNotFoundError:
            log.warning(f"File {file_path_str} not found, generating from scratch.")
            return ""
        except Exception as e:
            log.error(f"Error reading {file_path_str}: {e}")
            return ""

--- END OF FILE ./src/core/agents/execution_agent.py ---

--- START OF FILE ./src/core/agents/intent_translator.py ---
# src/agents/intent_translator.py
"""
Implements the IntentTranslator agent,
responsible for converting natural language user requests into structured,
executable goals for the CORE system.
"""

from __future__ import annotations

from core.cognitive_service import CognitiveService
from core.prompt_pipeline import PromptPipeline  # <-- ADD THIS IMPORT
from shared.config import settings
from shared.logger import getLogger

log = getLogger("intent_translator")


# ID: 419c46d8-1368-4447-a480-e040954870e5
class IntentTranslator:
    """An agent that translates natural language into structured goals."""

    def __init__(self, cognitive_service: CognitiveService):
        """Initializes the translator with the CognitiveService."""
        self.cognitive_service = cognitive_service
        self.prompt_pipeline = PromptPipeline(settings.REPO_PATH)  # <-- ADD THIS LINE
        self.prompt_path = settings.MIND / "prompts" / "intent_translator.prompt"
        if not self.prompt_path.exists():
            raise FileNotFoundError(
                "Constitutional prompt for IntentTranslator not found."
            )
        self.prompt_template = self.prompt_path.read_text(encoding="utf-8")

    # ID: 50ca512c-e6d4-475d-942e-4b8af8a4dc3c
    def translate(self, user_input: str) -> str:
        """
        Takes a user's natural language input and translates it into a
        structured goal for the PlannerAgent.
        """
        log.info(f"Translating user intent: '{user_input}'")
        client = self.cognitive_service.get_client_for_role("IntentTranslator")

        # Use the pipeline to inject context into the prompt
        final_prompt = self.prompt_pipeline.process(
            self.prompt_template.format(user_input=user_input)
        )

        structured_goal = client.make_request(final_prompt, user_id="intent_translator")
        log.info(f"Translated goal: '{structured_goal}'")
        return structured_goal

--- END OF FILE ./src/core/agents/intent_translator.py ---

--- START OF FILE ./src/core/agents/micro_planner.py ---
# src/core/agents/micro_planner.py
"""
Implements the MicroPlannerAgent, a specialized agent for generating safe,
low-risk plans that can be auto-approved under the micro_proposal_policy.
"""
from __future__ import annotations

import json
from typing import Any, Dict, List

from core.cognitive_service import CognitiveService
from shared.config import settings
from shared.logger import getLogger
from shared.utils.parsing import extract_json_from_response

log = getLogger("micro_planner_agent")


# ID: cc3308b8-f2b2-43ab-b412-0f5067a031a1
class MicroPlannerAgent:
    """Decomposes goals into safe, auto-approvable plans."""

    def __init__(self, cognitive_service: CognitiveService):
        """Initializes the MicroPlannerAgent."""
        self.cognitive_service = cognitive_service

        # --- THIS IS THE REFACTOR ---
        # Load policy and prompt using the centralized settings object.
        self.policy = settings.load("charter.policies.agent.micro_proposal_policy")
        self.prompt_template = settings.get_path(
            "mind.prompts.micro_planner"
        ).read_text(encoding="utf-8")
        # --- END OF REFACTOR ---

    # ID: f9c908ca-b681-4f2d-9009-ba1ad3c936b3
    async def create_micro_plan(self, goal: str) -> List[Dict[str, Any]]:
        """Creates a safe execution plan from a user goal."""
        policy_content = json.dumps(self.policy, indent=2)
        final_prompt = self.prompt_template.format(
            policy_content=policy_content, user_goal=goal
        )

        planner_client = self.cognitive_service.get_client_for_role("Planner")
        response_text = await planner_client.make_request_async(
            final_prompt, user_id="micro_planner_agent"
        )

        plan = extract_json_from_response(response_text)
        if isinstance(plan, list):
            return plan

        log.warning(
            "Micro-planner did not return a valid JSON list. Returning empty plan."
        )
        return []

--- END OF FILE ./src/core/agents/micro_planner.py ---

--- START OF FILE ./src/core/agents/plan_executor.py ---
# src/core/agents/plan_executor.py
"""
Executes a sequence of predefined code modification tasks including file creation,
function editing, capability tagging, and proposal generation.
"""

from __future__ import annotations

import asyncio
import uuid
from typing import List

import yaml

from core.agents.code_editor import CodeEditor
from core.agents.utils import SymbolLocator
from core.file_handler import FileHandler
from core.git_service import GitService
from core.validation_pipeline import validate_code
from features.governance.audit_context import AuditorContext
from shared.logger import getLogger
from shared.models import ExecutionTask, PlanExecutionError, PlannerConfig, TaskParams

log = getLogger(__name__)


# ID: a2b23de4-07fa-4a66-8f29-783934079956
class PlanExecutor:
    """A service that takes a list of ExecutionTasks and executes them sequentially."""

    def __init__(
        self, file_handler: FileHandler, git_service: GitService, config: PlannerConfig
    ):
        """Initializes the executor with necessary dependencies."""
        self.file_handler = file_handler
        self.git_service = git_service
        self.config = config
        self.repo_path = self.file_handler.repo_path
        self.symbol_locator = SymbolLocator()
        self.code_editor = CodeEditor()
        self._executor = asyncio.get_event_loop().run_in_executor
        self.file_context: dict[str, str] = {}  # To store content from read_file
        self.auditor_context = AuditorContext(self.repo_path)

    # ID: 65f105d2-27e4-4fca-8f96-27decc90bca5
    async def execute_plan(self, plan: List[ExecutionTask]):
        """Executes the entire plan, one task at a time."""
        for i, task in enumerate(plan, 1):
            log.info(f"--- Executing Step {i}/{len(plan)}: {task.step} ---")
            await self._execute_task_with_timeout(task)

    async def _execute_task_with_timeout(self, task: ExecutionTask):
        """Execute task with timeout protection."""
        timeout = self.config.task_timeout
        try:
            await asyncio.wait_for(self._execute_task(task), timeout=timeout)
        except asyncio.TimeoutError:
            raise PlanExecutionError(f"Task '{task.step}' timed out after {timeout}s")

    async def _execute_task(self, task: ExecutionTask):
        """Dispatcher that executes a single task from a plan based on its action type."""
        action_map = {
            "read_file": self._execute_read_file,
            "edit_file": self._execute_edit_file,
            "add_capability_tag": self._execute_add_tag,
            "create_file": self._execute_create_file,
            "edit_function": self._execute_edit_function,
            "create_proposal": self._execute_create_proposal,
            "delete_file": self._execute_delete_file,
        }
        if task.action in action_map:
            await action_map[task.action](task.params)
        else:
            log.warning(f"Skipping task: Unknown action '{task.action}'.")

    async def _execute_read_file(self, params: TaskParams):
        """Executes the 'read_file' action and stores content in context."""
        file_path_str = params.file_path
        if not file_path_str:
            raise PlanExecutionError("Missing 'file_path' for read_file action.")

        full_path = self.repo_path / file_path_str
        if not full_path.exists():
            raise PlanExecutionError(f"File to be read does not exist: {file_path_str}")

        self.file_context[file_path_str] = full_path.read_text(encoding="utf-8")
        log.info(f"📖 Read file '{file_path_str}' into context.")

    async def _execute_edit_file(self, params: TaskParams):
        """Executes the 'edit_file' action using the context from 'read_file'."""
        file_path_str = params.file_path
        new_content = params.code  # The planner should now provide the full new content
        if not all([file_path_str, new_content]):
            raise PlanExecutionError(
                "Missing 'file_path' or 'code' for edit_file action."
            )

        full_path = self.repo_path / file_path_str
        if not full_path.exists():
            raise PlanExecutionError(
                f"File to be edited does not exist: {file_path_str}"
            )

        validation_result = validate_code(
            file_path_str, new_content, auditor_context=self.auditor_context
        )
        if validation_result["status"] == "dirty":
            raise PlanExecutionError(
                f"Generated code for '{file_path_str}' failed validation.",
                violations=validation_result["violations"],
            )

        pending_id = self.file_handler.add_pending_write(
            prompt=f"Goal: edit file {file_path_str}",
            suggested_path=file_path_str,
            code=validation_result["code"],
        )
        self.file_handler.confirm_write(pending_id)

        if self.config.auto_commit and self.git_service.is_git_repo():
            self.git_service.add(file_path_str)
            self.git_service.commit(f"feat: Modify file {file_path_str}")

    async def _execute_delete_file(self, params: TaskParams):
        """Executes the 'delete_file' action."""
        file_path_str = params.file_path
        if not file_path_str:
            raise PlanExecutionError("Missing 'file_path' for delete_file action.")

        full_path = self.repo_path / file_path_str
        if not full_path.exists():
            log.warning(
                f"File '{file_path_str}' to be deleted does not exist. Skipping."
            )
            return

        full_path.unlink()
        log.info(f"🗑️  Deleted file: {file_path_str}")

        if self.config.auto_commit and self.git_service.is_git_repo():
            self.git_service._run_command(["git", "rm", file_path_str])
            self.git_service.commit(
                f"refactor(cleanup): Remove obsolete file {file_path_str}"
            )

    async def _execute_create_proposal(self, params: TaskParams):
        """Executes the 'create_proposal' action."""
        target_path = params.file_path
        content = params.code
        justification = params.justification

        if not all([target_path, content, justification]):
            raise PlanExecutionError("Missing required parameters for create_proposal.")

        proposal_id = str(uuid.uuid4())[:8]
        proposal_filename = (
            f"cr-{proposal_id}-{target_path.split('/')[-1].replace('.py','')}.yaml"
        )
        proposal_path = self.repo_path / ".intent/proposals" / proposal_filename

        proposal_content = {
            "target_path": target_path,
            "action": "replace_file",
            "justification": justification,
            "content": content,
        }

        yaml_content = yaml.dump(
            proposal_content, indent=2, default_flow_style=False, sort_keys=True
        )

        proposal_path.parent.mkdir(parents=True, exist_ok=True)
        proposal_path.write_text(yaml_content, encoding="utf-8")
        log.info(f"🏛️  Created constitutional proposal: {proposal_filename}")

        if self.config.auto_commit and self.git_service.is_git_repo():
            self.git_service.add(str(proposal_path))
            self.git_service.commit(
                f"feat(proposal): Create proposal for {target_path}"
            )

    async def _execute_add_tag(self, params: TaskParams):
        """Executes the surgical 'add_capability_tag' action."""
        file_path, symbol_name, tag = params.file_path, params.symbol_name, params.tag
        line_number = await self._executor(
            None,
            self.symbol_locator.find_symbol_line,
            self.repo_path / file_path,
            symbol_name,
        )
        if not line_number:
            raise PlanExecutionError(
                f"Could not find symbol '{symbol_name}' in '{file_path}'."
            )

        full_path = self.repo_path / file_path
        if not full_path.exists():
            raise PlanExecutionError(f"File '{file_path}' does not exist.")

        lines = full_path.read_text(encoding="utf-8").splitlines()

        insertion_index = line_number - 1

        original_line = lines[insertion_index]
        indentation_spaces = len(original_line) - len(original_line.lstrip(" "))
        lines.insert(insertion_index, f"{' ' * indentation_spaces}# ID: {tag}")

        modified_code = "\n".join(lines)

        validation_result = validate_code(
            file_path, modified_code, auditor_context=self.auditor_context
        )
        if validation_result["status"] == "dirty":
            raise PlanExecutionError(
                f"Surgical modification for '{file_path}' failed validation.",
                violations=validation_result["violations"],
            )

        pending_id = self.file_handler.add_pending_write(
            prompt=f"Goal: add tag to {symbol_name}",
            suggested_path=file_path,
            code=validation_result["code"],
        )
        self.file_handler.confirm_write(pending_id)

        if self.config.auto_commit and self.git_service.is_git_repo():
            self.git_service.add(file_path)
            self.git_service.commit(
                f"refactor(capability): Add '{tag}' tag to {symbol_name}"
            )

    async def _execute_create_file(self, params: TaskParams):
        """Executes the 'create_file' action."""
        file_path, code = params.file_path, params.code
        full_path = self.repo_path / file_path
        if full_path.exists():
            raise FileExistsError(
                f"File '{file_path}' already exists. Use 'edit_function' instead."
            )

        validation_result = validate_code(
            file_path, code, auditor_context=self.auditor_context
        )
        if validation_result["status"] == "dirty":
            raise PlanExecutionError(
                f"Generated code for '{file_path}' failed validation.",
                violations=validation_result["violations"],
            )

        pending_id = self.file_handler.add_pending_write(
            prompt=f"Goal: create file {file_path}",
            suggested_path=file_path,
            code=validation_result["code"],
        )
        self.file_handler.confirm_write(pending_id)

        if self.config.auto_commit and self.git_service.is_git_repo():
            self.git_service.add(file_path)
            self.git_service.commit(f"feat: Create new file {file_path}")

    async def _execute_edit_function(self, params: TaskParams):
        """Executes the 'edit_function' action using the CodeEditor."""
        file_path, symbol_name, new_code = (
            params.file_path,
            params.symbol_name,
            params.code,
        )
        full_path = self.repo_path / file_path

        if not full_path.exists():
            raise FileNotFoundError(
                f"Cannot edit function, file not found: '{file_path}'"
            )

        original_code = await self._executor(None, full_path.read_text, "utf-8")

        validation_result = validate_code(
            file_path, new_code, auditor_context=self.auditor_context
        )
        if validation_result["status"] == "dirty":
            raise PlanExecutionError(
                f"Generated code for '{symbol_name}' failed validation.",
                violations=validation_result["violations"],
            )

        validated_code_snippet = validation_result["code"]
        try:
            final_code = self.code_editor.replace_symbol_in_code(
                original_code, symbol_name, validated_code_snippet
            )
        except ValueError as e:
            raise PlanExecutionError(f"Failed to edit code in '{file_path}': {e}")

        pending_id = self.file_handler.add_pending_write(
            prompt=f"Goal: edit function {symbol_name} in {file_path}",
            suggested_path=file_path,
            code=final_code,
        )
        self.file_handler.confirm_write(pending_id)

        if self.config.auto_commit and self.git_service.is_git_repo():
            self.git_service.add(file_path)
            self.git_service.commit(
                f"feat: Modify function {symbol_name} in {file_path}"
            )

--- END OF FILE ./src/core/agents/plan_executor.py ---

--- START OF FILE ./src/core/agents/planner_agent.py ---
# src/core/agents/planner_agent.py
"""
The PlannerAgent is responsible for decomposing a high-level user goal
into a concrete, step-by-step execution plan that can be carried out
by the ExecutionAgent.
"""

from __future__ import annotations

import json
from typing import List

from pydantic import ValidationError
from rich.console import Console
from rich.syntax import Syntax

from core.cognitive_service import CognitiveService
from core.prompt_pipeline import PromptPipeline
from shared.config import settings
from shared.logger import getLogger
from shared.models import ExecutionTask, PlanExecutionError
from shared.utils.parsing import extract_json_from_response

log = getLogger(__name__)


# ID: 8a33ab90-80db-4455-b1b8-636405897ced
class PlannerAgent:
    """Decomposes goals into executable plans."""

    def __init__(self, cognitive_service: CognitiveService):
        """Initializes the PlannerAgent."""
        self.cognitive_service = cognitive_service
        self.prompt_template = settings.get_path(
            "mind.prompts.planner_agent"
        ).read_text(encoding="utf-8")
        self.actions_policy = settings.load(
            "charter.policies.governance.available_actions_policy"
        )
        self.prompt_pipeline = PromptPipeline(settings.REPO_PATH)

    def _build_planning_prompt(self, goal: str, reconnaissance_report: str) -> str:
        """Builds the detailed prompt for the planning LLM."""
        available_actions = self.actions_policy.get("actions", [])
        action_descriptions = "\n".join(
            [
                f"- `{action['name']}`: {action['description']}"
                for action in available_actions
            ]
        )
        base_prompt = self.prompt_template.format(
            goal=goal,
            action_descriptions=action_descriptions,
            reconnaissance_report=reconnaissance_report,
        )
        return self.prompt_pipeline.process(base_prompt)

    def _log_plan_summary(self, plan: List[ExecutionTask]):
        """Logs a human-readable summary of the execution plan."""
        console = Console()
        log.info("🧠 The PlannerAgent has created the following execution plan:")
        for i, task in enumerate(plan, 1):
            log.info(f"  {i}. {task.step} (Action: {task.action})")
        log.info("🕵️ The ExecutionAgent will now carry out this plan.")
        try:
            plan_json = json.dumps([t.model_dump() for t in plan], indent=2)
            console.print(Syntax(plan_json, "json", theme="solarized-dark"))
        except Exception:
            log.warning("Could not serialize plan to JSON for logging.")

    # ID: b918335b-60af-4132-a944-88628a3caa66
    async def create_execution_plan(
        self, goal: str, reconnaissance_report: str
    ) -> List[ExecutionTask]:
        """Creates an execution plan from a user goal and a reconnaissance report."""
        max_retries = settings.model_extra.get("CORE_MAX_RETRIES", 3)

        prompt = self._build_planning_prompt(goal, reconnaissance_report)
        client = await self.cognitive_service.get_client_for_role("Planner")

        for attempt in range(max_retries):
            log.info("🧠 Generating step-by-step plan from reconnaissance context...")
            response_text = await client.make_request_async(prompt)

            if response_text:
                try:
                    parsed_json = extract_json_from_response(response_text)
                    if not isinstance(parsed_json, list):
                        raise ValueError(
                            "LLM did not return a valid JSON list for the plan."
                        )

                    validated_plan = [ExecutionTask(**task) for task in parsed_json]
                    self._log_plan_summary(validated_plan)
                    return validated_plan
                except (ValueError, ValidationError, json.JSONDecodeError) as e:
                    log.warning(f"Plan creation attempt {attempt + 1} failed: {e}")
                    if attempt == max_retries - 1:
                        raise PlanExecutionError(
                            "Failed to create a valid plan after max retries."
                        )
        return []

--- END OF FILE ./src/core/agents/planner_agent.py ---

--- START OF FILE ./src/core/agents/reconnaissance_agent.py ---
# src/core/agents/reconnaissance_agent.py
"""
Implements the ReconnaissanceAgent, which performs targeted queries and semantic
search against the knowledge graph to build a minimal, surgical context for the Planner.
"""

from __future__ import annotations

import re
from typing import Any, Dict, List

from core.cognitive_service import CognitiveService
from shared.logger import getLogger

log = getLogger("recon_agent")

SYMBOL_REGEX = re.compile(r"\b([A-Z][A-Za-z0-9_]+|`[a-zA-Z0-9_./]+`)\b")


# ID: f2d9b442-6f3f-4a62-978c-6d5fb9c20b1d
class ReconnaissanceAgent:
    """Queries the knowledge graph to build a focused context for a task."""

    def __init__(
        self, knowledge_graph: Dict[str, Any], cognitive_service: CognitiveService
    ):
        """Initializes with the knowledge graph and cognitive service for search."""
        self.graph = knowledge_graph
        self.symbols = knowledge_graph.get("symbols", {})
        self.cognitive_service = cognitive_service

    async def _find_relevant_files(self, goal: str) -> List[str]:
        """Performs a semantic search to find files relevant to the goal."""
        log.info("   -> Performing semantic search for relevant files...")
        try:
            search_results = await self.cognitive_service.search_capabilities(
                goal, limit=3
            )
            if not search_results:
                return []

            relevant_files = set()
            for hit in search_results:
                if (payload := hit.get("payload")) and (
                    file_path := payload.get("source_path")
                ):
                    relevant_files.add(file_path)

            log.info(f"   -> Found relevant files: {list(relevant_files)}")
            return sorted(list(relevant_files))
        except Exception as e:
            log.warning(f"Semantic file search failed: {e}")
            return []

    # ID: f3952e9d-1228-4013-9bc8-91d0b551d3b2
    async def generate_report(self, goal: str) -> str:
        """
        Analyzes a goal, queries the graph, and generates a surgical context report.
        """
        log.info(f"🔬 Conducting reconnaissance for goal: '{goal}'")

        # Perform both symbol-based and semantic search for comprehensive context
        target_symbols = [s.replace("`", "") for s in SYMBOL_REGEX.findall(goal)]
        relevant_files = await self._find_relevant_files(goal)

        log.info(f"   -> Identified target symbols: {target_symbols}")

        report_parts = ["# Reconnaissance Report"]

        if relevant_files:
            report_parts.append("\n## Relevant Files Identified by Semantic Search:")
            for file in relevant_files:
                report_parts.append(f"- `{file}`")
        else:
            report_parts.append(
                "\n- No specific relevant files were identified via semantic search."
            )

        if not target_symbols:
            report_parts.append(
                "\n- No specific code symbols were identified in the goal."
            )
        else:
            for symbol_name in target_symbols:
                symbol_data = self._find_symbol_data(symbol_name)
                if not symbol_data:
                    report_parts.append(
                        f"\n## Symbol: `{symbol_name}`\n\n- **Status:** Not found in the Knowledge Graph."
                    )
                    continue

                callers = self._find_callers(symbol_name)
                report_parts.append(
                    f"\n## Symbol: `{symbol_data.get('key', symbol_name)}`"
                )
                report_parts.append(f"- **Type:** {symbol_data.get('type')}")
                report_parts.append(f"- **Location:** `{symbol_data.get('file')}`")
                report_parts.append(f"- **Intent:** {symbol_data.get('intent')}")

                if callers:
                    report_parts.append("- **Referenced By:**")
                    for caller in callers:
                        report_parts.append(f"  - `{caller.get('key')}`")
                else:
                    report_parts.append(
                        "- **Referenced By:** None. This symbol appears to be unreferenced."
                    )

        report_parts.append(
            "\n---\n**Conclusion:** The analysis is complete. Use this information to form a precise plan."
        )
        report = "\n".join(report_parts)
        log.info(f"   -> Generated Surgical Context Report:\n{report}")
        return report

    def _find_symbol_data(self, symbol_name: str) -> Dict | None:
        """Finds the main data entry for a symbol by name or key."""
        for key, data in self.symbols.items():
            if key.endswith(f"::{symbol_name}") or data.get("name") == symbol_name:
                return data
        return None

    def _find_callers(self, symbol_name: str) -> List[Dict]:
        """Finds all symbols in the graph that call the target symbol."""
        return [
            data
            for data in self.symbols.values()
            if symbol_name in data.get("calls", [])
        ]

--- END OF FILE ./src/core/agents/reconnaissance_agent.py ---

--- START OF FILE ./src/core/agents/tagger_agent.py ---
# src/agents/tagger_agent.py
"""
Implements the CapabilityTaggerAgent, which finds unassigned capabilities
and uses an LLM to suggest constitutionally-valid names for them.
"""
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Optional

from rich.console import Console
from rich.table import Table

from core.cognitive_service import CognitiveService
from core.knowledge_service import KnowledgeService
from shared.config import settings
from shared.logger import getLogger
from shared.utils.parallel_processor import ThrottledParallelProcessor

log = getLogger("tagger_agent")


# ID: 444b630b-9cf5-4e70-ad60-4756e34144e8
class CapabilityTaggerAgent:
    """An agent that finds unassigned capabilities and suggests names."""

    def __init__(
        self,
        cognitive_service: CognitiveService,
        knowledge_service: KnowledgeService,
    ):
        """Initializes the agent with the tools it needs."""
        self.cognitive_service = cognitive_service
        self.knowledge_service = knowledge_service
        self.console = Console()
        prompt_path = settings.MIND / "prompts" / "capability_tagger.prompt"
        self.prompt_template = prompt_path.read_text(encoding="utf-8")
        self.existing_capabilities = self.knowledge_service.list_capabilities()
        self.tagger_client = self.cognitive_service.get_client_for_role("CodeReviewer")

    def _extract_symbol_info(self, symbol: Dict[str, Any]) -> Dict[str, Any]:
        """Extracts the relevant information for the prompt from a symbol entry."""
        return {
            "key": symbol.get("key"),
            "name": symbol.get("name"),
            "file": symbol.get("file"),
            "domain": symbol.get("domain"),
            "docstring": symbol.get("docstring"),
        }

    def _build_suggestion_prompt(self, symbol_info: Dict[str, Any]) -> str:
        """Builds the final prompt for AI suggestion request."""
        return self.prompt_template.format(
            existing_capabilities=json.dumps(self.existing_capabilities, indent=2),
            symbol_info=json.dumps(symbol_info, indent=2),
        )

    async def _get_suggestion_for_symbol(
        self, symbol: Dict[str, Any]
    ) -> Optional[Dict[str, str]]:
        """Async worker to get a single tag suggestion from the LLM."""
        symbol_info = self._extract_symbol_info(symbol)
        final_prompt = self._build_suggestion_prompt(symbol_info)
        response = await self.tagger_client.make_request_async(
            final_prompt, user_id="tagger_agent"
        )
        try:
            parsed = json.loads(response)
            suggestion = parsed.get("suggested_capability")

            if suggestion is None:
                return None

            if suggestion:
                return {
                    "key": symbol["key"],
                    "name": symbol["name"],
                    "file": symbol["file"],
                    "suggestion": suggestion,
                }
        except (json.JSONDecodeError, AttributeError):
            log.warning(f"Could not parse suggestion for {symbol['name']}.")
        return None

    # ID: 4c92bdd4-66f8-4292-b9c4-daeb2d7fdff7
    async def suggest_and_apply_tags(
        self, file_path: Path | None = None
    ) -> Optional[Dict[str, Dict]]:
        """
        Finds unassigned public symbols, gets AI-powered suggestions, and returns them.
        """
        log.info("🔍 Searching for unassigned capabilities...")
        all_unassigned = [
            s
            for s in self.knowledge_service.graph.get("symbols", {}).values()
            if s.get("capability") == "unassigned"
        ]
        public_unassigned_symbols = [
            s for s in all_unassigned if not s.get("name", "").startswith("_")
        ]
        log.info(
            f"   -> Filtering to {len(public_unassigned_symbols)} public symbols for AI analysis."
        )

        target_symbols = [
            s
            for s in public_unassigned_symbols
            if not file_path or s.get("file") == str(file_path)
        ]

        if not target_symbols:
            return None

        log.info(f"Found {len(target_symbols)} unassigned public symbols. Analyzing...")

        processor = ThrottledParallelProcessor(description="Analyzing symbols...")
        # --- THIS IS THE KEY LINE ---
        results = await processor.run_async(
            target_symbols, self._get_suggestion_for_symbol
        )
        # --- END KEY LINE ---

        suggestions_to_return = {}
        table = Table(title="🤖 Capability Tagger Agent Suggestions")
        table.add_column("Symbol", style="cyan")
        table.add_column("File", style="green")
        table.add_column("Suggested Capability", style="yellow")

        valid_results = filter(None, results)
        for res in valid_results:
            table.add_row(res["name"], res["file"], res["suggestion"])
            suggestions_to_return[res["key"]] = res

        if not suggestions_to_return:
            return None

        self.console.print(table)
        return suggestions_to_return

--- END OF FILE ./src/core/agents/tagger_agent.py ---

--- START OF FILE ./src/core/agents/utils.py ---
# src/agents/utils.py
"""
Utility classes and functions for CORE agents including symbol location
and plan execution context management.
"""

from __future__ import annotations

import ast
from pathlib import Path
from typing import Optional

from core.git_service import GitService
from shared.logger import getLogger
from shared.models import PlannerConfig

log = getLogger(__name__)


# ID: fd0b06b9-209b-4cdf-bac1-79b179e5810a
class SymbolLocator:
    """Dedicated class for finding symbols in code files."""

    @staticmethod
    # ID: 2d44d022-7e57-4ab6-8bef-bcf0ae9ed360
    def find_symbol_line(file_path: Path, symbol_name: str) -> Optional[int]:
        """Find the 1-based line number of a function or class definition in a file."""
        if not file_path.exists():
            raise FileNotFoundError(f"File not found: {file_path}")

        try:
            code = file_path.read_text(encoding="utf-8")
            tree = ast.parse(code)
            for node in ast.walk(tree):
                if isinstance(
                    node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
                ):
                    if node.name == symbol_name:
                        return node.lineno
        except (SyntaxError, UnicodeDecodeError) as e:
            raise RuntimeError(f"Failed to parse {file_path}: {e}") from e
        return None


# ID: 6eba16a2-dd3b-4f89-b993-9ebc9eca5f1e
class PlanExecutionContext:
    """Context manager for safe plan execution with rollback."""

    def __init__(self, git_service: GitService, config: PlannerConfig):
        """Initialize the context with the required services."""
        self.git_service = git_service
        self.config = config
        self.initial_commit: Optional[str] = None

    def __enter__(self):
        """Set up the execution context, capturing the initial git commit hash."""
        if self.git_service.is_git_repo():
            try:
                self.initial_commit = self.git_service.get_current_commit()
            except Exception as e:
                log.warning(f"Could not get current commit for rollback: {e}")
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        """Clean up and handle rollback on failure."""
        if exc_type and self.initial_commit and self.config.rollback_on_failure:
            log.warning("Rolling back to initial state due to failure")
            try:
                self.git_service.reset_to_commit(self.initial_commit)
            except Exception as e:
                log.error(f"Failed to rollback: {e}")

--- END OF FILE ./src/core/agents/utils.py ---

--- START OF FILE ./src/core/black_formatter.py ---
# src/core/black_formatter.py
"""
Formats Python code using the Black formatter with robust error handling for syntax and formatting issues.
"""

from __future__ import annotations

import black


# --- MODIFICATION: The function now returns only the formatted code on success ---
# --- and raises a specific exception on failure, simplifying its contract. ---
# ID: 044478bd-8231-48ff-af43-6bc3c022d69c
def format_code_with_black(code: str) -> str:
    """Formats the given Python code using Black, raising `black.InvalidInput` for syntax errors or `Exception` for other formatting issues."""
    """
    Attempts to format the given Python code using Black.

    Args:
        code: The Python source code to format.

    Returns:
        The formatted code as a string.

    Raises:
        black.InvalidInput: If the code contains a syntax error that Black cannot handle.
        Exception: For other unexpected Black formatting errors.
    """
    try:
        mode = black.FileMode()
        formatted_code = black.format_str(code, mode=mode)
        return formatted_code
    except black.InvalidInput as e:
        # Re-raise with a clear message for the pipeline to catch.
        raise black.InvalidInput(
            f"Black could not format the code due to a syntax error: {e}"
        )
    except Exception as e:
        # Catch any other unexpected errors from Black.
        raise Exception(f"An unexpected error occurred during Black formatting: {e}")

--- END OF FILE ./src/core/black_formatter.py ---

--- START OF FILE ./src/core/capabilities.py ---
# src/core/capabilities.py
"""
Orchestrates the system's self-analysis cycle by executing introspection tools as governed subprocesses.
"""

from __future__ import annotations

import subprocess
import sys
from pathlib import Path

from dotenv import load_dotenv

from shared.logger import getLogger

log = getLogger(__name__)


# ID: b36292a6-98b1-44fb-b76a-a2faad96564b
def introspection():
    """
    Runs a full self-analysis cycle to inspect system structure and health.
    This orchestrates the execution of the system's own introspection tools
    as separate, governed processes.
    """
    log.info("🔍 Starting introspection cycle...")

    project_root = Path(__file__).resolve().parents[2]
    python_executable = sys.executable

    tools_to_run = [
        ("Knowledge Graph Builder", "system.tools.codegraph_builder"),
        ("Constitutional Auditor", "system.governance.constitutional_auditor"),
    ]

    all_passed = True
    for name, module in tools_to_run:
        log.info(f"Running {name}...")
        try:
            result = subprocess.run(
                [python_executable, "-m", module],
                cwd=project_root,
                capture_output=True,
                text=True,
                check=True,
            )
            # --- THIS IS THE FIX ---
            # If the process was successful, print its standard output.
            # This gives us the detailed report from the auditor.
            if result.stdout:
                # We use print() directly here so the rich formatting from the
                # auditor's console is preserved perfectly.
                print(result.stdout)

            if result.stderr:
                log.warning(f"{name} stderr:\n{result.stderr}")
            log.info(f"✅ {name} completed successfully.")
        except subprocess.CalledProcessError as e:
            log.error(f"❌ {name} failed with exit code {e.returncode}.")
            # Print the output on failure so we can see the full error report.
            if e.stdout:
                print(e.stdout)
            if e.stderr:
                print(e.stderr)
            all_passed = False
        except Exception as e:
            log.error(
                f"💥 An unexpected error occurred while running {name}: {e}",
                exc_info=True,
            )
            all_passed = False

    log.info("🧠 Introspection cycle completed.")
    return all_passed


if __name__ == "__main__":
    load_dotenv()
    # Allows running the full introspection cycle directly from the CLI.
    if not introspection():
        sys.exit(1)
    sys.exit(0)

--- END OF FILE ./src/core/capabilities.py ---

--- START OF FILE ./src/core/cognitive_service.py ---
# src/core/cognitive_service.py
"""
Manages the provisioning of configured LLM clients for cognitive roles based on
the project's constitutional architecture.
"""

from __future__ import annotations

import asyncio
from pathlib import Path
from typing import Any, Dict, List

from sqlalchemy import text

from core.agents.deduction_agent import DeductionAgent
from services.adapters.embedding_provider import EmbeddingService
from services.clients.llm_api_client import BaseLLMClient
from services.clients.qdrant_client import QdrantService
from services.repositories.db.engine import get_session
from shared.config import settings
from shared.logger import getLogger
from shared.utils.embedding_utils import _Adapter, chunk_and_embed

log = getLogger(__name__)


# ID: aa34ec94-6843-45c5-8558-a9dcd34e60f3
class CognitiveService:
    """Manages the lifecycle and provision of role-based LLM clients."""

    def __init__(self, repo_path: Path | None = None):
        """
        Initializes the service. Policies are loaded asynchronously on first use.
        """
        self.repo_path = repo_path or settings.REPO_PATH
        self._client_cache: Dict[str, BaseLLMClient] = {}
        self._deduction_agent = DeductionAgent()

        self._roles_map: Dict[str, Any] | None = None
        self._resources_map: Dict[str, Any] | None = None
        self._lock = asyncio.Lock()

        log.info(
            "CognitiveService initialized. Policies will be loaded from DB on first use."
        )
        self.qdrant_service = QdrantService()

        # --- THIS IS THE FIX ---
        # The api_key is now correctly passed, and it can be None.
        self.embedding_service = EmbeddingService(
            model=settings.LOCAL_EMBEDDING_MODEL_NAME,
            base_url=settings.LOCAL_EMBEDDING_API_URL,
            api_key=settings.LOCAL_EMBEDDING_API_KEY,  # This is now safe
            expected_dim=settings.LOCAL_EMBEDDING_DIM,
        )
        # --- END OF FIX ---

    async def _load_policies_from_db(self):
        """Loads cognitive roles and LLM resources from the database."""
        async with self._lock:
            if self._roles_map is not None and self._resources_map is not None:
                return

            log.info("Loading cognitive policies from database for the first time...")
            async with get_session() as session:
                # Load roles
                roles_result = await session.execute(
                    text("SELECT * FROM core.cognitive_roles")
                )
                self._roles_map = {
                    row._mapping["role"]: dict(row._mapping) for row in roles_result
                }

                # Load resources
                resources_result = await session.execute(
                    text("SELECT * FROM core.llm_resources")
                )
                self._resources_map = {
                    row._mapping["name"]: dict(row._mapping) for row in resources_result
                }

            # The deduction agent now loads its manifest from the DB as well
            await self._deduction_agent._load_resource_manifest_from_db()

            log.info(
                f"Loaded {len(self._roles_map)} roles and {len(self._resources_map)} resources from DB."
            )

    # ID: 62a17551-c92a-43bd-8544-58fc5ab07468
    async def get_client_for_role(
        self, role_name: str, task_context: Dict[str, Any] | None = None
    ) -> BaseLLMClient:
        """
        Gets a configured LLM client for a specific cognitive role.
        """
        await self._load_policies_from_db()

        role_config = self._roles_map.get(role_name)
        if not role_config:
            raise ValueError(f"Cognitive role '{role_name}' is not defined.")

        context = task_context or {}
        context["role_config"] = role_config
        resource_name = await self._deduction_agent.select_best_resource(context)

        if resource_name in self._client_cache:
            return self._client_cache[resource_name]

        resource_config = self._resources_map.get(resource_name)
        if not resource_config:
            raise ValueError(f"Resource '{resource_name}' is not in the manifest.")

        env_prefix = resource_config.get("env_prefix", "").upper()
        model_extra = settings.model_extra or {}
        api_url = getattr(settings, f"{env_prefix}_API_URL", None) or model_extra.get(
            f"{env_prefix}_API_URL"
        )
        api_key = getattr(settings, f"{env_prefix}_API_KEY", None) or model_extra.get(
            f"{env_prefix}_API_KEY"
        )
        model_name = getattr(
            settings, f"{env_prefix}_MODEL_NAME", None
        ) or model_extra.get(f"{env_prefix}_MODEL_NAME")

        if not api_url or not model_name:
            raise ValueError(
                f"Configuration for resource prefix '{env_prefix}' is missing URL or Model Name."
            )

        client = BaseLLMClient(api_url=api_url, model_name=model_name, api_key=api_key)
        self._client_cache[resource_name] = client

        log.info(
            f"Dynamically provisioned client for role '{role_name}' using resource '{resource_name}' ({model_name})."
        )
        return client

    # ID: 482c11b6-9d96-4c1c-b680-fdb00ea7cb0b
    async def get_embedding_for_code(self, source_code: str) -> List[float]:
        """
        Gets a vector embedding for a piece of source code using the 'Vectorizer' role.
        """
        log.debug("Using dedicated EmbeddingService to generate embedding...")
        try:
            adapter = _Adapter(self.embedding_service)
            embedding_vector = await chunk_and_embed(adapter, source_code)
            return embedding_vector.tolist()
        except Exception as e:
            log.error(f"Failed to generate embedding: {e}", exc_info=True)
            raise

    # ID: a0c7430d-93ee-4cd2-9bc3-3dbf399bf848
    async def search_capabilities(
        self, query: str, limit: int = 5
    ) -> List[Dict[str, Any]]:
        """
        Performs a semantic search for capabilities based on a natural language query.
        """
        log.info(f"Performing semantic search for query: '{query}'")
        try:
            log.debug("   -> Vectorizing search query...")
            query_vector = await self.get_embedding_for_code(query)

            log.debug("   -> Searching for similar capabilities in Qdrant...")
            search_results = await self.qdrant_service.search_similar(
                query_vector, limit=limit
            )
            # Add the key to the payload for easier access
            for result in search_results:
                if "payload" in result and "symbol" in result["payload"]:
                    result["payload"]["key"] = result["payload"]["symbol"]

            return search_results

        except Exception as e:
            log.error(f"❌ Semantic search failed: {e}", exc_info=True)
            return []

--- END OF FILE ./src/core/cognitive_service.py ---

--- START OF FILE ./src/core/crate_processing_service.py ---
# src/core/crate_processing_service.py
"""
Provides the core service for processing asynchronous, autonomous change requests (Intent Crates).
"""

from __future__ import annotations

import shutil
import tempfile
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List

import jsonschema
import yaml
from rich.console import Console

from features.governance.constitutional_auditor import AuditScope, ConstitutionalAuditor
from features.introspection.knowledge_graph_service import (
    KnowledgeGraphBuilder,
)
from shared.action_logger import action_logger
from shared.config import settings
from shared.logger import getLogger
from shared.models import AuditFinding

log = getLogger("crate_processing_service")
console = Console()


@dataclass
# ID: a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d
class Crate:
    """A simple data class representing a validated Intent Crate."""

    path: Path
    manifest: Dict[str, Any]


# ID: 5d7a8b3e-1f2c-4d5e-6f7a-8b9c0d1e2f3a
class CrateProcessingService:
    """
    Orchestrates the lifecycle of an Intent Crate: validation, canary testing, application, and result logging.
    """

    def __init__(self):
        """Initializes the service with its required dependencies and constitutional policies."""
        self.repo_root = settings.REPO_PATH
        self.crate_policy = settings.load(
            "charter.policies.governance.intent_crate_policy"
        )
        self.crate_schema = settings.load(
            "charter.schemas.constitutional.intent_crate_schema"
        )

        self.inbox_path = self.repo_root / "work" / "crates" / "inbox"
        self.processing_path = self.repo_root / "work" / "crates" / "processing"
        self.accepted_path = self.repo_root / "work" / "crates" / "accepted"
        self.rejected_path = self.repo_root / "work" / "crates" / "rejected"

        for path in [
            self.inbox_path,
            self.processing_path,
            self.accepted_path,
            self.rejected_path,
        ]:
            path.mkdir(parents=True, exist_ok=True)

        log.info("CrateProcessingService initialized and constitutionally configured.")

    # ID: 4e3d2c1b-0a9b-8c7d-6e5f-4a3b2c1d0e9f
    def _scan_and_validate_inbox(self) -> List[Crate]:
        """Scans the inbox for crates and validates their manifests."""
        valid_crates = []
        if not self.inbox_path.exists():
            return []

        for item in self.inbox_path.iterdir():
            if not item.is_dir():
                continue

            crate_id = item.name
            action_logger.log_event("crate.validation.started", {"crate_id": crate_id})
            manifest_path = item / "manifest.yaml"
            if not manifest_path.exists():
                reason = "missing manifest.yaml"
                log.warning(f"Skipping invalid crate '{crate_id}': {reason}.")
                action_logger.log_event(
                    "crate.validation.failed", {"crate_id": crate_id, "reason": reason}
                )
                continue

            try:
                manifest_content = settings._load_file_content(manifest_path)
                jsonschema.validate(instance=manifest_content, schema=self.crate_schema)
                valid_crates.append(Crate(path=item, manifest=manifest_content))
                log.info(
                    f"Validated crate '{crate_id}' with intent: '{manifest_content['intent']}'"
                )
            except (ValueError, jsonschema.ValidationError) as e:
                reason = f"Manifest validation failed: {e}"
                log.error(f"Rejecting invalid crate '{crate_id}': {reason}")
                action_logger.log_event(
                    "crate.validation.failed", {"crate_id": crate_id, "reason": str(e)}
                )
                self._move_crate_to_rejected(item, reason)
                continue

        return valid_crates

    # ID: 1b2c3d4e-5f6a-7b8c-9d0e-1f2a3b4c5d6e
    async def _run_canary_validation(
        self, crate: Crate
    ) -> tuple[bool, List[AuditFinding]]:
        """Creates a temporary environment, applies crate changes, and runs a full audit."""
        with tempfile.TemporaryDirectory() as tmpdir:
            canary_path = Path(tmpdir) / "canary_repo"
            console.print(f"   -> Creating canary environment at {canary_path}")

            shutil.copytree(
                self.repo_root,
                canary_path,
                dirs_exist_ok=True,
                ignore=shutil.ignore_patterns(
                    ".git", ".venv", "__pycache__", "work", "reports"
                ),
            )

            env_file = self.repo_root / ".env"
            if env_file.exists():
                shutil.copy(env_file, canary_path / ".env")
                console.print(
                    "   -> Copied runtime environment configuration to canary."
                )

            console.print("   -> Applying proposed changes to canary...")
            payload_files = crate.manifest.get("payload_files", [])
            for file_in_payload in payload_files:
                source_path = crate.path / file_in_payload
                if crate.manifest.get("type") == "CONSTITUTIONAL_AMENDMENT":
                    target_path = (
                        canary_path
                        / ".intent/charter/policies/governance"
                        / file_in_payload
                    )
                else:
                    target_path = canary_path / file_in_payload

                target_path.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(source_path, target_path)

            console.print("   -> Building canary's internal knowledge graph...")
            canary_builder = KnowledgeGraphBuilder(root_path=canary_path)
            await canary_builder.build_and_sync()

            console.print("   -> 🔬 Running full constitutional audit on canary...")
            auditor = ConstitutionalAuditor(repo_root_override=canary_path)
            passed, findings, _ = await auditor.run_full_audit_async(
                scope=AuditScope.STATIC_ONLY
            )

            if passed:
                console.print("   -> [bold green]✅ Canary audit PASSED.[/bold green]")
                return True, []
            else:
                console.print("   -> [bold red]❌ Canary audit FAILED.[/bold red]")
                return False, findings

    def _apply_accepted_crate(self, crate: Crate):
        """Applies the payload of an accepted crate to the live repository."""
        console.print(
            f"   -> Applying accepted crate '{crate.path.name}' to live system..."
        )
        payload_files = crate.manifest.get("payload_files", [])
        for file_in_payload in payload_files:
            source_path = crate.path / file_in_payload

            if crate.manifest.get("type") == "CONSTITUTIONAL_AMENDMENT":
                target_path = (
                    self.repo_root
                    / ".intent/charter/policies/governance"
                    / file_in_payload
                )
            else:
                target_path = self.repo_root / file_in_payload

            target_path.parent.mkdir(parents=True, exist_ok=True)
            shutil.copy2(source_path, target_path)
            console.print(f"      -> Applied '{file_in_payload}'")

    def _write_result_manifest(self, crate_path: Path, status: str, details: Any):
        """Writes a result.yaml file into the processed crate directory."""
        result_content = {
            "status": status,
            "processed_at_utc": datetime.now(timezone.utc).isoformat(),
        }
        if isinstance(details, str):
            result_content["justification"] = details
        elif isinstance(details, list):
            result_content["violations"] = [finding.as_dict() for finding in details]

        result_path = crate_path / "result.yaml"
        result_path.write_text(yaml.dump(result_content, indent=2), "utf-8")

    def _move_crate_to_rejected(self, crate_path: Path, details: Any):
        """Moves a crate to the rejected directory and writes a result manifest."""
        crate_id = crate_path.name
        final_path = self.rejected_path / crate_id
        shutil.move(str(crate_path), str(final_path))
        self._write_result_manifest(final_path, "rejected", details)

        reason_summary = (
            details
            if isinstance(details, str)
            else f"{len(details)} constitutional violations found."
        )
        console.print(f"   -> Moved to rejected. Reason: {reason_summary}")

        log_details = {"crate_id": crate_id}
        if isinstance(details, str):
            log_details["reason"] = details
        else:
            log_details["violations"] = [finding.as_dict() for finding in details]

        action_logger.log_event("crate.processing.rejected", log_details)

    # ID: 9a8b7c6d-5e4f-3a2b-1c0d-9e8f7a6b5c4d
    async def process_pending_crates_async(self):
        """
        The main entry point for the service. It finds and processes all crates in the inbox.
        """
        console.print(
            "[bold cyan]🚀 Starting new crate processing cycle...[/bold cyan]"
        )

        valid_crates = self._scan_and_validate_inbox()
        if not valid_crates:
            console.print("✅ No valid crates found in the inbox. Cycle complete.")
            return

        console.print(f"Found {len(valid_crates)} valid crate(s) to process.")

        for crate in valid_crates:
            crate_id = crate.path.name
            console.print(f"\n[bold]Processing crate: {crate_id}[/bold]")
            try:
                processing_path = self.processing_path / crate_id
                shutil.move(str(crate.path), str(processing_path))
                crate.path = processing_path
                console.print(
                    f"   -> Moved to processing: {processing_path.relative_to(self.repo_root)}"
                )
                action_logger.log_event(
                    "crate.processing.started", {"crate_id": crate_id}
                )

                is_safe, findings = await self._run_canary_validation(crate)

                if is_safe:
                    self._apply_accepted_crate(crate)
                    final_path = self.accepted_path / crate.path.name
                    shutil.move(str(crate.path), str(final_path))
                    self._write_result_manifest(
                        final_path,
                        "accepted",
                        "Canary audit passed and changes were applied.",
                    )
                    console.print("   -> Moved to accepted.")
                    action_logger.log_event(
                        "crate.processing.accepted",
                        {
                            "crate_id": crate_id,
                            "reason": "Canary audit passed and changes applied.",
                        },
                    )
                else:
                    self._move_crate_to_rejected(crate.path, findings)

            except Exception as e:
                log.error(f"Failed to process crate '{crate_id}': {e}", exc_info=True)
                self._move_crate_to_rejected(
                    crate.path, f"Internal processing error: {e}"
                )
                continue


# ID: 3e2d1c0b-9a8b-7c6d-5e4f-3a2b1c0d9e8f
async def process_crates():
    """High-level function to instantiate and run the service."""
    service = CrateProcessingService()
    await service.process_pending_crates_async()

--- END OF FILE ./src/core/crate_processing_service.py ---

--- START OF FILE ./src/core/errors.py ---
# src/core/errors.py
"""
Centralizes HTTP exception handling to prevent sensitive stack trace leaks and ensure consistent error responses.
"""

from __future__ import annotations

from fastapi import Request
from fastapi.responses import JSONResponse
from starlette import status
from starlette.exceptions import HTTPException as StarletteHTTPException

from shared.logger import getLogger

log = getLogger("core_api.errors")


# ID: 08e2d78e-754e-4050-a426-dcca66d5319c
def register_exception_handlers(app):
    """Registers custom exception handlers with the FastAPI application."""

    @app.exception_handler(StarletteHTTPException)
    # ID: f3baf803-cdab-47ae-8a50-2f612e783819
    async def http_exception_handler(request: Request, exc: StarletteHTTPException):
        """
        Handles FastAPI's built-in HTTP exceptions to ensure consistent
        JSON error responses.
        """
        log.warning(
            f"HTTP Exception: {exc.status_code} {exc.detail} for request: "
            f"{request.method} {request.url.path}"
        )
        return JSONResponse(
            status_code=exc.status_code,
            content={"error": "request_error", "detail": exc.detail},
        )

    @app.exception_handler(Exception)
    # ID: 37d3d6d4-048d-4a31-9e02-93f3a7ddf5bc
    async def unhandled_exception_handler(request: Request, exc: Exception):
        """
        Catches any unhandled exception, logs the full traceback internally,
        and returns a generic 500 Internal Server Error to the client.
        This is a critical security measure to prevent leaking stack traces.
        """
        log.exception(
            f"Unhandled exception for request: {request.method} {request.url.path}"
        )
        return JSONResponse(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            content={
                "error": "internal_server_error",
                "detail": "An unexpected internal error occurred.",
            },
        )

    log.info("Registered global exception handlers.")

--- END OF FILE ./src/core/errors.py ---

--- START OF FILE ./src/core/file_classifier.py ---
# src/core/file_classifier.py
"""
File classification utilities for the validation pipeline.

This module provides functionality to classify files based on their extensions,
determining the appropriate validation strategy for each file type.
"""

from __future__ import annotations

from pathlib import Path


# ID: efe53dfb-fd71-4cd1-9f4d-1b1718c4f76a
def get_file_classification(file_path: str) -> str:
    """Determines the file type based on its extension.

    Args:
        file_path: Path to the file to classify

    Returns:
        A string representing the file type ('python', 'yaml', 'text', or 'unknown')
    """
    suffix = Path(file_path).suffix.lower()
    if suffix == ".py":
        return "python"
    if suffix in [".yaml", ".yml"]:
        return "yaml"
    if suffix in [".md", ".txt", ".json"]:
        return "text"
    return "unknown"

--- END OF FILE ./src/core/file_classifier.py ---

--- START OF FILE ./src/core/file_handler.py ---
# src/core/file_handler.py
"""
Provides safe, auditable file operations with staged writes
requiring confirmation for traceability and rollback capabilities.
"""

from __future__ import annotations

import json
import threading
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict
from uuid import uuid4

from shared.logger import getLogger

log = getLogger(__name__)


# ID: 8e74376f-d709-48be-bf0c-0e286f390f67
class FileHandler:
    """
    Central class for safe, auditable file operations in CORE.
    All writes are staged first and require confirmation. Validation is handled
    by the calling agent via the validation_pipeline.
    """

    def __init__(self, repo_path: str):
        """
        Initialize FileHandler with repository root.
        """
        self.repo_path = Path(repo_path).resolve()
        if not self.repo_path.is_dir():
            raise ValueError(f"Invalid repository path provided: {repo_path}")

        # --- THIS IS THE FIX ---
        # All operational directories are now relative to the repo_path
        # that the handler was initialized with. This makes the handler
        # safe to use in different contexts (like our integration test).
        self.log_dir = self.repo_path / "logs"
        self.pending_dir = self.repo_path / "pending_writes"
        self.undo_log = self.log_dir / "undo_log.jsonl"

        self.log_dir.mkdir(exist_ok=True)
        self.pending_dir.mkdir(exist_ok=True)
        # --- END OF FIX ---

        self.pending_writes: Dict[str, Dict[str, Any]] = {}
        self._lock = threading.Lock()

    # ID: bf348511-75e7-442c-9aac-58ced078e564
    def add_pending_write(self, prompt: str, suggested_path: str, code: str) -> str:
        """
        Stages a pending write operation for later confirmation.
        """
        pending_id = str(uuid4())
        rel_path = Path(suggested_path).as_posix()
        entry = {
            "id": pending_id,
            "prompt": prompt,
            "path": rel_path,
            "code": code,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

        with self._lock:
            self.pending_writes[pending_id] = entry

        pending_file = self.pending_dir / f"{pending_id}.json"
        pending_file.write_text(json.dumps(entry, indent=2), encoding="utf-8")
        return pending_id

    # ID: 6238a0d8-0c8d-4c74-b792-7587dc13807a
    def confirm_write(self, pending_id: str) -> Dict[str, str]:
        """
        Confirms and applies a pending write to disk. Assumes content has been validated.
        """
        with self._lock:
            pending_op = self.pending_writes.pop(pending_id, None)

        pending_file = self.pending_dir / f"{pending_id}.json"
        if pending_file.exists():
            pending_file.unlink(missing_ok=True)

        if not pending_op:
            return {
                "status": "error",
                "message": f"Pending write ID '{pending_id}' not found or already processed.",
            }

        file_rel_path = pending_op["path"]

        try:
            abs_file_path = self.repo_path / file_rel_path

            if not abs_file_path.resolve().is_relative_to(self.repo_path.resolve()):
                raise ValueError(
                    f"Attempted to write outside of repository boundary: {file_rel_path}"
                )

            abs_file_path.parent.mkdir(parents=True, exist_ok=True)
            abs_file_path.write_text(pending_op["code"], encoding="utf-8")

            log.info(f"Wrote to {file_rel_path}")
            return {
                "status": "success",
                "message": f"Wrote to {file_rel_path}",
                "file_path": file_rel_path,
            }
        except Exception as e:
            if pending_op:
                with self._lock:
                    self.pending_writes[pending_id] = pending_op
                pending_file.write_text(
                    json.dumps(pending_op, indent=2), encoding="utf-8"
                )
            return {"status": "error", "message": f"Failed to write file: {str(e)}"}

--- END OF FILE ./src/core/file_handler.py ---

--- START OF FILE ./src/core/git_service.py ---
# src/core/git_service.py
"""
GitService: thin, testable wrapper around git commands used by CORE.

Responsibilities
- Validate repo path and .git presence on init.
- Provide small, composable operations (status, add, commit, etc.).
- Raise RuntimeError with useful stderr/stdout on git failures.
"""

from __future__ import annotations

import subprocess
from pathlib import Path

from shared.logger import getLogger

log = getLogger(__name__)


# ID: c1c9c30d-f864-4d43-8e12-d5263e52c15c
class GitService:
    """Provides basic git operations for agents and services."""

    def __init__(self, repo_path: str | Path):
        """
        Initializes the GitService and validates the repository path.
        """
        self.repo_path = Path(repo_path).resolve()

        git_dir = self.repo_path / ".git"
        if not git_dir.exists():
            raise ValueError(f"Not a git repository ('.git' missing): {self.repo_path}")
        log.info(f"GitService initialized for repo at {self.repo_path}")

    def _run_command(self, command: list[str]) -> str:
        """Runs a git command and returns stdout; raises RuntimeError on failure."""
        try:
            log.debug(f"Running git command: {' '.join(command)}")
            result = subprocess.run(
                ["git", *command],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True,
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            msg = e.stderr or e.stdout or ""
            log.error(f"Git command failed: {msg}")
            raise RuntimeError(f"Git command failed: {msg}") from e

    # ID: 41b4a07f-880b-4180-8e2e-ab7109b07ffc
    def get_current_commit(self) -> str:
        """Returns the hash of the current HEAD commit."""
        return self._run_command(["rev-parse", "HEAD"])

    # ID: 33b35c95-2d76-4729-9c16-32d7a877585b
    def reset_to_commit(self, commit_hash: str):
        """Resets the repository to a specific commit."""
        self._run_command(["reset", "--hard", commit_hash])
        log.info(f"Repository reset to commit {commit_hash}")

    # ID: eed906a4-ba54-4af9-94fe-9865d6906c96
    def get_staged_files(self) -> list[str]:
        """Returns a list of files that are currently staged for commit."""
        try:
            output = self._run_command(
                ["diff", "--cached", "--name-only", "--diff-filter=ACMR"]
            )
            if not output:
                return []
            return output.splitlines()
        except RuntimeError:
            return []

    # ID: 8d60714d-0214-48a9-be5b-9011e53ad93e
    def is_git_repo(self) -> bool:
        """Returns True if a '.git' directory exists (lightweight check for tests)."""
        return (self.repo_path / ".git").exists()

    # ID: b5420530-081f-4fa8-9754-5a00bedd5924
    def status_porcelain(self) -> str:
        """Returns the porcelain status output."""
        return self._run_command(["status", "--porcelain"])

    # ID: 5f740625-7aa7-4755-9fcd-f464ae852b2f
    def add(self, file_path: str = ".") -> None:
        """Stages a file (or path)."""
        self._run_command(["add", file_path])

    # ID: 2874a643-2e40-44f0-917f-a928484b2c67
    def add_all(self) -> None:
        """Stages all changes, including untracked files."""
        self._run_command(["add", "-A"])

    # ID: 55ed0386-16c1-458a-9b8f-f3ca0dc73696
    def commit(self, message: str) -> None:
        """
        Commits staged changes with the provided message.
        """
        try:
            status_output = self.status_porcelain()
            if not status_output.strip():
                log.info("No changes to commit.")
                return

            self.add_all()
            self._run_command(["commit", "-m", message])
            log.info(f"Committed changes with message: '{message}'")
        except RuntimeError as e:
            emsg = (str(e) or "").lower()
            if "nothing to commit" in emsg or "no changes added to commit" in emsg:
                log.info("No changes staged. Skipping commit.")
                return
            raise

--- END OF FILE ./src/core/git_service.py ---

--- START OF FILE ./src/core/intent_alignment.py ---
# src/core/intent_alignment.py
"""
Lightweight guard to ensure a requested goal aligns with CORE's mission/scope.

- Loads NorthStar/mission text from .intent (best-effort; no hard failures).
- Optional blocklist: .intent/policies/blocked_topics.txt (one term per line).
- Returns (ok: bool, details: dict) with short reason codes only.
"""

from __future__ import annotations

import logging
import re
from pathlib import Path
from typing import Dict, List, Tuple

log = logging.getLogger(__name__)

_INTENT_PATH_CANDIDATES: List[Path] = [
    Path(".intent/mission/northstar.md"),
    Path(".intent/mission/mission.md"),
    Path(".intent/mission/northstar.txt"),
    Path(".intent/NorthStar.md"),
]

_BLOCKLIST_PATH = Path(".intent/policies/blocked_topics.txt")


def _read_text_first(paths: List[Path]) -> str:
    """Finds and reads the first existing file from a list of candidate paths."""
    for p in paths:
        try:
            if p.exists():
                return p.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            log.debug("Failed reading %s", p, exc_info=True)
    return ""


def _read_blocklist() -> List[str]:
    """Reads the blocklist file, returning a list of lowercased, stripped terms."""
    if _BLOCKLIST_PATH.exists():
        try:
            return [
                ln.strip().lower()
                for ln in _BLOCKLIST_PATH.read_text(
                    encoding="utf-8", errors="ignore"
                ).splitlines()
                if ln.strip() and not ln.strip().startswith("#")
            ]
        except Exception:
            log.debug("Failed reading blocklist at %s", _BLOCKLIST_PATH, exc_info=True)
    return []


def _tokenize(text: str) -> List[str]:
    """Converts a string into a list of lowercase alphanumeric tokens."""
    return re.findall(r"[a-zA-Z0-9]+", text.lower())


# ID: f1267ace-1e0a-47f8-8d81-36ce4262913a
def check_goal_alignment(
    goal: str, project_root: Path = Path(".")
) -> Tuple[bool, Dict]:
    """
    Returns (ok, details). details = { 'coverage': float|None, 'violations': [codes...] }
    Violations codes: 'blocked_topic', 'low_mission_overlap'
    """
    violations: List[str] = []
    mission = _read_text_first(_INTENT_PATH_CANDIDATES)
    blocked = _read_blocklist()

    # Blocklist
    goal_l = goal.lower()
    if blocked and any(term in goal_l for term in blocked):
        violations.append("blocked_topic")

    # Mission overlap (very simple lexical overlap)
    coverage = None
    if mission:
        g_tokens = set(_tokenize(goal))
        m_tokens = set(_tokenize(mission))
        if g_tokens:
            overlap = len(g_tokens & m_tokens)
            coverage = round(overlap / max(1, len(g_tokens)), 3)
            if coverage < 0.10:  # conservative default; tune later
                violations.append("low_mission_overlap")

    ok = not violations
    return ok, {"coverage": coverage, "violations": violations}

--- END OF FILE ./src/core/intent_alignment.py ---

--- START OF FILE ./src/core/intent_guard.py ---
# src/core/intent_guard.py
"""
IntentGuard — CORE's Constitutional Enforcement Module
Enforces safety, structure, and intent alignment for all file changes.
Loads governance rules from .intent/policies/*.yaml and prevents unauthorized
self-modifications of the CORE constitution.
"""
from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Tuple

from shared.config_loader import load_yaml_file
from shared.logger import getLogger

log = getLogger(__name__)


@dataclass
# ID: 1499a5c2-5fc6-4ea3-8049-21702aa20f6e
class PolicyRule:
    """Structured representation of a policy rule."""

    name: str
    pattern: str
    action: str
    description: str
    severity: str = "error"

    @classmethod
    # ID: db43791c-92bd-435e-8ade-85620f3cf4f6
    def from_dict(cls, data: Dict) -> "PolicyRule":
        """Create PolicyRule from dictionary data."""
        return cls(
            name=data.get("name", "unnamed"),
            pattern=data.get("pattern", ""),
            action=data.get("action", "deny"),
            description=data.get("description", ""),
            severity=data.get("severity", "error"),
        )


@dataclass
# ID: 8bdef506-b2b3-4b1e-9a11-96e8d79282b3
class ViolationReport:
    """Detailed violation report with context."""

    rule_name: str
    path: str
    message: str
    severity: str
    suggested_fix: Optional[str] = None


# ID: 1f189a22-8497-44f9-af8e-00888b0eca0e
class IntentGuard:
    """
    Central enforcement engine for CORE's safety and governance policies.
    """

    def __init__(self, repo_path: Path):
        """Initialize IntentGuard with repository path and load all policies."""
        self.repo_path = Path(repo_path).resolve()
        self.intent_path = self.repo_path / ".intent"
        self.proposals_path = self.intent_path / "proposals"
        self.policies_path = self.intent_path / "charter" / "policies"

        self.rules: List[PolicyRule] = []
        self._load_policies()

        log.info(f"IntentGuard initialized with {len(self.rules)} rules loaded.")

    def _load_policies(self):
        """Load rules from all YAML files in the `.intent/charter/policies/` directory."""
        if not self.policies_path.is_dir():
            log.warning(f"Policies directory not found: {self.policies_path}")
            return

        for policy_file in self.policies_path.glob("*.yaml"):
            try:
                content = load_yaml_file(policy_file)
                if (
                    content
                    and "rules" in content
                    and isinstance(content["rules"], list)
                ):
                    for rule_data in content["rules"]:
                        if isinstance(rule_data, dict):
                            self.rules.append(PolicyRule.from_dict(rule_data))
            except Exception as e:
                log.error(f"Failed to load policy file {policy_file}: {e}")

    # ID: abd3b486-3aaa-4dee-8a99-2a0fbd8f1c28
    def check_transaction(
        self, proposed_paths: List[str]
    ) -> Tuple[bool, List[ViolationReport]]:
        """
        Check if a proposed set of file changes complies with all active rules.
        """
        violations = []
        for path_str in proposed_paths:
            path = (self.repo_path / path_str).resolve()
            violations.extend(self._check_single_path(path, path_str))
        return len(violations) == 0, violations

    def _check_single_path(self, path: Path, path_str: str) -> List[ViolationReport]:
        """Check a single path against all rules."""
        violations = []
        constitutional_violation = self._check_constitutional_integrity(path, path_str)
        if constitutional_violation:
            violations.append(constitutional_violation)
        violations.extend(self._check_policy_rules(path, path_str))
        return violations

    def _check_constitutional_integrity(
        self, path: Path, path_str: str
    ) -> Optional[ViolationReport]:
        """Check if the path violates constitutional immutability rules."""
        try:
            charter_path_resolved = (self.intent_path / "charter").resolve()
            if charter_path_resolved in path.parents or path == charter_path_resolved:
                return self._create_constitutional_violation(path_str)
        except Exception as e:
            log.error(f"Error checking constitutional integrity for {path_str}: {e}")
        return None

    def _create_constitutional_violation(self, path_str: str) -> ViolationReport:
        """Create a constitutional violation report."""
        return ViolationReport(
            rule_name="immutable_charter",
            path=path_str,
            message=f"Direct write to '{path_str}' is forbidden. Changes to the Charter require a formal proposal.",
            severity="error",
        )

    def _check_policy_rules(self, path: Path, path_str: str) -> List[ViolationReport]:
        """Check path against all loaded policy rules."""
        violations = []
        for rule in self.rules:
            try:
                if self._matches_pattern(path_str, rule.pattern):
                    violations.extend(self._apply_rule_action(rule, path_str))
            except Exception as e:
                log.error(f"Error applying rule '{rule.name}' to {path_str}: {e}")
        return violations

    def _apply_rule_action(
        self, rule: PolicyRule, path_str: str
    ) -> List[ViolationReport]:
        """Apply the action for a matched rule."""
        if rule.action == "deny":
            return [
                ViolationReport(
                    rule_name=rule.name,
                    path=path_str,
                    message=f"Rule '{rule.name}' violation: {rule.description}",
                    severity=rule.severity,
                )
            ]
        elif rule.action == "warn":
            log.warning(f"Policy warning for {path_str}: {rule.description}")
        return []

    def _matches_pattern(self, path: str, pattern: str) -> bool:
        """Check if a path matches a given glob pattern."""
        return Path(path).match(pattern)

--- END OF FILE ./src/core/intent_guard.py ---

--- START OF FILE ./src/core/invokers/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/core/invokers/__init__.py ---

--- START OF FILE ./src/core/invokers/capability_invoker.py ---
[EMPTY FILE]
--- END OF FILE ./src/core/invokers/capability_invoker.py ---

--- START OF FILE ./src/core/knowledge_service.py ---
# src/core/knowledge_service.py
"""
Provides a runtime service for agents to query the system's knowledge graph
from the database, which is the single source of truth.
"""

from __future__ import annotations

import asyncio
from pathlib import Path
from typing import Any, Dict, List, Set

from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.logger import getLogger

log = getLogger(__name__)


# ID: 2ea793f9-c474-4de2-b41d-4c6a2d1f5646
class KnowledgeService:
    """A read-only service to access the system's knowledge graph from the database."""

    def __init__(self, repo_path: Path):
        """Initializes the service."""
        self.repo_path = repo_path
        self._graph: Dict[str, Any] | None = None
        self._graph_load_lock = asyncio.Lock()
        log.info("KnowledgeService initialized.")

    # ID: 67d7ea3f-672b-40d7-8362-be4735081420
    async def get_graph(self) -> Dict[str, Any]:
        """
        Lazily loads the knowledge graph from the database on first access.
        This method is now the primary async entry point for getting graph data.
        """
        if self._graph is None:
            async with self._graph_load_lock:
                # Double-check lock to prevent race conditions
                if self._graph is None:
                    log.info("Knowledge graph not loaded, fetching from database...")
                    self._graph = await self._get_graph_from_db()
        return self._graph

    async def _get_graph_from_db(self) -> Dict[str, Any]:
        """
        Fetches the knowledge graph from the database view and reconstructs it
        into the dictionary format expected by the system.
        """
        symbols_map: Dict[str, Any] = {}
        try:
            async with get_session() as session:
                result = await session.execute(
                    text("SELECT * FROM core.knowledge_graph")
                )
                for row in result:
                    row_dict = dict(row._mapping)
                    symbols_map[row_dict["symbol_path"]] = row_dict
        except Exception as e:
            log.error(f"Failed to load knowledge graph from database: {e}")
            return {"symbols": {}}

        log.info(f"Successfully loaded {len(symbols_map)} symbols from database.")
        return {"symbols": symbols_map}

    # ID: 53b1bc81-af62-45f3-b6e4-b18e328ef088
    async def list_capabilities(self) -> List[str]:
        """Returns a sorted list of all unique, declared capabilities."""
        graph = await self.get_graph()
        symbols = graph.get("symbols", {}).values()
        capabilities: Set[str] = {
            s["capability"]
            for s in symbols
            if s.get("capability") and s.get("capability") != "unassigned"
        }
        return sorted(list(capabilities))

--- END OF FILE ./src/core/knowledge_service.py ---

--- START OF FILE ./src/core/main.py ---
# src/core/main.py
"""
Provides the FastAPI-based API gateway and execution engine for the CORE system's goal processing and system integration.
"""

from __future__ import annotations

from contextlib import asynccontextmanager
from pathlib import Path

from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Request
from fastapi import status as http_status
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

from core.cognitive_service import CognitiveService
from core.errors import register_exception_handlers
from core.intent_alignment import check_goal_alignment
from core.knowledge_service import KnowledgeService
from services.clients.qdrant_client import QdrantService
from shared.config import settings
from shared.logger import getLogger

log = getLogger(__name__)
load_dotenv()


@asynccontextmanager
# ID: f453301d-951e-4a0e-8f21-1048e361840d
async def lifespan(app: FastAPI):
    """FastAPI lifespan handler — runs startup and shutdown logic."""
    log.info("🚀 Starting CORE system...")

    log.info("🛠️  Initializing shared services...")
    repo_path = Path(".")

    knowledge_service = KnowledgeService(repo_path)
    await knowledge_service.get_graph()

    app.state.knowledge_service = knowledge_service
    app.state.cognitive_service = CognitiveService(repo_path)
    app.state.qdrant_service = QdrantService()

    if not settings.LLM_ENABLED:
        log.warning(
            "⚠️ LLMs are disabled. The 'execute_goal' endpoint will not be functional."
        )

    log.info("✅ CORE system is online and ready.")
    yield
    log.info("🛑 CORE system shutting down.")


app = FastAPI(lifespan=lifespan)
register_exception_handlers(app)


# ID: f1f7835a-faf3-4ce4-9953-314053c4e07d
class GoalRequest(BaseModel):
    """Defines the request body for the /execute_goal endpoint."""

    goal: str = Field(min_length=1, json_schema_extra={"strip_whitespace": True})


# ID: 830bec8a-4a90-4b37-b38c-af4ad39180b0
class AlignmentRequest(BaseModel):
    """Request schema for /guard/align."""

    goal: str = Field(min_length=1, json_schema_extra={"strip_whitespace": True})
    min_coverage: float | None = Field(default=None, ge=0.0, le=1.0)


# ID: f8653eb9-4323-4302-9774-8d99e16b7026
class SearchRequest(BaseModel):
    """Defines the request body for the /knowledge/search endpoint."""

    query: str = Field(..., min_length=1, description="The natural language query.")
    limit: int = Field(
        5, gt=0, le=50, description="The maximum number of results to return."
    )


@app.post("/knowledge/search")
# ID: c1e2f3a4-b5d6-7e8f-9a0b-1c2d3e4f5a6b
async def search_knowledge(request_data: SearchRequest, request: Request):
    """
    Performs a semantic search for capabilities in the knowledge base.
    """
    cognitive_service: CognitiveService = request.app.state.cognitive_service
    try:
        results = await cognitive_service.search_capabilities(
            query=request_data.query, limit=request_data.limit
        )
        return {"results": results}
    except Exception as e:
        log.error(f"Semantic search API endpoint failed: {e}", exc_info=True)
        raise HTTPException(
            status_code=http_status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="An error occurred during the search process.",
        )


@app.post("/guard/align")
# ID: 16de5543-e473-492d-a09d-2ee4927e944e
async def guard_align(payload: AlignmentRequest):
    """Evaluate a goal against the NorthStar and optional blocklist."""
    ok, details = check_goal_alignment(payload.goal, Path("."))
    if payload.min_coverage is not None:
        cov = details.get("coverage")
        if cov is None or cov < payload.min_coverage:
            ok = False
            if "low_mission_overlap" not in details["violations"]:
                details["violations"].append("low_mission_overlap")
    status = "ok" if ok else "rejected"
    return JSONResponse(
        {"status": status, "details": details}, status_code=http_status.HTTP_200_OK
    )


@app.get("/knowledge/capabilities")
# ID: 3f1cfcdc-1f47-421c-b166-cbfda59eeed3
async def list_capabilities(request: Request):
    """Returns a list of all capabilities the system has declared."""
    knowledge_service: KnowledgeService = request.app.state.knowledge_service
    capabilities = await knowledge_service.list_capabilities()
    return {"capabilities": capabilities}


@app.post("/execute_goal")
# ID: f98b4887-03b3-4e90-8016-93cda8dc2a81
async def execute_goal(request_data: GoalRequest, request: Request):
    """
    Execute a high-level goal by planning and generating code.
    """
    from core.agents.execution_agent import ExecutionAgent
    from core.agents.plan_executor import PlanExecutor
    from core.agents.planner_agent import PlannerAgent
    from core.agents.reconnaissance_agent import ReconnaissanceAgent
    from core.file_handler import FileHandler
    from core.git_service import GitService
    from core.prompt_pipeline import PromptPipeline
    from features.governance.audit_context import AuditorContext
    from shared.models import PlanExecutionError, PlannerConfig

    goal = request_data.goal
    log.info("🎯 Received new goal via API: %r", goal[:200])

    if not settings.LLM_ENABLED:
        raise HTTPException(
            status_code=503,
            detail="LLM capabilities are disabled in the current environment configuration.",
        )

    try:
        repo_path = Path(".")
        auditor_context = AuditorContext(repo_path)
        await auditor_context.load_knowledge_graph()  # Ensure context is loaded

        git_service = GitService(repo_path=str(repo_path))
        cognitive_service: CognitiveService = request.app.state.cognitive_service
        knowledge_service: KnowledgeService = request.app.state.knowledge_service
        file_handler = FileHandler(repo_path=str(repo_path))
        prompt_pipeline = PromptPipeline(repo_path=repo_path)
        planner_config = PlannerConfig()
        plan_executor = PlanExecutor(file_handler, git_service, planner_config)

        graph = await knowledge_service.get_graph()
        recon_agent = ReconnaissanceAgent(graph)
        context_report = recon_agent.generate_report(goal)
        log.info(f"   -> Generated Surgical Context Report:\n{context_report}")

        planner = PlannerAgent(cognitive_service)
        plan = planner.create_execution_plan(goal)
        if not plan:
            raise PlanExecutionError("Planner failed to create a valid execution plan.")

        executor = ExecutionAgent(
            cognitive_service, prompt_pipeline, plan_executor, auditor_context
        )
        success, message = await executor.execute_plan(high_level_goal=goal, plan=plan)

        if success:
            return JSONResponse(
                content={"status": "success", "message": message},
                status_code=http_status.HTTP_200_OK,
            )
        else:
            raise HTTPException(status_code=500, detail=message)

    except PlanExecutionError as e:
        raise HTTPException(status_code=400, detail=f"Planning Error: {e}")
    except Exception as e:
        log.error(f"💥 Unexpected error during goal execution: {e}", exc_info=True)
        raise HTTPException(
            status_code=500, detail=f"An unexpected error occurred: {e}"
        )


@app.get("/")
# ID: 2fe70272-eba7-4666-9d31-2dba9c2c6851
async def root():
    """Root endpoint — returns system status."""
    return {"message": "CORE system is online and self-governing."}

--- END OF FILE ./src/core/main.py ---

--- START OF FILE ./src/core/prompt_pipeline.py ---
# src/core/prompt_pipeline.py
"""
PromptPipeline — CORE's Unified Directive Processor

A single pipeline that processes all [[directive:...]] blocks in a user prompt.
Responsible for:
- Injecting context (e.g., file contents)
- Expanding includes
- Adding analysis from introspection tools
- Enriching with manifest data

This is the central "pre-processor" for all LLM interactions.
"""

from __future__ import annotations

import re
from pathlib import Path

import yaml

# --- FIX: Define a constant for a reasonable file size limit (1MB) ---
MAX_FILE_SIZE_BYTES = 1 * 1024 * 1024


# ID: 55fc4bff-0f88-435c-b988-23861ee401e8
class PromptPipeline:
    """
    Processes and enriches user prompts by resolving directives like
    [[include:...]] and [[analysis:...]]. Ensures the LLM receives full
    context before generating code.
    """

    def __init__(self, repo_path: Path):
        """
        Initialize PromptPipeline with repository root.

        Args:
            repo_path (Path): Root path of the repository.
        """
        self.repo_path = Path(repo_path).resolve()

        # Regex patterns for directive matching
        self.context_pattern = re.compile(r"\[\[context:(.+?)\]\]")
        self.include_pattern = re.compile(r"\[\[include:(.+?)\]\]")
        self.analysis_pattern = re.compile(r"\[\[analysis:(.+?)\]\]")
        self.manifest_pattern = re.compile(r"\[\[manifest:(.+?)\]\]")

    def _replace_context_match(self, match: re.Match) -> str:
        """
        Dynamically replaces a [[context:...]] regex match with file content
        or an error message if the file is missing, unreadable, or exceeds
        size limits.
        """
        file_path = match.group(1).strip()
        abs_path = self.repo_path / file_path
        if abs_path.exists() and abs_path.is_file():
            # --- FIX: Add file size check to prevent memory bloat ---
            if abs_path.stat().st_size > MAX_FILE_SIZE_BYTES:
                return (
                    f"\n❌ Could not include {file_path}: "
                    f"File size exceeds 1MB limit.\n"
                )
            try:
                content = abs_path.read_text(encoding="utf-8")
                return (
                    f"\n--- CONTEXT: {file_path} ---\n"
                    f"{content}\n"
                    f"--- END CONTEXT ---\n"
                )
            except Exception as e:
                return f"\n❌ Could not read {file_path}: {str(e)}\n"
        return f"\n❌ File not found: {file_path}\n"

    def _inject_context(self, prompt: str) -> str:
        """Replaces [[context:file.py]] directives with actual file content."""
        return self.context_pattern.sub(self._replace_context_match, prompt)

    def _replace_include_match(self, match: re.Match) -> str:
        """
        Dynamically replaces an [[include:...]] regex match with file content
        or an error message if the file is missing, unreadable, or exceeds
        size limits.
        """
        file_path = match.group(1).strip()
        abs_path = self.repo_path / file_path
        if abs_path.exists() and abs_path.is_file():
            # --- FIX: Add file size check to prevent memory bloat ---
            if abs_path.stat().st_size > MAX_FILE_SIZE_BYTES:
                return (
                    f"\n❌ Could not include {file_path}: "
                    f"File size exceeds 1MB limit.\n"
                )
            try:
                content = abs_path.read_text(encoding="utf-8")
                return (
                    f"\n--- INCLUDED: {file_path} ---\n"
                    f"{content}\n"
                    f"--- END INCLUDE ---\n"
                )
            except Exception as e:
                return f"\n❌ Could not read {file_path}: {str(e)}\n"
        return f"\n❌ File not found: {file_path}\n"

    def _inject_includes(self, prompt: str) -> str:
        """Replaces [[include:file.py]] directives with file content."""
        return self.include_pattern.sub(self._replace_include_match, prompt)

    def _replace_analysis_match(self, match: re.Match) -> str:
        """
        Dynamically replaces an [[analysis:...]] regex match with a
        placeholder analysis message for the given file path.
        """
        file_path = match.group(1).strip()
        # This functionality is a placeholder.
        return f"\n--- ANALYSIS FOR {file_path} (DEFERRED) ---\n"

    def _inject_analysis(self, prompt: str) -> str:
        """Replaces [[analysis:file.py]] directives with code analysis."""
        return self.analysis_pattern.sub(self._replace_analysis_match, prompt)

    def _replace_manifest_match(self, match: re.Match) -> str:
        """
        Dynamically replaces a [[manifest:...]] regex match with
        manifest data or an error.
        """
        manifest_path = self.repo_path / ".intent" / "project_manifest.yaml"
        if not manifest_path.exists():
            return f"\n❌ Manifest file not found at {manifest_path}\n"

        try:
            manifest = yaml.safe_load(manifest_path.read_text(encoding="utf-8"))
        except Exception:
            return f"\n❌ Could not parse manifest file at {manifest_path}\n"

        field = match.group(1).strip()
        value = manifest
        # Improved logic for nested key access
        for key in field.split("."):
            value = value.get(key) if isinstance(value, dict) else None
            if value is None:
                break

        if value is None:
            return f"\n❌ Manifest field not found: {field}\n"

        # Pretty print for better context
        if isinstance(value, (dict, list)):
            value_str = yaml.dump(value, indent=2)
        else:
            value_str = str(value)

        return (
            f"\n--- MANIFEST: {field} ---\n" f"{value_str}\n" f"--- END MANIFEST ---\n"
        )

    def _inject_manifest(self, prompt: str) -> str:
        """
        Replaces [[manifest:field]] directives with data from
        project_manifest.yaml.
        """
        return self.manifest_pattern.sub(self._replace_manifest_match, prompt)

    # ID: 05c566aa-d219-49bd-8b74-daa023b81e46
    def process(self, prompt: str) -> str:
        """
        Processes the full prompt by sequentially resolving all directives.
        This is the main entry point for prompt enrichment.
        """
        prompt = self._inject_context(prompt)
        prompt = self._inject_includes(prompt)
        prompt = self._inject_analysis(prompt)
        prompt = self._inject_manifest(prompt)
        return prompt

--- END OF FILE ./src/core/prompt_pipeline.py ---

--- START OF FILE ./src/core/python_validator.py ---
# src/core/python_validator.py
"""
Python code validation pipeline.
"""
from __future__ import annotations

from typing import TYPE_CHECKING, Any, Dict, List, Tuple

import black

from core.black_formatter import format_code_with_black
from core.ruff_linter import fix_and_lint_code_with_ruff
from core.syntax_checker import check_syntax

from .validation_policies import PolicyValidator
from .validation_quality import QualityChecker

if TYPE_CHECKING:
    from system.governance.audit_context import AuditorContext

Violation = Dict[str, Any]


# ID: df30ee5a-2cf7-4671-a10b-5d995a28310a
def validate_python_code(
    path_hint: str, code: str, auditor_context: "AuditorContext"
) -> Tuple[str, List[Violation]]:
    """Comprehensive validation pipeline for Python code."""
    all_violations: List[Violation] = []

    safety_policy = auditor_context.policies.get("safety_policy", {})
    policy_validator = PolicyValidator(safety_policy.get("rules", []))
    quality_checker = QualityChecker()

    try:
        formatted_code = format_code_with_black(code)
    except (black.InvalidInput, Exception) as e:
        all_violations.append(
            {
                "rule": "tooling.black_failure",
                "message": str(e),
                "line": 0,
                "severity": "error",
            }
        )
        return code, all_violations

    fixed_code, ruff_violations = fix_and_lint_code_with_ruff(formatted_code, path_hint)
    all_violations.extend(ruff_violations)

    syntax_violations = check_syntax(path_hint, fixed_code)
    all_violations.extend(syntax_violations)
    if any(v["severity"] == "error" for v in syntax_violations):
        return fixed_code, all_violations

    all_violations.extend(policy_validator.check_semantics(fixed_code, path_hint))
    all_violations.extend(quality_checker.check_for_todo_comments(fixed_code))

    return fixed_code, all_violations

--- END OF FILE ./src/core/python_validator.py ---

--- START OF FILE ./src/core/ruff_linter.py ---
# src/core/ruff_linter.py
"""
Provides a utility to fix and lint Python code using Ruff's JSON output format.
Runs Ruff lint checks on generated Python code before it's staged.
Returns a success flag and an optional linting message.
"""

from __future__ import annotations

import json
import os
import subprocess
import tempfile
from typing import Any, Dict, List, Tuple

from shared.logger import getLogger

log = getLogger(__name__)
Violation = Dict[str, Any]


# --- MODIFICATION: Complete refactor to use Ruff's JSON output. ---
# --- The function now returns the fixed code and a list of structured violations. ---
# ID: 592ac81a-25a7-4313-9977-41f4dbca3cde
def fix_and_lint_code_with_ruff(
    code: str, display_filename: str = "<code>"
) -> Tuple[str, List[Violation]]:
    """
    Fix and lint the provided Python code using Ruff's JSON output format.

    Args:
        code (str): Source code to fix and lint.
        display_filename (str): Optional display name for readable error messages.

    Returns:
        A tuple containing:
        - The potentially fixed code as a string.
        - A list of structured violation dictionaries for any remaining issues.
    """
    violations = []
    with tempfile.NamedTemporaryFile(
        suffix=".py", mode="w+", delete=False, encoding="utf-8"
    ) as tmp_file:
        tmp_file.write(code)
        tmp_file_path = tmp_file.name

    try:
        # Step 1: Run Ruff with --fix to apply safe fixes. This modifies the temp file.
        subprocess.run(
            ["ruff", "check", tmp_file_path, "--fix", "--exit-zero", "--quiet"],
            capture_output=True,
            text=True,
            check=False,
        )

        # Step 2: Read the potentially modified code back from the file.
        with open(tmp_file_path, "r", encoding="utf-8") as f:
            fixed_code = f.read()

        # Step 3: Run Ruff again without fix, but with JSON output to get remaining violations.
        result = subprocess.run(
            ["ruff", "check", tmp_file_path, "--format", "json", "--exit-zero"],
            capture_output=True,
            text=True,
            check=False,
        )

        # Parse the JSON output for any remaining violations.
        if result.stdout:
            ruff_violations = json.loads(result.stdout)
            for v in ruff_violations:
                violations.append(
                    {
                        "rule": v.get("code", "RUFF-UNKNOWN"),
                        "message": v.get("message", "Unknown Ruff error"),
                        "line": v.get("location", {}).get("row", 0),
                        "severity": "warning",  # Assume all ruff issues are warnings for now
                    }
                )

        return fixed_code, violations

    except FileNotFoundError:
        log.error("Ruff is not installed or not in your PATH. Please install it.")
        # Return a critical violation if the tool itself is missing.
        tool_missing_violation = {
            "rule": "tooling.missing",
            "message": "Ruff is not installed or not in your PATH.",
            "line": 0,
            "severity": "error",
        }
        return code, [tool_missing_violation]
    except json.JSONDecodeError:
        log.error("Failed to parse Ruff's JSON output.")
        return code, []  # Return empty if we can't parse, to avoid crashing.
    except Exception as e:
        log.error(f"An unexpected error occurred during Ruff execution: {e}")
        return code, []
    finally:
        if os.path.exists(tmp_file_path):
            os.remove(tmp_file_path)

--- END OF FILE ./src/core/ruff_linter.py ---

--- START OF FILE ./src/core/self_correction_engine.py ---
# src/core/self_correction_engine.py
"""
Handles automated correction of code failures by generating and validating LLM-suggested repairs based on structured violation data.
"""

from __future__ import annotations

import json

from core.cognitive_service import CognitiveService
from core.file_handler import FileHandler
from core.prompt_pipeline import PromptPipeline
from core.validation_pipeline import validate_code
from shared.config import settings
from shared.utils.parsing import parse_write_blocks

REPO_PATH = settings.REPO_PATH
pipeline = PromptPipeline(repo_path=REPO_PATH)
file_handler = FileHandler(str(REPO_PATH))


# ID: c60020bd-5910-406e-ae64-ca227982142d
async def attempt_correction(
    failure_context: dict, cognitive_service: CognitiveService
) -> dict:
    """Attempts to fix a failed validation or test result using an enriched LLM prompt."""
    generator = await cognitive_service.get_client_for_role("Coder")

    file_path = failure_context.get("file_path")
    code = failure_context.get("code")
    violations = failure_context.get("violations", [])

    if not all([file_path, code, violations]):
        return {
            "status": "error",
            "message": "Missing required failure context fields.",
        }

    correction_prompt = (
        f"You are CORE's self-correction agent.\n\nA recent code generation attempt failed validation.\n"
        f"Please analyze the violations and fix the code below.\n\nFile: {file_path}\n\n"
        f"[[violations]]\n{json.dumps(violations, indent=2)}\n[[/violations]]\n\n"
        f"[[code]]\n{code.strip()}\n[[/code]]\n\n"
        f"Respond with the full, corrected code in a single write block:\n[[write:{file_path}]]\n<corrected code here>\n[[/write]]"
    )

    final_prompt = pipeline.process(correction_prompt)
    llm_output = await generator.make_request_async(final_prompt, user_id="auto_repair")

    write_blocks = parse_write_blocks(llm_output)

    if not write_blocks:
        return {
            "status": "error",
            "message": "LLM did not produce a valid correction in a write block.",
        }

    path, fixed_code = list(write_blocks.items())[0]

    # Note: A full implementation would need the auditor_context here.
    # For now, we assume a basic validation is sufficient for self-correction.
    validation_result = validate_code(path, fixed_code)
    if validation_result["status"] == "dirty":
        return {
            "status": "correction_failed_validation",
            "message": "The corrected code still fails validation.",
            "violations": validation_result["violations"],
        }

    pending_id = file_handler.add_pending_write(
        prompt=final_prompt, suggested_path=path, code=validation_result["code"]
    )
    return {
        "status": "retry_staged",
        "pending_id": pending_id,
        "file_path": path,
        "message": "Corrected code staged for approval.",
    }

--- END OF FILE ./src/core/self_correction_engine.py ---

--- START OF FILE ./src/core/service_registry.py ---
# src/core/service_registry.py
"""
Provides a centralized, lazily-initialized service registry for CORE.
This acts as a simple dependency injection container.
"""
from __future__ import annotations

import asyncio
import importlib
from pathlib import Path
from typing import Any, Dict

from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.config import settings
from shared.logger import getLogger

log = getLogger("service_registry")


# ID: 06afd27a-3b75-4e6c-a335-7e471365c65d
class ServiceRegistry:
    """A simple singleton service locator and DI container."""

    _instances: Dict[str, Any] = {}
    _service_map: Dict[str, str] = {}
    _initialized = False
    _lock = asyncio.Lock()

    def __init__(self, repo_path: Path | None = None):
        self.repo_path = repo_path or settings.REPO_PATH

    async def _initialize_from_db(self):
        """Loads the service map from the database on first access."""
        async with self._lock:
            if self._initialized:
                return

            log.info("Initializing ServiceRegistry from database...")
            try:
                async with get_session() as session:
                    result = await session.execute(
                        text("SELECT name, implementation FROM core.runtime_services")
                    )
                    for row in result:
                        self._service_map[row.name] = row.implementation
                self._initialized = True
                log.info(
                    f"ServiceRegistry initialized with {len(self._service_map)} services."
                )
            except Exception as e:
                log.critical(
                    f"Failed to initialize ServiceRegistry from DB: {e}", exc_info=True
                )
                # In a real app, you might exit or have a fallback
                self._initialized = False

    def _import_class(self, class_path: str):
        """Dynamically imports a class from a string path."""
        module_path, class_name = class_path.rsplit(".", 1)
        module = importlib.import_module(module_path)
        return getattr(module, class_name)

    # ID: fc217b8c-bba2-4600-aac9-4630903e83d2
    async def get_service(self, name: str) -> Any:
        """Lazily initializes and returns a singleton instance of a service."""
        if not self._initialized:
            await self._initialize_from_db()

        if name not in self._instances:
            if name not in self._service_map:
                raise ValueError(f"Service '{name}' not found in registry.")

            class_path = self._service_map[name]
            service_class = self._import_class(class_path)

            if name in ["knowledge_service", "cognitive_service", "auditor"]:
                self._instances[name] = service_class(self.repo_path)
            else:
                self._instances[name] = service_class()

            log.debug(f"Lazily initialized service: {name}")

        return self._instances[name]


# Global instance
service_registry = ServiceRegistry()

--- END OF FILE ./src/core/service_registry.py ---

--- START OF FILE ./src/core/syntax_checker.py ---
# src/core/syntax_checker.py
"""
Handles Python syntax validation for code before it's staged for write/commit operations.
"""

from __future__ import annotations

# --- THIS IS THE FIX ---
# Add all the necessary imports that were missing.
import ast
from typing import Any, Dict, List

Violation = Dict[str, Any]
# --- END OF FIX ---


# ID: c1e335fb-1ee0-4e76-b6bd-9ed7a7494f14
def check_syntax(file_path: str, code: str) -> List[Violation]:
    """Checks the given Python code for syntax errors and returns a list of violations, if any."""
    """
    Checks whether the given code has valid Python syntax.

    Args:
        file_path (str): File name (used to detect .py files).
        code (str): Source code string.

    Returns:
        A list of violation dictionaries. An empty list means the syntax is valid.
    """
    if not file_path.endswith(".py"):
        return []

    try:
        ast.parse(code)
        return []
    except SyntaxError as e:
        error_line = e.text.strip() if e.text else "<source unavailable>"
        return [
            {
                "rule": "E999",  # Ruff's code for syntax errors
                "message": f"Invalid Python syntax: {e.msg} near '{error_line}'",
                "line": e.lineno,
                "severity": "error",
            }
        ]

--- END OF FILE ./src/core/syntax_checker.py ---

--- START OF FILE ./src/core/test_runner.py ---
# src/core/test_runner.py
"""
Executes pytest on the project's test suite and captures structured results for
system integrity verification.
"""

from __future__ import annotations

import datetime
import json
import os
import subprocess
from pathlib import Path
from typing import Dict

from shared.config import settings
from shared.logger import getLogger

log = getLogger(__name__)


# ID: f22f2743-a396-4ca4-b88b-94cd76ee8572
def run_tests(silent: bool = True) -> Dict[str, str]:
    """Executes pytest on the tests/ directory and returns a structured result."""
    log.info("🧪 Running tests with pytest...")
    result = {
        "exit_code": "-1",
        "stdout": "",
        "stderr": "",
        "summary": "❌ Unknown error",
        "timestamp": datetime.datetime.utcnow().isoformat(),
    }

    repo_root = Path(__file__).resolve().parents[2]
    tests_path = repo_root / "tests"
    cmd = ["pytest", str(tests_path), "--tb=short", "-q"]

    timeout = os.getenv("TEST_RUNNER_TIMEOUT")
    try:
        timeout_val = int(timeout) if timeout else None
    except ValueError:
        timeout_val = None

    try:
        proc = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False,
            timeout=timeout_val,
        )
        result["exit_code"] = str(proc.returncode)
        result["stdout"] = proc.stdout.strip()
        result["stderr"] = proc.stderr.strip()
        result["summary"] = _summarize(proc.stdout)

        if not silent:
            log.info(f"Pytest stdout:\n{proc.stdout}")
            if proc.stderr:
                log.warning(f"Pytest stderr:\n{proc.stderr}")

    except subprocess.TimeoutExpired:
        result["stderr"] = "Test run timed out."
        result["summary"] = "⏰ Timeout"
        log.error("Pytest run timed out.")
    except FileNotFoundError:
        result["stderr"] = "pytest is not installed or not found in PATH."
        result["summary"] = "❌ Pytest not available"
        log.error("Pytest command not found. Is it installed in the environment?")
    except Exception as e:
        result["stderr"] = str(e)
        result["summary"] = "❌ Test run error"
        log.error(f"An unexpected error occurred during test run: {e}", exc_info=True)

    _log_test_result(result)
    _store_failure_if_any(result)

    log.info(f"🏁 Test run complete. Summary: {result['summary']}")
    return result


def _summarize(output: str) -> str:
    """Parses pytest output to find the final summary line."""
    lines = output.strip().splitlines()
    for line in reversed(lines):
        if "passed" in line or "failed" in line or "error" in line:
            return line.strip()
    return "No test summary found."


def _log_test_result(data: Dict[str, str]):
    """Appends a JSON record of a test run to the persistent log file."""
    try:
        log_path = Path(settings.CORE_ACTION_LOG_PATH)
        log_path.parent.mkdir(parents=True, exist_ok=True)
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(data) + "\n")
    except Exception as e:
        log.warning(f"Failed to write to persistent test log file: {e}", exc_info=True)


def _store_failure_if_any(data: Dict[str, str]):
    """Saves the details of a failed test run to a dedicated file for easy access."""
    try:
        failure_path = Path("logs/test_failures.json")
        if data.get("exit_code") != "0":
            failure_path.parent.mkdir(parents=True, exist_ok=True)
            payload = {
                "summary": data.get("summary"),
                "stdout": data.get("stdout"),
                "timestamp": data.get("timestamp"),
            }
            failure_path.write_text(json.dumps(payload, indent=2), encoding="utf-8")
        elif failure_path.exists():
            failure_path.unlink(missing_ok=True)
    except Exception as e:
        log.warning(f"Could not save test failure data: {e}", exc_info=True)

--- END OF FILE ./src/core/test_runner.py ---

--- START OF FILE ./src/core/validation_pipeline.py ---
# src/core/validation_pipeline.py
"""
A context-aware validation pipeline that applies different validation steps based on file type.
"""
from __future__ import annotations

from typing import TYPE_CHECKING, Any, Dict

from shared.logger import getLogger

from .file_classifier import get_file_classification
from .python_validator import validate_python_code
from .yaml_validator import validate_yaml_code

if TYPE_CHECKING:
    from system.governance.audit_context import AuditorContext

log = getLogger(__name__)


# ID: 50694eab-72fa-4e20-8f95-3b9f3d7bcb5e
def validate_code(
    file_path: str,
    code: str,
    quiet: bool = False,
    auditor_context: "AuditorContext" | None = None,
) -> Dict[str, Any]:
    """Validate a file's code by routing it to the appropriate validation pipeline."""
    classification = get_file_classification(file_path)
    if not quiet:
        log.debug(f"Validation: Classifying '{file_path}' as '{classification}'.")

    final_code = code
    violations = []

    if classification == "python":
        if not auditor_context:
            raise ValueError("AuditorContext is required for validating Python code.")
        final_code, violations = validate_python_code(file_path, code, auditor_context)
    elif classification == "yaml":
        final_code, violations = validate_yaml_code(code)

    is_dirty = any(v.get("severity") == "error" for v in violations)
    status = "dirty" if is_dirty else "clean"

    return {"status": status, "violations": violations, "code": final_code}

--- END OF FILE ./src/core/validation_pipeline.py ---

--- START OF FILE ./src/core/validation_policies.py ---
# src/core/validation_policies.py
"""
Policy-aware validation logic for enforcing safety and security policies.
This module is given pre-loaded policies and scans AST nodes for violations.
"""
from __future__ import annotations

import ast
from pathlib import Path
from typing import Any, Dict, List

Violation = Dict[str, Any]


# ID: dcff1afd-963d-419c-8f66-31978115cfc9
class PolicyValidator:
    """Handles policy-aware validation including safety checks and forbidden patterns."""

    def __init__(self, safety_policy_rules: List[Dict]):
        """
        Initialize the policy validator with pre-loaded safety policy rules.
        """
        self.safety_rules = safety_policy_rules

    def _get_full_attribute_name(self, node: ast.Attribute) -> str:
        """Recursively builds the full name of an attribute call."""
        parts = []
        current = node
        while isinstance(current, ast.Attribute):
            parts.insert(0, current.attr)
            current = current.value
        if isinstance(current, ast.Name):
            parts.insert(0, current.id)
        return ".".join(parts)

    def _find_dangerous_patterns(
        self, tree: ast.AST, file_path: str
    ) -> List[Violation]:
        """Scans the AST for calls and imports forbidden by safety policies."""
        violations: List[Violation] = []
        rules = self.safety_rules

        forbidden_calls = set()
        forbidden_imports = set()

        for rule in rules:
            exclude_patterns = [
                p
                for p in rule.get("scope", {}).get("exclude", [])
                if isinstance(p, str)
            ]
            is_excluded = any(Path(file_path).match(p) for p in exclude_patterns)

            if is_excluded:
                continue

            if rule.get("id") == "no_dangerous_execution":
                patterns = {
                    p.replace("(", "")
                    for p in rule.get("detection", {}).get("patterns", [])
                }
                forbidden_calls.update(patterns)
            elif rule.get("id") == "no_unsafe_imports":
                patterns = {
                    imp.split(" ")[-1]
                    for imp in rule.get("detection", {}).get("forbidden", [])
                }
                forbidden_imports.update(patterns)

        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                full_call_name = ""
                if isinstance(node.func, ast.Name):
                    full_call_name = node.func.id
                elif isinstance(node.func, ast.Attribute):
                    full_call_name = self._get_full_attribute_name(node.func)

                if full_call_name in forbidden_calls:
                    violations.append(
                        {
                            "rule": "safety.dangerous_call",
                            "message": f"Use of forbidden call: '{full_call_name}'",
                            "line": node.lineno,
                            "severity": "error",
                        }
                    )
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    if alias.name.split(".")[0] in forbidden_imports:
                        violations.append(
                            {
                                "rule": "safety.forbidden_import",
                                "message": f"Import of forbidden module: '{alias.name}'",
                                "line": node.lineno,
                                "severity": "error",
                            }
                        )
            elif isinstance(node, ast.ImportFrom):
                if node.module and node.module.split(".")[0] in forbidden_imports:
                    violations.append(
                        {
                            "rule": "safety.forbidden_import",
                            "message": f"Import from forbidden module: '{node.module}'",
                            "line": node.lineno,
                            "severity": "error",
                        }
                    )
        return violations

    # ID: d6059c1e-83ab-4c9a-8ebf-e596fa79494d
    def check_semantics(self, code: str, file_path: str) -> List[Violation]:
        """Runs all policy-aware semantic checks on a string of Python code."""
        try:
            tree = ast.parse(code)
        except SyntaxError:
            return []
        return self._find_dangerous_patterns(tree, file_path)

--- END OF FILE ./src/core/validation_policies.py ---

--- START OF FILE ./src/core/validation_quality.py ---
# src/core/validation_quality.py
"""
Code quality validation checks for maintainability and clarity.

This module provides quality-focused validation checks such as detecting
TODO comments and other code clarity issues that don't affect functionality
but impact maintainability.
"""

from __future__ import annotations

from typing import Any, Dict, List

Violation = Dict[str, Any]


# ID: 0c6502f3-6d97-41e8-a618-6ae63a489e8b
class QualityChecker:
    """Handles code quality and clarity validation checks."""

    # ID: 972208ef-200e-4836-851d-f82f24e3b779
    def check_for_todo_comments(self, code: str) -> List[Violation]:
        """Scans source code for TODO/FIXME comments and returns them as violations.

        Args:
            code: The source code to scan for TODO comments

        Returns:
            List of violations for each TODO/FIXME comment found
        """
        violations: List[Violation] = []
        for i, line in enumerate(code.splitlines(), 1):
            if "#" in line:
                comment = line.split("#", 1)[1]
                if "TODO" in comment or "FIXME" in comment:
                    violations.append(
                        {
                            "rule": "clarity.no_todo_comments",
                            "message": f"Unresolved '{comment.strip()}' on line {i}",
                            "line": i,
                            "severity": "warning",
                        }
                    )
        return violations

--- END OF FILE ./src/core/validation_quality.py ---

--- START OF FILE ./src/core/yaml_validator.py ---
# src/core/yaml_validator.py
"""
YAML validation pipeline.

This module provides validation functionality specifically for YAML files,
checking for syntax errors and structural issues.
"""

from __future__ import annotations

from typing import Any, Dict, List, Tuple

import yaml

Violation = Dict[str, Any]


# ID: f3bbf4e9-71b5-4dad-8ad8-ee93b90dd8c0
def validate_yaml_code(code: str) -> Tuple[str, List[Violation]]:
    """Validation pipeline for YAML code.

    This function validates YAML syntax and structure, returning any violations
    found during the validation process.

    Args:
        code: The YAML code to validate

    Returns:
        A tuple containing the original code and list of violations
    """
    violations = []
    try:
        yaml.safe_load(code)
    except yaml.YAMLError as e:
        violations.append(
            {
                "rule": "syntax.yaml",
                "message": f"Invalid YAML format: {e}",
                "line": e.problem_mark.line + 1 if e.problem_mark else 0,
                "severity": "error",
            }
        )
    return code, violations

--- END OF FILE ./src/core/yaml_validator.py ---

--- START OF FILE ./src/features/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/features/__init__.py ---

--- START OF FILE ./src/features/demo/hello_world.py ---
# src/features/demo/hello_world.py

# ID: 3615ba5c-4515-4435-b62b-a0e945430872
def print_greeting():
    """Prints a simple greeting to the console."""
    print("Hello from the CORE system!")

--- END OF FILE ./src/features/demo/hello_world.py ---

--- START OF FILE ./src/features/governance/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/features/governance/__init__.py ---

--- START OF FILE ./src/features/governance/audit_context.py ---
# src/features/governance/audit_context.py
"""
Defines the AuditorContext, a central data object that provides a consistent
view of the project's constitution and state for all audit checks.
"""
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict

import yaml

from core.knowledge_service import KnowledgeService
from shared.logger import getLogger

log = getLogger("audit_context")


# ID: aebe6840-e855-4c4e-8310-59faad75fa6f
class AuditorContext:
    """
    A data class that loads and provides access to all constitutional
    artifacts needed by the auditor and its checks.
    """

    def __init__(self, repo_path: Path):
        self.repo_path = repo_path.resolve()
        self.intent_path = self.repo_path / ".intent"
        self.mind_path = self.intent_path / "mind"
        self.charter_path = self.intent_path / "charter"
        self.src_dir: Path = self.repo_path / "src"

        # These can be loaded synchronously
        self.meta: Dict[str, Any] = self._load_yaml(self.intent_path / "meta.yaml")
        self.policies: Dict[str, Any] = self._load_policies()
        self.source_structure: Dict[str, Any] = self._load_yaml(
            self.mind_path / "knowledge" / "source_structure.yaml"
        )
        # Initialize knowledge graph components as empty; they will be loaded async
        self.knowledge_graph: Dict[str, Any] = {"symbols": {}}
        self.symbols_list: list = []
        self.symbols_map: dict = {}
        log.debug("AuditorContext initialized synchronously.")

    # ID: cd0c99b3-b02a-425a-8339-ceec1745d9b7
    async def load_knowledge_graph(self):
        """Asynchronously loads the knowledge graph from the service."""
        log.debug("Asynchronously loading knowledge graph...")
        knowledge_service = KnowledgeService(self.repo_path)
        self.knowledge_graph = await knowledge_service.get_graph()
        self.symbols_list = list(self.knowledge_graph.get("symbols", {}).values())
        self.symbols_map = self.knowledge_graph.get("symbols", {})
        log.debug("Knowledge graph loaded.")

    def _load_yaml(self, path: Path) -> Dict[str, Any]:
        """Safely loads a single YAML file, returning an empty dict on failure."""
        if not path.exists():
            log.warning(f"Constitutional file not found: {path}")
            return {}
        try:
            return yaml.safe_load(path.read_text("utf-8")) or {}
        except (yaml.YAMLError, IOError) as e:
            log.error(f"Failed to load or parse YAML at {path}: {e}")
            return {}

    def _load_policies(self) -> Dict[str, Any]:
        """Loads all policy files from the charter into a dictionary."""
        policies_dir = self.charter_path / "policies"
        loaded_policies: Dict[str, Any] = {}
        if not policies_dir.is_dir():
            log.warning(f"Policies directory not found: {policies_dir}")
            return {}

        for policy_file in policies_dir.glob("*_policy.yaml"):
            policy_id = policy_file.stem
            policy_content = self._load_yaml(policy_file)
            if policy_content:
                loaded_policies[policy_id] = policy_content

        log.debug(f"Loaded {len(loaded_policies)} policies.")
        return loaded_policies

--- END OF FILE ./src/features/governance/audit_context.py ---

--- START OF FILE ./src/features/governance/checks/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/features/governance/checks/__init__.py ---

--- START OF FILE ./src/features/governance/checks/base_check.py ---
# src/features/governance/checks/base_check.py
"""
Provides a shared base class for all constitutional audit checks to inherit from.
"""
from __future__ import annotations

from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from features.governance.audit_context import AuditorContext


# ID: 2cb0374b-a487-4dce-bab1-c2ee8a693b0a
class BaseCheck:
    """A base class for audit checks, providing a shared context."""

    def __init__(self, context: "AuditorContext"):
        """
        Initializes the check with a shared auditor context.
        This common initializer serves the 'dry_by_design' principle.
        """
        self.context = context
        self.repo_root = context.repo_path
        self.intent_path = context.intent_path
        self.src_dir = context.src_dir

--- END OF FILE ./src/features/governance/checks/base_check.py ---

--- START OF FILE ./src/features/governance/checks/capability_coverage.py ---
# src/features/governance/checks/capability_coverage.py
"""
A constitutional audit check to ensure that all capabilities declared in the
project manifest are implemented in the database.
"""
from __future__ import annotations

from typing import List, Set

from features.governance.audit_context import AuditorContext
from shared.models import AuditFinding, AuditSeverity


# ID: 979ce56f-7f3c-40e7-8736-ce219bab6ad8
class CapabilityCoverageCheck:
    """
    Verifies that every capability in the manifest has a corresponding
    implementation entry in the database's symbols table.
    """

    def __init__(self, context: AuditorContext):
        self.context = context

    # ID: e0730fb8-2616-42b2-915b-48f30ff4ac17
    def execute(self) -> List[AuditFinding]:
        """
        Runs the check and returns a list of findings for any violations.
        """
        findings = []

        manifest_path = self.context.mind_path / "project_manifest.yaml"
        if not manifest_path.exists():
            findings.append(
                AuditFinding(
                    check_id="manifest.missing.project_manifest",
                    severity=AuditSeverity.ERROR,
                    message="The project_manifest.yaml file is missing from .intent/mind/.",
                    file_path=str(manifest_path.relative_to(self.context.repo_path)),
                )
            )
            return findings

        manifest_content = self.context._load_yaml(manifest_path)
        declared_capabilities: Set[str] = set(manifest_content.get("capabilities", []))

        # --- THIS IS THE CORRECT LOGIC ---
        # The source of truth for implementation is the database, not code comments.
        implemented_capabilities: Set[str] = {
            s["key"]
            for s in self.context.knowledge_graph.get("symbols", {}).values()
            if s.get("key")  # A symbol has a capability if its 'key' is not null
        }
        # --- END OF CORRECT LOGIC ---

        missing_implementations = declared_capabilities - implemented_capabilities

        for cap_key in sorted(list(missing_implementations)):
            findings.append(
                AuditFinding(
                    check_id="capability.coverage.missing_implementation",
                    severity=AuditSeverity.WARNING,
                    message=f"Capability '{cap_key}' is declared in the manifest but has no implementation linked in the database.",
                    file_path=str(manifest_path.relative_to(self.context.repo_path)),
                )
            )

        return findings

--- END OF FILE ./src/features/governance/checks/capability_coverage.py ---

--- START OF FILE ./src/features/governance/checks/domain_placement.py ---
# src/features/governance/checks/domain_placement.py
"""
A constitutional audit check to ensure capabilities are declared in the
correct domain manifest file.
"""
from __future__ import annotations

from typing import List

from features.governance.audit_context import AuditorContext
from shared.models import AuditFinding, AuditSeverity
from shared.utils.yaml_processor import yaml_processor


# ID: 0cd8ad5a-ed46-4f18-8335-f95b747d6164
class DomainPlacementCheck:
    """
    Validates that capability keys declared in a domain manifest file
    match the domain of that file.
    """

    def __init__(self, context: AuditorContext):
        self.context = context
        self.domains_dir = self.context.mind_path / "knowledge" / "domains"

    # ID: 7eb75aef-6463-450d-8088-e9a64e3d85c8
    def execute(self) -> List[AuditFinding]:
        """
        Runs the check and returns a list of findings for any violations.
        """
        findings = []
        if not self.domains_dir.is_dir():
            return findings

        for domain_file in self.domains_dir.glob("*.yaml"):
            domain_name = domain_file.stem
            manifest_content = yaml_processor.load(domain_file)
            if not manifest_content:
                continue

            capabilities = manifest_content.get("tags", [])
            if not isinstance(capabilities, list):
                continue

            for cap in capabilities:
                if isinstance(cap, dict) and "key" in cap:
                    cap_key = cap["key"]
                    if not cap_key.startswith(f"{domain_name}."):
                        findings.append(
                            AuditFinding(
                                check_id="domain.placement.mismatch",
                                severity=AuditSeverity.ERROR,
                                message=f"Capability '{cap_key}' is misplaced in '{domain_file.name}'. It should be in a '{cap_key.split('.')[0]}.yaml' manifest.",
                                file_path=str(
                                    domain_file.relative_to(self.context.repo_path)
                                ),
                            )
                        )
        return findings

--- END OF FILE ./src/features/governance/checks/domain_placement.py ---

--- START OF FILE ./src/features/governance/checks/duplication_check.py ---
# src/features/governance/checks/duplication_check.py
"""
A constitutional audit check to find semantically duplicate or near-duplicate
symbols (functions/classes) using the Qdrant vector database.
"""
from __future__ import annotations

import asyncio
from typing import Any, Dict, List

from rich.progress import track

from features.governance.audit_context import AuditorContext
from services.clients.qdrant_client import QdrantService
from shared.logger import getLogger
from shared.models import AuditFinding, AuditSeverity

log = getLogger("duplication_check")

# The similarity score above which two symbols are considered near-duplicates.
# TODO: This should be moved to a constitutional policy file.
SIMILARITY_THRESHOLD = 0.80


# ID: 16e4e42b-3f70-444f-933e-ec1679cd8992
class DuplicationCheck:
    """
    Enforces the 'dry_by_design' principle by finding semantically similar symbols.
    """

    def __init__(self, context: AuditorContext):
        self.context = context
        self.symbols = self.context.knowledge_graph.get("symbols", {})
        self.qdrant_service = QdrantService()

    async def _check_single_symbol(self, symbol: Dict[str, Any]) -> List[AuditFinding]:
        """Checks a single symbol for duplicates against the Qdrant index."""
        findings = []
        symbol_key = symbol.get("symbol_path")  # Use symbol_path for consistency
        vector_id = symbol.get("vector_id")

        if not vector_id:
            return []

        try:
            query_vector = await self.qdrant_service.get_vector_by_id(
                point_id=vector_id
            )
            if not query_vector:
                return []

            similar_hits = await self.qdrant_service.search_similar(
                query_vector=query_vector, limit=5
            )

            for hit in similar_hits:
                hit_symbol_key = hit["payload"]["chunk_id"]
                if hit_symbol_key == symbol_key:
                    continue

                if hit["score"] > SIMILARITY_THRESHOLD:
                    if symbol_key < hit_symbol_key:
                        findings.append(
                            AuditFinding(
                                check_id="duplication.semantic.near_duplicate_found",
                                severity=AuditSeverity.WARNING,
                                message=(
                                    f"Potential duplicate logic found between '{symbol_key}' and "
                                    f"'{hit_symbol_key}' (Similarity: {hit['score']:.2f})"
                                ),
                                file_path=symbol.get("file"),
                            )
                        )
        except Exception as e:
            log.warning(f"Could not perform duplication check for '{symbol_key}': {e}")

        return findings

    # ID: 614e5982-8163-49f9-8762-689960b9851a
    async def execute(self) -> List[AuditFinding]:
        """
        Asynchronously runs the duplication check across all vectorized symbols.
        """
        vectorized_symbols = [s for s in self.symbols.values() if s.get("vector_id")]

        if not vectorized_symbols:
            return []

        tasks = [self._check_single_symbol(symbol) for symbol in vectorized_symbols]

        results = []
        for future in track(
            asyncio.as_completed(tasks),
            description="Checking for duplicate code...",
            total=len(tasks),
        ):
            results.extend(await future)
        return results

--- END OF FILE ./src/features/governance/checks/duplication_check.py ---

--- START OF FILE ./src/features/governance/checks/environment_checks.py ---
# src/features/governance/checks/environment_checks.py
"""
Audits the system's runtime environment for required configuration.
"""
from __future__ import annotations

import os

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity


# ID: 0c3965b7-b3f3-4fb6-bbbb-c94a1ffae3fe
class EnvironmentChecks(BaseCheck):
    """Container for environment and runtime configuration checks."""

    def __init__(self, context):
        super().__init__(context)
        self.requirements = self.context.policies.get("runtime_requirements", {})

    # ID: 0c0e7695-b11e-4ad8-9e74-23d5f79dad00
    def execute(self) -> list[AuditFinding]:
        """
        Verifies that required environment variables specified in
        runtime_requirements.yaml are set.
        """
        findings = []
        required_vars = self.requirements.get("variables", {})

        for name, config in required_vars.items():
            if config.get("required") and not os.getenv(name):
                msg = (
                    f"Required environment variable '{name}' is not set. "
                    f"Description: {config.get('description', 'No description.')}"
                )
                findings.append(
                    AuditFinding(
                        check_id="environment.variable.missing",
                        severity=AuditSeverity.ERROR,
                        message=msg,
                        file_path=".env",
                    )
                )
        return findings

--- END OF FILE ./src/features/governance/checks/environment_checks.py ---

--- START OF FILE ./src/features/governance/checks/file_checks.py ---
# src/features/governance/checks/file_checks.py
"""
Audits file existence and orphan detection for constitutional governance files.
"""
from __future__ import annotations

from typing import List, Set

from features.governance.checks.base_check import BaseCheck
from shared.config import settings  # <-- NEW IMPORT
from shared.models import AuditFinding, AuditSeverity
from shared.utils.constitutional_parser import get_all_constitutional_paths

# Files that are allowed to exist but are not indexed in meta.yaml
KNOWN_UNINDEXED_FILES = {
    ".intent/charter/constitution/approvers.yaml.example",
    # Keys should not be checked into git, but if they are, don't flag as orphan
    ".intent/keys/private.key",
}


# ID: 37b5ae2f-c3c2-4db4-9677-f16fd788c908
class FileChecks(BaseCheck):
    """Container for file-based constitutional checks."""

    # ID: 56481071-3a0c-437d-ba57-533bc03d9ed6
    def execute(self) -> List[AuditFinding]:
        """Runs all file-related checks."""
        # --- THIS IS THE REFACTOR ---
        # 1. Load the meta.yaml content using the settings object.
        meta_content = settings._meta_config  # Access the pre-loaded dictionary

        # 2. Pass the content to the pure parser function.
        required_files = get_all_constitutional_paths(meta_content, self.intent_path)
        # --- END OF REFACTOR ---

        findings = self._check_required_files(required_files)
        findings.extend(self._check_for_orphaned_intent_files(required_files))
        return findings

    def _check_required_files(self, required_files: Set[str]) -> List[AuditFinding]:
        """Verify that all files declared in meta.yaml exist on disk."""
        findings: List[AuditFinding] = []

        for file_rel_path in sorted(required_files):
            full_path = self.repo_root / file_rel_path
            if not full_path.exists():
                findings.append(
                    AuditFinding(
                        check_id="file.meta.missing",
                        severity=AuditSeverity.ERROR,
                        message=f"Missing constitutionally-required file declared in meta.yaml: '{file_rel_path}'",
                        file_path=file_rel_path,
                    )
                )
        return findings

    def _check_for_orphaned_intent_files(
        self, declared_files: Set[str]
    ) -> List[AuditFinding]:
        """Find .intent files not referenced in meta.yaml."""
        findings: List[AuditFinding] = []

        # Add a README to proposals, which is fine to be un-indexed
        all_known_files = declared_files.union(KNOWN_UNINDEXED_FILES)
        if (self.intent_path / "proposals/README.md").exists():
            all_known_files.add(".intent/proposals/README.md")

        physical_files: Set[str] = {
            str(p.relative_to(self.repo_root)).replace("\\", "/")
            for p in self.intent_path.rglob("*")
            if p.is_file()
        }

        orphaned_files = sorted(physical_files - all_known_files)

        for orphan in orphaned_files:
            # We can be more lenient with prompts and reports, as they may not all be indexed
            if "prompts" in orphan or "reports" in orphan:
                continue
            findings.append(
                AuditFinding(
                    check_id="file.meta.orphaned",
                    severity=AuditSeverity.WARNING,
                    message=f"Orphaned intent file: '{orphan}' is not a recognized constitutional file. Add it to meta.yaml or remove it.",
                    file_path=orphan,
                )
            )
        return findings

--- END OF FILE ./src/features/governance/checks/file_checks.py ---

--- START OF FILE ./src/features/governance/checks/health_checks.py ---
# src/features/governance/checks/health_checks.py
"""
Audits codebase health for complexity, atomicity, and line length violations.
"""
from __future__ import annotations

import ast
import statistics
from pathlib import Path
from typing import List

from radon.visitors import ComplexityVisitor

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity


# ID: 64e34c49-4bad-4d35-8de7-df4f67b51adc
class HealthChecks(BaseCheck):
    """Container for codebase health constitutional checks."""

    def __init__(self, context):
        """Initializes the check with a shared auditor context."""
        super().__init__(context)
        self.health_policy = self.context.policies.get("code_health_policy", {})

    # ID: ee9a54dc-c6c9-44c3-9966-746cf4db7d94
    def execute(self) -> list[AuditFinding]:
        """Measures code complexity and atomicity against defined policies."""
        policy_rules = self.health_policy.get("rules", {})

        file_line_counts = {}
        all_violations = []

        unique_files = {
            s["file_path"]
            for s in self.context.symbols_list
            if s.get("file_path", "").startswith("src/")
        }

        for file_path_str in sorted(list(unique_files)):
            if not file_path_str.endswith(".py"):
                continue

            file_path = self.context.repo_root / file_path_str
            logical_lines, violations = self._analyze_python_file(
                file_path, policy_rules
            )

            if logical_lines > 0:
                file_line_counts[file_path] = logical_lines
            all_violations.extend(violations)

        all_violations.extend(
            self._find_file_size_outliers(file_line_counts, policy_rules)
        )
        return all_violations

    def _analyze_python_file(
        self, file_path: Path, rules: dict
    ) -> tuple[int, List[AuditFinding]]:
        """Analyze a single Python file for health violations."""
        try:
            source_code = file_path.read_text(encoding="utf-8")
            logical_lines = self._count_logical_lines(source_code)

            if logical_lines > rules.get("max_module_lloc", 300):
                return logical_lines, [
                    AuditFinding(
                        check_id="health.module.too_long",
                        severity=AuditSeverity.WARNING,
                        message=f"Module has {logical_lines} logical lines of code (limit: {rules.get('max_module_lloc', 300)}).",
                        file_path=str(file_path.relative_to(self.context.repo_root)),
                    )
                ]

            syntax_tree = ast.parse(source_code)
            complexity_visitor = ComplexityVisitor.from_ast(syntax_tree)
            violations = self._check_function_metrics(
                complexity_visitor,
                rules,
                str(file_path.relative_to(self.context.repo_root)),
            )
            return logical_lines, violations
        except Exception:
            return 0, []

    def _count_logical_lines(self, source_code: str) -> int:
        """Calculates the Logical Lines of Code (LLOC), ignoring comments and blank lines."""
        return sum(
            1
            for line in source_code.splitlines()
            if line.strip() and not line.strip().startswith("#")
        )

    def _check_function_metrics(
        self,
        visitor: ComplexityVisitor,
        rules: dict,
        file_path_str: str,
    ) -> List[AuditFinding]:
        """Check function complexity and function length."""
        violations = []
        for function in visitor.functions:
            if function.cognitive_complexity > rules.get(
                "max_cognitive_complexity", 15
            ):
                violations.append(
                    AuditFinding(
                        check_id="health.function.too_complex",
                        severity=AuditSeverity.WARNING,
                        message=f"Function '{function.name}' has Cognitive Complexity of {function.cognitive_complexity} (limit: {rules.get('max_cognitive_complexity', 15)}).",
                        file_path=file_path_str,
                    )
                )

            if function.lloc > rules.get("max_function_lloc", 80):
                violations.append(
                    AuditFinding(
                        check_id="health.function.too_long",
                        severity=AuditSeverity.WARNING,
                        message=f"Function '{function.name}' has {function.lloc} logical lines of code (limit: {rules.get('max_function_lloc', 80)}).",
                        file_path=file_path_str,
                    )
                )
        return violations

    def _find_file_size_outliers(
        self, file_line_counts: dict, rules: dict
    ) -> List[AuditFinding]:
        """Check for files that are statistical outliers in size."""
        if len(file_line_counts) < 3:
            return []

        violations = []
        line_count_values = list(file_line_counts.values())
        average_lines = statistics.mean(line_count_values)
        standard_deviation = statistics.stdev(line_count_values)
        outlier_threshold = average_lines + (
            rules.get("outlier_standard_deviations", 2.0) * standard_deviation
        )

        for file_path, line_count in file_line_counts.items():
            if line_count > outlier_threshold:
                violations.append(
                    AuditFinding(
                        check_id="health.module.outlier",
                        severity=AuditSeverity.WARNING,
                        message=f"Possible complexity outlier ({line_count} LLOC vs. AVG of {average_lines:.0f}). This may violate 'separation_of_concerns'.",
                        file_path=str(file_path.relative_to(self.context.repo_root)),
                    )
                )
        return violations

--- END OF FILE ./src/features/governance/checks/health_checks.py ---

--- START OF FILE ./src/features/governance/checks/id_coverage_check.py ---
# src/features/governance/checks/id_coverage_check.py
"""
A constitutional audit check to enforce that every public symbol in the codebase
has a registered ID in the database.
"""
from __future__ import annotations

import ast
import re
import uuid
from typing import List

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity

# Pre-compiled regex for efficiency
ID_TAG_REGEX = re.compile(
    r"#\s*ID:\s*([0-9a-fA-F]{8}-([0-9a-fA-F]{4}-){3}[0-9a-fA-F]{12})"
)


# ID: 80af23eb-ec62-4180-b1bb-1ce3903affc1
class IdCoverageCheck(BaseCheck):
    """
    Ensures every public function/class in `src/` has a valid, DB-registered ID tag.
    """

    # ID: 8aee0db7-143c-4ae6-a2a2-576469823c8e
    def execute(self) -> List[AuditFinding]:
        """
        Runs the check and returns a list of findings for any violations.
        """
        findings = []
        # db_uuids: Set[str] = set() # This would be populated from the DB in a real async check.
        # For this implementation, we'll focus on the AST scan. A full implementation
        # would make this check async and query core.symbols.

        # NOTE: A full implementation would query the DB. For this synchronous pass,
        # we focus on presence and format, which is the core of the task.
        # async with get_session() as session:
        #     result = await session.execute(text("SELECT uuid FROM core.symbols"))
        #     db_uuids = {str(row[0]) for row in result}

        for file_path in self.context.src_dir.rglob("*.py"):
            try:
                content = file_path.read_text("utf-8")
                source_lines = content.splitlines()
                tree = ast.parse(content)

                for node in ast.walk(tree):
                    if not isinstance(
                        node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
                    ):
                        continue

                    # Rule 1: Must be a public symbol
                    if node.name.startswith("_"):
                        continue

                    # Rule 2: Must have an ID tag
                    tag_line_index = node.lineno - 2
                    if not (0 <= tag_line_index < len(source_lines)):
                        findings.append(self._finding_for_missing_tag(file_path, node))
                        continue

                    line_above = source_lines[tag_line_index].strip()
                    match = ID_TAG_REGEX.match(line_above)

                    if not match:
                        findings.append(self._finding_for_missing_tag(file_path, node))
                        continue

                    # Rule 3: The ID must be a valid UUID
                    try:
                        # Validate that the matched group is a valid UUID
                        uuid.UUID(match.group(1))
                        # Rule 4 (Conceptual): The UUID must be in the database
                        # if db_uuids and found_uuid not in db_uuids:
                        #     findings.append(self._finding_for_unregistered_id(file_path, node, found_uuid))
                    except ValueError:
                        findings.append(
                            self._finding_for_invalid_id(file_path, node, line_above)
                        )

            except Exception:
                continue

        return findings

    def _finding_for_missing_tag(self, file_path, node):
        return AuditFinding(
            check_id="linkage.id.missing",
            severity=AuditSeverity.ERROR,
            message=f"Public symbol '{node.name}' is missing a required '# ID: <uuid>' tag.",
            file_path=str(file_path.relative_to(self.context.repo_path)),
            line_number=node.lineno,
        )

    def _finding_for_invalid_id(self, file_path, node, line_content):
        return AuditFinding(
            check_id="linkage.id.invalid_format",
            severity=AuditSeverity.ERROR,
            message=f"Invalid UUID format for symbol '{node.name}'. Found: '{line_content}'",
            file_path=str(file_path.relative_to(self.context.repo_path)),
            line_number=node.lineno - 1,
        )

    def _finding_for_unregistered_id(self, file_path, node, found_uuid):
        return AuditFinding(
            check_id="linkage.id.unregistered",
            severity=AuditSeverity.ERROR,
            message=f"ID '{found_uuid}' for symbol '{node.name}' is not registered in the database.",
            file_path=str(file_path.relative_to(self.context.repo_path)),
            line_number=node.lineno - 1,
        )

--- END OF FILE ./src/features/governance/checks/id_coverage_check.py ---

--- START OF FILE ./src/features/governance/checks/import_rules.py ---
# src/features/governance/checks/import_rules.py
"""
A constitutional audit check to enforce architectural import rules as
defined in the source_structure.yaml manifest.
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict, List, Set

from sqlalchemy import text

from features.governance.audit_context import AuditorContext
from services.repositories.db.engine import get_session
from shared.models import AuditFinding, AuditSeverity
from shared.utils.import_scanner import scan_imports_for_file


# ID: 0690cf39-3739-449e-9228-2c7c8526209b
class ImportRulesCheck:
    """
    Ensures that code files only import modules from their allowed domains.
    This check now reads its configuration from the database.
    """

    def __init__(self, context: AuditorContext):
        self.context = context
        self.domain_map: Dict[str, str] = {}
        self.import_rules: Dict[str, Set[str]] = {}
        # The data is now loaded asynchronously when execute is called.

    async def _load_rules_from_db(self):
        """Loads domain maps and import rules from the database."""
        async with get_session() as session:
            await session.execute(text("SELECT key FROM core.domains"))

        structure = self.context.source_structure.get("structure", [])
        for domain_info in structure:
            path_str = domain_info.get("path")
            domain_name = domain_info.get("domain")
            if path_str and domain_name:
                # --- THIS IS THE FIX ---
                full_path = str((self.context.repo_path / path_str).resolve())
                # --- END OF FIX ---
                self.domain_map[full_path] = domain_name

        for domain_info in structure:
            domain_name = domain_info.get("domain")
            allowed_imports = domain_info.get("allowed_imports", [])
            if domain_name:
                self.import_rules[domain_name] = set(allowed_imports)

    def _get_domain_for_path(self, file_path: Path) -> str | None:
        """Finds the domain for a given absolute file path."""
        abs_path_str = str(file_path.resolve())
        for domain_path, domain_name in self.domain_map.items():
            if abs_path_str.startswith(domain_path):
                return domain_name
        return None

    # ID: f1a7dedb-d5e4-442d-8957-b7f974778bc5
    async def execute(self) -> List[AuditFinding]:
        """
        Runs the check by scanning all source files and validating their imports.
        """
        await self._load_rules_from_db()

        findings = []
        # --- THIS IS THE FIX ---
        src_path = self.context.repo_path / "src"
        # --- END OF FIX ---

        for file_path in src_path.rglob("*.py"):
            file_domain = self._get_domain_for_path(file_path)
            if not file_domain:
                continue

            allowed_imports = self.import_rules.get(file_domain, set())
            imported_modules = scan_imports_for_file(file_path)

            for module_str in imported_modules:
                if not module_str.startswith(
                    ("core", "features", "services", "shared", "cli", "api")
                ):
                    continue

                top_level_package = module_str.split(".")[0]

                if top_level_package not in allowed_imports:
                    findings.append(
                        AuditFinding(
                            check_id="architecture.import_violation",
                            severity=AuditSeverity.ERROR,
                            message=f"Illegal import of '{module_str}' in domain '{file_domain}'. Allowed: {sorted(list(allowed_imports))}",
                            file_path=str(
                                file_path.relative_to(self.context.repo_path)
                            ),
                        )
                    )
        return findings

--- END OF FILE ./src/features/governance/checks/import_rules.py ---

--- START OF FILE ./src/features/governance/checks/knowledge_source_check.py ---
# src/features/governance/checks/knowledge_source_check.py
"""
A constitutional audit check to enforce the single source of truth for knowledge.
"""
from __future__ import annotations

from typing import List

from features.governance.checks.base_check import BaseCheck
from shared.config import settings
from shared.models import AuditFinding, AuditSeverity


# ID: 17efaec9-2238-46a9-945e-fa2610882d80
class KnowledgeSourceCheck(BaseCheck):
    """
    Verifies that knowledge_graph.json is not read directly by runtime components,
    except for those explicitly permitted by the knowledge_source_policy.
    """

    # ID: 8dfccaae-a166-4e22-8673-33d0e3b6a784
    def execute(self) -> List[AuditFinding]:
        """
        Runs the check by scanning all source files for forbidden access patterns.
        """
        findings = []
        forbidden_string = "knowledge_graph.json"

        # --- THIS IS THE FIX ---
        # The check now loads its configuration from the constitution via the settings object.
        # It has no hardcoded knowledge of which files are allowed.
        try:
            policy = settings.load(
                "charter.policies.governance.knowledge_source_policy"
            )
            allowed_files = set(policy.get("allowed_access_paths", []))
        except (FileNotFoundError, IOError):
            # Fail safely if the policy is missing
            allowed_files = set()
        # --- END OF FIX ---

        for file_path in self.src_dir.rglob("*.py"):
            file_path_str = str(file_path.relative_to(self.repo_root))

            if file_path_str in allowed_files:
                continue

            try:
                content = file_path.read_text("utf-8")
                if forbidden_string in content:
                    findings.append(
                        AuditFinding(
                            check_id="knowledge.source.direct_access",
                            severity=AuditSeverity.ERROR,
                            message=f"Illegal direct access to '{forbidden_string}'. Use the KnowledgeService instead.",
                            file_path=file_path_str,
                        )
                    )
            except Exception:
                continue

        return findings

--- END OF FILE ./src/features/governance/checks/knowledge_source_check.py ---

--- START OF FILE ./src/features/governance/checks/legacy_tag_check.py ---
# src/features/governance/checks/legacy_tag_check.py
from __future__ import annotations

import re

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity


# ID: 0649c22b-9336-490b-9ffd-25e202924301
class LegacyTagCheck(BaseCheck):

    # ID: 94e602d4-47da-455d-be69-fe7a037bcb2b
    def execute(self) -> list[AuditFinding]:
        findings = []
        pattern = re.compile(r"#\s*CAPABILITY:", re.IGNORECASE)
        exclude_dirs = {
            ".git",
            ".venv",
            "__pycache__",
            ".pytest_cache",
            ".ruff_cache",
            "reports",
        }
        exclude_files = {"poetry.lock", "project_context.txt"}
        binary_extensions = {
            ".png",
            ".jpg",
            ".jpeg",
            ".gif",
            ".ico",
            ".pyc",
            ".so",
            ".o",
            ".zip",
            ".gz",
            ".pdf",
        }

        # --- THIS IS THE FIX ---
        # The loop now correctly uses self.repo_root, which is set by the BaseCheck parent class.
        for file_path in self.repo_root.rglob("*"):
            if not file_path.is_file():
                continue

            if any(part in exclude_dirs for part in file_path.parts):
                continue
            if file_path.name in exclude_files:
                continue
            if file_path.suffix in binary_extensions:
                continue

            try:
                content = file_path.read_text(encoding="utf-8")
                for i, line in enumerate(content.splitlines(), 1):
                    if pattern.search(line):
                        findings.append(
                            AuditFinding(
                                check_id="style.no_legacy_capability_tags",
                                severity=AuditSeverity.ERROR,
                                file_path=str(file_path.relative_to(self.repo_root)),
                                line_number=i,
                            )
                        )
            except UnicodeDecodeError:
                continue
            except Exception:
                continue

        return findings

--- END OF FILE ./src/features/governance/checks/legacy_tag_check.py ---

--- START OF FILE ./src/features/governance/checks/manifest_lint.py ---
# src/features/governance/checks/manifest_lint.py
"""
Audits capability manifests for quality issues like placeholder text.
"""
from __future__ import annotations

from typing import List

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity


# ID: 3de1c035-00f6-4de2-b778-2b7baaf4594b
class ManifestLintCheck(BaseCheck):
    """Checks for placeholder text in capability manifests."""

    def __init__(self, context):
        super().__init__(context)
        self.linter_policy = self.context.policies.get("capability_linter_policy", {})

    # ID: 6831b833-92a9-4f37-adc9-c3eb7dd3b3d7
    def execute(self) -> List[AuditFinding]:
        """Finds capabilities with placeholder descriptions."""
        findings = []
        rule = next(
            (
                r
                for r in self.linter_policy.get("rules", [])
                if r.get("id") == "caps.no_placeholder_text"
            ),
            None,
        )
        if not rule:
            return []

        for symbol in self.context.symbols_list:
            description = symbol.get("intent", "") or ""
            if any(
                f.lower() in description.lower() for f in ["TBD", "N/A", "Auto-added"]
            ):
                findings.append(
                    AuditFinding(
                        check_id="manifest.lint.placeholder",
                        severity=AuditSeverity.WARNING,
                        message=f"Capability '{symbol.get('key')}' has a placeholder description: '{description}'",
                        file_path=symbol.get("file"),
                        line_number=symbol.get("line_number"),
                    )
                )
        return findings

--- END OF FILE ./src/features/governance/checks/manifest_lint.py ---

--- START OF FILE ./src/features/governance/checks/naming_conventions.py ---
# src/features/governance/checks/naming_conventions.py
"""
A constitutional audit check to enforce file and symbol naming conventions
as defined in the naming_conventions_policy.yaml.
"""
from __future__ import annotations

import re
from typing import List

from features.governance.audit_context import AuditorContext
from shared.models import AuditFinding, AuditSeverity


# ID: 48100636-3970-4d7b-835a-1a4279ef3717
class NamingConventionsCheck:
    """
    Ensures that file names match the patterns defined in the constitution.
    """

    def __init__(self, context: AuditorContext):
        self.context = context
        self.policy = self.context.policies.get("naming_conventions_policy", {})

    # ID: 3ceda015-448e-4745-9b09-573cc37edeb1
    def execute(self) -> List[AuditFinding]:
        """
        Runs the check by scanning all repository files against the policy rules.
        """
        findings = []
        rules = self.policy.get("rules", [])
        if not rules:
            return findings

        for rule in rules:
            scope_glob = rule.get("scope", "**/*")
            pattern = rule.get("pattern")
            exclusions = rule.get("exclusions", [])

            if not pattern:
                continue

            try:
                compiled_pattern = re.compile(pattern)
            except re.error:
                # Invalid regex in policy, skip this rule
                continue

            for file_path in self.context.repo_path.glob(scope_glob):
                if not file_path.is_file():
                    continue

                # Check against exclusions
                if any(file_path.match(ex) for ex in exclusions):
                    continue

                if not compiled_pattern.match(file_path.name):
                    findings.append(
                        AuditFinding(
                            check_id=f"naming.{rule.get('id', 'unnamed_rule')}",
                            severity=AuditSeverity.ERROR,
                            message=f"File name '{file_path.name}' violates naming convention. Expected pattern: {pattern}",
                            file_path=str(
                                file_path.relative_to(self.context.repo_path)
                            ),
                        )
                    )
        return findings

--- END OF FILE ./src/features/governance/checks/naming_conventions.py ---

--- START OF FILE ./src/features/governance/checks/orphaned_logic.py ---
# src/features/governance/checks/orphaned_logic.py
"""
A constitutional audit check to find "orphaned logic" - public symbols
that have not been assigned a capability ID.
"""
from __future__ import annotations

from typing import Any, Dict, List

from features.governance.audit_context import AuditorContext
from shared.models import AuditFinding, AuditSeverity


# ID: f7064ae9-8396-4e53-b550-f85b482fb2a5
class OrphanedLogicCheck:
    """
    Ensures that all public symbols are assigned a capability, preventing
    undocumented or untracked functionality.
    """

    def __init__(self, context: AuditorContext):
        self.context = context
        self.symbols = self.context.knowledge_graph.get("symbols", {})

    # ID: 92129e3b-c392-41a2-a836-d3e2af32e011
    def find_unassigned_public_symbols(self) -> List[Dict[str, Any]]:
        """Finds all public symbols with a capability of 'unassigned'."""
        unassigned = []
        for symbol_data in self.symbols.values():
            is_public = not symbol_data.get("name", "").startswith("_")
            is_unassigned = symbol_data.get("capability") == "unassigned"
            if is_public and is_unassigned:
                unassigned.append(symbol_data)
        return unassigned

    # ID: f7903b52-27f9-44e2-b3b5-5d0d90c5e949
    def execute(self) -> List[AuditFinding]:
        """
        Runs the check and returns a list of findings for any orphaned symbols.
        """
        findings = []
        orphaned_symbols = self.find_unassigned_public_symbols()

        for symbol in orphaned_symbols:
            findings.append(
                AuditFinding(
                    check_id="capability.assignment.orphaned_logic",
                    severity=AuditSeverity.WARNING,
                    message=f"Public symbol '{symbol['name']}' is not assigned to a capability.",
                    file_path=symbol.get("file"),
                    line_number=symbol.get("line_number"),
                )
            )

        return findings

--- END OF FILE ./src/features/governance/checks/orphaned_logic.py ---

--- START OF FILE ./src/features/governance/checks/security_checks.py ---
# src/features/governance/checks/security_checks.py
"""
Scans source code for hardcoded secrets based on configurable detection patterns
and exclusion rules.
"""
from __future__ import annotations

import re

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity


# ID: e5596ce5-1529-4670-864a-5bd8adfc160d
class SecurityChecks(BaseCheck):
    """Container for security-related constitutional checks."""

    def __init__(self, context):
        """Initializes the check with a shared auditor context."""
        super().__init__(context)
        self.secrets_policy = self.context.policies.get("secrets_management_policy", {})

    # ID: 7c0ecd2a-1bc2-45c9-8da9-48a8b6c35876
    def execute(self) -> list[AuditFinding]:
        """Scans source code for patterns that look like hardcoded secrets."""
        findings = []
        rule = next(
            (
                r
                for r in self.secrets_policy.get("rules", [])
                if r.get("id") == "no_hardcoded_secrets"
            ),
            None,
        )

        if not rule:
            return []

        patterns = rule.get("detection", {}).get("patterns", [])
        exclude_globs = rule.get("detection", {}).get("exclude", [])
        compiled_patterns = [re.compile(p) for p in patterns]

        files_to_scan = {
            s["file_path"] for s in self.context.symbols_list if s.get("file_path")
        }

        for file_path_str in sorted(list(files_to_scan)):
            file_path = self.context.repo_root / file_path_str
            if any(file_path.match(glob) for glob in exclude_globs):
                continue

            try:
                content = file_path.read_text(encoding="utf-8")
                for i, line in enumerate(content.splitlines(), 1):
                    for pattern in compiled_patterns:
                        if pattern.search(line):
                            findings.append(
                                AuditFinding(
                                    check_id="security.secrets.hardcoded",
                                    severity=AuditSeverity.ERROR,
                                    message=f"Potential hardcoded secret found on line {i}.",
                                    file_path=str(file_path_str),
                                    line_number=i,
                                )
                            )
            except Exception:
                continue

        return findings

--- END OF FILE ./src/features/governance/checks/security_checks.py ---

--- START OF FILE ./src/features/governance/checks/style_checks.py ---
# src/features/governance/checks/style_checks.py
"""
Auditor checks for code style and convention compliance, as defined in
.intent/charter/policies/code_style_policy.yaml.
"""
from __future__ import annotations

import ast

from features.governance.checks.base_check import BaseCheck
from shared.models import AuditFinding, AuditSeverity


# ID: fd4ffac0-217f-4b9c-9a70-3a0106779421
class StyleChecks(BaseCheck):
    """Container for code style and convention constitutional checks."""

    def __init__(self, context):
        """Initializes the check with a shared auditor context."""
        super().__init__(context)
        self.style_policy = self.context.policies.get("code_style_policy", {})

    # ID: 221505d0-4c6d-4e24-b68c-b8475765a984
    def execute(self) -> list[AuditFinding]:
        """Verifies that Python modules adhere to documented style conventions."""
        findings = []
        rules = {rule.get("id"): rule for rule in self.style_policy.get("rules", [])}
        files_to_check = {
            s["file_path"]
            for s in self.context.symbols_list
            if s.get("file_path", "").endswith(".py")
        }

        for file_rel_path in sorted(list(files_to_check)):
            file_abs_path = self.context.repo_root / file_rel_path
            try:
                source_code = file_abs_path.read_text(encoding="utf-8")
                tree = ast.parse(source_code)

                if "style.docstrings_public_apis" in rules:
                    has_docstring = (
                        tree.body
                        and isinstance(tree.body[0], ast.Expr)
                        and isinstance(tree.body[0].value, ast.Constant)
                    )
                    if not has_docstring:
                        findings.append(
                            AuditFinding(
                                check_id="style.docstring.missing_module",
                                severity=AuditSeverity.WARNING,
                                message="Missing required module-level docstring.",
                                file_path=file_rel_path,
                            )
                        )

            except Exception as e:
                findings.append(
                    AuditFinding(
                        check_id="style.parser.error",
                        severity=AuditSeverity.ERROR,
                        message=f"Could not parse or check file: {e}",
                        file_path=file_rel_path,
                    )
                )
        return findings

--- END OF FILE ./src/features/governance/checks/style_checks.py ---

--- START OF FILE ./src/features/governance/constitutional_auditor.py ---
# src/features/governance/constitutional_auditor.py
"""
The Constitutional Auditor is the primary enforcement mechanism for the CORE constitution.
It runs a series of checks to ensure the codebase and its declared intent are aligned.
"""
from __future__ import annotations

import asyncio
from enum import Enum, auto
from pathlib import Path
from typing import Any, List, Tuple

from rich.console import Console

from features.governance.audit_context import AuditorContext
from features.governance.checks.capability_coverage import CapabilityCoverageCheck
from features.governance.checks.domain_placement import DomainPlacementCheck
from features.governance.checks.duplication_check import DuplicationCheck
from features.governance.checks.environment_checks import EnvironmentChecks
from features.governance.checks.file_checks import FileChecks
from features.governance.checks.health_checks import HealthChecks
from features.governance.checks.id_coverage_check import IdCoverageCheck
from features.governance.checks.import_rules import ImportRulesCheck
from features.governance.checks.knowledge_source_check import KnowledgeSourceCheck
from features.governance.checks.manifest_lint import ManifestLintCheck
from features.governance.checks.naming_conventions import NamingConventionsCheck
from features.governance.checks.orphaned_logic import OrphanedLogicCheck
from features.governance.checks.security_checks import SecurityChecks
from features.governance.checks.style_checks import StyleChecks
from shared.logger import getLogger
from shared.models import AuditFinding

log = getLogger("constitutional_auditor")
console = Console()


# ID: 7a8b9c0d-1e2f-3a4b-5c6d-7e8f9a0b1c2e
class AuditScope(Enum):
    """Defines the scope of an audit, allowing for targeted check execution."""

    FULL = auto()
    STATIC_ONLY = auto()


# ID: 5e27884e-b01e-4861-84b0-2e8c8facdb74
class ConstitutionalAuditor:
    """Orchestrates all constitutional checks and reports the findings."""

    def __init__(self, repo_root_override: Path | None = None):
        self.repo_root = repo_root_override or Path(".").resolve()
        self.context = AuditorContext(self.repo_root)
        self.all_checks: List[Any] = []

    async def _initialize_checks(self):
        """Initializes all checks after the context has loaded its async data."""
        if self.all_checks:
            return
        await self.context.load_knowledge_graph()
        self.all_checks = [
            FileChecks(self.context),
            EnvironmentChecks(self.context),
            HealthChecks(self.context),
            StyleChecks(self.context),
            SecurityChecks(self.context),
            CapabilityCoverageCheck(self.context),
            DomainPlacementCheck(self.context),
            ManifestLintCheck(self.context),
            ImportRulesCheck(self.context),
            NamingConventionsCheck(self.context),
            OrphanedLogicCheck(self.context),
            DuplicationCheck(self.context),
            KnowledgeSourceCheck(self.context),
            IdCoverageCheck(self.context),
        ]
        log.info(
            f"ConstitutionalAuditor initialized with {len(self.all_checks)} total checks."
        )

    def _get_checks_for_scope(self, scope: AuditScope) -> List[Any]:
        """Filters the list of checks based on the requested audit scope."""
        if scope == AuditScope.FULL:
            return self.all_checks

        if scope == AuditScope.STATIC_ONLY:
            # Exclude checks that require a live environment or are known to be noisy
            excluded_checks = (EnvironmentChecks, DuplicationCheck)
            return [
                check
                for check in self.all_checks
                if not isinstance(check, excluded_checks)
            ]

        return []

    # ID: fcbf94ee-eb92-4c49-8c84-7b5b2aeff2ff
    async def run_full_audit_async(
        self, scope: AuditScope = AuditScope.FULL
    ) -> Tuple[bool, List[AuditFinding], int]:
        """Asynchronously runs all registered checks for a given scope and returns the results."""
        await self._initialize_checks()
        checks_to_run = self._get_checks_for_scope(scope)
        log.info(
            f"Running audit with scope '{scope.name}' ({len(checks_to_run)} checks)..."
        )

        all_findings: List[AuditFinding] = []
        for check in checks_to_run:
            try:
                # DuplicationCheck is now handled like any other async check
                if asyncio.iscoroutinefunction(getattr(check, "execute", None)):
                    findings = await check.execute()
                else:
                    findings = check.execute()
                all_findings.extend(findings)
            except Exception as e:
                log.error(
                    f"Error executing check '{type(check).__name__}': {e}",
                    exc_info=True,
                )

        unassigned_symbols_count = len(
            OrphanedLogicCheck(self.context).find_unassigned_public_symbols()
        )
        has_errors = any(f.severity.is_blocking for f in all_findings)
        return not has_errors, all_findings, unassigned_symbols_count

    # ID: 0c850a95-21f6-4a54-8c23-f731e8eb4a8f
    def run_full_audit(
        self, scope: AuditScope = AuditScope.FULL
    ) -> Tuple[bool, List[AuditFinding], int]:
        """Synchronous wrapper to run the full async audit for a given scope."""
        return asyncio.run(self.run_full_audit_async(scope))

--- END OF FILE ./src/features/governance/constitutional_auditor.py ---

--- START OF FILE ./src/features/governance/key_management_service.py ---
# src/system/admin/keys.py
"""
Intent: Key management commands for the CORE Admin CLI.
Provides Ed25519 key generation and helper output for approver configuration.
"""

from __future__ import annotations

import os
from datetime import datetime, timezone

import typer
import yaml
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import ed25519

from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.keys")


# ID: db20f1c4-d8ae-495f-9e3e-402594eea728
def register(app: typer.Typer) -> None:
    """Intent: Register key management commands under the admin CLI."""

    @app.command("keygen")
    # ID: b02176d9-c38f-4447-9ad5-ef17d6648263
    def keygen(
        identity: str = typer.Argument(
            ..., help="Identity for the key pair (e.g., 'your.name@example.com')."
        ),
    ) -> None:
        """Intent: Generate a new Ed25519 key pair and print an approver YAML block."""
        log.info(f"🔑 Generating new key pair for identity: {identity}")

        # --- THIS IS THE FIX: Use the new, constitutionally-valid setting ---
        key_storage_dir = settings.REPO_PATH / settings.KEY_STORAGE_DIR
        key_storage_dir.mkdir(parents=True, exist_ok=True)
        private_key_path = key_storage_dir / "private.key"
        # --- END OF FIX ---

        if private_key_path.exists():
            typer.confirm(
                "⚠️ A private key already exists. Overwriting it will invalidate your "
                "old identity. Continue?",
                abort=True,
            )

        private_key = ed25519.Ed25519PrivateKey.generate()
        public_key = private_key.public_key()

        pem_private = private_key.private_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PrivateFormat.PKCS8,
            encryption_algorithm=serialization.NoEncryption(),
        )
        private_key_path.write_bytes(pem_private)
        os.chmod(private_key_path, 0o600)

        pem_public = public_key.public_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PublicFormat.SubjectPublicKeyInfo,
        )

        log.info(f"\n✅ Private key saved securely to: {private_key_path}")
        log.info(
            "\n📋 Add the following YAML block to "
            "'.intent/constitution/approvers.yaml' under 'approvers':\n"
        )

        approver_data = {
            "identity": identity,
            "public_key": pem_public.decode("utf-8"),
            "created_at": datetime.now(timezone.utc).isoformat(),
            "role": "maintainer",
            "description": "Primary maintainer",
        }
        # Use sort_keys=False to maintain a more readable order
        print(yaml.dump([approver_data], indent=2, sort_keys=False))

--- END OF FILE ./src/features/governance/key_management_service.py ---

--- START OF FILE ./src/features/governance/micro_proposal_validator.py ---
# src/features/governance/micro_proposal_validator.py
"""
Provides a centralized, single-source-of-truth validator for micro-proposal plans.
"""
from __future__ import annotations

from pathlib import Path
from typing import List, Tuple

from shared.config import settings
from shared.logger import getLogger
from shared.models import ExecutionTask

log = getLogger("micro_proposal_validator")


# ID: dd3a6e30-1762-4cd3-b7b5-dab8f43bed13
class MicroProposalValidator:
    """Validates an execution plan against the micro_proposal_policy."""

    def __init__(self):
        """Initializes the validator by loading the governing policy."""
        self.policy = settings.load("charter.policies.agent.micro_proposal_policy")
        rules = self.policy.get("rules", [])
        self.policy_rules = {rule.get("id"): rule for rule in rules}
        self.allowed_actions = set(
            self.policy_rules.get("safe_actions", {}).get("allowed_actions", [])
        )
        self.allowed_paths = self.policy_rules.get("safe_paths", {}).get(
            "allowed_paths", []
        )
        self.forbidden_paths = self.policy_rules.get("safe_paths", {}).get(
            "forbidden_paths", []
        )

    # ID: 4e5a2a40-6a66-478a-b9eb-b2af08edb161
    def validate(self, plan: List[ExecutionTask]) -> Tuple[bool, str]:
        """
        Validates the entire plan.

        Returns:
            A tuple (is_valid: bool, error_message: str).
        """
        for task in plan:
            # Validate action
            if task.action not in self.allowed_actions:
                return (
                    False,
                    f"Action '{task.action}' is not in the list of allowed safe actions.",
                )

            # Validate path
            file_path = Path(task.params.file_path)
            if self._is_path_forbidden(file_path):
                return (
                    False,
                    f"Path '{file_path}' is explicitly forbidden by the micro-proposal policy.",
                )

            if not self._is_path_allowed(file_path):
                return (
                    False,
                    f"Path '{file_path}' does not match any allowed path patterns in the micro-proposal policy.",
                )

        return True, ""

    def _is_path_forbidden(self, path: Path) -> bool:
        """Checks if a path matches any forbidden patterns."""
        if not self.forbidden_paths:
            return False
        for pattern in self.forbidden_paths:
            try:
                # Handle '**' correctly by checking parent directories
                if "**" in pattern:
                    base_dir_str = pattern.split("**")[0]
                    base_dir = (settings.REPO_PATH / base_dir_str).resolve()
                    if path.resolve().is_relative_to(base_dir):
                        return True
                if path.match(pattern):
                    return True
            except Exception:
                continue
        return False

    def _is_path_allowed(self, path: Path) -> bool:
        """Checks if a path matches any allowed patterns."""
        if not self.allowed_paths:
            return True  # If no allowed_paths are specified, all non-forbidden paths are implicitly allowed

        for pattern in self.allowed_paths:
            if path.match(pattern):
                return True
        return False

--- END OF FILE ./src/features/governance/micro_proposal_validator.py ---

--- START OF FILE ./src/features/governance/policy_coverage_service.py ---
# src/features/governance/policy_coverage_service.py
"""
Provides a service to perform a meta-audit on the constitution itself,
checking for policy coverage and structural integrity.
"""
from __future__ import annotations

import hashlib
import json
from dataclasses import dataclass
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from pydantic import BaseModel

from shared.config import settings
from shared.logger import getLogger

log = getLogger("policy_coverage_service")


# ID: 01a2975a-5754-435d-9e5a-78fc10648abc
class PolicyCoverageReport(BaseModel):
    report_id: str
    generated_at_utc: str
    repo_root: str
    summary: Dict[str, int]
    records: List[Dict[str, Any]]
    exit_code: int


@dataclass
class _PolicyRef:
    """Internal helper to track discovered policies."""

    id: str
    path: Path
    status: str = "active"
    title: Optional[str] = None


# ID: 78d662f3-f672-4f51-b73e-fb411c106728
class PolicyCoverageService:
    """
    Runs a meta-audit on the constitution to ensure all active policies
    are well-formed and covered by the governance model.
    """

    def __init__(self, repo_root: Optional[Path] = None):
        self.repo_root: Path = repo_root or settings.REPO_PATH
        # --- THIS IS THE REFACTOR ---
        # The service now loads its governing policy via the settings object
        self.enforcement_model_policy = settings.load(
            "charter.policies.governance.enforcement_model_policy"
        )
        self.enforcement_model = self._load_enforcement_model()
        # --- END OF REFACTOR ---

    def _load_enforcement_model(self) -> Dict[str, int]:
        """Loads and parses the enforcement model from the pre-loaded policy content."""
        levels = self.enforcement_model_policy.get("levels", {})
        # Note: exit_code is not a standard part of the model, so we default to standard behavior
        return {
            "error": (
                1 if (levels.get("error") or {}).get("ci_behavior") == "fail" else 0
            ),
            "warn": 0,
            "info": 0,
        }

    def _discover_active_policies(self) -> List[_PolicyRef]:
        """Discovers all active policies by reading the meta.yaml index via settings."""
        refs = []
        # settings._meta_config is a private but convenient accessor here
        policies_in_meta = settings._meta_config.get("charter", {}).get("policies", {})

        # ID: 1fead1e3-077b-4243-92dc-5b151d6fc690
        def find_policies_recursive(data: Any, prefix: str):
            if isinstance(data, dict):
                for key, value in data.items():
                    find_policies_recursive(value, f"{prefix}.{key}" if prefix else key)
            elif isinstance(data, str) and data.endswith("_policy.yaml"):
                logical_path = prefix.replace("charter.policies.", "", 1)
                full_path = settings.get_path(prefix)
                if full_path.exists():
                    refs.append(_PolicyRef(id=logical_path, path=full_path))

        find_policies_recursive(policies_in_meta, "charter.policies")
        return refs

    @staticmethod
    def _extract_rules(policy_data: Dict[str, Any]) -> List[Dict[str, str]]:
        """Extracts and normalizes rule definitions from a policy file."""
        rules = policy_data.get("rules", [])
        if not isinstance(rules, list):
            return [{"id": "__policy_present__", "enforcement": "warn"}]

        extracted = []
        for r in rules:
            if isinstance(r, dict):
                extracted.append(
                    {
                        "id": str(r.get("id", "__missing_id__")),
                        "enforcement": str(r.get("enforcement", "warn")).lower(),
                    }
                )
        return extracted or [{"id": "__policy_present__", "enforcement": "warn"}]

    # ID: 07977c2f-e3df-4c79-a7eb-f7761d4a6487
    def run(self) -> PolicyCoverageReport:
        """
        Executes the policy coverage audit and returns a structured report.
        """
        policies = self._discover_active_policies()
        records: List[Dict[str, Any]] = []
        failures: List[Tuple[str, str]] = []

        for policy_ref in policies:
            policy_data = settings.load(f"charter.policies.{policy_ref.id}")
            rules = self._extract_rules(policy_data)

            for rule in rules:
                level = rule["enforcement"]
                is_covered = bool(rule["id"] != "__missing_id__") and level in [
                    "error",
                    "warn",
                    "info",
                ]

                records.append(
                    {
                        "policy_id": policy_ref.id,
                        "policy_path": str(policy_ref.path.relative_to(self.repo_root)),
                        "rule_id": rule["id"],
                        "enforcement": level,
                        "covered": is_covered,
                    }
                )
                if not is_covered:
                    failures.append((policy_ref.id, level))

        exit_code = 0
        for _, level in failures:
            exit_code = max(exit_code, self.enforcement_model.get(level, 0))

        report_dict = {
            "generated_at_utc": datetime.now(timezone.utc).isoformat(),
            "repo_root": str(self.repo_root),
            "summary": {
                "policies_seen": len(policies),
                "rules_found": len(records),
                "uncovered_rules": len(failures),
            },
            "records": records,
            "exit_code": exit_code,
        }

        report_json = json.dumps(report_dict, sort_keys=True, separators=(",", ":"))
        report_id = hashlib.sha256(report_json.encode("utf-8")).hexdigest()
        report_dict["report_id"] = report_id

        return PolicyCoverageReport(**report_dict)

--- END OF FILE ./src/features/governance/policy_coverage_service.py ---

--- START OF FILE ./src/features/introspection/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/features/introspection/__init__.py ---

--- START OF FILE ./src/features/introspection/audit_unassigned_capabilities.py ---
# src/features/introspection/audit_unassigned_capabilities.py
"""
Provides a utility to find and report on symbols in the knowledge graph
that have not been assigned a capability ID.
"""
from __future__ import annotations

import asyncio
from typing import Any, Dict, List

from core.knowledge_service import KnowledgeService
from shared.config import settings
from shared.logger import getLogger

log = getLogger("audit_unassigned_caps")


# ID: d93e7a47-27c1-4fa5-bf39-0a44bef8bf59
def get_unassigned_symbols() -> List[Dict[str, Any]]:
    """
    Scans the knowledge graph for governable symbols with a capability of
    'unassigned' and returns them.
    """

    async def _async_get():
        knowledge_service = KnowledgeService(settings.REPO_PATH)
        graph = await knowledge_service.get_graph()
        symbols = graph.get("symbols", {})
        unassigned = []

        for key, symbol_data in symbols.items():
            is_public = not symbol_data.get("name", "").startswith("_")
            is_unassigned = symbol_data.get("capability") == "unassigned"

            if is_public and is_unassigned:
                symbol_data["key"] = key
                unassigned.append(symbol_data)
        return unassigned

    try:
        return asyncio.run(_async_get())
    except Exception as e:
        log.error(f"Error processing knowledge graph: {e}")
        return []

--- END OF FILE ./src/features/introspection/audit_unassigned_capabilities.py ---

--- START OF FILE ./src/features/introspection/capability_discovery_service.py ---
# src/features/introspection/capability_discovery_service.py
"""
Handles the discovery and validation of capability definitions from various
constitutional sources, including domain-specific manifests and alias maps.
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict, Iterable, List, Optional, Set

import yaml

from shared.logger import getLogger
from shared.models import CapabilityMeta

log = getLogger("capability_discovery")


# ID: 0a3c2441-928c-47e6-9f9d-3663b31245af
class CapabilityRegistry:
    """
    Holds the canonical capability keys and alias mapping.
    Provides simple resolution (canonical → itself, alias → canonical).
    """

    def __init__(self, canonical: Set[str], aliases: Dict[str, str]):
        """Initializes the registry with canonical tags and an alias map."""
        self.canonical: Set[str] = set(canonical)
        self.aliases: Dict[str, str] = dict(aliases)

    # ID: 6d38d34c-a0da-4bce-a961-c3ff9c0f093e
    def resolve(self, tag: str) -> Optional[str]:
        """
        Return canonical capability if `tag` is known, otherwise None.
        Resolution is single-hop (alias -> canonical).
        """
        if tag in self.canonical:
            return tag
        return self.aliases.get(tag)


def _load_yaml(path: Path) -> dict:
    """Loads a YAML file with basic error handling."""
    with path.open("r", encoding="utf-8") as f:
        data = yaml.safe_load(f) or {}
        if not isinstance(data, dict):
            raise ValueError(f"YAML root must be an object: {path}")
        return data


def _iter_capability_files(base: Path) -> Iterable[Path]:
    """
    Yields YAML files under capability_tags/, ignoring schema and non-yaml files.
    """
    if not base.exists():
        return []
    for p in sorted(base.glob("**/*")):
        if p.is_dir():
            if p.name in {"schemas"}:
                continue
            continue
        if p.suffix.lower() in {".yaml", ".yml"}:
            yield p


def _extract_canonical_from_doc(doc: dict) -> Set[str]:
    """
    Extracts canonical capability keys from a domain manifest file.
    """
    canonical: Set[str] = set()
    tags = doc.get("tags", [])
    if isinstance(tags, list):
        for item in tags:
            if (
                isinstance(item, dict)
                and "key" in item
                and isinstance(item["key"], str)
            ):
                canonical.add(item["key"])
    return canonical


def _extract_aliases_from_doc(doc: dict) -> Dict[str, str]:
    """
    Extracts aliases from a manifest file.
    """
    aliases: Dict[str, str] = {}
    raw = doc.get("aliases")
    if isinstance(raw, dict):
        for k, v in raw.items():
            if isinstance(k, str) and isinstance(v, str) and k and v:
                aliases[k] = v
    return aliases


def _merge_sets(*sets: Iterable[str]) -> Set[str]:
    """Merges multiple iterables into a single set."""
    acc: Set[str] = set()
    for s in sets:
        acc.update(s)
    return acc


def _detect_alias_cycles(aliases: Dict[str, str]) -> List[List[str]]:
    """Detects simple cycles in the alias graph."""
    visited: Set[str] = set()
    stack: Set[str] = set()
    cycles: List[List[str]] = []

    # ID: 208ce23e-ee4f-4e52-90e8-f2a8949fc284
    def dfs(node: str, path: List[str]):
        visited.add(node)
        stack.add(node)
        nxt = aliases.get(node)
        if nxt:
            if nxt not in visited:
                dfs(nxt, path + [nxt])
            elif nxt in stack:
                if nxt in path:
                    idx = path.index(nxt)
                    cycles.append(path[idx:] + [nxt])
        stack.remove(node)

    for a in aliases:
        if a not in visited:
            dfs(a, [a])

    return cycles


# ID: 2779fe54-cfaf-4b3b-8df5-156347d53166
def load_and_validate_capabilities(intent_dir: Path) -> CapabilityRegistry:
    """
    Loads and validates all canonical capabilities and aliases.
    """
    base = intent_dir / "knowledge" / "capability_tags"
    canonical_tags: Set[str] = set()
    alias_map: Dict[str, str] = {}

    if not base.exists():
        raise FileNotFoundError(f"Capability tags directory not found: {base}")

    for path in _iter_capability_files(base):
        try:
            doc = _load_yaml(path)
        except Exception as e:
            raise ValueError(f"Failed to load capability YAML: {path} ({e})") from e

        canonical_tags |= _extract_canonical_from_doc(doc)
        alias_map.update(_extract_aliases_from_doc(doc))

    cycles = _detect_alias_cycles(alias_map)
    if cycles:
        formatted = "; ".join(" -> ".join(c) for c in cycles)
        raise ValueError(f"Alias cycle(s) detected: {formatted}")

    unresolved = [(a, t) for a, t in alias_map.items() if t not in canonical_tags]
    if unresolved:
        lines = "\n - ".join(f"'{a}' → '{t}'" for a, t in unresolved)
        raise ValueError(
            "Alias targets that do not map to a canonical capability:\n - " + lines
        )

    return CapabilityRegistry(canonical=canonical_tags, aliases=alias_map)


# ID: 8bd2e3d4-f273-4d7d-bf6d-a47b7f0fefce
def validate_agent_roles(agent_roles: dict, registry: CapabilityRegistry) -> None:
    """Validates agent role configurations against the capability registry."""
    errors: List[str] = []
    roles = agent_roles.get("roles", {})
    if not isinstance(roles, dict):
        raise ValueError("agent_roles must contain a 'roles' mapping")

    for role, cfg in roles.items():
        allowed = cfg.get("allowed_tags", [])
        for tag in allowed:
            if not registry.resolve(tag):
                errors.append(
                    f"Role '{role}' references unknown capability tag '{tag}'"
                )
    if errors:
        joined = "\n - ".join(errors)
        raise ValueError(
            "Agent role configuration contains unresolved/invalid capability tags:\n - "
            + joined
        )


# ID: 650d3944-b37d-4aaf-8f7f-d0c08530cb86
def collect_code_capabilities(
    root: Path, include_globs: List[str], exclude_globs: List[str], require_kgb: bool
) -> Dict[str, CapabilityMeta]:
    """Unified discovery entrypoint."""
    from features.introspection.discovery.from_kgb import collect_from_kgb
    from features.introspection.discovery.from_source_scan import (
        collect_from_source_scan,
    )

    try:
        if require_kgb:
            return collect_from_kgb(root)
        return collect_from_source_scan(root, include_globs, exclude_globs)
    except Exception as e:
        log.warning(
            f"Capability discovery failed: {e}. Returning empty.", exc_info=True
        )
        return {}

--- END OF FILE ./src/features/introspection/capability_discovery_service.py ---

--- START OF FILE ./src/features/introspection/discovery/from_kgb.py ---
# src/features/introspection/discovery/from_kgb.py
"""
Discovers implemented capabilities by leveraging the KnowledgeGraphBuilder.
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict

from features.introspection.knowledge_graph_service import KnowledgeGraphBuilder
from shared.models import CapabilityMeta


# ID: 12a7fddd-fa62-4dd8-8e1b-54208392a078
def collect_from_kgb(root: Path) -> Dict[str, CapabilityMeta]:
    """
    Uses the KnowledgeGraphBuilder to find all capabilities.
    """
    builder = KnowledgeGraphBuilder(root_path=root)
    graph = builder.build()

    capabilities: Dict[str, CapabilityMeta] = {}
    for symbol in graph.get("symbols", {}).values():
        cap_key = symbol.get("capability")
        if cap_key and cap_key != "unassigned":
            capabilities[cap_key] = CapabilityMeta(
                key=cap_key,
                domain=symbol.get("domain"),
                owner=symbol.get("owner"),
            )
    return capabilities

--- END OF FILE ./src/features/introspection/discovery/from_kgb.py ---

--- START OF FILE ./src/features/introspection/discovery/from_manifest.py ---
# src/features/introspection/discovery/from_manifest.py
"""
Discovers capability definitions by parsing constitutional manifest files.
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict

import yaml

from shared.logger import getLogger
from shared.models import CapabilityMeta

log = getLogger("discovery.from_manifest")


# ID: 67f5324b-5dbd-4250-a216-bbd557d3c8e9
def load_manifest_capabilities(
    root: Path, explicit_path: Path | None = None
) -> Dict[str, CapabilityMeta]:
    """
    Scans for manifest files and aggregates all declared capabilities.
    The primary source of truth is now .intent/mind/project_manifest.yaml.
    """
    capabilities: Dict[str, CapabilityMeta] = {}

    manifest_path = root / ".intent" / "mind" / "project_manifest.yaml"

    if manifest_path.exists():
        try:
            content = yaml.safe_load(manifest_path.read_text("utf-8")) or {}
            caps = content.get("capabilities", [])

            if isinstance(caps, list):
                for key in caps:
                    if isinstance(key, str):
                        # --- THIS IS THE FIX ---
                        # Instead of storing None, we store an actual instance
                        # of the CapabilityMeta dataclass, as the consumer expects.
                        capabilities[key] = CapabilityMeta(key=key)
                        # --- END OF FIX ---

        except (yaml.YAMLError, IOError) as e:
            log.warning(f"Could not parse manifest at {manifest_path}: {e}")

    return capabilities

--- END OF FILE ./src/features/introspection/discovery/from_manifest.py ---

--- START OF FILE ./src/features/introspection/discovery/from_source_scan.py ---
# src/features/introspection/discovery/from_source_scan.py
"""
Discovers implemented capabilities by performing a direct source code scan.
This is a fallback for when the knowledge graph is not available.
"""
from __future__ import annotations

import re
from pathlib import Path
from typing import Dict, List

from shared.models import CapabilityMeta

CAPABILITY_PATTERN = re.compile(r"#\s*CAPABILITY:\s*(\S+)")


# ID: 3fb50751-54f5-4282-9b52-fcc5eb6c23d2
def collect_from_source_scan(
    root: Path, include_globs: List[str], exclude_globs: List[str]
) -> Dict[str, CapabilityMeta]:
    """
    Scans Python files for # CAPABILITY tags.
    """
    capabilities: Dict[str, CapabilityMeta] = {}
    search_path = root / "src"

    files_to_scan = list(search_path.rglob("*.py"))

    for py_file in files_to_scan:
        try:
            content = py_file.read_text("utf-8")
            matches = CAPABILITY_PATTERN.findall(content)
            for cap_key in matches:
                if cap_key not in capabilities:
                    capabilities[cap_key] = CapabilityMeta(key=cap_key)
        except (IOError, UnicodeDecodeError):
            continue

    return capabilities

--- END OF FILE ./src/features/introspection/discovery/from_source_scan.py ---

--- START OF FILE ./src/features/introspection/drift_detector.py ---
# src/features/introspection/drift_detector.py
"""
Detects drift between declared capabilities in manifests and implemented
capabilities in the source code.
"""
from __future__ import annotations

import json
from dataclasses import asdict
from pathlib import Path
from typing import Dict, Set

from shared.models import CapabilityMeta, DriftReport


# ID: 6cc5efdf-037e-4862-b13e-0a569d889a97
def detect_capability_drift(
    manifest_caps: Dict[str, CapabilityMeta], code_caps: Dict[str, CapabilityMeta]
) -> DriftReport:
    """
    Compares two dictionaries of capabilities and returns a drift report.
    """
    manifest_keys: Set[str] = set(manifest_caps.keys())
    code_keys: Set[str] = set(code_caps.keys())

    missing_in_code = sorted(list(manifest_keys - code_keys))
    undeclared_in_manifest = sorted(list(code_keys - manifest_keys))

    mismatched = []
    for key in manifest_keys.intersection(code_keys):
        manifest_cap = manifest_caps[key]
        code_cap = code_caps[key]
        if manifest_cap != code_cap:
            mismatched.append(
                {
                    "capability": key,
                    "manifest": asdict(manifest_cap),
                    "code": asdict(code_cap),
                }
            )

    return DriftReport(
        missing_in_code=missing_in_code,
        undeclared_in_manifest=undeclared_in_manifest,
        mismatched_mappings=mismatched,
    )


# ID: db10bc9b-b4b3-41f2-8d81-b32731540d95
def write_report(path: Path, report: DriftReport) -> None:
    """Writes the drift report to a JSON file."""
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(report.to_dict(), indent=2), encoding="utf-8")

--- END OF FILE ./src/features/introspection/drift_detector.py ---

--- START OF FILE ./src/features/introspection/drift_service.py ---
# src/features/introspection/drift_service.py
"""
Provides a dedicated service for detecting drift between the declared constitution
and the implemented reality of the codebase.
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict

from core.knowledge_service import KnowledgeService
from features.introspection.discovery.from_manifest import (
    load_manifest_capabilities,
)
from features.introspection.drift_detector import detect_capability_drift
from shared.models import CapabilityMeta, DriftReport


# ID: 58d789bd-6dc5-440d-ad53-efb8a204b4d3
async def run_drift_analysis_async(root: Path) -> DriftReport:
    """
    Performs a full drift analysis by comparing manifest capabilities
    against the capabilities discovered in the codebase via the KnowledgeService.
    """
    manifest_caps = load_manifest_capabilities(root, explicit_path=None)

    knowledge_service = KnowledgeService(root)
    graph = await knowledge_service.get_graph()

    code_caps: Dict[str, CapabilityMeta] = {}
    for symbol in graph.get("symbols", {}).values():
        key = symbol.get("key")
        if key and key != "unassigned":
            code_caps[key] = CapabilityMeta(
                key=key,
                domain=symbol.get("domain"),
                owner=symbol.get("owner"),
            )

    return detect_capability_drift(manifest_caps, code_caps)

--- END OF FILE ./src/features/introspection/drift_service.py ---

--- START OF FILE ./src/features/introspection/export_vectors.py ---
# src/features/introspection/export_vectors.py
"""
A utility to export all vectors and their payloads from the Qdrant database
to a local JSONL file for analysis, clustering, or backup.
"""
from __future__ import annotations

import asyncio
import json
from pathlib import Path

import typer
from rich.console import Console
from rich.progress import track

from services.clients.qdrant_client import QdrantService
from shared.logger import getLogger

log = getLogger("export_vectors")
console = Console()


async def _async_export(output_path: Path):
    """The core async logic for exporting vectors."""
    console.print(
        f"🚀 Exporting all vectors to [bold cyan]{output_path}[/bold cyan]..."
    )
    output_path.parent.mkdir(parents=True, exist_ok=True)

    qdrant_service = QdrantService()

    try:
        all_vectors = await qdrant_service.get_all_vectors()

        if not all_vectors:
            console.print(
                "[yellow]No vectors found in the database to export.[/yellow]"
            )
            return

        count = 0
        with output_path.open("w", encoding="utf-8") as f:
            for record in track(all_vectors, description="Writing vectors..."):
                line_data = {
                    "id": record.id,
                    "payload": record.payload,
                    "vector": record.vector,
                }
                f.write(json.dumps(line_data) + "\n")
                count += 1

        console.print(
            f"[bold green]✅ Successfully exported {count} vectors.[/bold green]"
        )

    except Exception as e:
        log.error(f"Failed to export vectors: {e}", exc_info=True)
        console.print(f"[bold red]❌ An error occurred during export: {e}[/bold red]")
        raise typer.Exit(code=1)


# ID: 51a560a2-7304-49d9-9b31-364cc68ae0c3
def export_vectors(
    output: Path = typer.Option(
        "reports/vectors_export.jsonl",
        "--output",
        "-o",
        help="The path to save the exported JSONL file.",
    )
):
    """Exports all vectors from Qdrant to a JSONL file."""
    asyncio.run(_async_export(output))


if __name__ == "__main__":
    typer.run(export_vectors)

--- END OF FILE ./src/features/introspection/export_vectors.py ---

--- START OF FILE ./src/features/introspection/generate_capability_docs.py ---
# src/features/introspection/generate_capability_docs.py
"""
Generates the canonical capability reference documentation from the database.
"""
from __future__ import annotations

import asyncio

from rich.console import Console
from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.config import settings

console = Console()

# --- Configuration ---
OUTPUT_PATH = settings.REPO_PATH / "docs" / "10_CAPABILITY_REFERENCE.md"
GITHUB_URL_BASE = "https://github.com/DariuszNewecki/CORE/blob/main/"

HEADER = """
# 10. Capability Reference

This document is the canonical, auto-generated reference for all capabilities recognized by the CORE constitution.
It is generated from the `core.knowledge_graph` database view and should not be edited manually.
"""


async def _fetch_capabilities() -> list[dict]:
    """Fetches all public capabilities from the database knowledge graph view."""
    console.print("[cyan]Fetching capabilities from the database...[/cyan]")
    async with get_session() as session:
        stmt = text(
            """
            SELECT capability, intent, file, line_number
            FROM core.knowledge_graph
            WHERE is_public = TRUE AND capability IS NOT NULL
            ORDER BY capability;
            """
        )
        result = await session.execute(stmt)
        return [dict(row._mapping) for row in result]


def _group_by_domain(capabilities: list[dict]) -> dict[str, list[dict]]:
    """Groups capabilities by their domain prefix."""
    domains = {}
    for cap in capabilities:
        key = cap["capability"]
        # Infer domain from the key, e.g., 'autonomy.self_healing.fix_headers' -> 'autonomy.self_healing'
        domain_key = ".".join(key.split(".")[:-1]) if "." in key else "general"
        if domain_key not in domains:
            domains[domain_key] = []
        domains[domain_key].append(cap)
    return domains


# ID: 2ea63de3-081d-40b3-9386-0d372487aabd
def main():
    """The main entry point for the documentation generation script."""

    async def _async_main():
        capabilities = await _fetch_capabilities()
        if not capabilities:
            console.print(
                "[yellow]Warning: No capabilities found in the database. Documentation will be empty.[/yellow]"
            )
            return

        domains = _group_by_domain(capabilities)

        console.print(
            f"[cyan]Generating documentation for {len(capabilities)} capabilities across {len(domains)} domains...[/cyan]"
        )

        md_content = [HEADER.strip(), ""]

        for domain_name in sorted(domains.keys()):
            md_content.append(f"## Domain: `{domain_name}`")
            md_content.append("")

            for cap in sorted(domains[domain_name], key=lambda x: x["capability"]):
                md_content.append(f"- **`{cap['capability']}`**")

                description = cap.get("intent") or "No description provided."
                md_content.append(f"  - **Description:** {description.strip()}")

                file_path = cap.get("file")
                # Use a default line number if it's missing to avoid errors
                line_number = cap.get("line_number") or 0
                github_link = f"{GITHUB_URL_BASE}{file_path}#L{line_number + 1}"
                md_content.append(f"  - **Source:** [{file_path}]({github_link})")
            md_content.append("")

        final_text = "\n".join(md_content)

        OUTPUT_PATH.write_text(final_text, encoding="utf-8")
        console.print(
            f"[bold green]✅ Capability reference documentation successfully written to {OUTPUT_PATH}[/bold green]"
        )

    asyncio.run(_async_main())


if __name__ == "__main__":
    main()

--- END OF FILE ./src/features/introspection/generate_capability_docs.py ---

--- START OF FILE ./src/features/introspection/generate_correction_map.py ---
# src/features/introspection/generate_correction_map.py
"""
A utility to generate alias maps from semantic clustering results.
It takes the proposed domain mappings and creates a YAML file that can be used
by the AliasResolver to standardize capability keys.
"""
from __future__ import annotations

import json
from pathlib import Path

import typer
import yaml
from rich.console import Console

from shared.logger import getLogger

log = getLogger("generate_correction_map")
console = Console()


# ID: b6657e93-2382-43ef-b9fb-71104aecee1f
def generate_maps(
    input_path: Path = typer.Option(
        "reports/proposed_domains.json",
        "--input",
        "-i",
        help="Path to the JSON file with proposed domains from clustering.",
        exists=True,
    ),
    output: Path = typer.Option(
        "reports/aliases.yaml",
        "--output",
        "-o",
        help="Path to save the generated aliases YAML file.",
    ),
):
    """
    Generates an alias map from clustering results to a YAML file.
    """
    console.print(
        f"🗺️  Generating alias map from [bold cyan]{input_path}[/bold cyan]..."
    )

    try:
        proposed_domains = json.loads(input_path.read_text("utf-8"))
    except (json.JSONDecodeError, FileNotFoundError) as e:
        log.error(f"Failed to load or parse input file: {e}")
        raise typer.Exit(code=1)

    # In this simplified model, we might just be creating a map of old_key -> new_key
    # For now, let's assume the clustering output is a simple dictionary.
    # A more complex implementation might rationalize domains.

    alias_map = {"aliases": proposed_domains}

    output.parent.mkdir(parents=True, exist_ok=True)
    output.write_text(yaml.dump(alias_map, indent=2, sort_keys=True), "utf-8")

    console.print(
        f"✅ Successfully generated alias map with {len(proposed_domains)} entries."
    )
    console.print(f"   -> Saved to: [bold green]{output}[/bold green]")


if __name__ == "__main__":
    typer.run(generate_maps)

--- END OF FILE ./src/features/introspection/generate_correction_map.py ---

--- START OF FILE ./src/features/introspection/knowledge_graph_service.py ---
# src/features/introspection/knowledge_graph_service.py
"""
Provides the KnowledgeGraphBuilder, the primary tool for introspecting the
codebase and synchronizing the discovered knowledge with the database.
"""
from __future__ import annotations

import ast
import json
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List

import yaml
from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.ast_utility import (
    FunctionCallVisitor,
    calculate_structural_hash,
    extract_base_classes,
    extract_docstring,
    extract_parameters,
    parse_metadata_comment,
)
from shared.config import settings
from shared.logger import getLogger

log = getLogger("knowledge_graph_builder")


# ID: 64fe527b-e2ab-4232-9a54-1a24d17a6ff1
class KnowledgeGraphBuilder:
    """
    Scans the source code to build a comprehensive knowledge graph and syncs it
    to the operational database.
    """

    def __init__(self, root_path: Path):
        self.root_path = root_path
        self.intent_dir = self.root_path / ".intent"
        self.src_dir = self.root_path / "src"
        self.symbols: Dict[str, Dict[str, Any]] = {}
        self.domain_map = self._load_domain_map()
        self.entry_point_patterns = self._load_entry_point_patterns()

    def _load_domain_map(self) -> Dict[str, str]:
        """Loads the architectural domain map from the constitution."""
        try:
            structure_path = (
                self.intent_dir / "mind" / "knowledge" / "source_structure.yaml"
            )
            structure = yaml.safe_load(structure_path.read_text("utf-8"))
            return {
                str(self.src_dir / d.get("path", "").replace("src/", "")): d["domain"]
                for d in structure.get("structure", [])
            }
        except (FileNotFoundError, yaml.YAMLError, KeyError):
            return {}

    def _load_entry_point_patterns(self) -> List[Dict[str, Any]]:
        """Loads the declarative patterns for identifying system entry points."""
        try:
            patterns_path = (
                self.intent_dir / "mind" / "knowledge" / "entry_point_patterns.yaml"
            )
            patterns = yaml.safe_load(patterns_path.read_text("utf-8"))
            return patterns.get("patterns", [])
        except (FileNotFoundError, yaml.YAMLError):
            return []

    async def _sync_symbols_to_db(self, symbols: List[Dict]):
        """Performs a TRUNCATE and INSERT to sync symbols to the database."""
        if not symbols:
            return

        async with get_session() as session:
            async with session.begin():
                await session.execute(text("TRUNCATE TABLE core.symbols CASCADE"))
                await session.execute(
                    text(
                        """
                        INSERT INTO core.symbols (uuid, key, symbol_path, file_path, is_public, title, description, owner, status, structural_hash)
                        VALUES (:uuid, :key, :symbol_path, :file_path, :is_public, :title, :description, 'unassigned_agent', 'active', :structural_hash)
                    """
                    ),
                    symbols,
                )
        log.info(f"Successfully synced {len(symbols)} symbols to the database.")

    # ID: 6de62bc4-767f-4bc1-b5f1-25ee31af1009
    async def build_and_sync(self) -> Dict[str, Any]:  # <-- NOW ASYNC
        """
        Executes the full build and sync process for the knowledge graph.
        """
        log.info(f"Building knowledge graph for repository at: {self.root_path}")
        for py_file in self.src_dir.rglob("*.py"):
            self._scan_file(py_file)

        # Sync to database
        await self._sync_symbols_to_db(list(self.symbols.values()))  # <-- NOW AWAITED

        knowledge_graph = {
            "metadata": {
                "generated_at": datetime.now(timezone.utc).isoformat(),
                "repo_root": str(self.root_path),
            },
            "symbols": self.symbols,
        }

        output_path = settings.REPO_PATH / "reports" / "knowledge_graph.json"
        output_path.parent.mkdir(parents=True, exist_ok=True)
        output_path.write_text(json.dumps(knowledge_graph, indent=2))
        log.info(
            f"Knowledge graph artifact with {len(self.symbols)} symbols saved to {output_path}"
        )

        return knowledge_graph

    def _scan_file(self, file_path: Path):
        """Scans a single Python file and adds its symbols to the graph."""
        try:
            content = file_path.read_text(encoding="utf-8")
            tree = ast.parse(content, filename=str(file_path))
            source_lines = content.splitlines()

            for node in ast.walk(tree):
                if isinstance(
                    node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
                ):
                    self._process_symbol(node, file_path, source_lines)
        except Exception as e:
            log.error(f"Failed to process file {file_path}: {e}")

    def _determine_domain(self, file_path: Path) -> str:
        """Determines the architectural domain of a file."""
        abs_file_path = file_path.resolve()
        for domain_path, domain_name in self.domain_map.items():
            if str(abs_file_path).startswith(str(Path(domain_path).resolve())):
                return domain_name
        return "unknown"

    def _process_symbol(self, node: ast.AST, file_path: Path, source_lines: List[str]):
        """Extracts all relevant data from a symbol AST node."""
        if not hasattr(node, "name"):
            return

        rel_path = file_path.relative_to(self.root_path)
        symbol_path_key = f"{rel_path}::{node.name}"
        metadata = parse_metadata_comment(node, source_lines)
        docstring = (extract_docstring(node) or "").strip()

        call_visitor = FunctionCallVisitor()
        call_visitor.visit(node)

        symbol_data = {
            "uuid": symbol_path_key,
            "key": metadata.get("capability"),
            "symbol_path": symbol_path_key,
            "name": node.name,
            "type": type(node).__name__,
            "file_path": str(rel_path),
            "is_public": not node.name.startswith("_"),
            "title": node.name.replace("_", " ").title(),
            "description": docstring.split("\n")[0] if docstring else None,
            "docstring": docstring,
            "calls": sorted(list(set(call_visitor.calls))),
            "line_number": node.lineno,
            "end_line_number": getattr(node, "end_lineno", node.lineno),
            "is_async": isinstance(node, ast.AsyncFunctionDef),
            "parameters": extract_parameters(node) if hasattr(node, "args") else [],
            "is_class": isinstance(node, ast.ClassDef),
            "base_classes": (
                extract_base_classes(node) if isinstance(node, ast.ClassDef) else []
            ),
            "structural_hash": calculate_structural_hash(node),
        }
        self.symbols[symbol_path_key] = symbol_data

--- END OF FILE ./src/features/introspection/knowledge_graph_service.py ---

--- START OF FILE ./src/features/introspection/knowledge_helpers.py ---
# src/features/introspection/knowledge_helpers.py
"""
Helper utilities for knowledge graph vectorization:
- extract_source_code
- collect_vectorization_tasks (chunk-based diffing)
- reporting helpers (log_failure)
"""

from __future__ import annotations

import ast  # <-- Add this import
import fnmatch
from pathlib import Path
from typing import Dict, Optional

from shared.logger import getLogger
from shared.utils.embedding_utils import normalize_text, sha256_hex

log = getLogger("core_admin.knowledge.helpers")


# --- START: NEW ROBUST FUNCTION ---
# ID: 8eedaa86-01be-461c-a3b1-a3a61716fefc
def extract_source_code_from_ast(repo_root: Path, symbol_data: dict) -> str | None:
    """
    Extracts the source code for a symbol using AST, which is more reliable
    than line numbers when they are not available.
    """
    file_path_str = symbol_data.get("file_path")
    symbol_path_str = symbol_data.get("symbol_path")

    if not file_path_str or not symbol_path_str:
        return None

    file_path = repo_root / file_path_str
    if not file_path.exists():
        return None

    symbol_name = symbol_path_str.split("::")[-1]

    try:
        content = file_path.read_text("utf-8")
        tree = ast.parse(content, filename=str(file_path))
        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                if hasattr(node, "name") and node.name == symbol_name:
                    return ast.get_source_segment(content, node)
    except Exception as e:
        log.warning(
            f"AST parsing failed for {file_path_str} while seeking {symbol_name}: {e}"
        )
        return None

    return None


# --- END: NEW ROBUST FUNCTION ---


# ID: 23ae9ecc-4809-4146-9655-bcf3a9f75736
def extract_source_code(repo_root: Path, symbol_data: dict) -> str:
    """
    Extracts the source code for a symbol (legacy, uses line numbers).
    """
    if "source_code" in symbol_data and symbol_data["source_code"]:
        return symbol_data["source_code"]

    log.warning(
        f"Symbol '{symbol_data.get('key')}' is missing pre-extracted source code. "
        "Falling back to line numbers. Consider rebuilding the knowledge graph."
    )
    file_path_str = symbol_data.get("file")
    start = symbol_data.get("line_number")
    end = symbol_data.get("end_line_number")

    if not all([file_path_str, isinstance(start, int), isinstance(end, int)]):
        raise ValueError(
            f"Invalid or missing line numbers for symbol '{symbol_data.get('key')}'. "
            "Cannot extract source code."
        )

    file_path = (repo_root / file_path_str).resolve()
    if not file_path.exists():
        raise FileNotFoundError(f"Source file not found for symbol: {file_path}")

    lines = file_path.read_text(encoding="utf-8", errors="ignore").splitlines()
    if not (1 <= start <= end <= len(lines)):
        raise ValueError(
            f"Line numbers for symbol '{symbol_data.get('key')}' are out of bounds."
        )

    return "\n".join(lines[start - 1 : end])


# ID: 538af724-9c5b-4720-b3bf-964be836b2de
def log_failure(failure_log_path: Path, key: str, message: str, category: str) -> None:
    """Append a failure line to the given log file path. Ensures parent exists."""
    failure_log_path.parent.mkdir(parents=True, exist_ok=True)
    with failure_log_path.open("a", encoding="utf-8") as f:
        f.write(f"{category}\t{key}\t{message}\n")


# ID: d7880ea9-b988-4ba6-8358-b41636c0b43b
def collect_vectorization_tasks(
    symbols_map: dict,
    stored_chunks: Dict[str, dict],
    repo_root: Path,
    target: Optional[str] = None,
    force_recompute: bool = False,
    respect_model_revision: bool = True,
) -> list[dict]:
    """
    Build tasks for chunks. If `force_recompute` is True, it includes all targeted chunks
    regardless of their hash.
    """
    tasks: list[dict] = []

    for symbol_key, symbol_data in symbols_map.items():
        cap_key = symbol_data.get("capability")
        if not cap_key or cap_key == "unassigned":
            continue

        if target:
            is_match = fnmatch.fnmatch(symbol_key, target) or fnmatch.fnmatch(
                cap_key, target
            )
            if not is_match:
                continue

        if force_recompute:
            tasks.append(
                {"cap_key": cap_key, "symbol_key": symbol_key, "action": "vectorize"}
            )
            continue

        try:
            source_code = extract_source_code(repo_root, symbol_data)
            normalized_code = normalize_text(source_code)
            current_hash = sha256_hex(normalized_code)
        except Exception as e:
            log.warning(f"Could not compute hash for '{symbol_key}': {e}")
            current_hash = None

        stored = stored_chunks.get(symbol_key)
        up_to_date = False
        if stored and stored.get("hash") and current_hash:
            if respect_model_revision:
                up_to_date = stored["hash"] == current_hash and stored.get(
                    "rev"
                ) == symbol_data.get("model_revision")
            else:
                up_to_date = stored["hash"] == current_hash

        if up_to_date:
            continue

        tasks.append(
            {"cap_key": cap_key, "symbol_key": symbol_key, "action": "vectorize"}
        )

    return tasks

--- END OF FILE ./src/features/introspection/knowledge_helpers.py ---

--- START OF FILE ./src/features/introspection/knowledge_vectorizer.py ---
# src/system/admin/knowledge_vectorizer.py
"""
Handles the vectorization of individual capabilities (per-chunk), including interaction with Qdrant.
Idempotency is enforced at the chunk (symbol_key) level via `chunk_id` stored in the payload.
"""

from __future__ import annotations

from datetime import datetime, timezone
from pathlib import Path
from typing import Dict

from core.cognitive_service import CognitiveService
from services.clients.qdrant_client import QdrantService
from shared.config import settings
from shared.logger import getLogger
from shared.services.embedding_utils import normalize_text, sha256_hex

from .knowledge_helpers import extract_source_code, log_failure

log = getLogger("core_admin.knowledge")

DEFAULT_PAGE_SIZE = 250
MAX_SCROLL_LIMIT = 10000


# ID: 81ddb9e8-60c9-4564-bd08-b5e6c2843381
async def get_stored_chunks(qdrant_service: QdrantService) -> Dict[str, dict]:
    """
    Return mapping: chunk_id (symbol_key) -> {hash, rev, point_id, capability}
    """
    log.info("Checking Qdrant for already vectorized chunks...")
    chunks: Dict[str, dict] = {}
    next_offset = None
    try:
        while True:
            stored_points, next_offset = await qdrant_service.client.scroll(
                collection_name=qdrant_service.collection_name,
                limit=DEFAULT_PAGE_SIZE,
                offset=next_offset,
                with_payload=[
                    "chunk_id",
                    "content_sha256",
                    "model_rev",
                    "capability_tags",
                ],
                with_vectors=False,
            )
            for point in stored_points:
                payload = point.payload or {}
                cid = payload.get("chunk_id")
                if not cid:
                    continue
                chunks[cid] = {
                    "hash": payload.get("content_sha256"),
                    "rev": payload.get("model_rev"),
                    "point_id": str(point.id),
                    "capability": (payload.get("capability_tags") or [None])[0],
                }
            if not next_offset:
                break
        log.info(f"Found {len(chunks)} chunks already in Qdrant")
        return chunks
    except Exception as e:
        log.warning(f"Could not retrieve stored chunks from Qdrant: {e}")
        return {}


# ID: 9e54c111-0ffc-4a99-b243-8b89569335e1
async def sync_existing_vector_ids(
    qdrant_service: QdrantService, symbols_map: dict
) -> int:
    """
    Sync vector IDs from Qdrant for chunks (symbols) that already exist
    but don't have vector_id in knowledge graph.
    """
    log.info("Syncing existing vector IDs from Qdrant...")
    try:
        stored_points, _ = await qdrant_service.client.scroll(
            collection_name=qdrant_service.collection_name,
            limit=MAX_SCROLL_LIMIT,
            with_payload=["chunk_id"],
            with_vectors=False,
        )
        chunk_to_point_id: Dict[str, str] = {
            p.payload["chunk_id"]: str(p.id)
            for p in stored_points
            if p.payload and "chunk_id" in p.payload
        }
        synced_count = 0
        for symbol_key, symbol_data in symbols_map.items():
            if not symbol_data.get("vector_id") and symbol_key in chunk_to_point_id:
                symbol_data["vector_id"] = chunk_to_point_id[symbol_key]
                synced_count += 1
        if synced_count > 0:
            log.info(f"Synced {synced_count} existing vector IDs from Qdrant")
        return synced_count
    except Exception as e:
        log.warning(f"Could not sync existing vector IDs from Qdrant: {e}")
        return 0


# ID: 5140843f-a6d0-44e1-a592-2b82c33d7fa9
async def process_vectorization_task(
    task: dict,
    repo_root: Path,
    symbols_map: dict,
    cognitive_service: CognitiveService,
    qdrant_service: QdrantService,
    dry_run: bool,
    failure_log_path: Path,
    verbose: bool,
    stored_chunks: Dict[str, dict] | None = None,
) -> bool:
    """
    Process a single vectorization task. It assumes the decision to process has already been made.
    """
    cap_key = task["cap_key"]
    symbol_key = task["symbol_key"]

    try:
        source_code = extract_source_code(repo_root, symbols_map[symbol_key])
        normalized_code = normalize_text(source_code)
        content_hash = sha256_hex(normalized_code)

        # --- START: THE FINAL, CORRECT FIX ---
        # The redundant skipping logic has been REMOVED.
        # This function now unconditionally processes the task it is given.
        # --- END: THE FINAL, CORRECT FIX ---

        log.debug(f"Processing chunk '{symbol_key}' (cap: {cap_key})")
        vector = await cognitive_service.get_embedding_for_code(normalized_code)

        payload_data = {
            "source_path": symbols_map[symbol_key].get("file"),
            "source_type": "code",
            "chunk_id": symbol_key,
            "content_sha256": content_hash,
            "language": "python",
            "symbol": symbol_key,
            "capability_tags": [cap_key],
            "model_rev": settings.EMBED_MODEL_REVISION,
        }

        if dry_run:
            symbols_map[symbol_key]["vector_id"] = f"dry_run_{symbol_key}"
            log.info(f"[DRY RUN] Would vectorize '{cap_key}' (chunk: {symbol_key})")
            return True

        point_id = await qdrant_service.upsert_capability_vector(
            vector=vector,
            payload_data=payload_data,
        )
        symbols_map[symbol_key].update(
            {
                "vector_id": str(point_id),
                "vectorized_at": datetime.now(timezone.utc).isoformat(),
                "embedding_model": settings.LOCAL_EMBEDDING_MODEL_NAME,
                "model_revision": settings.EMBED_MODEL_REVISION,
                "content_hash": content_hash,
            }
        )
        log.debug(
            f"Successfully vectorized '{cap_key}' (chunk: {symbol_key}) with ID: {point_id}"
        )
        return True

    except Exception as e:
        log.error(f"Failed to process capability '{cap_key}': {e}")
        if not dry_run:
            log_failure(failure_log_path, cap_key, str(e), "knowledge_vectorize")
        if verbose:
            log.exception(f"Detailed error for '{cap_key}':")
        return False

--- END OF FILE ./src/features/introspection/knowledge_vectorizer.py ---

--- START OF FILE ./src/features/introspection/semantic_clusterer.py ---
# src/system/tools/semantic_clusterer.py
"""
Performs semantic clustering on exported capability vectors to discover data-driven domains.
"""
from __future__ import annotations

import json
from pathlib import Path

import numpy as np
import typer
from dotenv import load_dotenv

from shared.logger import getLogger

try:
    from sklearn.cluster import KMeans
except ImportError:
    KMeans = None

log = getLogger("core_tools.semantic_clusterer")
app = typer.Typer(
    help="Export vector data from Qdrant for semantic analysis.",
    add_completion=False,
)


# ID: 5350324a-ea70-4235-b220-d2a227a30b0a
def run_clustering(
    input_path: Path,
    output: Path,
    n_clusters: int,
):
    """
    Loads exported vectors, runs K-Means clustering, and saves the proposed
    capability-to-domain mappings to a JSON file.
    """
    if KMeans is None:
        log.error("scikit-learn is not installed. Aborting.")
        raise RuntimeError("scikit-learn is not installed for clustering.")

    log.info("🚀 Starting semantic clustering process...")
    output.parent.mkdir(parents=True, exist_ok=True)

    log.info(f"   -> Loading vectors from {input_path}...")
    vectors = []
    capability_keys = []
    with input_path.open("r", encoding="utf-8") as f:
        for line in f:
            record = json.loads(line)
            # --- START: THE DEFINITIVE FIX ---
            # We now correctly look for the 'symbol' key, which is the unique ID.
            if "vector" in record and "payload" in record:
                if "symbol" in record["payload"]:
                    vectors.append(record["vector"])
                    capability_keys.append(record["payload"]["symbol"])
            # --- END: THE DEFINITIVE FIX ---

    if not vectors:
        log.error(f"❌ No valid vector data found in {input_path}.")
        raise ValueError(f"No valid vector data found in {input_path}.")

    log.info(
        f"   -> Loaded {len(vectors)} vectors for clustering into {n_clusters} domains."
    )
    X = np.array(vectors)
    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init="auto")
    kmeans.fit(X)
    labels = kmeans.labels_
    proposed_domains = {
        key: f"domain_{label}" for key, label in zip(capability_keys, labels)
    }

    with output.open("w", encoding="utf-8") as f:
        json.dump(proposed_domains, f, indent=2, sort_keys=True)
    log.info(
        f"✅ Successfully generated domain proposals for {len(proposed_domains)} capabilities and saved to {output}"
    )


if __name__ == "__main__":
    load_dotenv()
    typer.run(run_clustering)

--- END OF FILE ./src/features/introspection/semantic_clusterer.py ---

--- START OF FILE ./src/features/introspection/sync_service.py ---
# src/features/introspection/sync_service.py
from __future__ import annotations

import ast
import uuid
from typing import Any, Dict, List

from rich.console import Console
from sqlalchemy import text

from services.repositories.db.engine import get_session
from shared.ast_utility import calculate_structural_hash
from shared.config import settings

console = Console()


# ID: b1bfdf4e-f1d6-4ad8-b2ad-f8e65589b618
class SymbolScanner:
    """Scans the codebase to extract symbol information."""

    # ID: b7f12001-466a-43fe-98ab-f6d6053c5d40
    def scan(self) -> List[Dict[str, Any]]:
        """Scans all Python files in src/ and extracts ID'd symbols."""
        src_dir = settings.REPO_PATH / "src"
        all_symbols = []
        # --- FIX: Use a set to track seen symbol_paths to prevent duplicates ---
        seen_symbol_paths = set()

        for file_path in src_dir.rglob("*.py"):
            try:
                content = file_path.read_text("utf-8")
                source_lines = content.splitlines()
                tree = ast.parse(content)
                for node in ast.walk(tree):
                    if isinstance(
                        node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
                    ):
                        # --- FIX: Stricter filtering for what constitutes a governable symbol ---
                        is_public = not node.name.startswith("_")
                        is_dunder = node.name.startswith("__") and node.name.endswith(
                            "__"
                        )
                        if is_public and not is_dunder:
                            self._process_symbol(
                                node,
                                file_path,
                                source_lines,
                                all_symbols,
                                seen_symbol_paths,
                            )
            except Exception as e:
                console.print(f"[bold red]Error scanning {file_path}: {e}[/bold red]")
        return all_symbols

    def _process_symbol(
        self, node, file_path, source_lines, all_symbols, seen_symbol_paths
    ):
        """Extracts metadata for a single symbol, avoiding duplicates."""
        tag_line_index = node.lineno - 2
        symbol_id = None
        if 0 <= tag_line_index < len(source_lines):
            line_above = source_lines[tag_line_index].strip()
            if line_above.startswith("# ID:"):
                try:
                    symbol_id = str(uuid.UUID(line_above.split(":", 1)[1].strip()))
                except ValueError:
                    console.print(
                        f"[yellow]Warning: Invalid UUID format in {file_path} at line {node.lineno-1}[/yellow]"
                    )
                    return

        if symbol_id:
            rel_path_str = str(file_path.relative_to(settings.REPO_PATH))
            symbol_path = f"{rel_path_str}::{node.name}"

            # --- FIX: Prevent adding symbols with duplicate paths ---
            if symbol_path in seen_symbol_paths:
                console.print(
                    f"[yellow]Warning: Duplicate symbol path detected and skipped: {symbol_path}[/yellow]"
                )
                return
            seen_symbol_paths.add(symbol_path)

            all_symbols.append(
                {
                    "uuid": symbol_id,
                    "symbol_path": symbol_path,
                    "file_path": rel_path_str,
                    "structural_hash": calculate_structural_hash(node),
                }
            )


# ID: 1673589c-8198-494c-9bac-d40fd7d60322
async def run_sync_with_db() -> Dict[str, int]:
    """
    Executes the full, database-centric sync logic using a temporary table.
    """
    scanner = SymbolScanner()
    code_state = scanner.scan()
    stats = {"scanned": len(code_state), "inserted": 0, "updated": 0, "deleted": 0}

    async with get_session() as session:
        async with session.begin():
            # Step 1: Create and populate the staging table
            await session.execute(
                text(
                    "CREATE TEMPORARY TABLE core_symbols_staging (LIKE core.symbols INCLUDING DEFAULTS) ON COMMIT DROP;"
                )
            )
            if code_state:
                await session.execute(
                    text(
                        """
                        INSERT INTO core_symbols_staging (uuid, symbol_path, file_path, structural_hash, is_public)
                        VALUES (:uuid, :symbol_path, :file_path, :structural_hash, TRUE)
                    """
                    ),
                    code_state,
                )

            # Step 2: Delete symbols that are no longer in the codebase
            delete_stmt = text(
                "DELETE FROM core.symbols WHERE uuid NOT IN (SELECT uuid FROM core_symbols_staging);"
            )
            result = await session.execute(delete_stmt)
            stats["deleted"] = result.rowcount

            # Step 3: Update symbols where the structural hash has changed
            update_stmt = text(
                """
                UPDATE core.symbols s
                SET
                    symbol_path = st.symbol_path,
                    file_path = st.file_path,
                    structural_hash = st.structural_hash,
                    updated_at = NOW()
                FROM core_symbols_staging st
                WHERE s.uuid = st.uuid
                  AND (s.structural_hash IS NULL OR s.structural_hash != st.structural_hash OR s.symbol_path != st.symbol_path);
            """
            )
            result = await session.execute(update_stmt)
            stats["updated"] = result.rowcount

            # --- FIX: Make the INSERT statement robust to conflicts on both uuid and symbol_path ---
            insert_stmt = text(
                """
                INSERT INTO core.symbols (uuid, symbol_path, file_path, structural_hash, is_public)
                SELECT uuid, symbol_path, file_path, structural_hash, TRUE
                FROM core_symbols_staging
                ON CONFLICT (uuid) DO NOTHING;
            """
            )
            result = await session.execute(insert_stmt)
            stats["inserted"] = result.rowcount

    return stats

--- END OF FILE ./src/features/introspection/sync_service.py ---

--- START OF FILE ./src/features/introspection/vectorization_service.py ---
# src/features/introspection/vectorization_service.py
"""
High-performance orchestrator for capability vectorization.
This version reads its work queue directly from the database, treating it as the
single source of truth for the symbol catalog.
"""
from __future__ import annotations

import ast
import hashlib
from pathlib import Path
from typing import Dict, List, Optional

from rich.console import Console
from rich.progress import track
from sqlalchemy import text

from core.cognitive_service import CognitiveService
from features.introspection.knowledge_helpers import log_failure
from services.clients.qdrant_client import QdrantService
from services.repositories.db.engine import get_session
from shared.config import settings
from shared.logger import getLogger
from shared.utils.embedding_utils import normalize_text

log = getLogger("core_admin.knowledge.orchestrator")
console = Console()


# ID: 65f3e8b5-35c7-4138-b177-f1a5faceee4d
async def _fetch_symbols_from_db() -> List[Dict]:
    """Queries the database to get the full list of symbols to be vectorized."""
    async with get_session() as session:
        stmt = text(
            """
            SELECT uuid, symbol_path, file_path, structural_hash
            FROM core.symbols
            WHERE status = 'active'
        """
        )
        result = await session.execute(stmt)
        return [dict(row._mapping) for row in result]


# ID: 11c635ed-9d61-4d04-b7c8-5a55a210e64b
async def _fetch_existing_vectors(qdrant_service: QdrantService) -> Dict[str, str]:
    """Fetches existing vectors from Qdrant and returns a map of content_hash -> point_id."""
    existing_vectors = {}
    records, _ = await qdrant_service.client.scroll(
        collection_name=qdrant_service.collection_name,
        limit=10000,
        with_payload=["content_sha256"],
        with_vectors=False,
    )
    for record in records:
        if record.payload and "content_sha256" in record.payload:
            existing_vectors[record.payload["content_sha256"]] = record.id
    return existing_vectors


# ID: 9d0b75e7-f064-49a3-b743-92bb3cc8e9a9
def _get_source_code(file_path: Path, symbol_path: str) -> Optional[str]:
    """Extracts the source code of a specific symbol from a file using AST."""
    if not file_path.exists():
        return None

    content = file_path.read_text("utf-8", errors="ignore")
    try:
        tree = ast.parse(content)
        symbol_name = symbol_path.split("::")[-1]

        for node in ast.walk(tree):
            if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                if hasattr(node, "name") and node.name == symbol_name:
                    return ast.get_source_segment(content, node)
    except Exception:
        return None
    return None


# ID: e06caaf0-1af4-421a-ad5c-e468c8d41f36
async def _process_vectorization_task(
    task: Dict,
    cognitive_service: CognitiveService,
    qdrant_service: QdrantService,
    failure_log_path: Path,
) -> Optional[str]:
    """Processes a single symbol: gets embedding and upserts to Qdrant. Returns Qdrant point ID on success."""
    try:
        vector = await cognitive_service.get_embedding_for_code(task["source_code"])
        payload_data = {
            "source_path": task["file_path"],
            "source_type": "code",
            "chunk_id": task["symbol_path"],
            "content_sha256": task["code_hash"],
            "language": "python",
            "symbol": task["symbol_path"],
            "capability_tags": [task["uuid"]],  # Use the UUID as the tag
        }
        point_id = await qdrant_service.upsert_capability_vector(
            vector=vector, payload_data=payload_data
        )
        return point_id
    except Exception as e:
        log.error(f"Failed to process symbol '{task['symbol_path']}': {e}")
        log_failure(
            failure_log_path, task["symbol_path"], str(e), "vectorization_error"
        )
        return None


# ID: 10de89a4-bc4a-42cc-adc6-d276de8be7c3
async def _update_symbols_in_db(updates: List[Dict]):
    """Bulk updates the vector_id for symbols in the database."""
    if not updates:
        return
    async with get_session() as session:
        async with session.begin():
            await session.execute(
                text(
                    """
                    UPDATE core.symbols SET vector_id = :vector_id, updated_at = NOW()
                    WHERE uuid = :uuid
                """
                ),
                updates,
            )
        await session.commit()
    console.print(f"   -> Updated {len(updates)} vector IDs in the database.")


# ID: 1171223d-a43d-4c61-a493-f29f8e75218b
async def run_vectorize(dry_run: bool = False, force: bool = False):
    """
    The main orchestration logic for vectorizing capabilities based on the database.
    """
    console.print("[bold cyan]🚀 Starting Database-Driven Vectorization...[/bold cyan]")
    failure_log_path = settings.REPO_PATH / "logs" / "vectorization_failures.log"
    failure_log_path.parent.mkdir(parents=True, exist_ok=True)

    symbols_in_db = await _fetch_symbols_from_db()
    console.print(f"   -> Found {len(symbols_in_db)} active symbols in the database.")

    qdrant_service = QdrantService()
    existing_vectors = await _fetch_existing_vectors(qdrant_service)
    console.print(f"   -> Found {len(existing_vectors)} existing vectors in Qdrant.")

    tasks = []
    for symbol in symbols_in_db:
        file_path = settings.REPO_PATH / symbol["file_path"]
        source_code = _get_source_code(file_path, symbol["symbol_path"])
        if not source_code:
            continue

        normalized_code = normalize_text(source_code)
        code_hash = hashlib.sha256(normalized_code.encode("utf-8")).hexdigest()

        if not force and code_hash in existing_vectors:
            continue

        tasks.append({**symbol, "source_code": normalized_code, "code_hash": code_hash})

    if not tasks:
        console.print(
            "[bold green]✅ Vector knowledge base is already up-to-date.[/bold green]"
        )
        return

    console.print(f"   -> Preparing to vectorize {len(tasks)} new or modified symbols.")

    if dry_run:
        console.print(
            "\n[bold yellow]💧 Dry Run: No embeddings will be generated or stored.[/bold yellow]"
        )
        return

    cognitive_service = CognitiveService(settings.REPO_PATH)
    updates_to_db = []

    for task in track(tasks, description="Vectorizing symbols..."):
        point_id = await _process_vectorization_task(
            task, cognitive_service, qdrant_service, failure_log_path
        )
        if point_id:
            updates_to_db.append({"uuid": task["uuid"], "vector_id": point_id})

    await _update_symbols_in_db(updates_to_db)

    console.print(
        f"\n[bold green]✅ Vectorization complete. Processed {len(updates_to_db)}/{len(tasks)} symbols.[/bold green]"
    )
    if len(updates_to_db) < len(tasks):
        console.print(
            f"[bold red]   -> {len(tasks) - len(updates_to_db)} failures were logged to {failure_log_path}[/bold red]"
        )

--- END OF FILE ./src/features/introspection/vectorization_service.py ---

--- START OF FILE ./src/features/maintenance/maintenance_service.py ---
# src/features/maintenance/maintenance_service.py
"""
Provides centralized services for repository maintenance tasks that were
previously handled by standalone scripts.
"""
from __future__ import annotations

import re

from rich.console import Console

from shared.config import settings

console = Console()

# This map defines the OLD python import paths to the NEW python import paths.
REWIRE_MAP = {
    # Legacy system.admin -> new cli.commands
    "system.admin": "cli.commands",
    "system.admin_cli": "cli.admin_cli",
    # Legacy agents -> new core.agents
    "agents": "core.agents",
    # Legacy system.tools -> new features
    "system.tools.codegraph_builder": "features.introspection.knowledge_graph_service",
    "system.tools.scaffolder": "features.project_lifecycle.scaffolding_service",
    # Legacy shared locations
    "shared.services.qdrant_service": "services.clients.qdrant_client",
    "shared.services.embedding_service": "services.adapters.embedding_provider",
    "shared.services.repositories.db.engine": "services.repositories.db.engine",
    "system.governance.models": "shared.models",
}


# ID: 76ae8501-8f82-4a13-9648-bf1af142aae3
def rewire_imports(dry_run: bool = True) -> int:
    """
    Scans the entire 'src' directory and corrects Python import statements
    based on the architectural REWIRE_MAP. This is a critical tool for use
    after major refactoring.

    Args:
        dry_run: If True, only prints changes without writing them.

    Returns:
        The number of import changes made or proposed.
    """
    src_dir = settings.REPO_PATH / "src"
    all_python_files = list(src_dir.rglob("*.py"))
    total_changes = 0
    import_re = re.compile(r"^(from\s+([a-zA-Z0-9_.]+)|import\s+([a-zA-Z0-9_.]+))")

    # Sort keys by length, longest first, to handle nested paths correctly
    sorted_rewire_keys = sorted(REWIRE_MAP.keys(), key=len, reverse=True)

    for file_path in all_python_files:
        try:
            content = file_path.read_text(encoding="utf-8")
            lines = content.splitlines()
            new_lines = []
            file_was_changed = False

            for line in lines:
                match = import_re.match(line)
                if not match:
                    new_lines.append(line)
                    continue

                original_import_path = match.group(2) or match.group(3)
                modified_line = line

                for old_prefix in sorted_rewire_keys:
                    if original_import_path.startswith(old_prefix):
                        new_prefix = REWIRE_MAP[old_prefix]
                        new_import_path = original_import_path.replace(
                            old_prefix, new_prefix, 1
                        )
                        modified_line = line.replace(
                            original_import_path, new_import_path
                        )
                        break  # Stop after the first (longest) match

                if modified_line != line:
                    console.print(
                        f"\n📝 Change detected in: [yellow]{file_path.relative_to(settings.REPO_PATH)}[/yellow]"
                    )
                    console.print(f"  - {line}")
                    console.print(f"  + [green]{modified_line}[/green]")
                    new_lines.append(modified_line)
                    file_was_changed = True
                    total_changes += 1
                else:
                    new_lines.append(line)

            if file_was_changed and not dry_run:
                file_path.write_text("\n".join(new_lines) + "\n", encoding="utf-8")

        except Exception as e:
            console.print(f"❌ Error processing {file_path}: {e}")

    return total_changes

--- END OF FILE ./src/features/maintenance/maintenance_service.py ---

--- START OF FILE ./src/features/project_lifecycle/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/features/project_lifecycle/__init__.py ---

--- START OF FILE ./src/features/project_lifecycle/bootstrap_service.py ---
# src/system/admin/bootstrap.py
"""
Provides CLI commands for bootstrapping the project with initial setup tasks,
such as creating a default set of GitHub issues for a new repository.
"""
from __future__ import annotations

import shutil
import subprocess
from typing import Optional

import typer
from rich.console import Console

from shared.logger import getLogger

log = getLogger("core_admin.bootstrap")
console = Console()

bootstrap_app = typer.Typer(
    help="Commands for project bootstrapping and initial setup."
)

ISSUES_TO_CREATE = [
    {
        "title": "Add JSON logging & request IDs",
        "body": "**Goal**: Switch logger to support LOG_FORMAT=json and add request id middleware in FastAPI.\n\n**Acceptance**\n- LOG_FORMAT=json writes structured logs\n- x-request-id is set/propagated\n- Docs updated in docs/CONVENTIONS.md",
        "labels": "roadmap,organizational,ci",
    },
    {
        "title": "Pre-commit hooks (Black, Ruff)",
        "body": "**Goal**: Add .pre-commit-config.yaml and wire to Make.\n\n**Acceptance**\n- pre-commit runs Black/Ruff locally\n- CI stays green",
        "labels": "roadmap,organizational,ci",
    },
    {
        "title": "Docs: CONVENTIONS.md & DEPENDENCIES.md",
        "body": "**Goal**: Codify folder map, import rules, capability tags, dependency policy.\n\n**Acceptance**\n- New contributors can place files w/o asking\n- Import discipline matrix documented",
        "labels": "roadmap,organizational,docs",
    },
    {
        "title": "Governance: proposal.schema.json + proposal_checks",
        "body": "**Goal**: Enforce schema & drift checks for .intent/proposals.\n\n**Acceptance**\n- Auditor shows schema pass/fail\n- Drift (token mismatch) → warning\n- Example proposal present",
        "labels": "roadmap,organizational,audit",
    },
]

LABELS_TO_ENSURE = [
    {"name": "roadmap", "color": "0366d6", "desc": "Roadmap item"},
    {"name": "organizational", "color": "a2eeef", "desc": "Project organization"},
    {"name": "ci", "color": "7057ff", "desc": "CI/CD"},
    {"name": "audit", "color": "d73a4a", "desc": "Constitutional audit & governance"},
    {"name": "docs", "color": "0e8a16", "desc": "Documentation"},
]


def _run_gh_command(command: list[str], ignore_errors: bool = False):
    """Helper to run a 'gh' command and handle errors."""
    if not shutil.which("gh"):
        console.print(
            "[bold red]❌ 'gh' (GitHub CLI) command not found in your PATH.[/bold red]"
        )
        console.print("   -> Please install it to use this feature.")
        raise typer.Exit(code=1)
    try:
        subprocess.run(command, check=True, capture_output=True, text=True)
    except subprocess.CalledProcessError as e:
        if not ignore_errors:
            console.print(f"[bold red]Error running gh command: {e.stderr}[/bold red]")
            raise typer.Exit(code=1)


@bootstrap_app.command("issues")
# ID: 695834ae-f6a1-49ed-baa8-7e99276df2ac
def bootstrap_issues(
    repo: Optional[str] = typer.Option(
        None, "--repo", help="The GitHub repository in 'owner/repo' format."
    ),
):
    """Creates a standard set of starter issues for the project on GitHub."""
    console.print("[bold cyan]🚀 Bootstrapping standard GitHub issues...[/bold cyan]")

    console.print("   -> Ensuring required labels exist...")
    for label in LABELS_TO_ENSURE:
        cmd = [
            "gh",
            "label",
            "create",
            label["name"],
            "--color",
            label["color"],
            "--description",
            label["desc"],
        ]
        if repo:
            cmd.extend(["--repo", repo])
        _run_gh_command(cmd, ignore_errors=True)

    console.print(f"   -> Creating {len(ISSUES_TO_CREATE)} starter issues...")
    for issue in ISSUES_TO_CREATE:
        cmd = [
            "gh",
            "issue",
            "create",
            "--title",
            issue["title"],
            "--body",
            issue["body"],
            "--label",
            issue["labels"],
        ]
        if repo:
            cmd.extend(["--repo", repo])
        _run_gh_command(cmd)

    console.print(
        "[bold green]✅ Successfully created starter issues on GitHub.[/bold green]"
    )


# ID: 86fe149d-06be-4cf8-a874-b03b28c1fe39
def register(app: typer.Typer):
    """Register the 'bootstrap' command group with the main CLI app."""
    app.add_typer(bootstrap_app, name="bootstrap")

--- END OF FILE ./src/features/project_lifecycle/bootstrap_service.py ---

--- START OF FILE ./src/features/project_lifecycle/definition_service.py ---
# src/features/project_lifecycle/definition_service.py
from __future__ import annotations

import asyncio
from typing import Any, Dict, List

from rich.console import Console
from sqlalchemy import text

from core.cognitive_service import CognitiveService
from features.introspection.knowledge_helpers import extract_source_code
from services.repositories.db.engine import get_session
from shared.config import settings

console = Console()


# ID: 4fe1a3d1-a3a9-428b-9e6a-7282fe7ffe36
async def get_undefined_symbols() -> List[Dict[str, Any]]:
    """Fetches symbols from the DB that have a UUID but no capability key yet."""
    async with get_session() as session:
        # --- THIS IS THE FIX ---
        # Query the knowledge_graph VIEW, which has all the necessary columns,
        # including the line numbers that extract_source_code needs.
        result = await session.execute(
            text(
                "SELECT uuid, file, symbol_path, line_number, end_line_number FROM core.knowledge_graph WHERE capability IS NULL"
            )
        )
        return [dict(row._mapping) for row in result]


# ID: c5e8625f-56fb-414c-b5b6-652c35061ce5
async def define_single_symbol(
    symbol: Dict[str, Any], cognitive_service: CognitiveService
) -> Dict[str, str]:
    """Uses an AI to generate a definition for a single symbol."""
    try:
        source_code = extract_source_code(settings.REPO_PATH, symbol)
    except (ValueError, FileNotFoundError) as e:
        console.print(
            f"[yellow]Warning: Could not extract source for {symbol.get('symbol_path', 'unknown symbol')}: {e}[/yellow]"
        )
        return {"uuid": symbol["uuid"], "key": "error.code_not_found"}

    if not source_code:
        return {"uuid": symbol["uuid"], "key": "error.code_not_found"}

    prompt_template = "Analyze the following code and propose a structured, dot-notation capability key (e.g., domain.subdomain.action):\n\n```python\n{code}\n```\n\nRespond with ONLY the key."
    final_prompt = prompt_template.format(code=source_code)

    definer_agent = cognitive_service.get_client_for_role("Planner")
    suggested_key = await definer_agent.make_request_async(
        final_prompt, user_id="definer_agent"
    )

    return {"uuid": symbol["uuid"], "key": suggested_key.strip()}


# ID: d1d22715-6f9f-4742-9a8e-9fdeef776af6
async def update_definitions_in_db(definitions: List[Dict[str, str]]):
    """Updates the 'key' column for symbols in the database."""
    # Filter out any symbols that failed during the definition process
    valid_definitions = [
        d for d in definitions if d.get("key") and not d["key"].startswith("error.")
    ]
    if not valid_definitions:
        return

    async with get_session() as session:
        async with session.begin():
            await session.execute(
                text("UPDATE core.symbols SET key = :key WHERE uuid = :uuid"),
                valid_definitions,
            )


# ID: 0d859072-4aa5-49b6-9cf5-cd26405892f6
async def define_new_symbols():
    """The main orchestrator for the autonomous definition process."""
    undefined_symbols = await get_undefined_symbols()
    if not undefined_symbols:
        console.print("   -> No new symbols to define.")
        return

    console.print(f"   -> Found {len(undefined_symbols)} new symbols to define...")
    cognitive_service = CognitiveService(settings.REPO_PATH)

    tasks = [
        define_single_symbol(symbol, cognitive_service) for symbol in undefined_symbols
    ]
    definitions = await asyncio.gather(*tasks)

    await update_definitions_in_db(definitions)

    valid_definitions_count = len(
        [d for d in definitions if d.get("key") and not d["key"].startswith("error.")]
    )
    console.print(
        f"   -> Successfully defined {valid_definitions_count} new capabilities."
    )

--- END OF FILE ./src/features/project_lifecycle/definition_service.py ---

--- START OF FILE ./src/features/project_lifecycle/integration_service.py ---
# src/features/project_lifecycle/integration_service.py
from __future__ import annotations

from rich.console import Console

from core.git_service import GitService
from features.governance.constitutional_auditor import ConstitutionalAuditor
from features.introspection.sync_service import run_sync_with_db
from features.introspection.vectorization_service import run_vectorize
from features.project_lifecycle.definition_service import define_new_symbols
from features.self_healing.id_tagging_service import assign_missing_ids
from shared.config import settings

console = Console()


# ID: 47b10dad-7f52-4962-bc07-7b82a2c12f42
async def integrate_changes(commit_message: str):
    """
    Orchestrates the full, autonomous integration of staged code changes.
    """
    git_service = GitService(settings.REPO_PATH)

    # 1. Check for staged changes
    staged_files = git_service.get_staged_files()
    if not staged_files:
        console.print(
            "[yellow]No staged changes found to integrate. Please use 'git add'.[/yellow]"
        )
        return

    console.print(f"Integrating {len(staged_files)} staged file(s)...")

    # 2. Assign IDs to new symbols
    console.print("\n[bold]Step 1/5: Assigning IDs to new symbols...[/bold]")
    assign_missing_ids(dry_run=False)
    # Re-stage any files that were modified by the ID tagger
    git_service.add_all()

    # 3. Synchronize with the database
    console.print(
        "\n[bold]Step 2/5: Synchronizing code state with the database...[/bold]"
    )
    await run_sync_with_db()

    # 4. Autonomously define new symbols
    console.print("\n[bold]Step 3/5: Autonomously defining new capabilities...[/bold]")
    await define_new_symbols()

    # 5. Vectorize new symbols
    console.print("\n[bold]Step 4/5: Vectorizing new symbols...[/bold]")
    await run_vectorize(
        dry_run=False, force=False
    )  # force=False ensures we only vectorize new things

    # 6. Constitutional Audit
    console.print("\n[bold]Step 5/5: Running full constitutional audit...[/bold]")
    auditor = ConstitutionalAuditor(settings.REPO_PATH)
    passed, findings, _ = await auditor.run_full_audit_async()
    if not passed:
        console.print(
            "[bold red]❌ Constitutional audit failed. Integration aborted.[/bold red]"
        )
        # Optionally, print findings here
        return

    # 7. Git Commit
    console.print("\n[bold]Final Step: Committing changes...[/bold]")
    git_service.commit(commit_message)
    console.print(
        "[bold green]✅ Successfully integrated and committed changes.[/bold green]"
    )

--- END OF FILE ./src/features/project_lifecycle/integration_service.py ---

--- START OF FILE ./src/features/project_lifecycle/scaffolding_service.py ---
# src/features/project_lifecycle/scaffolding_service.py
"""
Provides a reusable service for scaffolding new CORE-governed projects with constitutional compliance.
"""

from __future__ import annotations

import shutil
from pathlib import Path

import typer
import yaml

from shared.config import settings  # <-- MODIFIED IMPORT
from shared.logger import getLogger
from shared.path_utils import get_repo_root

log = getLogger("core_admin.scaffolder")
CORE_ROOT = get_repo_root()

# This is a good candidate to be defined in a policy in the future
STARTER_KITS_DIR = CORE_ROOT / "src" / "features" / "project_lifecycle" / "starter_kits"


# ID: 356e7222-34ea-443d-8e17-2ab64b3f9c8b
class Scaffolder:
    """A reusable service for creating new, constitutionally-governed projects."""

    def __init__(
        self,
        project_name: str,
        profile: str = "default",
        workspace_dir: Path | None = None,
    ):
        """Initializes the Scaffolder with project name, profile, and workspace directory."""
        self.name = project_name
        self.profile = profile

        # --- THIS IS THE REFACTOR ---
        # Load the source_structure policy using the new settings object
        source_structure = settings.load("mind.knowledge.source_structure")
        workspace_path_str = source_structure.get("paths", {}).get("workspace", "work")
        # --- END OF REFACTOR ---

        self.workspace = workspace_dir or (CORE_ROOT / workspace_path_str)

        self.project_root = self.workspace / self.name
        self.starter_kit_path = STARTER_KITS_DIR / self.profile

        if not self.starter_kit_path.is_dir():
            raise FileNotFoundError(
                f"Starter kit profile '{self.profile}' not found at "
                f"{self.starter_kit_path}."
            )

    # ID: c4ca3239-7e79-48d8-8a6a-dddf3323cf66
    def scaffold_base_structure(self):
        """Creates the base project structure, including tests and CI directories."""
        log.info(f"💾 Creating project structure at {self.project_root}...")
        if self.project_root.exists():
            raise FileExistsError(f"Directory '{self.project_root}' already exists.")

        self.project_root.mkdir(parents=True, exist_ok=True)
        (self.project_root / "src").mkdir()
        (self.project_root / "tests").mkdir()
        (self.project_root / ".github" / "workflows").mkdir(parents=True, exist_ok=True)
        (self.project_root / "reports").mkdir()

        intent_dir = self.project_root / ".intent"
        intent_dir.mkdir()

        constitutional_files_to_copy = [
            "principles.yaml",
            "project_manifest.yaml",
            "safety_policies.yaml",
            "source_structure.yaml",
        ]

        for filename in constitutional_files_to_copy:
            source_path = self.starter_kit_path / filename
            if source_path.exists():
                shutil.copy(source_path, intent_dir / filename)

        readme_template = self.starter_kit_path / "README.md"
        if readme_template.exists():
            shutil.copy(readme_template, intent_dir / "README.md")

        for template_path in self.starter_kit_path.glob("*.template"):
            content = template_path.read_text(encoding="utf-8").format(
                project_name=self.name
            )
            target_name = (
                ".gitignore"
                if template_path.name == "gitignore.template"
                else template_path.name.replace(".template", "")
            )
            (self.project_root / target_name).write_text(content, encoding="utf-8")

        manifest_path = intent_dir / "project_manifest.yaml"
        if manifest_path.exists():
            manifest_data = yaml.safe_load(manifest_path.read_text(encoding="utf-8"))
            if manifest_data:
                manifest_data["name"] = self.name
                manifest_path.write_text(
                    yaml.dump(manifest_data, indent=2), encoding="utf-8"
                )

        log.info(f"   -> ✅ Base structure for '{self.name}' created successfully.")

    # ID: 167f91ce-7b9f-4d07-9722-a5283af11019
    def write_file(self, relative_path: str, content: str):
        """Writes content to a file within the new project's directory, creating parent directories as needed."""
        target_file = self.project_root / relative_path
        target_file.parent.mkdir(parents=True, exist_ok=True)
        target_file.write_text(content, encoding="utf-8")
        log.info(f"   -> 📄 Wrote agent-generated file: {relative_path}")


# ID: c38bc7ce-2f6f-447b-9919-b6f7c2e6cf64
def new_project(
    name: str = typer.Argument(
        ...,
        help="The name of the new CORE-governed application to create.",
    ),
    profile: str = typer.Option(
        "default",
        "--profile",
        help="The starter kit profile to use for the new project's constitution.",
    ),
    dry_run: bool = typer.Option(
        True,
        "--dry-run/--write",
        help="Show what will be created without writing files. Use --write to apply.",
    ),
):
    """Scaffolds a new CORE-governed application with the given name, profile, and dry-run option, including base structure and README generation."""
    scaffolder = Scaffolder(project_name=name, profile=profile)
    log.info(
        f"🚀 Scaffolding new CORE application: '{name}' using '{profile}' profile."
    )
    if dry_run:
        log.info("\n💧 Dry Run Mode: No files will be written.")
        typer.secho(
            f"Would create project '{name}' in '{scaffolder.workspace}/' with the "
            f"'{profile}' starter kit.",
            fg=typer.colors.YELLOW,
        )
    else:
        try:
            scaffolder.scaffold_base_structure()
            readme_template_path = scaffolder.starter_kit_path / "README.md.template"
            if readme_template_path.exists():
                readme_content = readme_template_path.read_text(
                    encoding="utf-8"
                ).format(project_name=name)
                scaffolder.write_file("README.md", readme_content)

        except FileExistsError as e:
            log.error(f"❌ {e}")
            raise typer.Exit(code=1)
        except Exception as e:
            log.error(f"❌ An unexpected error occurred: {e}", exc_info=True)
            raise typer.Exit(code=1)

--- END OF FILE ./src/features/project_lifecycle/scaffolding_service.py ---

--- START OF FILE ./src/features/self_healing/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/features/self_healing/__init__.py ---

--- START OF FILE ./src/features/self_healing/clarity_service.py ---
# src/system/admin/fixer_clarity.py
"""
Implements the 'fix clarity' command, using an AI agent to perform
principled refactoring of Python code for improved readability and simplicity.
"""
from __future__ import annotations

import asyncio
from pathlib import Path

import typer
from rich.console import Console

from core.cognitive_service import CognitiveService
from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.fixer_clarity")
console = Console()


async def _async_fix_clarity(file_path: Path, dry_run: bool):
    """Async core logic for clarity-focused refactoring."""
    log.info(f"🔬 Analyzing '{file_path.name}' for clarity improvements...")

    cognitive_service = CognitiveService(settings.REPO_PATH)
    prompt_template = (
        settings.MIND / "prompts" / "refactor_for_clarity.prompt"
    ).read_text()

    original_code = file_path.read_text("utf-8")
    final_prompt = prompt_template.replace("{source_code}", original_code)

    refactor_client = cognitive_service.get_client_for_role("RefactoringArchitect")

    with console.status(
        "[bold green]Asking AI Architect to refactor for clarity...[/bold green]"
    ):
        refactored_code = await refactor_client.make_request_async(
            final_prompt, user_id="clarity_fixer_agent"
        )

    if not refactored_code.strip() or refactored_code.strip() == original_code.strip():
        console.print(
            "[bold green]✅ AI Architect found no clarity improvements to make.[/bold green]"
        )
        return

    if dry_run:
        console.print(
            f"\n[bold yellow]-- DRY RUN: Would refactor {file_path.name} --[/bold yellow]"
        )
        # You can add a diff view here if desired in the future
    else:
        file_path.write_text(refactored_code, "utf-8")
        console.print(
            f"\n[bold green]✅ Successfully refactored '{file_path.name}' for clarity.[/bold green]"
        )


# ID: 90f74d6c-6ee1-4174-b231-1813d97b1562
def fix_clarity(
    file_path: Path = typer.Argument(
        ..., help="Path to the Python file to refactor.", exists=True, dir_okay=False
    ),
    write: bool = typer.Option(
        False, "--write", help="Apply the refactoring to the file."
    ),
):
    """Uses an AI agent to refactor a Python file for improved clarity and simplicity."""
    asyncio.run(_async_fix_clarity(file_path, dry_run=not write))

--- END OF FILE ./src/features/self_healing/clarity_service.py ---

--- START OF FILE ./src/features/self_healing/complexity_service.py ---
# src/features/self_healing/complexity_service.py
"""
Administrative tool for identifying and refactoring code complexity outliers.
This version includes a "Semantic Capability Reconciliation" step to ensure
that refactoring not only improves the code but also proposes necessary
amendments to the system's constitution.
"""

from __future__ import annotations

import asyncio
import json
import re
import uuid
from pathlib import Path
from typing import Any, Dict, List, Optional

import typer
import yaml
from rich.console import Console
from rich.panel import Panel

from core.cognitive_service import CognitiveService
from core.validation_pipeline import validate_code
from features.governance.audit_context import AuditorContext
from shared.config import settings
from shared.logger import getLogger
from shared.utils.parsing import extract_json_from_response, parse_write_blocks

log = getLogger("core_admin.fixer_complexity")
console = Console()
REPO_ROOT = settings.REPO_PATH


def _get_capabilities_from_code(code: str) -> List[str]:
    """A simple parser to extract # CAPABILITY tags from a string of code."""
    return re.findall(r"#\s*CAPABILITY:\s*(\S+)", code)


def _propose_constitutional_amendment(proposal_plan: Dict[str, Any]):
    """Creates a formal proposal file for a constitutional amendment."""
    proposal_dir = REPO_ROOT / ".intent" / "proposals"
    proposal_dir.mkdir(exist_ok=True)

    target_file_name = Path(proposal_plan["target_path"]).stem
    proposal_id = str(uuid.uuid4())[:8]
    proposal_filename = f"cr-refactor-{target_file_name}-{proposal_id}.yaml"
    proposal_path = proposal_dir / proposal_filename

    proposal_content = {
        "target_path": proposal_plan["target_path"],
        "action": "replace_file",
        "justification": proposal_plan["justification"],
        "content": yaml.dump(
            proposal_plan["content"], indent=2, default_flow_style=False
        ),
    }

    proposal_path.write_text(
        yaml.dump(proposal_content, indent=2, sort_keys=False), encoding="utf-8"
    )
    log.info(
        f"📄 Constitutional amendment proposed at: {proposal_path.relative_to(REPO_ROOT)}"
    )
    return True


async def _run_capability_reconciliation(
    cognitive_service: CognitiveService,
    original_code: str,
    original_capabilities: List[str],
    refactoring_plan: Dict[str, str],
) -> Dict[str, Any]:
    """
    Asks an AI Constitutionalist to analyze the refactoring, re-tag capabilities,
    and propose manifest changes.
    """
    log.info("🏛️  Asking AI Constitutionalist to reconcile capabilities...")
    refactored_code_json = json.dumps(refactoring_plan, indent=2)

    prompt = f"""
You are an expert CORE Constitutionalist. You understand that a good refactoring not only improves code but also clarifies purpose.
The original file provided these capabilities: {original_capabilities}
A refactoring has occurred, resulting in these new files:
{refactored_code_json}
Your task is to perform a semantic analysis and produce a JSON object with two keys: "code_modifications" and "constitutional_amendment_proposal".
1.  **code_modifications**: This should be a JSON object where keys are file paths and values are the complete, final source code WITH the original capabilities correctly re-tagged onto the new functions that now hold that responsibility.
2.  **constitutional_amendment_proposal**: If the refactoring has clarified purpose and new, more atomic capabilities should exist, define a manifest change proposal. If no change is needed, this key should be null. The proposal should have 'target_path', 'justification', and 'content' for the new manifest.
Your entire output must be a single, valid JSON object.
"""

    constitutionalist = cognitive_service.get_client_for_role("Planner")
    response = await constitutionalist.make_request_async(
        prompt, user_id="constitutionalist_agent"
    )

    try:
        reconciliation_result = extract_json_from_response(response)
        if not reconciliation_result:
            raise ValueError("No valid JSON object found in the AI's response.")
        log.info("   -> ✅ AI Constitutionalist provided a valid reconciliation plan.")
        return reconciliation_result
    except (json.JSONDecodeError, ValueError) as e:
        log.error(f"❌ Failed to parse reconciliation plan from AI: {e}")
        log.error(f"   -> AI Raw Response: {response}")
        return {
            "code_modifications": refactoring_plan,
            "constitutional_amendment_proposal": None,
        }


async def _async_complexity_outliers(
    file_path: Optional[Path],
    dry_run: bool,
):
    """Async core logic for identifying and refactoring complexity outliers."""
    log.info("🩺 Starting complexity outlier analysis and refactoring cycle...")
    outlier_files: list[str] = (
        [str(file_path.relative_to(REPO_ROOT))] if file_path else []
    )
    if not outlier_files:
        log.error("❌ Please provide a specific file path to refactor.")
        return

    cognitive_service = CognitiveService(REPO_ROOT)
    # The knowledge_summary is no longer needed for the simplified prompt.

    for file_rel_path in outlier_files:
        try:
            log.info(f"--- Processing: {file_rel_path} ---")
            source_code = (REPO_ROOT / file_rel_path).read_text(encoding="utf-8")
            # original_capabilities = _get_capabilities_from_code(source_code)

            log.info("🧠 Asking RefactoringArchitect for a plan...")
            prompt_template = (
                (settings.MIND / "prompts" / "refactor_outlier.prompt")
                .read_text(encoding="utf-8")
                .replace("{source_code}", source_code)
            )
            refactor_client = cognitive_service.get_client_for_role(
                "RefactoringArchitect"
            )
            response = await refactor_client.make_request_async(
                prompt_template, user_id="refactoring_agent"
            )

            refactoring_plan = parse_write_blocks(response)
            if not refactoring_plan:
                raise ValueError(
                    "No valid [[write:]] blocks found in the refactoring plan response."
                )

            log.info("🔬 Validating generated code for constitutional compliance...")
            auditor_context = AuditorContext(REPO_ROOT)
            validated_code_plan = {}
            for path, code in refactoring_plan.items():
                result = validate_code(path, str(code), auditor_context=auditor_context)
                if result["status"] == "dirty":
                    raise Exception(f"Validation FAILED for proposed file '{path}'")
                validated_code_plan[path] = result["code"]
            log.info("   -> ✅ Plan is valid and formatted.")

            # The complex reconciliation step is removed for robustness.
            # The human operator will run 'make check' to find and fix any
            # manifest issues manually, which is a safer workflow for now.
            final_code_to_write = validated_code_plan

            if dry_run:
                console.print(
                    Panel(
                        f"Refactoring Plan for [bold cyan]{file_rel_path}[/bold cyan]",
                        expand=False,
                    )
                )
                for path in final_code_to_write:
                    console.print(
                        f"  📄 [yellow]Action:[/yellow] Write to [bold]{path}[/bold]"
                    )
                log.warning("💧 Dry Run: Skipping write. Plan is valid.")
                continue

            log.info("💾 Applying validated and formatted refactoring...")
            # Delete the original large file before writing the new ones
            (REPO_ROOT / file_rel_path).unlink()
            for path, code in final_code_to_write.items():
                (REPO_ROOT / path).write_text(code, encoding="utf-8")

            log.info(
                "✅ Refactoring applied. Run 'make check' to validate the new code state and fix any manifest drift."
            )

        except Exception as e:
            log.error(f"❌ Failed to process '{file_rel_path}': {e}", exc_info=True)
            continue


# ID: 6e802493-3d72-40e4-b80e-89c1518fdabb
def complexity_outliers(
    file_path: Optional[Path] = typer.Argument(
        None,
        help="Optional: The path to a specific file to refactor. If omitted, outliers are detected automatically.",
        exists=True,
        dir_okay=False,
        resolve_path=True,
    ),
    dry_run: bool = typer.Option(
        True,
        "--dry-run/--write",
        help="Show what refactoring would be applied. Use --write to apply.",
    ),
):
    """Identifies and refactors complexity outliers to improve separation of concerns."""
    # This is a synchronous wrapper around the async core logic.
    asyncio.run(_async_complexity_outliers(file_path, dry_run))

--- END OF FILE ./src/features/self_healing/complexity_service.py ---

--- START OF FILE ./src/features/self_healing/docstring_service.py ---
# src/features/self_healing/docstring_service.py
"""
Implements the 'fix docstrings' command, an AI-powered tool to add
missing docstrings to functions and methods.
"""
from __future__ import annotations

import asyncio

import typer
from rich.progress import track

from core.cognitive_service import CognitiveService
from core.knowledge_service import KnowledgeService
from features.introspection.knowledge_helpers import extract_source_code
from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.fixer_docstrings")
REPO_ROOT = settings.REPO_PATH


async def _async_fix_docstrings(dry_run: bool):
    """Async core logic for finding and fixing missing docstrings."""
    log.info("🔍 Searching for symbols missing docstrings...")

    knowledge_service = KnowledgeService(REPO_ROOT)
    graph = await knowledge_service.get_graph()
    symbols = graph.get("symbols", {})

    symbols_to_fix = [
        s
        for s in symbols.values()
        if not s.get("docstring")
        and s.get("type") in ["FunctionDef", "AsyncFunctionDef"]
    ]

    if not symbols_to_fix:
        log.info("✅ No symbols are missing docstrings. Excellent!")
        return

    log.info(f"Found {len(symbols_to_fix)} symbol(s) missing docstrings. Fixing...")

    cognitive_service = CognitiveService(REPO_ROOT)
    prompt_template = (
        settings.MIND / "prompts" / "fix_function_docstring.prompt"
    ).read_text(encoding="utf-8")
    writer_client = cognitive_service.get_client_for_role("DocstringWriter")

    modification_plan = {}

    for symbol in track(symbols_to_fix, description="Generating docstrings..."):
        try:
            source_code = extract_source_code(REPO_ROOT, symbol)
            final_prompt = prompt_template.format(source_code=source_code)

            new_docstring_content = await writer_client.make_request_async(
                final_prompt, user_id="docstring_writer_agent"
            )

            if new_docstring_content:
                file_path = REPO_ROOT / symbol["file"]
                if file_path not in modification_plan:
                    modification_plan[file_path] = []

                modification_plan[file_path].append(
                    {
                        "line_number": symbol["line_number"],
                        "indent": len(symbol.get("name", ""))
                        - len(symbol.get("name", "").lstrip()),
                        "docstring": new_docstring_content.strip().replace('"', '\\"'),
                    }
                )

        except Exception as e:
            log.error(f"Could not process {symbol['symbol_path']}: {e}")

    if dry_run:
        typer.secho("\n💧 Dry Run Summary:", bold=True)
        for file_path, patches in modification_plan.items():
            typer.secho(
                f"  - Would add {len(patches)} docstring(s) to: "
                f"{file_path.relative_to(REPO_ROOT)}",
                fg=typer.colors.YELLOW,
            )
    else:
        log.info("\n💾 Writing changes to disk...")
        for file_path, patches in modification_plan.items():
            try:
                lines = file_path.read_text(encoding="utf-8").splitlines()
                patches.sort(key=lambda p: p["line_number"], reverse=True)

                for patch in patches:
                    indent_space = " " * (patch["indent"] + 4)
                    docstring = f'{indent_space}"""{patch["docstring"]}"""'
                    lines.insert(patch["line_number"], docstring)

                file_path.write_text("\n".join(lines) + "\n", encoding="utf-8")
                log.info(
                    f"   -> ✅ Wrote {len(patches)} docstring(s) to "
                    f"{file_path.relative_to(REPO_ROOT)}"
                )
            except Exception as e:
                log.error(f"Failed to write to {file_path}: {e}")


# ID: 974fbc4d-da2e-4f45-8199-30972715c284
def fix_docstrings(
    write: bool = typer.Option(
        False, "--write", help="Apply the suggested docstrings directly to the files."
    ),
):
    """Uses an AI agent to find and add missing docstrings to functions and methods."""
    asyncio.run(_async_fix_docstrings(dry_run=not write))

--- END OF FILE ./src/features/self_healing/docstring_service.py ---

--- START OF FILE ./src/features/self_healing/fix_manifest_hygiene.py ---
# src/features/self_healing/fix_manifest_hygiene.py
"""
A self-healing tool that scans domain manifests for misplaced capability
declarations and moves them to the correct manifest file.
"""
from __future__ import annotations

from pathlib import Path
from typing import Any, Dict

import typer
import yaml
from rich.console import Console

from shared.config import settings
from shared.logger import getLogger

log = getLogger("fix_manifest_hygiene")
console = Console()
REPO_ROOT = settings.REPO_PATH
DOMAINS_DIR = REPO_ROOT / ".intent" / "mind" / "knowledge" / "domains"


# ID: 104d24d1-119d-42ef-88c5-197eb75e0b81
def run_fix_manifest_hygiene(
    write: bool = typer.Option(
        False, "--write", help="Apply fixes to the manifest files."
    )
):
    """
    Scans for and corrects misplaced capability declarations in domain manifests.
    """
    dry_run = not write
    log.info("🧼 Starting manifest hygiene check for misplaced capabilities...")
    if not DOMAINS_DIR.is_dir():
        log.error(f"Domains directory not found at: {DOMAINS_DIR}")
        raise typer.Exit(code=1)

    all_domain_files = {p.stem: p for p in DOMAINS_DIR.glob("*.yaml")}
    changes_to_make: Dict[str, Dict[str, Any]] = {}

    for domain_name, file_path in all_domain_files.items():
        try:
            content = yaml.safe_load(file_path.read_text("utf-8")) or {}
            capabilities = content.get("tags", [])

            misplaced_caps = [
                cap
                for cap in capabilities
                if isinstance(cap, dict)
                and "key" in cap
                and not cap["key"].startswith(f"{domain_name}.")
            ]

            if misplaced_caps:
                # Keep only the correctly placed capabilities
                content["tags"] = [
                    cap for cap in capabilities if cap not in misplaced_caps
                ]
                changes_to_make[str(file_path)] = {
                    "action": "update",
                    "content": content,
                }

                # Move the misplaced capabilities to their correct files
                for cap in misplaced_caps:
                    correct_domain = cap["key"].split(".")[0]
                    correct_file_path = all_domain_files.get(correct_domain)

                    if correct_file_path:
                        correct_path_str = str(correct_file_path)
                        if correct_path_str not in changes_to_make:
                            changes_to_make[correct_path_str] = {
                                "action": "update",
                                "content": yaml.safe_load(
                                    correct_file_path.read_text("utf-8")
                                )
                                or {"tags": []},
                            }

                        changes_to_make[correct_path_str]["content"].setdefault(
                            "tags", []
                        ).append(cap)
                        log.info(
                            f"   -> Planning to move '{cap['key']}' from '{file_path.name}' to '{correct_file_path.name}'"
                        )
                    else:
                        log.warning(
                            f"   -> Could not find a manifest file for domain '{correct_domain}' to move '{cap['key']}'."
                        )

        except Exception as e:
            log.error(f"Error processing {file_path.name}: {e}")

    if not changes_to_make:
        console.print(
            "[bold green]✅ Manifest hygiene is perfect. No misplaced capabilities found.[/bold green]"
        )
        return

    if dry_run:
        console.print(
            "\n[bold yellow]-- DRY RUN: The following manifest changes would be applied --[/bold yellow]"
        )
        for path_str, change in changes_to_make.items():
            console.print(
                f"  - File to {change['action']}: {Path(path_str).relative_to(REPO_ROOT)}"
            )
        return

    console.print("\n[bold]Applying manifest hygiene fixes...[/bold]")
    for path_str, change in changes_to_make.items():
        try:
            Path(path_str).write_text(
                yaml.dump(change["content"], indent=2, sort_keys=False), "utf-8"
            )
            console.print(f"  - ✅ Updated {Path(path_str).name}")
        except Exception as e:
            console.print(f"  - ❌ Failed to update {Path(path_str).name}: {e}")


if __name__ == "__main__":
    typer.run(run_fix_manifest_hygiene)

--- END OF FILE ./src/features/self_healing/fix_manifest_hygiene.py ---

--- START OF FILE ./src/features/self_healing/header_service.py ---
# src/features/self_healing/header_service.py
"""
The orchestration logic for the unified header fixer, which uses a deterministic
tool to enforce constitutional style rules on Python file headers.
"""

from __future__ import annotations

from rich.progress import track

from shared.config import settings
from shared.logger import getLogger
from shared.utils.header_tools import HeaderTools

log = getLogger("core_admin.fixer")
REPO_ROOT = settings.REPO_PATH


def _run_header_fix_cycle(dry_run: bool, all_py_files: list[str]):
    """The core logic for finding and fixing all header style violations."""
    log.info(f"Scanning {len(all_py_files)} files for header compliance...")

    files_to_fix = {}
    for file_path_str in track(all_py_files, description="Analyzing headers..."):
        file_path = REPO_ROOT / file_path_str
        try:
            original_content = file_path.read_text(encoding="utf-8")
            # --- THIS IS THE FIX ---
            # The HeaderTools class is now correctly used to parse the content.
            header = HeaderTools.parse(original_content)

            # Check for violations that need fixing
            correct_location_comment = f"# {file_path_str}"
            is_compliant = (
                header.location == correct_location_comment
                and header.module_description is not None
                and header.has_future_import
            )

            if not is_compliant:
                header.location = correct_location_comment
                if not header.module_description:
                    # Provide a default, high-quality docstring
                    header.module_description = (
                        f'"""Provides functionality for the {file_path.stem} module."""'
                    )
                header.has_future_import = True

                corrected_code = HeaderTools.reconstruct(header)
                if corrected_code != original_content:
                    files_to_fix[file_path_str] = corrected_code

        except Exception as e:
            log.warning(f"Could not process {file_path_str}: {e}")

    if not files_to_fix:
        log.info("✅ All file headers are constitutionally compliant.")
        return

    log.info(f"Found {len(files_to_fix)} file(s) requiring header fixes.")

    if dry_run:
        for file_path in sorted(files_to_fix.keys()):
            log.info(f"   -> [DRY RUN] Would fix header in: {file_path}")
    else:
        log.info("💾 Writing changes to disk...")
        for file_path_str, new_code in files_to_fix.items():
            (REPO_ROOT / file_path_str).write_text(new_code, "utf-8")
        log.info("   -> ✅ All header fixes have been applied.")

--- END OF FILE ./src/features/self_healing/header_service.py ---

--- START OF FILE ./src/features/self_healing/id_tagging_service.py ---
# src/features/self_healing/id_tagging_service.py
from __future__ import annotations

import ast
import uuid
from collections import defaultdict

from rich.console import Console

from shared.config import settings

console = Console()


def _is_public(node: ast.FunctionDef | ast.AsyncFunctionDef | ast.ClassDef) -> bool:
    """Determines if a symbol is public (not starting with an underscore)."""
    return not node.name.startswith("_")


# ID: 38f29597-95bb-4e6c-aabb-72baaf841522
def assign_missing_ids(dry_run: bool = True) -> int:
    """
    Scans all Python files in the 'src/' directory, finds public symbols
    missing an '# ID:' tag, and adds a new UUID tag to them.

    Args:
        dry_run: If True, only reports on the changes that would be made.

    Returns:
        The total number of new IDs that were (or would be) assigned.
    """
    src_dir = settings.REPO_PATH / "src"
    files_to_process = list(src_dir.rglob("*.py"))
    total_ids_assigned = 0

    files_to_fix = defaultdict(list)

    for file_path in files_to_process:
        try:
            content = file_path.read_text("utf-8")
            source_lines = content.splitlines()
            tree = ast.parse(content)

            for node in ast.walk(tree):
                if isinstance(
                    node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)
                ):
                    if not _is_public(node):
                        continue

                    # Check the line above the symbol definition for an existing ID tag
                    tag_line_index = node.lineno - 2
                    has_id = False
                    if 0 <= tag_line_index < len(source_lines):
                        line_above = source_lines[tag_line_index]
                        # --- THIS IS THE FIX ---
                        # Use .strip() to correctly find indented ID tags.
                        if line_above.strip().startswith("# ID:"):
                            has_id = True
                        # --- END OF FIX ---

                    if not has_id:
                        # Found a public symbol that needs an ID
                        files_to_fix[file_path].append(
                            {"line_number": node.lineno, "name": node.name}
                        )
        except Exception as e:
            console.print(
                f"   -> [bold red]❌ Error processing {file_path}: {e}[/bold red]"
            )

    if not files_to_fix:
        console.print(
            "[bold green]✅ All public symbols already have IDs.[/bold green]"
        )
        return 0

    for file_path, fixes in files_to_fix.items():
        console.print(
            f"🔧 Processing file: [cyan]{file_path.relative_to(settings.REPO_PATH)}[/cyan]"
        )

        # Sort fixes by line number in reverse to safely insert new lines
        fixes.sort(key=lambda x: x["line_number"], reverse=True)

        if dry_run:
            for fix in fixes:
                console.print(
                    f"   -> [DRY RUN] Would assign new ID to '{fix['name']}' at line {fix['line_number']}"
                )
                total_ids_assigned += 1
            continue

        try:
            lines = file_path.read_text("utf-8").splitlines()
            for fix in fixes:
                # Get indentation from the function definition line
                line_index = fix["line_number"] - 1
                original_line = lines[line_index]
                indentation = len(original_line) - len(original_line.lstrip(" "))

                # Generate new ID and format the tag line
                new_id = str(uuid.uuid4())
                tag_line = f"{' ' * indentation}# ID: {new_id}"

                # Insert the new tag line
                lines.insert(line_index, tag_line)
                total_ids_assigned += 1

            file_path.write_text("\n".join(lines) + "\n", "utf-8")
            console.print(f"   -> ✅ Assigned {len(fixes)} new ID(s).")
        except Exception as e:
            console.print(
                f"   -> [bold red]❌ Error writing to {file_path}: {e}[/bold red]"
            )

    return total_ids_assigned

--- END OF FILE ./src/features/self_healing/id_tagging_service.py ---

--- START OF FILE ./src/features/self_healing/linelength_service.py ---
# src/features/self_healing/linelength_service.py
"""
Implements the 'fix line-lengths' command, an AI-powered tool to
refactor code for better readability by adhering to line length policies.
"""
from __future__ import annotations

import asyncio
from pathlib import Path
from typing import List, Optional

import typer
from rich.progress import track

from core.cognitive_service import CognitiveService
from core.validation_pipeline import validate_code
from features.governance.audit_context import AuditorContext
from shared.config import settings
from shared.logger import getLogger

log = getLogger("core_admin.fixer_linelength")
REPO_ROOT = settings.REPO_PATH


async def _async_fix_line_lengths(files_to_process: List[Path], dry_run: bool):
    """Async core logic for finding and fixing all line length violations."""
    log.info(
        f"Scanning {len(files_to_process)} files for lines longer than 100 characters..."
    )

    cognitive_service = CognitiveService(REPO_ROOT)
    prompt_template_path = settings.MIND / "prompts" / "fix_line_length.prompt"
    if not prompt_template_path.exists():
        log.error(f"Prompt not found at {prompt_template_path}. Cannot proceed.")
        raise typer.Exit(code=1)
    prompt_template = prompt_template_path.read_text(encoding="utf-8")
    fixer_client = cognitive_service.get_client_for_role("CodeStyleFixer")

    auditor_context = AuditorContext(REPO_ROOT)

    files_with_long_lines = []
    for file_path in files_to_process:
        try:
            for line in file_path.read_text(encoding="utf-8").splitlines():
                if len(line) > 100:
                    files_with_long_lines.append(file_path)
                    break
        except Exception:
            continue

    if not files_with_long_lines:
        log.info("✅ No files with long lines found. Nothing to do.")
        return

    log.info(f"Found {len(files_with_long_lines)} file(s) with long lines to fix.")

    modification_plan = {}

    for file_path in track(
        files_with_long_lines, description="Asking AI to refactor files..."
    ):
        try:
            original_content = file_path.read_text(encoding="utf-8")
            final_prompt = prompt_template.replace("{source_code}", original_content)

            corrected_code = await fixer_client.make_request_async(
                final_prompt, user_id="line_length_fixer_agent"
            )

            if corrected_code and corrected_code.strip() != original_content.strip():
                validation_result = validate_code(
                    str(file_path),
                    corrected_code,
                    quiet=True,
                    auditor_context=auditor_context,
                )
                if validation_result["status"] == "clean":
                    modification_plan[file_path] = validation_result["code"]
                else:
                    log.warning(
                        f"Skipping {file_path.name}: AI-generated code failed validation."
                    )
        except Exception as e:
            log.error(f"Could not process {file_path.name}: {e}")

    if dry_run:
        typer.secho("\n💧 Dry Run Summary:", bold=True)
        for file_path in sorted(modification_plan.keys()):
            typer.secho(
                f"  - Would fix line lengths in: {file_path.relative_to(REPO_ROOT)}",
                fg=typer.colors.YELLOW,
            )
    else:
        log.info("\n💾 Writing changes to disk...")
        for file_path, new_code in modification_plan.items():
            file_path.write_text(new_code, "utf-8")
            log.info(
                f"   -> ✅ Fixed line lengths in {file_path.relative_to(REPO_ROOT)}"
            )


# ID: 1655a2ca-f71f-470b-8f43-a33ee28d64dd
def fix_line_lengths(
    file_path: Optional[Path] = typer.Argument(
        None,
        help="Optional: A specific file to fix. If omitted, all project files are scanned.",
        exists=True,
        dir_okay=False,
        resolve_path=True,
    ),
    write: bool = typer.Option(
        False, "--write", help="Apply the changes directly to the files."
    ),
):
    """Uses an AI agent to refactor files with lines longer than 100 characters."""
    files_to_scan = []
    if file_path:
        files_to_scan.append(file_path)
    else:
        # Scan all Python files in the src directory
        src_dir = REPO_ROOT / "src"
        files_to_scan.extend(src_dir.rglob("*.py"))

    asyncio.run(_async_fix_line_lengths(files_to_scan, dry_run=not write))

--- END OF FILE ./src/features/self_healing/linelength_service.py ---

--- START OF FILE ./src/features/self_healing/policy_id_service.py ---
# src/features/self_healing/policy_id_service.py
"""
Provides the service logic for the one-time constitutional migration to add
UUIDs to all policy files, bringing them into compliance with the updated policy_schema.
"""
from __future__ import annotations

import uuid

import yaml
from rich.console import Console

from shared.config import settings

console = Console()


# ID: c1a2b3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d
def add_missing_policy_ids(dry_run: bool = True) -> int:
    """
    Scans all constitutional policy files and adds a `policy_id` UUID if it's missing.

    Args:
        dry_run: If True, only reports on the changes that would be made.

    Returns:
        The total number of policies that were (or would be) updated.
    """
    policies_dir = settings.REPO_PATH / ".intent" / "charter" / "policies"
    if not policies_dir.is_dir():
        console.print(
            f"[bold red]Policies directory not found at: {policies_dir}[/bold red]"
        )
        return 0

    files_to_process = list(policies_dir.rglob("*_policy.yaml"))
    policies_updated = 0

    console.print(
        f"🔍 Scanning {len(files_to_process)} policy files for missing IDs..."
    )

    for file_path in files_to_process:
        try:
            content = file_path.read_text("utf-8")
            # Use safe_load to check for the key's existence
            data = yaml.safe_load(content) or {}

            if "policy_id" in data:
                continue

            # If the key is missing, add it
            policies_updated += 1
            new_id = str(uuid.uuid4())

            # Prepend the new ID to the raw file content to preserve comments and structure
            new_content = f"policy_id: {new_id}\n" + content

            if dry_run:
                console.print(
                    f"  -> [DRY RUN] Would add `policy_id: {new_id}` to [cyan]{file_path.name}[/cyan]"
                )
            else:
                file_path.write_text(new_content, "utf-8")
                console.print(
                    f"  -> ✅ Added `policy_id` to [green]{file_path.name}[/green]"
                )

        except Exception as e:
            console.print(
                f"  -> [bold red]❌ Error processing {file_path.name}: {e}[/bold red]"
            )

    return policies_updated

--- END OF FILE ./src/features/self_healing/policy_id_service.py ---

--- START OF FILE ./src/features/self_healing/prune_orphaned_vectors.py ---
# src/features/self_healing/prune_orphaned_vectors.py
"""
A self-healing tool to find and delete orphaned vectors from the Qdrant database.
An orphan is a vector whose corresponding symbol no longer exists in the
knowledge graph.
"""
from __future__ import annotations

import asyncio

import typer
from qdrant_client import AsyncQdrantClient
from qdrant_client.http.models import PointsSelector
from rich.console import Console

from core.knowledge_service import KnowledgeService
from shared.config import settings
from shared.logger import getLogger

log = getLogger("prune_orphaned_vectors")
console = Console()
REPO_ROOT = settings.REPO_PATH


async def _async_main_sync(dry_run: bool):
    """Main async orchestration for pruning orphaned vectors."""
    log.info("🌿 Starting orphan vector pruning process...")

    knowledge_service = KnowledgeService(REPO_ROOT)
    graph = await knowledge_service.get_graph()
    known_symbol_keys = set(graph.get("symbols", {}).keys())
    log.info(
        f"   -> Found {len(known_symbol_keys)} known symbols in the knowledge graph."
    )

    client = AsyncQdrantClient(url=settings.QDRANT_URL)

    try:
        log.info("   -> Fetching all vector chunk IDs from Qdrant...")
        all_points, _ = await client.scroll(
            collection_name=settings.QDRANT_COLLECTION_NAME,
            limit=10000,
            with_payload=["chunk_id"],
            with_vectors=False,
        )

        vector_points_map = {
            p.payload["chunk_id"]: p.id
            for p in all_points
            if p.payload and "chunk_id" in p.payload
        }
        vector_chunk_keys = set(vector_points_map.keys())
        log.info(f"   -> Found {len(vector_chunk_keys)} vectors in Qdrant.")

        orphaned_chunk_keys = list(vector_chunk_keys - known_symbol_keys)

        if not orphaned_chunk_keys:
            console.print(
                "[bold green]✅ No orphaned vectors found. The vector store is clean.[/bold green]"
            )
            return

        console.print(
            f"[yellow]Found {len(orphaned_chunk_keys)} orphaned vectors to prune.[/yellow]"
        )

        point_ids_to_delete = [
            vector_points_map[key]
            for key in orphaned_chunk_keys
            if key in vector_points_map
        ]

        if dry_run:
            console.print(
                "\n[bold yellow]-- DRY RUN: The following vector point IDs would be deleted --[/bold yellow]"
            )
            for point_id in point_ids_to_delete[:20]:
                console.print(f"  - {point_id}")
            if len(point_ids_to_delete) > 20:
                console.print(f"  - ... and {len(point_ids_to_delete) - 20} more.")
            return

        if not point_ids_to_delete:
            console.print(
                "[bold green]✅ No orphaned vectors to prune after filtering.[/bold green]"
            )
            return

        console.print("\n[bold]Pruning orphaned vectors from Qdrant...[/bold]")

        await client.delete(
            collection_name=settings.QDRANT_COLLECTION_NAME,
            points_selector=PointsSelector(points=point_ids_to_delete),
        )

        console.print(
            f"[bold green]✅ Successfully pruned {len(point_ids_to_delete)} orphaned vectors.[/bold green]"
        )

    except Exception as e:
        log.error(f"An error occurred during vector pruning: {e}", exc_info=True)
        raise typer.Exit(code=1)


# ID: 9c0f083b-5653-4c1d-b4bb-f4f38528f062
def main_sync(
    write: bool = typer.Option(
        False, "--write", help="Permanently delete orphaned vectors from Qdrant."
    )
):
    """Entry point for the Typer command."""
    asyncio.run(_async_main_sync(dry_run=not write))


if __name__ == "__main__":
    typer.run(main_sync)

--- END OF FILE ./src/features/self_healing/prune_orphaned_vectors.py ---

--- START OF FILE ./src/features/self_healing/prune_private_capabilities.py ---
# src/features/self_healing/prune_private_capabilities.py
"""
A self-healing tool that scans the codebase and removes # CAPABILITY tags
from private symbols (those starting with an underscore), enforcing the
'caps.ignore_private' constitutional policy.
"""
from __future__ import annotations

import asyncio
import re

import typer
from rich.console import Console

from core.knowledge_service import KnowledgeService
from shared.config import settings
from shared.logger import getLogger

log = getLogger("prune_private_caps")
console = Console()
REPO_ROOT = settings.REPO_PATH


# ID: 85bc7272-2a3e-4833-80a6-fd3f27e5df9c
def main(
    write: bool = typer.Option(
        False, "--write", help="Apply fixes and remove tags from source files."
    )
):
    """
    Finds and removes capability tags from private symbols (_ or __).
    """
    dry_run = not write
    log.info("🐍 Pruning capability tags from private symbols...")

    async def _async_main():
        knowledge_service = KnowledgeService(REPO_ROOT)
        graph = await knowledge_service.get_graph()
        symbols = graph.get("symbols", {})

        private_symbols_with_tags = [
            s
            for s in symbols.values()
            if s.get("name", "").startswith("_")
            and s.get("capability") != "unassigned"
            and s.get("capability") is not None
        ]

        if not private_symbols_with_tags:
            console.print(
                "[bold green]✅ No private symbols with capability tags found. Compliance is perfect.[/bold green]"
            )
            return

        console.print(
            f"[yellow]Found {len(private_symbols_with_tags)} private symbol(s) with capability tags.[/yellow]"
        )

        files_to_modify = {}
        tag_pattern = re.compile(r"^\s*#\s*CAPABILITY:\s*\S+\s*$", re.IGNORECASE)

        for symbol in private_symbols_with_tags:
            file_path_str = symbol.get("file")
            if not file_path_str:
                continue

            file_path = REPO_ROOT / file_path_str
            line_num = symbol.get("line_number", 0)

            if file_path not in files_to_modify:
                if file_path.exists():
                    files_to_modify[file_path] = file_path.read_text(
                        "utf-8"
                    ).splitlines()
                else:
                    log.warning(
                        f"File not found for symbol {symbol['symbol_path']}: {file_path}"
                    )
                    continue

            tag_line_index = line_num - 2
            if 0 <= tag_line_index < len(files_to_modify[file_path]):
                line_to_check = files_to_modify[file_path][tag_line_index]
                if tag_pattern.match(line_to_check):
                    log.info(
                        f"   -> Planning to remove tag for '{symbol['name']}' in {file_path_str}"
                    )
                    files_to_modify[file_path][tag_line_index] = "__DELETE_THIS_LINE__"

        if dry_run:
            console.print(
                "\n[bold yellow]-- DRY RUN: No files will be changed --[/bold yellow]"
            )
            return

        console.print("\n[bold]Applying fixes to source files...[/bold]")
        for file_path, lines in files_to_modify.items():
            new_content = (
                "\n".join([line for line in lines if line != "__DELETE_THIS_LINE__"])
                + "\n"
            )
            file_path.write_text(new_content, "utf-8")
            console.print(f"  - ✅ Pruned tags from {file_path.relative_to(REPO_ROOT)}")

    asyncio.run(_async_main())


if __name__ == "__main__":
    typer.run(main)

--- END OF FILE ./src/features/self_healing/prune_private_capabilities.py ---

--- START OF FILE ./src/features/self_healing/purge_legacy_tags_service.py ---
# src/features/self_healing/purge_legacy_tags_service.py
from __future__ import annotations

from collections import defaultdict

from rich.console import Console

from features.governance.audit_context import AuditorContext
from features.governance.checks.legacy_tag_check import LegacyTagCheck
from shared.config import settings

console = Console()


# ID: 5b7a5950-e534-4fb8-ad13-f9e6ad555643
def purge_legacy_tags(dry_run: bool = True) -> int:
    """
    removes them from the source files. This function is constitutionally

    Args:
        dry_run: If True, only prints the actions that would be taken.

    Returns:
        The total number of lines that were (or would be) removed.
    """
    context = AuditorContext(settings.REPO_PATH)
    check = LegacyTagCheck(context)
    all_findings = check.execute()

    if not all_findings:
        console.print(
            "[bold green]✅ No legacy tags found anywhere in the project.[/bold green]"
        )
        return 0

    # --- THIS IS THE CRITICAL AMENDMENT ---
    # Filter the findings to only include those within the 'src/' directory.
    src_findings = [
        finding
        for finding in all_findings
        if finding.file_path and finding.file_path.startswith("src/")
    ]
    # --- END OF AMENDMENT ---

    if not src_findings:
        console.print(
            f"[bold yellow]🔍 Found {len(all_findings)} total legacy tag(s) in non-code files, but none in 'src/'. No automated action taken.[/bold yellow]"
        )
        return 0

    console.print(
        f"[bold]🔍 Found {len(all_findings)} total legacy tag(s). Purging the {len(src_findings)} found in 'src/'...[/bold]"
    )

    # Group findings by file path to process one file at a time
    files_to_fix = defaultdict(list)
    for finding in src_findings:
        files_to_fix[finding.file_path].append(finding.line_number)

    total_lines_removed = 0
    for file_path_str, line_numbers_to_delete in files_to_fix.items():
        console.print(f"🔧 Processing file: [cyan]{file_path_str}[/cyan]")
        file_path = settings.REPO_PATH / file_path_str

        # Your critical insight: sort line numbers in reverse to avoid index shifting
        sorted_line_numbers = sorted(line_numbers_to_delete, reverse=True)

        if dry_run:
            for line_num in sorted_line_numbers:
                console.print(f"   -> [DRY RUN] Would delete line {line_num}")
                total_lines_removed += 1
            continue

        try:
            lines = file_path.read_text("utf-8").splitlines()
            for line_num in sorted_line_numbers:
                # Convert 1-based line number to 0-based index
                index_to_delete = line_num - 1
                if 0 <= index_to_delete < len(lines):
                    del lines[index_to_delete]
                    total_lines_removed += 1

            file_path.write_text("\n".join(lines) + "\n", "utf-8")
            console.print(f"   -> ✅ Purged {len(sorted_line_numbers)} legacy tag(s).")
        except Exception as e:
            console.print(
                f"   -> [bold red]❌ Error processing {file_path_str}: {e}[/bold red]"
            )

    return total_lines_removed

--- END OF FILE ./src/features/self_healing/purge_legacy_tags_service.py ---

--- START OF FILE ./src/main.py ---
from fastapi import FastAPI

app = FastAPI()


@app.get("/healthz")
# ID: 89de6b05-7f14-4a8d-b938-b5abf9385cdb
async def health_check():
    return {"status": "ok"}

--- END OF FILE ./src/main.py ---

--- START OF FILE ./src/services/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/services/__init__.py ---

--- START OF FILE ./src/services/adapters/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/services/adapters/__init__.py ---

--- START OF FILE ./src/services/adapters/embedding_provider.py ---
# src/shared/services/embedding_service.py
"""
EmbeddingService (quality-first, single-file)

This is now a pure, low-level client. It has no knowledge of the constitution
and receives all configuration during initialization.
"""

from __future__ import annotations

import asyncio
import os
import random
from typing import Any, Dict, List, Optional
from urllib.parse import urlparse

import requests

from shared.logger import getLogger

log = getLogger("embedding_service")


# ID: 2593a4dc-adff-4d0c-aec9-09cc2a73cf97
class EmbeddingService:
    """
    Minimal, robust client for OpenAI-compatible or Ollama-compatible embeddings endpoint.
    Keeps the interface tiny and predictable.
    """

    def __init__(
        self,
        model: str,
        base_url: str,
        api_key: Optional[str],
        expected_dim: int,
        request_timeout_sec: float = 120.0,
        connect_timeout_sec: float = 10.0,
        max_retries: int = 4,
    ) -> None:
        """Initializes the EmbeddingService with explicit configuration."""
        self.model = model
        self.expected_dim = expected_dim
        self.base_url = base_url
        self.api_key = api_key
        self.request_timeout_sec = request_timeout_sec
        self.connect_timeout_sec = connect_timeout_sec
        self.max_retries = max_retries

        self._validate_configuration()
        self._detect_api_type_and_endpoint()
        self._log_initialization_info()

        if os.getenv("PYTEST_CURRENT_TEST") is None:
            self._check_server_health()

    def _validate_configuration(self) -> None:
        """Validates that required configuration parameters are present."""
        if not self.base_url or not self.model:
            raise ValueError("base_url and model are required for EmbeddingService.")

        parsed_url = urlparse(self.base_url)
        if not parsed_url.scheme or not parsed_url.netloc:
            raise ValueError(f"Invalid base_url: {self.base_url}")

    def _detect_api_type_and_endpoint(self) -> None:
        """Detects the API type and sets the appropriate endpoint path."""
        parsed_url = urlparse(self.base_url)

        if "11434" in self.base_url or "ollama" in parsed_url.netloc.lower():
            self.api_type = "ollama_compatible"
            self.endpoint_path = "/api/embeddings"
        else:
            self.api_type = "openai"
            self.endpoint_path = "/v1/embeddings"

    def _log_initialization_info(self) -> None:
        """Logs initialization information."""
        log.info(
            "EmbeddingService: model=%s dim=%s url=%s",
            self.model,
            self.expected_dim,
            self.base_url,
        )

    def _check_server_health(self) -> None:
        """Checks if the embedding server is responsive and model is available."""
        try:
            health_endpoint = self._get_health_check_endpoint()
            response = requests.get(health_endpoint, timeout=self.connect_timeout_sec)

            if response.status_code != 200:
                self._handle_health_check_failure(response)

            if self.api_type == "ollama_compatible":
                self._validate_ollama_model_availability(response)

        except Exception as e:
            log.error(f"Failed to check embedding server health: {e}", exc_info=True)
            raise RuntimeError(f"Embedding server health check failed: {e}") from e

    def _get_health_check_endpoint(self) -> str:
        """Returns the appropriate health check endpoint based on API type."""
        if self.api_type == "ollama_compatible":
            return f"{self.base_url}/api/tags"
        else:
            return f"{self.base_url}/v1/models"

    def _handle_health_check_failure(self, response: requests.Response) -> None:
        """Handles failed health check responses."""
        log.error(
            "Embedding server health check failed: HTTP %s: %s",
            response.status_code,
            response.text[:200],
        )
        raise RuntimeError("Embedding server is not responsive")

    def _validate_ollama_model_availability(self, response: requests.Response) -> None:
        """Validates that the specified model is available on the Ollama server."""
        models = response.json().get("models", [])
        available_model_names = [model.get("name", "") for model in models]

        if self.model not in available_model_names:
            log.error(
                "Model %s not found on server. Available: %s",
                self.model,
                available_model_names,
            )
            raise RuntimeError(f"Model {self.model} not available on server")

    # ID: 8543c877-b51c-4e97-bf5a-3e97f173be48
    async def get_embedding(self, text: str) -> List[float]:
        """
        Return a single embedding vector for the given text.
        Raises:
            ValueError if empty input or wrong dimension is returned.
            RuntimeError for non-retryable HTTP failures or server issues.
        """
        text = (text or "").strip()
        if not text:
            raise ValueError("EmbeddingService.get_embedding: empty text")

        payload = self._build_request_payload(text)
        headers = self._build_headers()
        response_data = await self._post_with_retries(json=payload, headers=headers)

        embedding = self._extract_embedding_from_response(response_data)
        self._validate_embedding_dimensions(embedding)

        return embedding

    def _build_request_payload(self, text: str) -> Dict[str, str]:
        """Builds the request payload based on API type."""
        if self.api_type == "ollama_compatible":
            return {"model": self.model, "prompt": text}
        else:
            return {"model": self.model, "input": text}

    def _build_headers(self) -> Dict[str, str]:
        """Builds request headers, including Authorization if an API key is present."""
        headers = {"Content-Type": "application/json"}
        if self.api_key:
            headers["Authorization"] = f"Bearer {self.api_key}"
        return headers

    def _extract_embedding_from_response(
        self, response_data: Dict[str, Any]
    ) -> List[float]:
        """Extracts the embedding vector from the API response."""
        try:
            embedding = response_data.get("embedding") or response_data.get(
                "data",
                [{}],
            )[0].get("embedding", [])
        except Exception as e:
            raise RuntimeError(f"EmbeddingService: invalid response format: {e}") from e

        if not isinstance(embedding, list) or not embedding:
            raise RuntimeError("EmbeddingService: empty embedding returned")

        return embedding

    def _validate_embedding_dimensions(self, embedding: List[float]) -> None:
        """Validates that the embedding has the expected dimensions."""
        if len(embedding) != self.expected_dim:
            raise ValueError(
                f"Unexpected embedding dimension {len(embedding)} != "
                f"expected {self.expected_dim}"
            )

    async def _post_with_retries(
        self, *, json: Dict[str, Any], headers: Dict[str, str]
    ) -> Dict[str, Any]:
        """
        Execute POST in a thread (to keep async),
        with exponential backoff and jitter for transient errors.
        """
        attempt = 0
        last_error: Optional[Exception] = None
        backoff_base_sec = 0.6
        endpoint_url = f"{self.base_url.rstrip('/')}{self.endpoint_path}"

        while attempt <= self.max_retries:
            try:
                response = await self._execute_http_request(endpoint_url, headers, json)
                self._validate_http_response(response)
                return response.json()

            except Exception as e:
                last_error = e
                attempt += 1

                if self._should_stop_retrying(e, attempt):
                    break

                await self._wait_before_retry(
                    attempt,
                    endpoint_url,
                    e,
                    backoff_base_sec,
                )

        raise RuntimeError(
            f"EmbeddingService: request to {endpoint_url} failed after "
            f"{self.max_retries} retries: {last_error}"
        ) from last_error

    async def _execute_http_request(
        self,
        endpoint_url: str,
        headers: Dict[str, str],
        json_data: Dict[str, Any],
    ) -> requests.Response:
        """Executes the HTTP request in a thread."""
        return await asyncio.to_thread(
            requests.post,
            endpoint_url,
            headers=headers,
            json=json_data,
            timeout=(self.connect_timeout_sec, self.request_timeout_sec),
        )

    def _validate_http_response(self, response: requests.Response) -> None:
        """Validates HTTP response status codes and raises appropriate errors."""
        status_code = response.status_code
        response_text = response.text[:200]

        if status_code in (408, 429, 500, 502, 503, 504):
            raise RuntimeError(f"Transient HTTP {status_code}: {response_text}")
        if status_code == 400:
            raise RuntimeError(f"Bad request: {response_text}")
        if status_code == 401:
            raise RuntimeError(f"Unauthorized: {response_text}")
        if status_code < 200 or status_code >= 300:
            raise RuntimeError(f"HTTP {status_code}: {response_text}")

    def _should_stop_retrying(self, error: Exception, attempt: int) -> bool:
        """Determines whether to stop retrying based on the error and attempt count."""
        if attempt > self.max_retries:
            return True
        if isinstance(error, RuntimeError) and "Transient" not in str(error):
            return True
        return False

    async def _wait_before_retry(
        self, attempt: int, endpoint_url: str, error: Exception, backoff_base_sec: float
    ) -> None:
        """Waits before retrying with exponential backoff and jitter."""
        backoff_time = backoff_base_sec * (2 ** (attempt - 1)) + random.uniform(0, 0.1)

        log.warning(
            "Embedding POST to %s failed (attempt %s/%s): %s; retrying in %.1fs",
            endpoint_url,
            attempt,
            self.max_retries,
            error,
            backoff_time,
        )

        await asyncio.sleep(backoff_time)

--- END OF FILE ./src/services/adapters/embedding_provider.py ---

--- START OF FILE ./src/services/clients/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/services/clients/__init__.py ---

--- START OF FILE ./src/services/clients/llm_api_client.py ---
# src/core/clients.py
"""
Provides a base client for asynchronous communication with Chat Completions
and Embedding APIs for LLM interactions.
"""

from __future__ import annotations

import asyncio
import random
from typing import Any, List

import httpx

from shared.logger import getLogger

log = getLogger(__name__)


# ID: ccbed73e-3e71-4ede-ac2a-3069ee9abc0f
class BaseLLMClient:
    """
    Base class for LLM clients, handling common request logic for Chat and Embedding APIs.
    """

    def __init__(self, api_url: str, model_name: str, api_key: str | None = None):
        """Initializes the LLM client with API credentials and endpoint."""
        if not api_url or not model_name:
            raise ValueError(
                f"{self.__class__.__name__} requires both API_URL and MODEL_NAME."
            )

        self.base_url = api_url.rstrip("/")
        self.api_key = api_key
        self.model_name = model_name
        self.api_type = self._determine_api_type(self.base_url)
        self.headers = self._get_headers()
        self.async_client = httpx.AsyncClient(timeout=180.0)

    def _determine_api_type(self, base_url: str) -> str:
        """Determines the API type based on the URL."""
        if "anthropic" in base_url:
            return "anthropic"
        if "localhost" in base_url or "127.0.0.1" in base_url:
            return "ollama_compatible"
        if "192.168.20.24" in base_url:
            return "ollama_compatible"
        return "openai"  # Default for DeepSeek and OpenAI

    def _get_headers(self) -> dict:
        """Determines the correct headers based on the API type."""
        if self.api_type == "anthropic":
            if not self.api_key:
                raise ValueError("Anthropic API requires an API key.")
            return {
                "x-api-key": self.api_key,
                "anthropic-version": "2023-06-01",
                "Content-Type": "application/json",
            }
        elif self.api_type == "openai":
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"
            return headers
        return {"Content-Type": "application/json"}

    def _get_api_url(self, task_type: str) -> str:
        """Gets the correct API endpoint URL based on the task type."""
        if task_type == "embedding":
            if self.api_type == "ollama_compatible":
                return f"{self.base_url}/api/embeddings"
            return f"{self.base_url}/v1/embeddings"
        if self.api_type == "anthropic":
            return f"{self.base_url}/v1/messages"
        return f"{self.base_url}/v1/chat/completions"

    def _prepare_payload(self, prompt: str, user_id: str, task_type: str) -> dict:
        """Prepares the request payload based on the API and task type."""
        if task_type == "embedding":
            if self.api_type == "ollama_compatible":
                return {"model": self.model_name, "prompt": prompt}
            # OpenAI/DeepSeek use "input"
            return {"model": self.model_name, "input": [prompt]}

        if self.api_type == "anthropic":
            return {
                "model": self.model_name,
                "max_tokens": 4096,
                "messages": [{"role": "user", "content": prompt}],
            }
        else:  # openai chat
            return {
                "model": self.model_name,
                "messages": [{"role": "user", "content": prompt}],
                "user": user_id,
            }

    def _parse_response(self, response_data: dict, task_type: str) -> Any:
        """Parses the response to extract the content based on API and task type."""
        try:
            if task_type == "embedding":
                embedding = response_data.get("embedding") or response_data.get(
                    "data", [{}]
                )[0].get("embedding", [])
                if not embedding:
                    raise ValueError("Invalid embedding format in API response.")
                return embedding

            if self.api_type == "anthropic":
                return response_data.get("content", [{}])[0].get("text", "")
            else:  # openai chat
                return response_data["choices"][0]["message"]["content"]
        except (KeyError, IndexError, ValueError) as e:
            log.error(
                f"Could not parse response for task '{task_type}': {response_data}"
            )
            raise ValueError(f"Invalid API response structure: {e}") from e

    # ID: 966c47f2-fe76-49e3-9691-d541f5c9b802
    async def make_request_async(
        self, prompt: str, user_id: str = "core_system", task_type: str = "chat"
    ) -> Any:
        """Sends a prompt asynchronously to the configured API."""
        api_url = self._get_api_url(task_type)
        payload = self._prepare_payload(prompt, user_id, task_type)

        backoff_delays = [0.8, 1.6, 3.2]
        timeout_config = httpx.Timeout(connect=10.0, read=120.0, write=30.0, pool=30.0)

        for attempt in range(len(backoff_delays) + 1):
            try:
                response = await self.async_client.post(
                    api_url, headers=self.headers, json=payload, timeout=timeout_config
                )
                response.raise_for_status()
                return self._parse_response(response.json(), task_type)
            except (
                httpx.HTTPStatusError,
                httpx.ReadTimeout,
                httpx.ConnectTimeout,
                httpx.TransportError,
            ) as e:
                if attempt < len(backoff_delays):
                    wait_time = backoff_delays[attempt] + random.uniform(0, 0.5)
                    log.warning(
                        f"Request failed (attempt {attempt + 1}/"
                        f"{len(backoff_delays) + 1}), retrying in "
                        f"{wait_time:.1f}s... Error: {e}"
                    )
                    await asyncio.sleep(wait_time)
                    continue
                log.error(f"Final attempt failed for {api_url}: {e}", exc_info=True)
                raise

    # ID: 08f4f3a4-ac7c-4817-ad31-2d2bc72f0d93
    async def get_embedding(self, text: str) -> List[float]:
        """Convenience method for embedding tasks."""
        return await self.make_request_async(
            prompt=text, user_id="embedding_service", task_type="embedding"
        )

--- END OF FILE ./src/services/clients/llm_api_client.py ---

--- START OF FILE ./src/services/clients/qdrant_client.py ---
# src/services/clients/qdrant_client.py
"""
QdrantService (quality-first, single-file)

This service now enforces the EmbeddingPayload schema for all upserts,
ensuring every vector is stored with complete, traceable provenance.
"""

from __future__ import annotations

import uuid
from typing import Any, List, Optional, Sequence

from shared.config import settings
from shared.models import EmbeddingPayload
from shared.time import now_iso as _now_iso

try:
    from qdrant_client import AsyncQdrantClient
    from qdrant_client.http import models as qm
except Exception as e:
    raise RuntimeError(
        "qdrant-client is required. Install with: pip install qdrant-client"
    ) from e

try:
    from shared.logger import getLogger

    log = getLogger("qdrant_service")
except Exception:
    import logging

    logging.basicConfig(level=logging.INFO)
    log = logging.getLogger("qdrant_service")


def _uuid5_from_text(text: str) -> str:
    """
    Deterministic UUID from text (stable across runs).
    Uses UUID5 with URL namespace to avoid collisions.
    """
    return str(uuid.uuid5(uuid.NAMESPACE_URL, text))


# ID: 3f5ec13f-ba90-4912-99fb-a040ac649db8
class QdrantService:
    """Handles all interactions with the Qdrant vector database."""

    def __init__(
        self,
        url: Optional[str] = None,
        api_key: Optional[str] = None,
        collection_name: Optional[str] = None,
        vector_size: Optional[int] = None,
    ) -> None:
        """Initializes the Qdrant client from constitutional settings."""
        self.url = url or settings.QDRANT_URL
        self.api_key = (
            api_key
            if api_key is not None
            else settings.model_extra.get("QDRANT_API_KEY")
        )
        self.collection_name = collection_name or settings.QDRANT_COLLECTION_NAME
        self.vector_size = int(vector_size or settings.LOCAL_EMBEDDING_DIM)

        if not self.url:
            raise ValueError("QDRANT_URL is not configured.")

        self.client = AsyncQdrantClient(
            url=self.url,
            api_key=self.api_key or None,
        )

        log.info(
            "QdrantService: url=%s collection=%s dim=%s",
            self.url,
            self.collection_name,
            self.vector_size,
        )

    # ID: 5f745907-7aab-4426-a8ed-573607f3e6d4
    async def ensure_collection(self) -> None:
        """Idempotently create the collection if it is missing."""
        try:
            collections_response = await self.client.get_collections()
            existing_collections = [c.name for c in collections_response.collections]
            if self.collection_name in existing_collections:
                return

            log.info(
                "Creating Qdrant collection '%s' (dim=%s, distance=cosine).",
                self.collection_name,
                self.vector_size,
            )

            await self.client.recreate_collection(
                collection_name=self.collection_name,
                vectors_config=qm.VectorParams(
                    size=self.vector_size, distance=qm.Distance.COSINE
                ),
                on_disk_payload=True,
            )
        except Exception as e:
            log.error(f"Failed to ensure Qdrant collection exists: {e}", exc_info=True)
            raise

    # ID: 21ca9b0a-5f75-4707-bd86-c2289d954b25
    async def upsert_capability_vector(
        self,
        vector: List[float],
        payload_data: dict,
    ) -> str:
        """
        Validates the payload against the EmbeddingPayload schema and upserts the vector.
        Deterministic ID derived from the chunk_id. Returns the point ID.
        """
        if len(vector) != self.vector_size:
            raise ValueError(f"Vector dim {len(vector)} != expected {self.vector_size}")

        try:
            payload_data["model"] = settings.LOCAL_EMBEDDING_MODEL_NAME
            payload_data["model_rev"] = settings.EMBED_MODEL_REVISION
            payload_data["dim"] = self.vector_size
            payload_data["created_at"] = _now_iso()
            payload = EmbeddingPayload(**payload_data)
        except Exception as e:
            log.error(f"Invalid embedding payload: {e}")
            raise ValueError(f"Invalid embedding payload: {e}") from e

        pid = _uuid5_from_text(payload.chunk_id)

        await self.client.upsert(
            collection_name=self.collection_name,
            points=[
                qm.PointStruct(
                    id=pid,
                    vector=vector,
                    payload=payload.model_dump(mode="json"),
                )
            ],
            wait=True,
        )

        log.info(f"Upserted vector for chunk '{payload.chunk_id}' with ID: {pid}")
        return pid

    # ID: fba683c2-34d0-4feb-96ab-950c97abbb49
    async def get_all_vectors(self) -> List[qm.Record]:
        """Fetches all points with their vectors and payloads from the collection."""
        try:
            records, _ = await self.client.scroll(
                collection_name=self.collection_name,
                limit=10000,
                with_payload=True,
                with_vectors=True,
            )
            return records
        except Exception as e:
            log.error(f"❌ Failed to retrieve all vectors from Qdrant: {e}")
            return []

    # ID: 0e8ad7db-3561-4f97-9891-ca419e374dcf
    async def search_similar(
        self,
        query_vector: Sequence[float],
        limit: int = 5,
        with_payload: bool = True,
        filter_: Optional[qm.Filter] = None,
    ) -> list[dict[str, Any]]:
        """
        Simple nearest-neighbor search.
        """
        search_result = await self.client.search(
            collection_name=self.collection_name,
            query_vector=list(map(float, query_vector)),
            limit=limit,
            with_payload=with_payload,
            query_filter=filter_,
        )
        return [{"score": hit.score, "payload": hit.payload} for hit in search_result]

    # ID: 55effb86-fea5-4dc8-bdce-e9b464e9f243
    async def get_vector_by_id(self, point_id: str) -> Optional[List[float]]:
        """Retrieves a single vector by its point ID."""
        try:
            records = await self.client.retrieve(
                collection_name=self.collection_name, ids=[point_id], with_vectors=True
            )
            if records and records[0].vector:
                return records[0].vector
        except Exception as e:
            log.warning(f"Could not retrieve vector for point ID {point_id}: {e}")
        return None

--- END OF FILE ./src/services/clients/qdrant_client.py ---

--- START OF FILE ./src/services/repositories/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/services/repositories/__init__.py ---

--- START OF FILE ./src/services/repositories/db/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/services/repositories/db/__init__.py ---

--- START OF FILE ./src/services/repositories/db/common.py ---
# src/services/repositories/db/common.py
"""
Provides common utilities for database-related CLI commands.
"""

from __future__ import annotations

import os
import pathlib
import subprocess
from datetime import datetime, timezone
from typing import List, Set

import sqlparse
import yaml
from sqlalchemy import text

from services.repositories.db.engine import get_session


# --- THIS IS THE DEFINITIVE FIX ---
# This module must be self-sufficient. This robust function finds the project
# root without relying on the global settings object, which may not be initialized yet.
def _get_repo_root_for_migration() -> pathlib.Path:
    """Finds the repo root by searching upwards for a known marker file."""
    current_path = pathlib.Path(__file__).resolve()
    for parent in [current_path, *current_path.parents]:
        if (parent / "pyproject.toml").exists():
            return parent
    raise RuntimeError("Could not determine the repository root for migration.")


REPO_ROOT = _get_repo_root_for_migration()
META_YAML_PATH = REPO_ROOT / ".intent" / "meta.yaml"
# --- END OF FIX ---


# ID: 80ae5adf-d9cc-432e-b962-369b8992c700
def load_policy() -> dict:
    """Load the database_policy.yaml using a minimal, self-contained pathfinder."""
    try:
        # Manually parse meta.yaml to find the true path to the database policy.
        # This makes the migration command robust and independent of the main app's
        # initialization sequence.
        with META_YAML_PATH.open("r", encoding="utf-8") as f:
            meta_config = yaml.safe_load(f)

        db_policy_path_str = meta_config["charter"]["policies"]["data"][
            "database_policy"
        ]
        # The path in meta.yaml is relative to the .intent directory
        db_policy_path = REPO_ROOT / ".intent" / db_policy_path_str

        with db_policy_path.open("r", encoding="utf-8") as f:
            return yaml.safe_load(f) or {}
    except (FileNotFoundError, KeyError) as e:
        raise FileNotFoundError(
            f"Could not locate database policy via meta.yaml. Ensure it's correctly indexed. Original error: {e}"
        ) from e
    except yaml.YAMLError as e:
        raise ValueError(
            f"Failed to parse a required YAML file for DB migration: {e}"
        ) from e


# ID: a5ec72d4-d489-434f-ad69-a36a39229d92
async def ensure_ledger() -> None:
    """Ensure core schema and the migrations ledger table exist."""
    async with get_session() as session:
        async with session.begin():
            await session.execute(text("create schema if not exists core"))
            await session.execute(
                text(
                    """
                    create table if not exists core._migrations (
                      id text primary key,
                      applied_at timestamptz not null default now()
                    )
                    """
                )
            )


# ID: ec3e6b37-b4e8-4870-80f5-10d652ac5902
async def get_applied() -> Set[str]:
    """Return set of applied migration IDs."""
    async with get_session() as session:
        result = await session.execute(text("select id from core._migrations"))
        return {r[0] for r in result}


# ID: 27163ec0-f952-4ed7-938b-080473bee2eb
async def apply_sql_file(path: pathlib.Path) -> None:
    """Apply a .sql file by splitting into single statements (asyncpg-safe)."""
    sql_text = path.read_text(encoding="utf-8")
    statements: List[str] = [s.strip() for s in sqlparse.split(sql_text) if s.strip()]
    async with get_session() as session:
        async with session.begin():
            for stmt in statements:
                await session.execute(text(stmt))


# ID: e3cbb291-e852-4ad5-bcc3-8b4046c1def0
async def record_applied(mig_id: str) -> None:
    """Record a migration as applied."""
    async with get_session() as session:
        async with session.begin():
            await session.execute(
                text(
                    "insert into core._migrations (id, applied_at) values (:id, :ts)"
                ).bindparams(id=mig_id, ts=datetime.now(tz=timezone.utc))
            )


# ID: c0a84f36-7546-405b-8de4-eba8548ff56b
def git_commit_sha() -> str:
    """Best-effort: get current commit SHA, or fallback to env, max 40 chars."""
    try:
        res = subprocess.run(
            ["git", "rev-parse", "--verify", "HEAD"],
            capture_output=True,
            text=True,
            check=False,
        )
        if res.returncode == 0:
            return res.stdout.strip()[:40]
    except Exception:
        pass
    return (os.getenv("GIT_COMMIT", "") or "").strip()[:40]

--- END OF FILE ./src/services/repositories/db/common.py ---

--- START OF FILE ./src/services/repositories/db/engine.py ---
# src/core/db/engine.py
"""
Provides a lazily-initialized, asynchronous database engine and session factory for CORE.
"""

from __future__ import annotations

import os
from contextlib import asynccontextmanager
from typing import AsyncIterator, Optional

from sqlalchemy.engine import URL
from sqlalchemy.ext.asyncio import (
    AsyncEngine,
    AsyncSession,
    async_sessionmaker,
    create_async_engine,
)

"""Convert an environment variable to a boolean based on common truthy string values."""
# --- START: LAZY INITIALIZATION ---
# These are initialized to None. They will be created on the first database access.
_engine: Optional[AsyncEngine] = None
"""Parse an integer environment variable or return a default value if invalid."""

_Session: Optional[async_sessionmaker[AsyncSession]] = None
# --- END: LAZY INITIALIZATION ---


def _initialize_db():
    """
    This function is called by consumers to ensure the engine and session are ready.
    It's idempotent and will only run the setup logic once.
    """
    global _engine, _Session
    if _engine is not None:
        return

    DATABASE_URL = os.getenv("DATABASE_URL")
    if not DATABASE_URL:
        # This RuntimeError is now correctly raised only when the DB is actually needed.
        raise RuntimeError("DATABASE_URL is not set. Add it to your .env")

    def _bool_env(name: str, default: bool = False) -> bool:
        v = os.getenv(name, str(default)).strip().lower()
        return v in {"1", "true", "yes", "on"}

    """Create and yield an async database session as a context manager."""

    def _int_env(name: str, default: int) -> int:
        try:
            return int(os.getenv(name, str(default)))
        except ValueError:
            return default

    POOL_SIZE = _int_env("DATABASE_POOL_SIZE", 5)
    MAX_OVERFLOW = _int_env("DATABASE_MAX_OVERFLOW", 5)
    ECHO = _bool_env("DATABASE_ECHO", False)

    _engine = create_async_engine(
        URL.create(DATABASE_URL) if "://" not in DATABASE_URL else DATABASE_URL,
        echo=ECHO,
        pool_pre_ping=True,
        pool_size=POOL_SIZE,
        max_overflow=MAX_OVERFLOW,
    )
    _Session = async_sessionmaker(_engine, expire_on_commit=False)


@asynccontextmanager
# ID: 8ec9a3ab-ee2f-4f9b-85e3-e06d7983b482
async def get_session() -> AsyncIterator[AsyncSession]:
    """
    Provides a database session, initializing the engine on first call.
    """
    _initialize_db()
    # At this point, _Session is guaranteed to be initialized.
    async with _Session() as session:
        yield session


# ID: 4ec8bd10-ae74-4b30-b60c-799fb7d9f9bb
async def ping() -> dict:
    """Lightweight connectivity check, initializing the engine on first call."""
    from sqlalchemy import text

    _initialize_db()
    # At this point, _engine is guaranteed to be initialized.
    async with _engine.connect() as conn:
        v = await conn.execute(text("select version()"))
        return {"ok": True, "version": v.scalar_one()}

--- END OF FILE ./src/services/repositories/db/engine.py ---

--- START OF FILE ./src/services/repositories/db/migration_service.py ---
# src/system/admin/commands/db/init_db.py
"""
Provides functionality for the init_db module.
"""

from __future__ import annotations

import asyncio
import pathlib

import typer
from rich.console import Console

from .common import (
    apply_sql_file,
    ensure_ledger,
    get_applied,
    load_policy,
    record_applied,
)

console = Console()


async def _run_migrations(apply: bool):
    """The core async logic for running migrations."""
    try:
        pol = load_policy()
        order = pol.get("migrations", {}).get("order", [])
        migration_dir = pol.get("migrations", {}).get("directory", "sql")
    except Exception as e:
        console.print(f"[bold red]❌ Error loading database policy: {e}[/bold red]")
        raise typer.Exit(code=1)

    await ensure_ledger()
    applied = await get_applied()
    pending = [m for m in order if m not in applied]

    if not pending:
        console.print("[bold green]✅ DB schema is up to date.[/bold green]")
        return

    console.print(f"[yellow]Pending migrations found: {pending}[/yellow]")
    if not apply:
        console.print("   -> Run with '--apply' to execute them.")
        return

    for mig in pending:
        console.print(f"   -> Applying migration: {mig}...")
        try:
            await apply_sql_file(pathlib.Path(migration_dir) / mig)
            await record_applied(mig)
            console.print("      [green]...success.[/green]")
        except Exception as e:
            console.print(f"[bold red]      ❌ FAILED to apply {mig}: {e}[/bold red]")
            raise typer.Exit(code=1)

    console.print(
        "[bold green]✅ All pending migrations applied successfully.[/bold green]"
    )


# ID: 7bb0c5ee-480b-4d14-9147-853c9f9b25c5
def init_db(
    apply: bool = typer.Option(False, "--apply", help="Apply pending migrations.")
):
    """Initialize DB schema and apply pending migrations."""
    asyncio.run(_run_migrations(apply))

--- END OF FILE ./src/services/repositories/db/migration_service.py ---

--- START OF FILE ./src/services/repositories/db/status_service.py ---
# src/services/repositories/db/status_service.py
"""
Provides functionality for the status module.
"""

from __future__ import annotations

import asyncio

import typer

from services.repositories.db.common import (
    ensure_ledger,
    get_applied,
    load_policy,
)  # <-- CORRECTED IMPORT
from services.repositories.db.engine import ping


# ID: 75fac84c-5818-47c0-9d50-c0670d065c8c
def status() -> None:
    """Show DB connectivity and migration status."""

    async def _run():
        # 1) connection/ping
        try:
            info = await ping()
            typer.echo(f"✅ Connected: {info['version']}")
        except Exception as e:
            typer.echo(f"❌ Connection failed: {e}", err=True)
            raise

        # 2) policy & migrations
        pol = load_policy()
        order = pol.get("migrations", {}).get("order", [])

        await ensure_ledger()
        applied = await get_applied()
        pending = [m for m in order if m not in applied]

        typer.echo(f"Applied: {sorted(list(applied)) or '—'}")
        typer.echo(f"Pending: {pending or '—'}")

    asyncio.run(_run())

--- END OF FILE ./src/services/repositories/db/status_service.py ---

--- START OF FILE ./src/shared/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/shared/__init__.py ---

--- START OF FILE ./src/shared/action_logger.py ---
# src/shared/action_logger.py
"""
Provides a dedicated service for writing structured, auditable events to the system's action log.
"""

from __future__ import annotations

import json
from datetime import datetime, timezone
from typing import Any, Dict

from shared.config import settings
from shared.logger import getLogger

log = getLogger("action_logger")


# ID: 7a8b9c0d-1e2f-3a4b-5c6d-7e8f9a0b1c2d
class ActionLogger:
    """Handles writing structured JSON events to the CORE_ACTION_LOG_PATH."""

    def __init__(self):
        """Initializes the logger, ensuring the log file's parent directory exists."""
        try:
            log_path_str = settings.CORE_ACTION_LOG_PATH
            if not log_path_str:
                raise ValueError("CORE_ACTION_LOG_PATH is not set in the environment.")
            self.log_path = settings.REPO_PATH / log_path_str
            self.log_path.parent.mkdir(parents=True, exist_ok=True)
        except (ValueError, AttributeError) as e:
            log.error(
                f"ActionLogger failed to initialize: {e}. Logging will be disabled."
            )
            self.log_path = None

    # ID: 5d7a8b9c-0d1e-2f3a-4b5c-6d7e8f9a0b1c
    def log_event(self, event_type: str, details: Dict[str, Any]):
        """
        Writes a single, timestamped event to the action log file.

        Args:
            event_type: A dot-notation string identifying the event (e.g., 'crate.processing.started').
            details: A dictionary of context-specific information about the event.
        """
        if not self.log_path:
            return  # Fail silently if the logger could not be initialized.

        log_entry = {
            "timestamp_utc": datetime.now(timezone.utc).isoformat(),
            "event_type": event_type,
            "details": details,
        }
        try:
            with self.log_path.open("a", encoding="utf-8") as f:
                f.write(json.dumps(log_entry) + "\n")
        except Exception as e:
            log.error(f"Failed to write to action log at {self.log_path}: {e}")


# A singleton instance for easy access across the application
action_logger = ActionLogger()

--- END OF FILE ./src/shared/action_logger.py ---

--- START OF FILE ./src/shared/ast_utility.py ---
# src/shared/ast_utility.py
"""
Utility functions for working with Python AST (Abstract Syntax Trees).

Provides helpers to parse, inspect, and analyze Python source code at the
AST level. Includes visitors for extracting function calls, base classes,
docstrings, parameters, metadata tags, and a robust structural hash that is
insensitive to docstrings and whitespace.
"""

from __future__ import annotations

import ast
import hashlib
import logging
from typing import Dict, List, Optional

log = logging.getLogger(__name__)


# --- THIS IS THE NEW, ROBUST HELPER FUNCTION ---
# ID: a1b2c3d4-e5f6-7a8b-9c0d-1e2f3a4b5c6d
def find_definition_line(
    node: ast.FunctionDef | ast.AsyncFunctionDef | ast.ClassDef, source_lines: List[str]
) -> int:
    """
    Finds the actual line number of the 'def' or 'class' keyword,
    skipping over any decorators.
    """
    if not node.decorator_list:
        return node.lineno

    # The line number of the last decorator
    last_decorator_line = (
        node.decorator_list[-1].end_lineno or node.decorator_list[-1].lineno
    )

    # Search for "def" or "class" from the last decorator onwards
    for i in range(last_decorator_line, len(source_lines)):
        line = source_lines[i].strip()
        if (
            line.startswith(f"def {node.name}")
            or line.startswith(f"async def {node.name}")
            or line.startswith(f"class {node.name}")
        ):
            return i + 1  # Return 1-based line number

    return node.lineno  # Fallback


# --- END OF NEW HELPER FUNCTION ---


# ---------------------------------------------------------------------------
# Basic extractors
# ---------------------------------------------------------------------------


# ID: 79ccf26e-3710-4802-9ccb-29423f545e45
def extract_docstring(node: ast.AST) -> Optional[str]:
    """Extract the docstring from the given AST node if it exists."""
    return ast.get_docstring(node)


# ID: 79024211-279d-40af-91c3-679d5afdcf9f
def extract_base_classes(node: ast.ClassDef) -> List[str]:
    """Return a list of base class names for the given class node."""
    bases: List[str] = []
    for base in node.bases:
        if isinstance(base, ast.Name):
            bases.append(base.id)
        elif isinstance(base, ast.Attribute):
            # e.g. module.Class — capture best-effort dotted path
            left = None
            if isinstance(base.value, ast.Name):
                left = base.value.id
            elif isinstance(base.value, ast.Attribute):
                # fallback: last attribute segment
                left = base.value.attr
            bases.append(f"{left}.{base.attr}" if left else base.attr)
    return bases


# ID: 502f4096-53ca-49d8-b3e4-ec7a075b0881
def extract_parameters(node: ast.FunctionDef | ast.AsyncFunctionDef) -> List[str]:
    """Extract parameter names from a function (or async function) definition node."""
    if not hasattr(node, "args") or node.args is None:
        return []
    return [arg.arg for arg in getattr(node.args, "args", [])]


# ID: d73a2936-68f4-4dc4-b6ef-db6188740683
class FunctionCallVisitor(ast.NodeVisitor):
    """Visitor that collects function call names within a node."""

    def __init__(self) -> None:
        """Initialize an empty collection of function call names."""
        self.calls: List[str] = []

    # ID: 2eec3148-6aeb-4d74-9dd3-b73be105ee02
    def visit_Call(self, node: ast.Call) -> None:
        """Record the called function/method name, then continue traversal."""
        if isinstance(node.func, ast.Name):
            self.calls.append(node.func.id)
        elif isinstance(node.func, ast.Attribute):
            self.calls.append(node.func.attr)
        self.generic_visit(node)


# ---------------------------------------------------------------------------
# Metadata parsing (used by knowledge discovery)
# ---------------------------------------------------------------------------


# ID: 5f4a3e52-b52a-49ac-aa37-a5201376979f
def parse_metadata_comment(node: ast.AST, source_lines: List[str]) -> Dict[str, str]:
    """Returns a dict like {'capability': 'domain.key'} when present; otherwise empty dict."""
    if getattr(node, "lineno", None) and node.lineno > 1:
        line = source_lines[node.lineno - 2].strip()
        if line.startswith("#") and "CAPABILITY:" in line.upper():
            try:
                # split on the first colon to preserve values containing colons
                prefix, value = line.split(":", 1)
                return {"capability": value.strip()}
            except ValueError:
                pass
    return {}


# ---------------------------------------------------------------------------
# Structural hashing (canonical implementation lives here)
# ---------------------------------------------------------------------------


def _strip_docstrings(node: ast.AST) -> ast.AST:
    """Remove leading docstring expressions from modules/classes/functions."""
    if isinstance(
        node, (ast.Module, ast.ClassDef, ast.FunctionDef, ast.AsyncFunctionDef)
    ):
        if (
            getattr(node, "body", None)
            and len(node.body) > 0
            and isinstance(node.body[0], ast.Expr)
            and isinstance(getattr(node.body[0], "value", None), ast.Constant)
            and isinstance(node.body[0].value.value, str)
        ):
            node.body = node.body[1:]

    for child in ast.iter_child_nodes(node):
        _strip_docstrings(child)

    return node


# ID: 1b0ec762-579f-4b3d-93eb-c88e42253c54
def calculate_structural_hash(node: ast.AST) -> str:
    """Calculate a stable structural hash for an AST node.

    The hash is:
      - insensitive to docstrings (they are stripped)
      - insensitive to whitespace and newlines
    """
    try:
        normalized = ast.parse(ast.unparse(node))
        normalized = _strip_docstrings(normalized)
        structural = ast.unparse(normalized).replace("\n", "").replace(" ", "")
        return hashlib.sha256(structural.encode("utf-8")).hexdigest()
    except Exception:
        # Fallback: never block callers on hashing
        try:
            fallback = ast.unparse(node)
        except Exception:
            fallback = repr(node)
        log.exception("Structural hash computation failed; using fallback hash.")
        return hashlib.sha256(fallback.encode("utf-8")).hexdigest()

--- END OF FILE ./src/shared/ast_utility.py ---

--- START OF FILE ./src/shared/config.py ---
# src/shared/config.py
from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict, Optional

import yaml
from pydantic import PrivateAttr
from pydantic_settings import BaseSettings, SettingsConfigDict

from shared.logger import getLogger

log = getLogger("core.config")

REPO_ROOT = Path(__file__).resolve().parents[2]


# ID: 07a85609-ecab-4168-a4dd-dc9112f974d3
class Settings(BaseSettings):
    """
    The single, canonical source of truth for all CORE configuration.
    It loads from environment variables and provides "Pathfinder" methods
    to access constitutional files via the .intent/meta.yaml index.
    """

    model_config = SettingsConfigDict(
        env_file=".env", env_file_encoding="utf-8", extra="allow", case_sensitive=True
    )

    _meta_config: Dict[str, Any] = PrivateAttr(default_factory=dict)

    REPO_PATH: Path = REPO_ROOT
    MIND: Path = REPO_PATH / ".intent"
    BODY: Path = REPO_PATH / "src"
    LLM_ENABLED: bool = True
    LOG_LEVEL: str = "INFO"
    CORE_MAX_CONCURRENT_REQUESTS: int = 5

    DATABASE_URL: str
    QDRANT_URL: str
    QDRANT_COLLECTION_NAME: str = "core_capabilities"

    LOCAL_EMBEDDING_API_URL: str
    LOCAL_EMBEDDING_MODEL_NAME: str
    LOCAL_EMBEDDING_DIM: int
    LOCAL_EMBEDDING_API_KEY: Optional[str] = None
    EMBED_MODEL_REVISION: str = "2025-09-15"

    # --- THIS IS THE FIX ---
    # Formally declare KEY_STORAGE_DIR with its correct type and a default value.
    # Pydantic will now automatically handle loading from .env and casting to a Path object.
    KEY_STORAGE_DIR: Path = REPO_PATH / ".intent" / "keys"
    # --- END OF FIX ---

    def __init__(self, **values: Any):
        super().__init__(**values)
        self._load_meta_config()

    def _load_meta_config(self):
        """Loads and caches the .intent/meta.yaml file, failing loudly if invalid."""
        meta_path = self.REPO_PATH / ".intent" / "meta.yaml"
        if not meta_path.exists():
            raise FileNotFoundError("FATAL: .intent/meta.yaml is missing.")
        try:
            self._meta_config = self._load_file_content(meta_path)
        except (IOError, ValueError) as e:
            raise RuntimeError(f"FATAL: Could not parse .intent/meta.yaml: {e}")

    def _load_file_content(self, file_path: Path) -> Dict[str, Any]:
        """Internal, unified loader for YAML or JSON files."""
        content = file_path.read_text("utf-8")
        if file_path.suffix in (".yaml", ".yml"):
            return yaml.safe_load(content) or {}
        elif file_path.suffix == ".json":
            return json.loads(content) or {}
        raise ValueError(f"Unsupported config file type: {file_path}")

    # ID: 8e9be503-e7c9-4afb-a6a5-385750ec91cf
    def get_path(self, logical_path: str) -> Path:
        """
        Gets the absolute path to a constitutional file using its logical,
        dot-notation path from meta.yaml.
        """
        keys = logical_path.split(".")
        value = self._meta_config
        try:
            for key in keys:
                value = value[key]
            if not isinstance(value, str):
                raise TypeError
            # Paths in meta.yaml are relative to the .intent directory
            return self.MIND / value
        except (KeyError, TypeError):
            raise FileNotFoundError(
                f"Logical path '{logical_path}' not found or invalid in meta.yaml."
            )

    # ID: b1c2d3e4-f5a6-b7c8-d9e0-f1a2b3c4d5e6
    def find_logical_path_for_file(self, filename: str) -> str:
        """
        Searches the meta.yaml index to find the full relative path for a given filename.
        """

        def _search_dict(d: Any) -> Optional[str]:
            if isinstance(d, dict):
                for key, value in d.items():
                    if isinstance(value, str) and value.endswith(filename):
                        return value
                    found = _search_dict(value)
                    if found:
                        return found
            return None

        found_path = _search_dict(self._meta_config)
        if found_path:
            return found_path
        raise ValueError(f"Filename '{filename}' not found in meta.yaml index.")

    # ID: 08272f29-c9c9-4c54-8253-b7fea9938050
    def load(self, logical_path: str) -> Dict[str, Any]:
        """
        Loads and parses a constitutional YAML/JSON file using its logical path.
        """
        file_path = self.get_path(logical_path)
        try:
            return self._load_file_content(file_path)
        except FileNotFoundError:
            log.error(
                f"File for logical path '{logical_path}' not found at expected location: {file_path}"
            )
            raise
        except (IOError, ValueError) as e:
            raise IOError(f"Failed to load or parse file for '{logical_path}': {e}")


try:
    settings = Settings()
except (RuntimeError, FileNotFoundError) as e:
    log.critical(f"FATAL ERROR during settings initialization: {e}")
    raise

--- END OF FILE ./src/shared/config.py ---

--- START OF FILE ./src/shared/config_loader.py ---
# src/shared/config_loader.py
"""
Utility for loading configuration files (YAML or JSON) safely.
"""

from __future__ import annotations

import json
from pathlib import Path
from typing import Any, Dict

import yaml

from shared.logger import getLogger

log = getLogger(__name__)


# ID: 85467d87-762e-461c-8c08-af2b982e2387
def load_yaml_file(file_path: Path) -> Dict[str, Any]:
    """Loads a YAML or JSON config file safely, with consistent error handling.

    Args:
        file_path: Path to the configuration file (must be .yaml, .yml, or .json).

    Returns:
        A dictionary containing the parsed configuration data.

    Raises:
        FileNotFoundError: If the file does not exist.
        ValueError: If the file format is unsupported or parsing fails.
    """
    if not file_path.exists():
        log.error(f"Config file not found: {file_path}")
        raise FileNotFoundError(f"Config file not found: {file_path}")

    try:
        content = file_path.read_text(encoding="utf-8")
        if file_path.suffix in (".yaml", ".yml"):
            return yaml.safe_load(content) or {}
        elif file_path.suffix == ".json":
            return json.loads(content) or {}
        else:
            log.error(f"Unsupported file type: {file_path.suffix}")
            raise ValueError(f"Unsupported config file type: {file_path}")
    except (yaml.YAMLError, json.JSONDecodeError) as e:
        log.error(f"Error parsing config {file_path}: {e}")
        raise ValueError(f"Invalid config format in {file_path}") from e
    except UnicodeDecodeError as e:
        log.error(f"Encoding error in {file_path}: {e}")
        raise ValueError(f"Encoding error in config {file_path}") from e

--- END OF FILE ./src/shared/config_loader.py ---

--- START OF FILE ./src/shared/constants.py ---
# src/shared/constants.py
"""
Centralized location for system-wide constant values.
"""

# Maximum allowed file size for system operations (1MB)
MAX_FILE_SIZE_BYTES = 1 * 1024 * 1024

--- END OF FILE ./src/shared/constants.py ---

--- START OF FILE ./src/shared/logger.py ---
# src/shared/logger.py

"""
CORE's Unified Logging System.

This module provides a single, pre-configured logger instance for the entire
application. It uses the 'rich' library to ensure all output is consistent,
beautifully formatted, and informative.

All other modules should import `getLogger` from this file instead of using
print() or configuring their own loggers.
"""

from __future__ import annotations

import logging
import os

from rich.logging import RichHandler

# --- Configuration ---
# Get the log level from the environment, defaulting to INFO
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO").upper()
LOG_FORMAT = "%(message)s"
LOG_DATE_FORMAT = "[%X]"  # e.g., [14:30:55]

# --- Prevent duplicate handlers if this module is reloaded ---
logging.getLogger().handlers = []

# --- Create and configure the handler ---
handler = RichHandler(
    rich_tracebacks=True,
    show_time=True,
    show_level=True,
    show_path=False,
    log_time_format=LOG_DATE_FORMAT,
)

# --- Configure the root logger ---
logging.basicConfig(
    level=LOG_LEVEL,
    format=LOG_FORMAT,
    handlers=[handler],
    force=True,  # Ensure our configuration overwrites any defaults
)

# --- THIS IS THE FIX: Set quieter log levels for noisy libraries ---
# This tells the http client library used by Qdrant to only log warnings and errors.
logging.getLogger("httpx").setLevel(logging.WARNING)
# We can also make our own verbose services quieter by default.
logging.getLogger("qdrant_service").setLevel(logging.WARNING)
# --- END OF FIX ---


# ID: b6a332e8-17ca-4a0a-8699-4eaff466aafe
def getLogger(name: str) -> logging.Logger:
    """
    Returns a pre-configured logger instance.

    Args:
        name (str): The name of the logger, typically __name__ of the calling module.

    Returns:
        logging.Logger: The configured logger.
    """
    return logging.getLogger(name)


# Example of a root-level logger if needed directly
log = getLogger("core_root")

# Set the log level for the root logger from the environment variable
log.setLevel(LOG_LEVEL)

--- END OF FILE ./src/shared/logger.py ---

--- START OF FILE ./src/shared/models/__init__.py ---
# src/shared/models/__init__.py
"""
Makes all Pydantic models in this directory available for easy import.
"""
from __future__ import annotations

from .audit_models import AuditFinding, AuditSeverity
from .capability_models import CapabilityMeta
from .drift_models import DriftReport  # <-- ADD THIS LINE
from .embedding_payload import EmbeddingPayload
from .execution_models import (
    ExecutionTask,
    PlanExecutionError,
    PlannerConfig,
    TaskParams,
)

__all__ = [
    "DriftReport",  # <-- AND ADD THIS LINE
    "EmbeddingPayload",
    "AuditFinding",
    "AuditSeverity",
    "ExecutionTask",
    "PlanExecutionError",
    "PlannerConfig",
    "TaskParams",
    "CapabilityMeta",
]

--- END OF FILE ./src/shared/models/__init__.py ---

--- START OF FILE ./src/shared/models/audit_models.py ---
# src/shared/models/audit_models.py
"""
Defines the Pydantic models for representing the results of a constitutional audit.
"""
from __future__ import annotations

from dataclasses import dataclass, field
from enum import IntEnum  # <-- CHANGED from Enum to IntEnum
from typing import Any, Dict, Optional


# ID: 5ccdae76-2214-413d-8551-13d4b224b694
class AuditSeverity(IntEnum):  # <-- CHANGED from Enum to IntEnum
    """Enumeration for the severity of an audit finding."""

    INFO = 1
    WARNING = 2
    ERROR = 3

    # This allows us to use severity.name in lowercase, e.g., 'info'
    def __str__(self):
        return self.name.lower()

    @property
    # ID: bad8d002-de4c-4b09-900f-0cd784c60242
    def is_blocking(self) -> bool:
        """Returns True if the severity level should block a CI/CD pipeline."""
        return self == AuditSeverity.ERROR


@dataclass
# ID: 1bc3d2f1-466b-49b9-aacd-6fac9e03a068
class AuditFinding:
    """Represents a single finding from a constitutional audit check."""

    check_id: str
    severity: AuditSeverity
    message: str
    file_path: Optional[str] = None
    line_number: Optional[int] = None
    context: Dict[str, Any] = field(default_factory=dict)

    # ID: d638215e-ceb0-421e-b33b-a0b191876530
    def as_dict(self) -> Dict[str, Any]:
        """Serializes the finding to a dictionary for reporting."""
        return {
            "check_id": self.check_id,
            "severity": str(self.severity),
            "message": self.message,
            "file_path": self.file_path,
            "line_number": self.line_number,
            "context": self.context,
        }

--- END OF FILE ./src/shared/models/audit_models.py ---

--- START OF FILE ./src/shared/models/capability_models.py ---
# src/shared/models/capability_models.py
"""
Defines the Pydantic/dataclass models for representing capabilities and
their metadata throughout the system.
"""
from __future__ import annotations

from dataclasses import dataclass
from typing import Optional


@dataclass
# ID: 6c0a8c58-e1f0-4182-9857-1eb3dfa0410e
class CapabilityMeta:
    """
    A dataclass to hold the metadata for a single capability, discovered
    either from manifest files or source code tags.
    """

    key: str
    domain: Optional[str] = None
    owner: Optional[str] = None

--- END OF FILE ./src/shared/models/capability_models.py ---

--- START OF FILE ./src/shared/models/drift_models.py ---
# src/shared/models/drift_models.py
"""
Defines the Pydantic/dataclass models for representing capability drift.
"""
from __future__ import annotations

from dataclasses import asdict, dataclass
from typing import Any, Dict, List


@dataclass
# ID: a8f4575c-a899-4dde-9d8f-c2825eaa7259
class DriftReport:
    """A structured report of the drift between manifest and code."""

    missing_in_code: List[str]
    undeclared_in_manifest: List[str]
    mismatched_mappings: List[Dict]

    # ID: 9db89268-07cb-4bf7-9abe-14df2f0aae8a
    def to_dict(self) -> Dict[str, Any]:
        """Serializes the report to a dictionary."""
        return asdict(self)

--- END OF FILE ./src/shared/models/drift_models.py ---

--- START OF FILE ./src/shared/models/embedding_payload.py ---
# src/shared/models/embedding_payload.py
"""
Defines the Pydantic model for the data payload associated with each
vector stored in the Qdrant database.
"""
from __future__ import annotations

from typing import List, Optional

from pydantic import BaseModel, Field


# ID: 103f4a4c-a895-4de7-b5bf-ce230bcda4aa
class EmbeddingPayload(BaseModel):
    """
    Strict schema for the payload of every vector stored in Qdrant.
    This ensures all stored knowledge is traceable to its origin.
    """

    source_path: str = Field(..., description="Repo-relative path of the source file.")
    source_type: str = Field(
        ..., description="Type of content (e.g., 'code', 'intent')."
    )
    chunk_id: str = Field(
        ..., description="Stable locator for the text chunk (e.g., symbol key)."
    )
    content_sha256: str = Field(
        ..., description="Fingerprint of the normalized chunk text."
    )
    model: str = Field(..., description="Name of the embedding model used.")
    model_rev: str = Field(..., description="Pinned revision of the embedding model.")
    dim: int = Field(..., description="Dimensionality of the vector.")
    created_at: str = Field(..., description="ISO 8601 timestamp of vector creation.")

    # Optional fields for richer context
    language: Optional[str] = Field(None, description="Programming or markup language.")
    symbol: Optional[str] = Field(
        None, description="For code: fully qualified function/class name."
    )
    capability_tags: Optional[List[str]] = Field(
        None, description="Associated capability tags."
    )

--- END OF FILE ./src/shared/models/embedding_payload.py ---

--- START OF FILE ./src/shared/models/execution_models.py ---
# src/shared/models/execution_models.py
"""
Defines the Pydantic models for representing autonomous execution plans and tasks.
"""
from __future__ import annotations

from typing import List, Optional

from pydantic import BaseModel, Field


# ID: 1a71c89f-73f0-436b-ad58-f24cfbdec162
class TaskParams(BaseModel):
    """Parameters for a single task in an execution plan."""

    file_path: str
    code: Optional[str] = None
    symbol_name: Optional[str] = None
    justification: Optional[str] = None
    tag: Optional[str] = None


# ID: 3173b37e-a64f-4227-92c5-84e444b68dc1
class ExecutionTask(BaseModel):
    """A single, validated step in an execution plan."""

    step: str
    action: str
    params: TaskParams


# ID: 73684d31-61e0-4f28-bb94-7134f296371b
class PlannerConfig(BaseModel):
    """Configuration for the Planner and Execution agents."""

    task_timeout: int = Field(default=300, description="Timeout for a single task.")
    rollback_on_failure: bool = Field(default=True, description="Rollback on failure.")
    auto_commit: bool = Field(default=True, description="Auto-commit changes.")


# ID: 1ccf34ef-9cea-4411-91b1-d93457a2b43a
class PlanExecutionError(Exception):
    """Custom exception for errors during plan execution."""

    def __init__(self, message: str, violations: List[dict] | None = None):
        super().__init__(message)
        self.violations = violations or []

--- END OF FILE ./src/shared/models/execution_models.py ---

--- START OF FILE ./src/shared/path_utils.py ---
# src/shared/path_utils.py
"""
Provides utility functions for working with file system paths within the repository structure.
"""

from __future__ import annotations

from pathlib import Path
from typing import Optional


# ID: d302f037-094f-4573-92d0-39dc29c012f6
def get_repo_root(start_path: Optional[Path] = None) -> Path:
    """Find and return the repository root by locating the .git directory, starting from the current directory or provided path."""
    """
    Find and return the repository root by locating the .git directory.
    Starts from current directory or provided path.

    Returns:
        Path: Absolute path to repo root.

    Raises:
        RuntimeError: If no .git directory is found.
    """
    current = Path(start_path or Path.cwd()).resolve()

    # Traverse upward until .git is found
    for parent in [current, *current.parents]:
        if (parent / ".git").exists():
            return parent

    raise RuntimeError("Not a git repository: could not find .git directory")

--- END OF FILE ./src/shared/path_utils.py ---

--- START OF FILE ./src/shared/schemas/manifest_validator.py ---
# src/shared/schemas/manifest_validator.py
"""
Provides utilities for validating manifest entries against JSON schemas using jsonschema.
"""

from __future__ import annotations

import json
from typing import Any, Dict, List, Tuple

import jsonschema

from shared.path_utils import get_repo_root

# --- THIS IS THE FIX ---
# The single source of truth for the location of constitutional schemas.
SCHEMA_DIR = get_repo_root() / ".intent" / "charter" / "schemas"
# --- END OF FIX ---


# ID: cfab52b8-8fed-4536-bc75-ed81a1161331
def load_schema(schema_name: str) -> Dict[str, Any]:
    """
    Load a JSON schema from the .intent/schemas/ directory.

    Args:
        schema_name (str): The filename of the schema (e.g., 'knowledge_graph_entry.schema.json').

    Returns:
        Dict[str, Any]: The loaded JSON schema.

    Raises:
        FileNotFoundError: If the schema file is not found.
        json.JSONDecodeError: If the schema file is not valid JSON.
    """
    schema_path = SCHEMA_DIR / schema_name

    if not schema_path.exists():
        raise FileNotFoundError(f"Schema file not found: {schema_path}")

    try:
        with open(schema_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        raise json.JSONDecodeError(
            f"Invalid JSON in schema file {schema_path}: {e.msg}", e.doc, e.pos
        )


# ID: 047e2cb8-1e18-4175-9be2-1017a2fba3d7
def validate_manifest_entry(
    entry: Dict[str, Any], schema_name: str = "knowledge_graph_entry.schema.json"
) -> Tuple[bool, List[str]]:
    """
    Validate a single manifest entry against a schema.

    Args:
        entry: The dictionary representing a single function/class entry.
        schema_name: The filename of the schema to validate against.

    Returns:
        A tuple of (is_valid: bool, list_of_error_messages: List[str]).
    """
    try:
        schema = load_schema(schema_name)
    except Exception as e:
        return False, [f"Failed to load schema '{schema_name}': {e}"]

    # Use Draft7Validator for compatibility with our schema definition.
    validator = jsonschema.Draft7Validator(schema)
    errors = []

    for error in validator.iter_errors(entry):
        # Create a user-friendly error message
        path = ".".join(str(p) for p in error.absolute_path) or "<root>"
        errors.append(f"Validation error at '{path}': {error.message}")

    is_valid = not errors
    return is_valid, errors

--- END OF FILE ./src/shared/schemas/manifest_validator.py ---

--- START OF FILE ./src/shared/time.py ---
# src/shared/time.py
"""
Lightweight time utilities shared across services.
Implements the canonical capability for a UTC ISO timestamp function.
"""
from __future__ import annotations

from datetime import datetime, timezone


# ID: 4f686bb3-7252-4f74-8e7c-d38a6ec85dc6
def now_iso() -> str:
    """Return current UTC timestamp in ISO 8601 format."""
    return datetime.now(timezone.utc).isoformat()

--- END OF FILE ./src/shared/time.py ---

--- START OF FILE ./src/shared/utils/__init__.py ---
[EMPTY FILE]
--- END OF FILE ./src/shared/utils/__init__.py ---

--- START OF FILE ./src/shared/utils/alias_resolver.py ---
# src/system/guard/alias_resolver.py
"""
Provides a utility for loading and resolving capability aliases from the
constitutionally-defined alias map.

If the alias file is missing or unreadable, this resolver degrades gracefully:
- it logs at DEBUG (not WARNING/ERROR), and
- it returns the identity (no aliasing).
"""
from __future__ import annotations

from pathlib import Path
from typing import Dict, Optional

from shared.config import settings
from shared.config_loader import load_yaml_file
from shared.logger import getLogger

log = getLogger("core_admin.alias_resolver")

__all__ = ["AliasResolver"]


# ID: b0a5e5d3-c7fa-4502-b457-d38addc0e922
class AliasResolver:
    """Loads and resolves capability aliases."""

    def __init__(self, alias_file_path: Optional[Path] = None):
        """
        Initializes the resolver by loading the alias map from the constitution.
        Defaults to reports/aliases.yaml.
        """
        self.alias_map: Dict[str, str] = {}
        path = alias_file_path or (settings.REPO_PATH / "reports" / "aliases.yaml")

        if path.exists():
            try:
                data = load_yaml_file(path)
                self.alias_map = (
                    data.get("aliases", {}) if isinstance(data, dict) else {}
                )
                log.info(
                    "Loaded %d capability aliases from %s.",
                    len(self.alias_map),
                    path,
                )
            except Exception as e:
                # Degrade silently to identity behavior
                self.alias_map = {}
                log.debug(
                    "Failed to load alias map from %s (%s). Proceeding without aliases.",
                    path,
                    e,
                )
        else:
            # No file present -> identity behavior without noise
            self.alias_map = {}
            log.debug(
                "Alias map not found at %s; proceeding without aliases.",
                path,
            )

    # ID: ebad6cf5-b36f-4c50-8e3b-eb2d1c33f289
    def resolve(self, key: str) -> str:
        """
        Resolves a capability key to its canonical name using the alias map.
        If the key is not an alias, it returns the original key.
        """
        return self.alias_map.get(key, key)

--- END OF FILE ./src/shared/utils/alias_resolver.py ---

--- START OF FILE ./src/shared/utils/constitutional_parser.py ---
# src/shared/utils/constitutional_parser.py
"""
Parses the constitutional structure definition from meta.yaml to discover all declared file paths.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Set


# ID: ae492732-1dab-4982-a129-1f7f9af67439
def get_all_constitutional_paths(meta_content: dict, intent_dir: Path) -> Set[str]:
    """
    Recursively discovers all declared constitutional file paths from the parsed
    content of meta.yaml.

    Args:
        meta_content: The dictionary parsed from meta.yaml.
        intent_dir: The path to the .intent directory.

    Returns:
        A set of repo-relative paths (e.g., '.intent/charter/policies/safety_policy.yaml').
    """
    repo_root = intent_dir.parent
    # The path to meta.yaml is known relative to the intent_dir
    known_paths: Set[str] = {
        str((intent_dir / "meta.yaml").relative_to(repo_root)).replace("\\", "/")
    }

    def _recursive_find(data: Any):
        if isinstance(data, dict):
            for value in data.values():
                _recursive_find(value)
        elif isinstance(data, list):
            for item in data:
                _recursive_find(item)
        elif (
            isinstance(data, str)
            and (intent_dir.name not in data)
            and ("/" in data or "\\" in data)
        ):
            # --- THIS IS THE DEFINITIVE FIX ---
            # All paths are constructed relative to the provided intent_dir,
            # removing the hardcoded ".intent".
            full_path = intent_dir / data
            known_paths.add(str(full_path.relative_to(repo_root)).replace("\\", "/"))
            # --- END OF FIX ---

    _recursive_find(meta_content)
    return known_paths

--- END OF FILE ./src/shared/utils/constitutional_parser.py ---

--- START OF FILE ./src/shared/utils/crypto.py ---
# src/shared/utils/crypto.py
"""
Provides shared, constitutionally-governed cryptographic utilities for
tasks like signing and token generation.
"""
from __future__ import annotations

import json
from typing import Any, Dict

from cryptography.hazmat.primitives import hashes


def _get_canonical_payload(proposal: Dict[str, Any]) -> str:
    """
    Creates a stable, sorted JSON string of the proposal's core intent,
    ignoring all other metadata like signatures. This is the single source
    of truth for what gets signed.
    """
    signable_data = {
        "target_path": proposal.get("target_path"),
        "action": proposal.get("action"),
        "justification": proposal.get("justification"),
        "content": proposal.get("content", ""),
    }
    return json.dumps(signable_data, sort_keys=True)


# ID: 38528901-21cb-4bbb-9f77-524beefdf990
def generate_approval_token(proposal: Dict[str, Any]) -> str:
    """
    Produces a deterministic token based on a canonical representation
    of the proposal's intent.
    """
    canonical_string = _get_canonical_payload(proposal)
    digest = hashes.Hash(hashes.SHA256())
    digest.update(canonical_string.encode("utf-8"))

    return f"core-proposal-v6:{digest.finalize().hex()}"

--- END OF FILE ./src/shared/utils/crypto.py ---

--- START OF FILE ./src/shared/utils/embedding_utils.py ---
# src/shared/utils/embedding_utils.py
"""
Provides utilities for handling text embeddings, including chunking and aggregation.
This module ensures that large documents can be processed reliably by embedding models.
"""
from __future__ import annotations

import asyncio
import hashlib
import re
from typing import List, Protocol

import numpy as np

from shared.logger import getLogger

log = getLogger("embedding_utils")

# A reasonable chunk size to avoid overwhelming the embedding model
DEFAULT_CHUNK_SIZE = 512
DEFAULT_CHUNK_OVERLAP = 50


# ID: f48d93d3-7ddf-4df2-8c10-dc63311b9485
class Embeddable(Protocol):
    """Defines the interface for any service that can create embeddings."""

    # ID: ac2f3e7e-34f5-44b6-80b1-dce2e7160c2e
    async def get_embedding(self, text: str) -> List[float]: ...


class _Adapter:
    """Internal adapter to make EmbeddingService conform to the Embeddable protocol."""

    def __init__(self, service):
        self._service = service

    # ID: 5a628ba4-df9b-4e8e-9ecc-9e74dc125b1f
    async def get_embedding(self, text: str) -> List[float]:
        return await self._service.get_embedding(text)


def _chunk_text(text: str, chunk_size: int, chunk_overlap: int) -> List[str]:
    """Splits text into overlapping chunks."""
    if not text:
        return []

    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunks.append(text[start:end])
        start += chunk_size - chunk_overlap
    return chunks


# ID: a652ae56-dc5d-47a9-90ea-7f873ca9239a
def normalize_text(text: str) -> str:
    """
    Applies a deterministic normalization process to text to ensure
    consistent hashing for content change detection.
    """
    if not isinstance(text, str):
        return ""
    # 1. Replace CRLF with LF
    # 2. Strip leading/trailing whitespace from the whole block
    # 3. Collapse multiple blank lines into a single blank line
    return re.sub(r"\n{3,}", "\n\n", text.replace("\r\n", "\n").strip())


# ID: 46703a51-3079-42fe-9bf7-e9724b009949
def sha256_hex(text: str) -> str:
    """Computes the SHA256 hex digest for a string."""
    return hashlib.sha256(text.encode("utf-8")).hexdigest()


# ID: 95c51c61-f288-483c-b76e-2915765004da
async def chunk_and_embed(
    embedder: Embeddable,
    text: str,
    chunk_size: int = DEFAULT_CHUNK_SIZE,
    chunk_overlap: int = DEFAULT_CHUNK_OVERLAP,
) -> np.ndarray:
    """
    Chunks text, gets embeddings for each chunk in parallel, and returns the
    averaged embedding vector for the entire text.
    """
    chunks = _chunk_text(text, chunk_size, chunk_overlap)
    if not chunks:
        # Should not happen with valid text, but as a safeguard
        raise ValueError("Cannot generate embedding for empty text.")

    embedding_tasks = [embedder.get_embedding(chunk) for chunk in chunks]
    chunk_vectors = await asyncio.gather(*embedding_tasks)

    # Convert list of lists to a 2D numpy array for easy averaging
    vector_array = np.array(chunk_vectors, dtype=np.float32)

    # Calculate the mean vector across the chunk dimension (axis=0)
    mean_vector = np.mean(vector_array, axis=0)

    # Normalize the final vector to unit length
    norm = np.linalg.norm(mean_vector)
    if norm == 0:
        return mean_vector  # Avoid division by zero

    normalized_vector = mean_vector / norm
    return normalized_vector

--- END OF FILE ./src/shared/utils/embedding_utils.py ---

--- START OF FILE ./src/shared/utils/header_tools.py ---
# src/shared/utils/header_tools.py
"""
Provides a deterministic tool for parsing and reconstructing Python file headers
according to CORE's constitutional style guide.
"""
from __future__ import annotations

from dataclasses import dataclass, field
from typing import List, Optional


@dataclass
# ID: 4a498b02-ef0b-4ce2-bd66-d8289669cd8f
class HeaderComponents:
    """A data class to hold the parsed components of a Python file header."""

    location: Optional[str] = None
    module_description: Optional[str] = None
    has_future_import: bool = False
    other_imports: List[str] = field(default_factory=list)
    body: List[str] = field(default_factory=list)


# ID: 3f524d93-83cd-41bd-b5e2-38a7703d39d4
class HeaderTools:
    """A stateless utility class for parsing and reconstructing file headers."""

    @staticmethod
    # ID: 8f8fa33d-1ab8-4ee8-8dc7-a71355167611
    def parse(source_code: str) -> HeaderComponents:
        """Parses the source code and extracts header components."""
        components = HeaderComponents()
        lines = source_code.splitlines()
        state = "start"
        docstring_lines = []

        for line in lines:
            if state == "start":
                if line.strip().startswith("#") and ("/" in line or "\\" in line):
                    components.location = line
                    state = "location_found"
                else:  # No header found, treat everything as body
                    components.body.append(line)
                    state = "body_started"

            elif state == "location_found":
                if not line.strip():
                    continue  # Skip blank lines
                if '"""' in line or "'''" in line:
                    docstring_lines.append(line)
                    if line.count('"""') == 2 or line.count("'''") == 2:
                        state = "docstring_done"
                    else:
                        state = "in_docstring"
                else:
                    components.body.append(line)
                    state = "body_started"

            elif state == "in_docstring":
                docstring_lines.append(line)
                if '"""' in line or "'''" in line:
                    state = "docstring_done"

            elif state == "docstring_done":
                if not line.strip():
                    continue
                if "from __future__ import annotations" in line:
                    components.has_future_import = True
                    state = "future_import_found"
                else:
                    components.body.append(line)
                    state = "body_started"

            elif state == "future_import_found":
                if line.strip().startswith("from") or line.strip().startswith("import"):
                    components.other_imports.append(line)
                else:
                    components.body.append(line)
                    state = "body_started"

            elif state == "body_started":
                components.body.append(line)

        if docstring_lines:
            components.module_description = "\n".join(docstring_lines)

        # --- START OF FIX ---
        # Strip future import from body if it was misplaced and rename variable 'l' to 'line'.
        body_without_future = [
            line
            for line in components.body
            if "from __future__ import annotations" not in line
        ]
        # --- END OF FIX ---
        if len(body_without_future) < len(components.body):
            components.has_future_import = True
            components.body = body_without_future

        return components

    @staticmethod
    # ID: e85d9dde-b46f-43f7-b83f-106a63103c48
    def reconstruct(components: HeaderComponents) -> str:
        """Reconstructs the source code from its parsed components."""
        parts = []
        if components.location:
            parts.append(components.location)

        if components.module_description:
            if parts:
                parts.append("")
            parts.append(components.module_description)

        if components.has_future_import:
            if parts:
                parts.append("")
            parts.append("from __future__ import annotations")

        if components.other_imports:
            parts.extend(components.other_imports)

        if components.body:
            if parts and (parts[-1] != "" or components.body[0] != ""):
                parts.append("")
            parts.extend(components.body)

        return "\n".join(parts) + "\n"

--- END OF FILE ./src/shared/utils/header_tools.py ---

--- START OF FILE ./src/shared/utils/import_scanner.py ---
# src/shared/utils/import_scanner.py
"""
Scans Python files to extract top-level import statements.
"""

from __future__ import annotations

import ast
from pathlib import Path
from typing import List

from shared.logger import getLogger

log = getLogger(__name__)


# ID: fd3f890e-c234-4942-afb0-3b7551d393b9
def scan_imports_for_file(file_path: Path) -> List[str]:
    """
    Parse a Python file and extract all imported module paths.

    Args:
        file_path (Path): Path to the file.

    Returns:
        List[str]: List of imported module paths.
    """
    imports = []
    try:
        source = file_path.read_text(encoding="utf-8")
        tree = ast.parse(source)

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)

    except Exception as e:
        log.warning(f"Failed to scan imports for {file_path}: {e}", exc_info=True)

    return imports

--- END OF FILE ./src/shared/utils/import_scanner.py ---

--- START OF FILE ./src/shared/utils/manifest_aggregator.py ---
# src/shared/utils/manifest_aggregator.py

"""
Aggregates domain-specific capability definitions from the constitution into a unified view.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict

import yaml

from shared.logger import getLogger

log = getLogger("manifest_aggregator")


# ID: 5f0549df-0ce5-468a-a232-c61663724a77
def aggregate_manifests(repo_root: Path) -> Dict[str, Any]:
    """
    Finds all domain-specific capability definition YAML files and merges them.
    This is "canary-aware": if a 'reports/proposed_manifests' directory
    exists, it will be used as the source of truth instead of the live
    '.intent/knowledge/domains' manifests.

    Args:
        repo_root (Path): The absolute path to the repository root.

    Returns:
        A dictionary representing the aggregated manifest.
    """
    # --- THIS IS THE FIX: Changed from log.info to log.debug ---
    log.debug(
        "🔍 Starting manifest aggregation by searching all constitutional sources..."
    )
    all_capabilities = []
    manifests_found = 0

    proposed_manifests_dir = repo_root / "reports" / "proposed_manifests"
    live_manifests_dir = repo_root / ".intent" / "knowledge" / "domains"

    if proposed_manifests_dir.is_dir() and any(proposed_manifests_dir.iterdir()):
        search_dir = proposed_manifests_dir
        log.warning(
            "   -> ⚠️ Found proposed manifests. Auditor will use these for validation."
        )
    else:
        search_dir = live_manifests_dir

    if search_dir.is_dir():
        for domain_file in sorted(search_dir.glob("*.yaml")):
            manifests_found += 1
            log.debug(f"   -> Loading capabilities from: {domain_file.name}")
            try:
                domain_manifest = yaml.safe_load(domain_file.read_text()) or {}
                if "tags" in domain_manifest and isinstance(
                    domain_manifest["tags"], list
                ):
                    all_capabilities.extend(domain_manifest["tags"])
            except yaml.YAMLError as e:
                log.error(
                    f"   -> ❌ Skipping invalid YAML file: {domain_file.name} - {e}"
                )
                continue

    log.debug(f"   -> Aggregated capabilities from {manifests_found} domain manifests.")

    monolith_path = repo_root / ".intent" / "project_manifest.yaml"
    monolith_data = {}
    if monolith_path.exists():
        monolith_data = yaml.safe_load(monolith_path.read_text())

    unique_caps = set()
    for item in all_capabilities:
        if isinstance(item, str):
            unique_caps.add(item)
        elif isinstance(item, dict) and "key" in item:
            unique_caps.add(item["key"])

    unique_caps.update(monolith_data.get("required_capabilities", []))

    return {
        "name": monolith_data.get("name", "CORE"),
        "intent": monolith_data.get("intent", "No intent provided."),
        "active_agents": monolith_data.get("active_agents", []),
        "required_capabilities": sorted(list(unique_caps)),
    }

--- END OF FILE ./src/shared/utils/manifest_aggregator.py ---

--- START OF FILE ./src/shared/utils/parallel_processor.py ---
# src/shared/utils/parallel_processor.py
"""
Provides a reusable, throttled parallel processor for running async tasks
concurrently with a progress bar, governed by a constitutional limit.
"""

from __future__ import annotations

import asyncio
from typing import Awaitable, Callable, List, TypeVar

from rich.progress import track

from shared.config import settings
from shared.logger import getLogger

log = getLogger("parallel_processor")
T = TypeVar("T")
R = TypeVar("R")


# ID: c88b0e64-3e38-4fef-983e-cd59281e53e0
class ThrottledParallelProcessor:
    """
    A dedicated executor for running a worker function over a list of items
    in parallel, with concurrency limited by the constitution.
    """

    def __init__(self, description: str = "Processing items..."):
        """
        Initializes the processor.
        """
        self.concurrency_limit = settings.CORE_MAX_CONCURRENT_REQUESTS
        self.description = description
        log.info(
            f"ThrottledParallelProcessor initialized with concurrency limit: "
            f"{self.concurrency_limit}"
        )

    async def _process_items_async(
        self, items: List[T], worker_fn: Callable[[T], Awaitable[R]]
    ) -> List[R]:
        """The core async logic for processing items in parallel."""
        semaphore = asyncio.Semaphore(self.concurrency_limit)
        results = []

        async def _worker(item: T) -> R:
            async with semaphore:
                return await worker_fn(item)

        tasks = [asyncio.create_task(_worker(item)) for item in items]

        # Use track for a visual progress bar in the console
        for task in track(
            asyncio.as_completed(tasks), description=self.description, total=len(items)
        ):
            results.append(await task)

        return results

    # --- START: THE DEFINITIVE FIX ---
    # ID: dee1af19-41c8-49c6-ba11-a109746795b7
    async def run_async(
        self, items: List[T], worker_fn: Callable[[T], Awaitable[R]]
    ) -> List[R]:
        """
        Asynchronous entry point to run the worker over all items.
        To be used when called from an already-running async function.
        """
        return await self._process_items_async(items, worker_fn)

    # ID: 466317ce-4caa-4c49-a466-5389d9c25874
    def run_sync(
        self, items: List[T], worker_fn: Callable[[T], Awaitable[R]]
    ) -> List[R]:
        """
        Synchronous entry point to run the async worker over all items.
        This will start and manage its own asyncio event loop.
        """
        return asyncio.run(self._process_items_async(items, worker_fn))

    # --- END: THE DEFINITIVE FIX ---

--- END OF FILE ./src/shared/utils/parallel_processor.py ---

--- START OF FILE ./src/shared/utils/parsing.py ---
# src/shared/utils/parsing.py
"""
Shared utilities for parsing structured data from unstructured text,
primarily from Large Language Model (LLM) outputs.
"""

from __future__ import annotations

import json
import re
from typing import Dict, List, Optional


# ID: f2bd2480-f310-4090-ac1a-58ce05bfc4d3
def extract_json_from_response(text: str) -> Optional[Dict | List]:
    """
    Extracts a JSON object or array from a raw text response.
    Handles markdown code blocks (```json) and raw JSON.
    Returns None if no valid JSON is found.
    """
    # Pattern for JSON within a markdown block, now more lenient
    match = re.search(
        r"```(json)?\s*(\{[\s\S]*?\}|\[[\s\S]*?\])\s*```", text, re.DOTALL
    )
    if match:
        # Group 2 will contain the JSON object or array
        json_str = match.group(2)
        try:
            return json.loads(json_str)
        except json.JSONDecodeError:
            pass  # Fall through to the next method if parsing fails

    # Fallback: Find the first '{' or '[' and try to parse from there
    try:
        start_brace = text.find("{")
        start_bracket = text.find("[")

        if start_brace == -1 and start_bracket == -1:
            return None

        if start_brace != -1 and (start_bracket == -1 or start_brace < start_bracket):
            start_index = start_brace
        else:
            start_index = start_bracket

        decoder = json.JSONDecoder()
        obj, _ = decoder.raw_decode(text[start_index:])
        return obj
    except (json.JSONDecodeError, ValueError):
        pass

    return None


# ID: 853be68b-f2d4-4494-bf4c-98200bc08026
def parse_write_blocks(text: str) -> Dict[str, str]:
    """
    Parses a string for one or more [[write:file_path]]...[[/write]] blocks.

    Args:
        text: The raw string output from an LLM.

    Returns:
        A dictionary where keys are file paths and values are the code blocks.
    """
    # Regex to find all occurrences of the write block pattern.
    # It captures the file path and the content between the tags.
    # re.DOTALL allows '.' to match newlines, which is crucial for multi-line code.
    pattern = re.compile(r"\[\[write:(.+?)\]\]\s*\n(.*?)\n\s*\[\[/write\]\]", re.DOTALL)

    matches = pattern.findall(text)

    # Return a dictionary comprehension of the found (path, content) tuples.
    # .strip() on the path and content cleans up any minor whitespace issues.
    return {path.strip(): content.strip() for path, content in matches}

--- END OF FILE ./src/shared/utils/parsing.py ---

--- START OF FILE ./src/shared/utils/yaml_processor.py ---
# src/shared/utils/yaml_processor.py
"""

Centralized YAML processor for constitutional compliance, providing consistent
parsing and validation of .intent/ files across all governance checks and tools.

This utility enforces dry_by_design by eliminating duplicate YAML loading logic
and provides constitutional features like:
- Safe loading with error context
- Duplicate key tolerance for diagnostic tools
- Schema validation hooks for future use
- Audit-friendly error reporting

All governance checks (manifest_lint, domain_placement, etc.) use this processor
to ensure consistent behavior and error handling across the constitutional audit
pipeline.
"""

from __future__ import annotations

from pathlib import Path
from typing import Any, Dict, Optional

from ruamel.yaml import YAML

from shared.logger import getLogger

log = getLogger("yaml_processor")


# ID: b824d032-49d4-486b-9182-99a76c78843f
class YAMLProcessor:
    """Centralized YAML processor for constitutional file operations."""

    def __init__(self, allow_duplicates: bool = False) -> None:
        """Initialize the YAML processor with constitutional configuration.

        Args:
            allow_duplicates: If True, allows duplicate keys for diagnostic tools
                             (default: False for strict constitutional compliance)
        """
        self.allow_duplicates = allow_duplicates
        self.yaml = YAML(typ="safe")
        if allow_duplicates:
            self.yaml.allow_duplicate_keys = True
            log.debug(
                "YAML processor configured for duplicate key tolerance (diagnostic mode)"
            )
        else:
            log.debug("YAML processor configured for strict constitutional compliance")

    # ID: 78d97bea-bfa3-49b2-ba62-8e4093d84fb0
    def load(self, file_path: Path) -> Optional[Dict[str, Any]]:
        """Load and parse a constitutional YAML file with error context.

        This is the single entry point for all YAML loading in governance checks,
        ensuring consistent error handling and logging.

        Args:
            file_path: Path to the .intent/ YAML file (e.g., domain manifests, policies)

        Returns:
            Parsed YAML content as dict, or None if file doesn't exist

        Raises:
            ValueError: If file exists but has invalid YAML structure
            OSError: If file system errors occur during reading
        """
        if not file_path.exists():
            log.debug(f"YAML file not found (non-error): {file_path}")
            return None

        try:
            log.debug(f"Loading YAML from: {file_path}")
            with file_path.open("r", encoding="utf-8") as f:
                content = self.yaml.load(f)

            if content is None:
                log.warning(f"YAML file is empty: {file_path}")
                return {}

            if not isinstance(content, dict):
                raise ValueError(
                    f"YAML root must be a mapping (dict), got {type(content).__name__}: {file_path}"
                )

            log.debug(f"Successfully loaded YAML: {file_path} ({len(content)} keys)")
            return content

        except Exception as e:
            log.error(f"YAML parsing failed for {file_path}: {e}")
            raise ValueError(
                f"Failed to parse constitutional YAML {file_path}: {e}"
            ) from e

    # ID: 7e913478-a8e9-4e75-bd12-54f2264487c6
    def load_strict(self, file_path: Path) -> Dict[str, Any]:
        """Load YAML with strict constitutional validation (no duplicate keys).

        Use for policy files and schemas where duplicate keys indicate errors.

        Args:
            file_path: Path to the .intent/ YAML file

        Returns:
            Parsed YAML content as dict

        Raises:
            ValueError: If file doesn't exist, has invalid structure, or contains duplicate keys
        """
        if self.allow_duplicates:
            raise ValueError(
                "Cannot use strict mode with duplicate key tolerance enabled"
            )

        content = self.load(file_path)
        if content is None:
            raise ValueError(f"Required constitutional file missing: {file_path}")

        return content

    # ID: 91acfb90-7639-41f3-b1cc-064e7d8a0d46
    def dump(self, data: Dict[str, Any], file_path: Path) -> None:
        """Write YAML content with constitutional formatting.

        Ensures consistent formatting for .intent/ files, preserving order and
        avoiding unnecessary whitespace.

        Args:
            data: Dict to write as YAML
            file_path: Path to write the YAML file

        Raises:
            OSError: If file system errors occur during writing
        """
        file_path.parent.mkdir(parents=True, exist_ok=True)

        try:
            log.debug(f"Dumping YAML to: {file_path}")
            with file_path.open("w", encoding="utf-8") as f:
                self.yaml.dump(data, f)
            log.debug(f"Successfully wrote YAML: {file_path}")
        except Exception as e:
            log.error(f"YAML write failed for {file_path}: {e}")
            raise OSError(
                f"Failed to write constitutional YAML {file_path}: {e}"
            ) from e


# Global instance for convenience (used by all governance checks)
# This follows the constitutional pattern of shared singletons for utilities
yaml_processor = YAMLProcessor(
    allow_duplicates=True
)  # Diagnostic tools need duplicate tolerance

# Strict processor for policy/schema validation
strict_yaml_processor = YAMLProcessor(allow_duplicates=False)

--- END OF FILE ./src/shared/utils/yaml_processor.py ---

--- START OF FILE ./tests/admin/test_guard_drift_cli.py ---
# tests/admin/test_guard_drift_cli.py
from __future__ import annotations

from pathlib import Path
from unittest.mock import AsyncMock

import pytest

from features.introspection.drift_service import run_drift_analysis_async
from shared.models import CapabilityMeta


def write(p: Path, text: str) -> None:
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(text, encoding="utf-8")


@pytest.mark.anyio
async def test_drift_analysis_clean(tmp_path: Path, mocker):
    """
    Tests that drift analysis reports a clean state when manifest and
    (mocked) code capabilities are in sync.
    """
    # ARRANGE
    # Mock the two data sources the service uses.
    # --- THIS IS THE FIX ---
    # The mocked return value MUST be a dictionary mapping strings to CapabilityMeta instances.
    mocker.patch(
        "features.introspection.drift_service.load_manifest_capabilities",
        return_value={
            "alpha.cap": CapabilityMeta(key="alpha.cap"),
            "beta.cap": CapabilityMeta(key="beta.cap"),
        },
    )
    # --- END OF FIX ---

    mock_graph_data = {
        "symbols": {
            "file1::func_a": {"key": "alpha.cap"},
            "file2::func_b": {"key": "beta.cap"},
        }
    }
    mocker.patch(
        "core.knowledge_service.KnowledgeService.get_graph",
        new_callable=AsyncMock,
        return_value=mock_graph_data,
    )

    # ACT
    report = await run_drift_analysis_async(tmp_path)

    # ASSERT
    assert not report.missing_in_code
    assert not report.undeclared_in_manifest
    assert not report.mismatched_mappings


@pytest.mark.anyio
async def test_drift_analysis_detects_drift(tmp_path: Path, mocker):
    """
    Tests that drift analysis correctly identifies discrepancies between
    the manifest and the (mocked) code capabilities.
    """
    # ARRANGE
    # Mock the manifest to declare one capability
    # --- THIS IS THE FIX ---
    mocker.patch(
        "features.introspection.drift_service.load_manifest_capabilities",
        return_value={"manifest.only.cap": CapabilityMeta(key="manifest.only.cap")},
    )
    # --- END OF FIX ---

    # Mock the code scan to find a different capability
    mock_graph_data = {"symbols": {"file1::func_a": {"key": "code.only.cap"}}}
    mocker.patch(
        "core.knowledge_service.KnowledgeService.get_graph",
        new_callable=AsyncMock,
        return_value=mock_graph_data,
    )

    # ACT
    report = await run_drift_analysis_async(tmp_path)

    # ASSERT
    assert report.missing_in_code == ["manifest.only.cap"]
    assert report.undeclared_in_manifest == ["code.only.cap"]

--- END OF FILE ./tests/admin/test_guard_drift_cli.py ---

--- START OF FILE ./tests/api/test_knowledge_api.py ---
# tests/api/test_knowledge_api.py
"""
Tests for the /knowledge API endpoints.
"""
from unittest.mock import AsyncMock

import pytest
from fastapi.testclient import TestClient

from core.main import app


# Use pytest.mark.anyio to run this test in an async context
@pytest.mark.anyio
async def test_list_capabilities_endpoint(mocker):
    """
    Tests the GET /knowledge/capabilities endpoint, mocking the service layer.
    """
    # 1. Arrange: Mock the KnowledgeService's async method to return a specific list.
    expected_capabilities = ["system.test.alpha", "system.test.beta"]
    mocker.patch(
        "core.knowledge_service.KnowledgeService.list_capabilities",
        new_callable=AsyncMock,
        return_value=expected_capabilities,
    )

    # 2. Act: Use the TestClient within the app's lifespan context manager.
    # This ensures the startup events (and service initializations) are run.
    with TestClient(app) as client:
        response = client.get("/knowledge/capabilities")

    # 3. Assert: Check the response.
    assert response.status_code == 200
    response_data = response.json()

    assert "capabilities" in response_data
    assert response_data["capabilities"] == expected_capabilities

--- END OF FILE ./tests/api/test_knowledge_api.py ---

--- START OF FILE ./tests/conftest.py ---
# tests/conftest.py
"""
Global test configuration and fixtures for pytest.
"""
from __future__ import annotations

from unittest.mock import AsyncMock

import pytest


@pytest.fixture(autouse=True)
def mock_embedding_service(mocker):
    """
    Automatically mocks the EmbeddingService for all tests to prevent
    slow, real network calls.

    This fixture replaces the `get_embedding` method with an async mock that
    returns a valid-looking vector of the correct dimension (768) instantly.
    This makes tests fast, reliable, and independent of external services.
    """
    # FIX 1: The vector dimension must match the project's configuration (768).
    fake_vector = [0.0] * 768

    # FIX 2: The path to the EmbeddingService has changed after the refactoring.
    mocker.patch(
        "services.adapters.embedding_provider.EmbeddingService.get_embedding",
        new_callable=AsyncMock,
        return_value=fake_vector,
    )

--- END OF FILE ./tests/conftest.py ---

--- START OF FILE ./tests/core/test_cognitive_service.py ---
# tests/core/test_cognitive_service.py
"""
Integration tests for the CognitiveService to ensure it correctly uses the
DeductionAgent to make policy-driven decisions.
"""

from __future__ import annotations

from pathlib import Path
from unittest.mock import patch

import pytest
import yaml

from core.cognitive_service import CognitiveService
from shared.config import Settings


@pytest.fixture
def mock_constitution(tmp_path: Path) -> Path:
    intent_dir = tmp_path / ".intent"
    (intent_dir / "charter" / "policies").mkdir(parents=True)  # Policies are in charter
    (intent_dir / "mind" / "knowledge").mkdir(parents=True)  # Knowledge is in mind

    # --- FIX: Policy is now agent_policy.yaml ---
    agent_policy = {
        "resource_selection": {
            "scoring_weights": {
                "cost": 0.8,
                "speed": 0.2,
                "quality": 0.0,
                "reasoning": 0.0,
            }
        }
    }
    (intent_dir / "charter" / "policies" / "agent_policy.yaml").write_text(
        yaml.dump(agent_policy)
    )

    resource_manifest = {
        "llm_resources": [
            {
                "name": "expensive_high_quality_model",
                "env_prefix": "EXPENSIVE",
                "provided_capabilities": ["natural_language_understanding"],
                "performance_metadata": {
                    "cost_rating": 5,
                    "speed_rating": 1,
                    "quality_rating": 5,
                    "reasoning_rating": 5,
                },
            },
            {
                "name": "cheap_fast_model",
                "env_prefix": "CHEAP",
                "provided_capabilities": ["natural_language_understanding"],
                "performance_metadata": {
                    "cost_rating": 1,
                    "speed_rating": 5,
                    "quality_rating": 2,
                    "reasoning_rating": 2,
                },
            },
        ]
    }
    (intent_dir / "mind" / "knowledge" / "resource_manifest.yaml").write_text(
        yaml.dump(resource_manifest)
    )
    cognitive_roles = {
        "cognitive_roles": [
            {
                "role": "Proofreader",
                "description": "A test role",
                "assigned_resource": "cheap_fast_model",  # This is now just a default
                "required_capabilities": ["natural_language_understanding"],
            }
        ]
    }
    (intent_dir / "mind" / "knowledge" / "cognitive_roles.yaml").write_text(
        yaml.dump(cognitive_roles)
    )
    return tmp_path


def test_cognitive_service_selects_cheapest_model_based_on_policy(
    mock_constitution: Path, monkeypatch
):
    """
    Verify that the CognitiveService, guided by the DeductionAgent, selects the
    resource that best matches the scoring policy (in this case, prioritizing cost).
    """
    monkeypatch.setenv("CHEAP_API_URL", "http://cheap.api")
    monkeypatch.setenv("CHEAP_API_KEY", "cheap_key")
    monkeypatch.setenv("CHEAP_MODEL_NAME", "cheap-model")
    monkeypatch.setenv("EXPENSIVE_API_URL", "http://expensive.api")
    monkeypatch.setenv("EXPENSIVE_API_KEY", "expensive_key")
    monkeypatch.setenv("EXPENSIVE_MODEL_NAME", "expensive-model")

    test_settings = Settings(
        REPO_PATH=mock_constitution,
        MIND=mock_constitution / ".intent",
        CHEAP_API_URL="http://cheap.api",
        CHEAP_API_KEY="cheap_key",
        CHEAP_MODEL_NAME="cheap-model",
        EXPENSIVE_API_URL="http://expensive.api",
        EXPENSIVE_API_KEY="expensive_key",
        EXPENSIVE_MODEL_NAME="expensive-model",
        _env_file=None,
    )

    # --- FIX: Update the patch paths ---
    with patch("core.agents.deduction_agent.settings", test_settings), patch(
        "core.cognitive_service.settings", test_settings
    ):
        service = CognitiveService(repo_path=mock_constitution)
        client = service.get_client_for_role("Proofreader")

        assert client.model_name == "cheap-model"
        assert "cheap.api" in client.base_url

--- END OF FILE ./tests/core/test_cognitive_service.py ---

--- START OF FILE ./tests/governance/test_local_mode_governance.py ---
# tests/governance/test_local_mode_governance.py
"""
Tests to ensure that CORE's governance principles are correctly
reflected in its configuration files.
"""
from shared.config_loader import load_yaml_file
from shared.path_utils import get_repo_root


def test_local_fallback_requires_git_checkpoint():
    """Ensure local_mode.yaml correctly enforces Git validation."""
    repo_root = get_repo_root()
    # --- THIS IS THE FIX ---
    # The config file now lives in the 'mind' directory.
    config_path = repo_root / ".intent" / "mind" / "config" / "local_mode.yaml"
    # --- END OF FIX ---

    # Check that the file actually exists before testing its content
    assert config_path.exists(), "local_mode.yaml configuration file is missing."

    config = load_yaml_file(config_path)

    # This is a critical safety check: local mode must not bypass Git commits.
    ignore_validation = config.get("apis", {}).get("git", {}).get("ignore_validation")
    assert (
        ignore_validation is False
    ), "CRITICAL: local_mode.yaml is configured to ignore Git validation."

--- END OF FILE ./tests/governance/test_local_mode_governance.py ---

--- START OF FILE ./tests/integration/test_full_run.py ---
# tests/integration/test_full_run.py
"""
An end-to-end integration test for the CORE system.
"""

import json
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock

import pytest
import yaml
from fastapi.testclient import TestClient

from core.main import app
from shared import config


@pytest.fixture
def mock_cognitive_service(mocker):
    """Mocks the CognitiveService to return mock clients with async methods."""
    mock_service = MagicMock()
    planner_client = MagicMock()
    planner_client.make_request.return_value = json.dumps(
        [
            {
                "step": "Create a simple Python file.",
                "action": "create_file",
                "params": {"file_path": "src/hello.py", "code": "print('hello')"},
            }
        ]
    )
    execution_client = MagicMock()
    execution_client.make_request_async = AsyncMock(return_value="print('hello world')")

    def get_client_side_effect(role_name, task_context=None):
        return planner_client if role_name == "Planner" else execution_client

    mock_service.get_client_for_role.side_effect = get_client_side_effect

    mocker.patch("core.main.CognitiveService", return_value=mock_service)
    return mock_service


@pytest.fixture
def test_git_repo(tmp_path: Path, monkeypatch, mocker):
    """
    Creates a temporary, valid Git repository with a complete and valid
    mock constitution for integration testing.
    """
    import subprocess

    subprocess.run(["git", "init"], cwd=tmp_path, check=True, capture_output=True)

    monkeypatch.setenv("REPO_PATH", str(tmp_path))
    monkeypatch.setenv("DATABASE_URL", f"sqlite+aiosqlite:///{tmp_path}/test.db")

    intent_dir = tmp_path / ".intent"
    charter_dir = intent_dir / "charter"
    mind_dir = intent_dir / "mind"

    (charter_dir / "policies").mkdir(parents=True, exist_ok=True)
    (mind_dir / "knowledge").mkdir(parents=True, exist_ok=True)
    (mind_dir / "prompts").mkdir(parents=True, exist_ok=True)
    (mind_dir / "config").mkdir(parents=True, exist_ok=True)
    (tmp_path / "src").mkdir(exist_ok=True)
    (tmp_path / "reports").mkdir(exist_ok=True)

    # Minimal charter policies
    (charter_dir / "policies" / "agent_policy.yaml").write_text(
        yaml.dump({"rules": []})
    )
    (charter_dir / "policies" / "safety_policy.yaml").write_text(
        yaml.dump({"rules": []})
    )
    (charter_dir / "policies" / "agent_behavior_policy.yaml").write_text(
        yaml.dump({"execution_agent": {"max_correction_attempts": 1}})
    )

    # Minimal mind knowledge
    (mind_dir / "knowledge" / "source_structure.yaml").write_text(
        yaml.dump({"structure": []})
    )
    (mind_dir / "knowledge" / "cognitive_roles.yaml").write_text(
        yaml.dump({"cognitive_roles": []})
    )
    (mind_dir / "knowledge" / "resource_manifest.yaml").write_text(
        yaml.dump({"llm_resources": []})
    )

    (mind_dir / "prompts" / "planner_agent.prompt").write_text("Goal: {goal}")

    (mind_dir / "config" / "actions.yaml").write_text(
        yaml.dump(
            {
                "actions": [
                    {
                        "name": "create_file",
                        "description": "Creates a file.",
                        "required_parameters": ["file_path", "code"],
                    }
                ]
            }
        )
    )

    meta_content = {
        "charter": {
            "policies": {
                "agent_policy": "charter/policies/agent_policy.yaml",
                "safety_policy": "charter/policies/safety_policy.yaml",
            }
        }
    }
    (intent_dir / "meta.yaml").write_text(yaml.dump(meta_content))

    # Mock the async graph loading to prevent real DB calls in this test
    mocker.patch(
        "core.knowledge_service.KnowledgeService._get_graph_from_db",
        new_callable=AsyncMock,
        return_value={"symbols": {}},
    )

    monkeypatch.setattr(config.settings, "MIND", intent_dir)

    monkeypatch.chdir(tmp_path)
    return tmp_path


def test_execute_goal_end_to_end(mock_cognitive_service, test_git_repo, mocker):
    """Tests the /execute_goal endpoint with a mocked cognitive service."""

    mocker.patch(
        "core.agents.plan_executor.PlanExecutor.execute_plan",
        new_callable=AsyncMock,
        return_value=(True, "Plan executed successfully."),
    )

    # --- THIS IS THE FIX ---
    # We now run the TestClient inside the app's lifespan context
    with TestClient(app) as client:
        response = client.post(
            "/execute_goal", json={"goal": "Create a hello world script"}
        )

        assert response.status_code == 200
        assert response.json()["status"] == "success"
    # --- END OF FIX ---

--- END OF FILE ./tests/integration/test_full_run.py ---

--- START OF FILE ./tests/unit/test_agent_utils.py ---
# tests/unit/test_agent_utils.py
import re
import textwrap

import pytest

from core.agents.code_editor import CodeEditor


@pytest.fixture
def code_editor():
    """Provides an instance of the CodeEditor."""
    return CodeEditor()


@pytest.fixture
def sample_code():
    """Provides a sample Python code snippet for testing."""
    return textwrap.dedent(
        """
        # A sample file
        import os

        class MyClass:
            def method_one(self):
                \"\"\"This is the first method.\"\"\"
                return 1

        def top_level_function(a, b):
            \"\"\"A function at the top level.\"\"\"
            return a + b
    """
    )


def test_replace_simple_function(code_editor, sample_code):
    """Tests replacing a top-level function with a new version."""
    new_function_code = textwrap.dedent(
        """
        def top_level_function(a, b):
            \"\"\"A modified function.\"\"\"
            # Added a comment
            return a * b  # Changed the operation
    """
    )
    modified_code = code_editor.replace_symbol_in_code(
        sample_code, "top_level_function", new_function_code
    )

    assert "return a * b" in modified_code
    assert "return a + b" not in modified_code
    assert "class MyClass:" in modified_code
    assert "method_one" in modified_code
    assert "# A sample file" in modified_code


def test_replace_method_in_class(code_editor, sample_code):
    """Tests replacing a method within a class."""
    new_method_code = textwrap.dedent(
        """
        def method_one(self):
            \"\"\"A new docstring for the method.\"\"\"
            return 100
    """
    )
    modified_code = code_editor.replace_symbol_in_code(
        sample_code, "method_one", new_method_code
    )

    assert "return 100" in modified_code
    assert not re.search(r"(?m)^\s*return\s+1\s*$", modified_code)
    assert "top_level_function" in modified_code
    assert "class MyClass:" in modified_code


def test_replace_symbol_not_found_raises_error(code_editor, sample_code):
    """Tests that a ValueError is raised if the target symbol doesn't exist."""
    new_code = "def new_func(): return None"
    with pytest.raises(ValueError, match="Symbol 'non_existent_function' not found"):
        code_editor.replace_symbol_in_code(
            sample_code, "non_existent_function", new_code
        )


def test_replace_with_invalid_original_syntax_raises_error(code_editor):
    """Tests that a ValueError is raised if the original code has a syntax error."""
    invalid_original_code = "def top_level_function(a, b) return a + b"
    new_code = "def top_level_function(a,b): return a*b"
    with pytest.raises(
        ValueError, match="Could not parse original code due to syntax error"
    ):
        code_editor.replace_symbol_in_code(
            invalid_original_code, "top_level_function", new_code
        )

--- END OF FILE ./tests/unit/test_agent_utils.py ---

--- START OF FILE ./tests/unit/test_config.py ---
# tests/unit/test_config.py

import pytest

from shared.config import Settings


def test_settings_loads_defined_attributes(monkeypatch):
    """Test that explicitly defined attributes are loaded correctly."""
    monkeypatch.setenv("LOG_LEVEL", "DEBUG")
    # We must create a new instance to re-evaluate the env var
    settings = Settings()
    assert settings.LOG_LEVEL == "DEBUG"


def test_settings_loads_extra_vars_via_constructor():
    """
    Tests that extra variables passed to the constructor are handled correctly
    in Pydantic v2 with extra='allow'.
    """
    # Arrange: Create a settings instance with extra keyword arguments.
    # This is the correct way to test the "extra" fields behavior.
    settings = Settings(
        MY_DYNAMIC_VARIABLE="hello_world",
        CHEAP_API_KEY="cheap_key_123",
        _env_file=None,  # Prevent loading the real .env file for test isolation
    )

    # Assert: In Pydantic v2, extra fields ARE accessible as direct attributes.
    assert hasattr(settings, "MY_DYNAMIC_VARIABLE")
    assert settings.MY_DYNAMIC_VARIABLE == "hello_world"
    assert hasattr(settings, "CHEAP_API_KEY")
    assert settings.CHEAP_API_KEY == "cheap_key_123"

    # Assert: They are ALSO correctly stored in the model_extra dictionary.
    assert "MY_DYNAMIC_VARIABLE" in settings.model_extra
    assert settings.model_extra["MY_DYNAMIC_VARIABLE"] == "hello_world"
    assert "CHEAP_API_KEY" in settings.model_extra
    assert settings.model_extra["CHEAP_API_KEY"] == "cheap_key_123"

    # Assert: They are not confused with the model's formally defined fields.
    defined_fields = set(Settings.model_fields.keys())
    assert "MY_DYNAMIC_VARIABLE" not in defined_fields


def test_settings_accessing_nonexistent_attribute_raises_error():
    """Test that accessing a truly non-existent attribute raises an AttributeError."""
    settings = Settings(_env_file=None)
    with pytest.raises(AttributeError):
        _ = settings.THIS_DOES_NOT_EXIST

--- END OF FILE ./tests/unit/test_config.py ---

--- START OF FILE ./tests/unit/test_execution_agent.py ---
# tests/unit/test_execution_agent.py
from __future__ import annotations

from unittest.mock import AsyncMock, MagicMock

import pytest

from core.agents.execution_agent import ExecutionAgent
from shared.models import ExecutionTask, PlanExecutionError, TaskParams

# This is our valid, constitutionally-compliant plan
VALID_PLAN = [
    ExecutionTask(
        step="Create a safe file.",
        action="autonomy.self_healing.format_code",  # This is in allowed_actions
        params=TaskParams(file_path="src/safe_dir/test.py"),  # This is in allowed_paths
    )
]

# This plan contains an action not permitted by the policy
INVALID_ACTION_PLAN = [
    ExecutionTask(
        step="Do something dangerous.",
        action="system.dangerous.execute_shell",  # NOT in allowed_actions
        params=TaskParams(file_path="src/safe_dir/test.py"),
    )
]

# This plan targets a constitutionally forbidden file path
INVALID_PATH_PLAN = [
    ExecutionTask(
        step="Modify the constitution.",
        action="autonomy.self_healing.format_code",  # Action is ok...
        params=TaskParams(
            file_path=".intent/charter/policies/safety_policy.yaml"
        ),  # ...but path is forbidden
    )
]


@pytest.fixture
def mock_execution_agent(tmp_path):
    """A pytest fixture to create a fully mocked ExecutionAgent for testing."""
    # 1. Create a mock constitution on the fly
    intent_dir = tmp_path / ".intent"
    (intent_dir / "charter" / "policies").mkdir(parents=True)

    # The agent_policy.yaml is needed for max_correction_attempts
    (intent_dir / "charter" / "policies" / "agent_policy.yaml").write_text(
        "execution_agent:\n  max_correction_attempts: 1"
    )

    # The micro_proposal_policy.yaml is the law we are testing against
    micro_policy = """
    rules:
      - id: safe_actions
        allowed_actions:
          - "autonomy.self_healing.format_code"
      - id: safe_paths
        allowed_paths:
          - "src/safe_dir/**"
        forbidden_paths:
          - ".intent/**"
    """
    (intent_dir / "charter" / "policies" / "micro_proposal_policy.yaml").write_text(
        micro_policy
    )

    # 2. Create mock dependencies for the ExecutionAgent
    mock_cognitive_service = MagicMock()
    mock_prompt_pipeline = MagicMock()
    mock_plan_executor = MagicMock()
    mock_auditor_context = MagicMock()

    # The agent needs a GitService to get the repo_path
    mock_git_service = MagicMock()
    mock_git_service.repo_path = tmp_path
    mock_plan_executor.git_service = mock_git_service

    # 3. Instantiate the real ExecutionAgent with mocked dependencies
    agent = ExecutionAgent(
        cognitive_service=mock_cognitive_service,
        prompt_pipeline=mock_prompt_pipeline,
        plan_executor=mock_plan_executor,
        auditor_context=mock_auditor_context,
    )
    return agent


def test_verify_plan_accepts_valid_plan(mock_execution_agent):
    """
    GIVEN a constitutionally valid plan
    WHEN the agent verifies the plan
    THEN it should complete without raising an exception.
    """
    # Act & Assert
    # The test passes if no exception is raised
    mock_execution_agent._verify_plan(VALID_PLAN)


def test_verify_plan_rejects_invalid_action(mock_execution_agent):
    """
    GIVEN a plan with an action not in the policy's allowed_actions list
    WHEN the agent verifies the plan
    THEN it should raise a PlanExecutionError.
    """
    # Act & Assert
    with pytest.raises(
        PlanExecutionError,
        match="Action 'system.dangerous.execute_shell' is not in the list of allowed safe actions",
    ):
        mock_execution_agent._verify_plan(INVALID_ACTION_PLAN)


def test_verify_plan_rejects_forbidden_path(mock_execution_agent):
    """
    GIVEN a plan targeting a path in the policy's forbidden_paths list
    WHEN the agent verifies the plan
    THEN it should raise a PlanExecutionError.
    """
    # Act & Assert
    with pytest.raises(
        PlanExecutionError, match="is explicitly forbidden by the micro-proposal policy"
    ):
        mock_execution_agent._verify_plan(INVALID_PATH_PLAN)


@pytest.mark.asyncio
async def test_execute_plan_aborts_on_invalid_plan(mock_execution_agent):
    """
    GIVEN an invalid plan
    WHEN the main execute_plan method is called
    THEN it should fail fast on the verification step and not attempt execution.
    """
    # Arrange
    # We can spy on the _generate_and_validate_all_tasks method to ensure it's never called.
    mock_execution_agent._generate_and_validate_all_tasks = AsyncMock()

    # Act
    success, message = await mock_execution_agent.execute_plan(
        "A test goal", INVALID_ACTION_PLAN
    )

    # Assert
    assert not success
    assert "Action 'system.dangerous.execute_shell' is not in the list" in message
    # Crucially, assert that the agent never even tried to start the execution loop
    mock_execution_agent._generate_and_validate_all_tasks.assert_not_called()

--- END OF FILE ./tests/unit/test_execution_agent.py ---

--- START OF FILE ./tests/unit/test_git_service.py ---
# tests/unit/test_git_service.py
from unittest.mock import MagicMock, call

import pytest

from core.git_service import GitService


@pytest.fixture
def mock_git_service(mocker, tmp_path):
    """Creates a GitService instance with a mocked subprocess.run."""
    (tmp_path / ".git").mkdir()

    mock_run = mocker.patch("subprocess.run")

    # Configure mock for the common flow: status -> add -A -> commit
    mock_run.side_effect = [
        MagicMock(stdout="?? new_file.py", stderr="", returncode=0),  # status
        MagicMock(stdout="", stderr="", returncode=0),  # add -A
        MagicMock(stdout="commit success", stderr="", returncode=0),  # commit
    ]

    service = GitService(repo_path=str(tmp_path))
    return service, mock_run


def test_git_add(mock_git_service):
    """Tests that the add method calls subprocess.run with the correct arguments."""
    service, mock_run = mock_git_service
    # Reset side_effect for this simple, single-call test
    mock_run.side_effect = None
    mock_run.return_value = MagicMock(stdout="", stderr="", returncode=0)

    file_to_add = "src/core/main.py"
    service.add(file_to_add)

    mock_run.assert_called_once_with(
        ["git", "add", file_to_add],
        cwd=service.repo_path,
        capture_output=True,
        text=True,
        check=True,
    )


def test_git_commit(mock_git_service):
    """Tests that commit runs: status -> add -A -> commit."""
    service, mock_run = mock_git_service
    commit_message = "feat(agent): Test commit"

    service.commit(commit_message)

    # With robust GitService: status -> add -A -> commit
    assert mock_run.call_count == 3

    expected_calls = [
        call(
            ["git", "status", "--porcelain"],
            cwd=service.repo_path,
            capture_output=True,
            text=True,
            check=True,
        ),
        call(
            ["git", "add", "-A"],
            cwd=service.repo_path,
            capture_output=True,
            text=True,
            check=True,
        ),
        call(
            ["git", "commit", "-m", commit_message],
            cwd=service.repo_path,
            capture_output=True,
            text=True,
            check=True,
        ),
    ]
    mock_run.assert_has_calls(expected_calls)


def test_is_git_repo_true(tmp_path):
    """Returns True when a .git directory exists."""
    (tmp_path / ".git").mkdir()
    service = GitService(repo_path=str(tmp_path))
    assert service.is_git_repo() is True


def test_is_git_repo_false(tmp_path):
    """Raises ValueError if .git is missing on init."""
    with pytest.raises(ValueError):
        GitService(repo_path=str(tmp_path))

--- END OF FILE ./tests/unit/test_git_service.py ---

--- START OF FILE ./tests/unit/test_intent_translator.py ---
# tests/unit/test_intent_translator.py
import json
from unittest.mock import MagicMock

import pytest

from core.agents.intent_translator import IntentTranslator
from shared.config import settings


@pytest.fixture
def mock_cognitive_service(mocker):
    """Mocks the CognitiveService and its client to return a predictable, structured response."""
    mock_client = MagicMock()
    mock_ai_response = json.dumps(
        {
            "status": "vague",
            "suggestion": "The user's goal is a bit vague. Based on the roadmap, did you mean to ask: 'Refactor the codebase to remove the obsolete BaseLLMClient and use CognitiveService'?",
        }
    )
    mock_client.make_request.return_value = mock_ai_response

    mock_service = MagicMock()
    mock_service.get_client_for_role.return_value = mock_client
    return mock_service


@pytest.fixture
def mock_prompt_pipeline(mocker):
    """Mocks the PromptPipeline to prevent file system access during the unit test."""
    mock_pipeline = mocker.patch("core.agents.intent_translator.PromptPipeline")
    mock_instance = mock_pipeline.return_value
    mock_instance.process.side_effect = lambda prompt: prompt
    return mock_instance


def test_translator_handles_vague_goal(
    mock_cognitive_service, mock_prompt_pipeline, tmp_path
):
    """
    Tests if the IntentTranslator can take a vague, human goal
    and produce a structured, actionable goal.
    """
    (tmp_path / ".intent" / "prompts").mkdir(parents=True)
    prompt_file = tmp_path / ".intent" / "prompts" / "intent_translator.prompt"
    prompt_file.write_text("User Request: {user_input}")

    settings.MIND = tmp_path / ".intent"

    translator = IntentTranslator(mock_cognitive_service)
    vague_goal = "optimize AI client usage"

    ai_json_response = translator.translate(vague_goal)

    response_lower = ai_json_response.lower()
    assert "did you mean to ask" in response_lower
    assert "basellmclient" in response_lower
    assert "cognitiveservice" in response_lower

--- END OF FILE ./tests/unit/test_intent_translator.py ---

--- START OF FILE ./tests/unit/test_planner_agent.py ---
# tests/unit/test_planner_agent.py
import json
from pathlib import Path
from unittest.mock import MagicMock

import pytest

from core.agents.planner_agent import PlannerAgent
from core.cognitive_service import CognitiveService
from shared.config import settings
from shared.models import ExecutionTask, PlanExecutionError


@pytest.fixture
def mock_cognitive_service():
    """Provides a mocked CognitiveService that returns a mock client."""
    mock_client = MagicMock()
    mock_service = MagicMock(spec=CognitiveService)
    mock_service.get_client_for_role.return_value = mock_client
    return mock_service


def setup_test_environment(tmp_path: Path):
    """Helper to create necessary constitutional files in a temp directory."""
    intent_dir = tmp_path / ".intent"
    # --- FIX: Create the correct directory structure ---
    (intent_dir / "mind" / "prompts").mkdir(parents=True)
    (intent_dir / "mind" / "config").mkdir(parents=True)

    prompt_file = intent_dir / "mind" / "prompts" / "planner_agent.prompt"
    prompt_file.write_text("Goal: {goal}\nActions:\n{action_descriptions}")

    actions_file = intent_dir / "mind" / "config" / "actions.yaml"
    actions_file.write_text(
        "actions:\n  - name: create_file\n    description: Creates a file.\n    required_parameters: ['file_path']"
    )
    return intent_dir


def test_create_execution_plan_success(mock_cognitive_service, tmp_path, mocker):
    """Tests that the planner can successfully parse a valid high-level plan."""
    intent_dir = setup_test_environment(tmp_path)
    mocker.patch.object(settings, "MIND", intent_dir)

    agent = PlannerAgent(cognitive_service=mock_cognitive_service)
    goal = "Test goal"

    plan_json = json.dumps(
        [
            {
                "step": "A valid step",
                "action": "create_file",
                "params": {"file_path": "src/test.py"},
            }
        ]
    )
    mock_cognitive_service.get_client_for_role.return_value.make_request.return_value = (
        f"```json\n{plan_json}\n```"
    )

    plan = agent.create_execution_plan(goal)

    assert len(plan) == 1
    assert isinstance(plan[0], ExecutionTask)
    assert plan[0].action == "create_file"


def test_create_execution_plan_fails_on_invalid_action(
    mock_cognitive_service, tmp_path, mocker
):
    """Tests that the planner fails if the plan contains an invalid action."""
    intent_dir = setup_test_environment(tmp_path)
    mocker.patch.object(settings, "MIND", intent_dir)

    agent = PlannerAgent(cognitive_service=mock_cognitive_service)
    goal = "Test goal"

    invalid_plan_json = json.dumps(
        [{"step": "Invalid action", "action": "make_coffee", "params": {}}]
    )
    mock_cognitive_service.get_client_for_role.return_value.make_request.return_value = (
        f"```json\n{invalid_plan_json}\n```"
    )

    with pytest.raises(PlanExecutionError):
        agent.create_execution_plan(goal)

--- END OF FILE ./tests/unit/test_planner_agent.py ---

--- END OF PROJECT CONTEXT BUNDLE ---
