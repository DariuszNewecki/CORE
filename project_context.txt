--- START OF FILE ./pyproject.toml ---
# pyproject.toml

[build-system]
# This part is correct: it tells Python to use Poetry to build the project.
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

# --- Poetry Project Metadata ---
# This [tool.poetry] section replaces the old [project] section.
# Poetry uses this to manage dependencies and package details.
[tool.poetry]
name = "core"
version = "0.1.0"
description = "CORE: A self-governing, intent-driven software development system."
authors = ["Your Name or Organization <your_email@example.com>"] # <-- UPDATE THIS LINE
license = "MIT"
readme = "README.md"
packages = [{include = "core", from = "src"}] # Tells Poetry about the src layout

# --- Main Dependencies ---
# This replaces the old [project].dependencies array.
[tool.poetry.dependencies]
python = ">=3.9"
fastapi = ">=0.95.0"
uvicorn = ">=0.21.0"
pyyaml = ">=6.0"
requests = ">=2.28.0"
python-dotenv = ">=1.0.0"

# --- Development Dependencies ---
# This replaces the old [project.optional-dependencies].
# All dev/test tools go here. You install them with `poetry install --with dev`.
[tool.poetry.group.dev.dependencies]
pytest = ">=7.0,<8.0" # Pinned to avoid the conflict we saw
pytest-asyncio = "==0.21.0" # Pinned to the version we know works
ruff = ">=0.0.254"

# --- Command-Line Scripts ---
# This replaces the old [project.scripts] section.
[tool.poetry.scripts]
# core-cli = "core.main:main" # Uncomment if you create a CLI entry point

# --- Configuration for development tools (These do not change) ---
[tool.ruff]
line-length = 88
select = ["E", "W", "F", "I"]

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"
pythonpath = ["src"]
--- END OF FILE ./pyproject.toml ---

--- START OF FILE ./README.md ---
# CORE
The last developer youâ€™ll ever need.

# In one-sentence
An AI-native operating core that hears a human problem, negotiates an intent bundle, and autonomously designs, builds, tests, deploys, and continuously rewrites complete applicationsâ€”while enforcing constitutional governance to prevent drift.

# What CORE does
Conversational onboarding â†’ turns raw problem statements into machine-enforceable YAML intent bundles
Dual-intent governance
Business intent (human-readable)
Architectural intent (machine-readable)
Capsule factory â†’ python -m core capsule new <name> scaffolds both bundles in seconds
Self-replication â†’ auto-regenerates its own source code (src/) to stay aligned with both bundles
Zero human commits â†’ CI gate rejects any .py file not produced by CORE

--- END OF FILE ./README.md ---

--- START OF FILE ./kill-core.sh ---
#!/bin/bash

# A simple script to find and kill the CORE FastAPI/Uvicorn process.
# It reliably finds the process listening on port 8000 and terminates it.

PORT=8000

# The '-t' flag for lsof is less portable than parsing output.
# This awk approach is more robust across different systems (Linux/macOS).
PID=$(lsof -i tcp:${PORT} | awk 'NR!=1 {print $2}')

# Check if the PID variable is empty or not.
if [ -n "$PID" ]; then
    echo "Found CORE process with PID: ${PID} on port ${PORT}"
    echo "Sending termination signal..."
    kill ${PID}
    
    # Give it a moment to shut down gracefully.
    sleep 1
    
    # Check if the process is still alive.
    if kill -0 ${PID} 2>/dev/null; then
        echo "Process did not respond to initial signal. Forcing termination..."
        kill -9 ${PID}
        echo "CORE process terminated with SIGKILL."
    else
        echo "CORE process terminated gracefully."
    fi
else
    echo "No CORE process found running on port ${PORT}."
fi

exit 0
--- END OF FILE ./kill-core.sh ---

--- START OF FILE ./docs/StrategicPlan.md ---
# Project CORE: A Strategic Plan for Refactoring and Evolution

## 1. Preamble: From Diagnosis to Vision

This document outlines the strategic plan to evolve the CORE system from its current state to a truly self-governing, resilient, and evolvable architecture.

The initial feeling of "running in circles" was a correct diagnosis of a system struggling with internal inconsistencies. The recent comprehensive audit, while displaying numerous errors and warnings, was not a sign of failure. It was the **first successful act of self-diagnosis** by the system's nascent "brain." The audit provided a clear, actionable roadmap, revealing a fundamental disconnect between the declared `intent` and the `source code` reality.

This plan details the two major phases of our work:
*   **Part A: Foundational Refactoring.** To achieve a stable, constitutionally compliant baseline by fixing the issues diagnosed by the audit.
*   **Part B: Enabling True Self-Governance.** To build the necessary mechanisms for the system to evolve its own code and constitution safely and autonomously.

---

## Part A: Foundational Refactoring (Achieving Stability)

This phase focuses on acting on the audit's results to create a clean, consistent, and understandable codebase. It is the work required to teach the system what a "good" state looks like.

### Step A1: Unify the "Brain"
*   **Goal:** Eliminate data redundancy and create a single source of truth for the system's knowledge of its own code.
*   **Status:** âœ… **COMPLETE**
*   **Outcome:** The dual `codegraph.json` and `function_manifest.json` files have been replaced by a single, comprehensive `.intent/knowledge/knowledge_graph.json`. The `KnowledgeGraphBuilder` tool is now the sole producer of this artifact.

### Step A2: Consolidate Governance
*   **Goal:** Eliminate redundant tools and establish a single, authoritative script for verifying the system's integrity.
*   **Status:** âœ… **COMPLETE**
*   **Outcome:** The `ConstitutionalAuditor` is now the master tool for all static analysis. Older, fragmented tools (`architectural_auditor`, `principle_validator`, etc.) have been merged into it or deleted.

### Step A3: Stabilize the System
*   **Goal:** Ensure the system has a reliable safety net for development.
*   **Status:** âœ… **COMPLETE**
*   **Outcome:** The test suite has been repaired. Obsolete tests were deleted, and configuration issues (`pythonpath`, dependency conflicts) were resolved, resulting in a stable and passing test run.

### Step A4: Achieve Constitutional Compliance
*   **Goal:** Resolve all critical errors reported by the `ConstitutionalAuditor`.
*   **Status:** âœ… **COMPLETE**
*   **Outcome:** All structural errors (domain mismatches, illegal imports) have been fixed. The "mind-body problem" has been solved by manually annotating the existing codebase with `# CAPABILITY:` tags, fully aligning the `project_manifest.yaml` with the implementation. The audit now reports **ZERO critical errors.**

---

## Part B: The Path Forward (Enabling Evolution)

With a stable foundation, we can now build the mechanisms that allow CORE to fulfill its prime directive: to evolve itself safely.

### Step B1: Trust the Brain (Simplification & Cleanup)

*   **Goal:** Eliminate all audit warnings by making the system's "brain" more intelligent.
*   **Guiding Principle:** We did not blindly patch the auditor. Instead, we enhanced the `KnowledgeGraphBuilder` so it could understand more complex, valid code patterns, thus resolving the root cause of the false warnings.
*   **Status:** âœ… **COMPLETE**
*   **Outcome:** The `KnowledgeGraphBuilder` has been upgraded with a context-aware AST visitor and a declarative pattern-matching engine (`.intent/knowledge/entry_point_patterns.yaml`). It now correctly identifies inheritance, framework callbacks, and CLI entry points. All schema violations were corrected, and all code was fully documented. The `ConstitutionalAuditor` now reports **ZERO errors and ZERO warnings.**

### Step B2: Build the Immune System (Governed Creation)

*   **Goal:** Evolve the `PlannerAgent` to ensure that all *newly generated* code is automatically compliant with the constitution, preventing future errors.
*   **Status:** âœ… **COMPLETE**
*   **Outcome:** The `PlannerAgent._execute_task` method now follows a complete `Generate -> Govern -> Validate -> Self-Correct -> Write` loop. It automatically adds capability tags, enforces docstrings, validates the code, and triggers a self-correction cycle on any validation failure, ensuring only constitutionally compliant code is ever written to disk.

### Step B3: The Constitutional Amendment Process

*   **Goal:** Transform `.intent/` from a "notepad" into a true constitution with a formal, safe amendment process. This allows CORE to evolve its own brain.
*   **Status:** â³ **IN PROGRESS**
*   **The Mechanism:**
    1.  **The Waiting Room (`.intent/proposals/`):** A dedicated directory for drafting changes to the constitution. Files here are not active.
    2.  **The Proposal Bundle:** A standardized YAML format for change requests (e.g., `cr-....yaml`) containing the `target_path`, `action`, `justification`, and proposed `content`.
    3.  **The Governance Layer:**
        *   **`IntentGuard`:** Enforces a new, critical rule: **No direct writes are allowed into `.intent/` except to the `proposals/` directory.**
        *   **`ConstitutionalAuditor`:** Scans `proposals/`, validates the format of any pending proposals, and reports them in a new "Pending Amendments" section of its report.
    4.  **The Ratification Mechanism (`core-admin` tool):** A human operator uses a simple CLI tool to manage the amendment lifecycle. The key command is `approve`.
    5.  **The "Canary" Pre-flight Check:** The `core-admin approve` command is designed to be fundamentally safe and solves the "how does it know it's broken if it's broken?" paradox.
        *   It spawns a **temporary, isolated "canary" instance** of CORE with the proposed change applied *in memory*.
        *   It commands this canary instance to run a full self-audit.
        *   If the canary audit succeeds, the change is permanently applied to the real `.intent/` directory.
        *   If the canary audit fails, the change is rejected, and the real `.intent/` directory is never touched, preventing system failure.

## 2. Conclusion

Upon completion of this plan, CORE will have evolved from a promising but inconsistent prototype into a robust, self-aware system. It will possess a stable foundation, a clear understanding of its own structure, andâ€”most importantlyâ€”a safe, governed process for both creating code and evolving its own foundational intent.

This plan transforms CORE from a system that is merely *audited* to one that is truly *governed*.
--- END OF FILE ./docs/StrategicPlan.md ---

--- START OF FILE ./docs/TheDocument.md ---
# The CORE Constitution

## Section 1: Prime Directive

CORE exists to transform spoken human intent into complete, evolving software systems â€” without drift, duplication, or degradation.

It does not merely generate code; it **governs**, **learns**, and **rewrites** itself under explicit intent and structural boundaries.

---

## Section 2: Purpose of This Document

This document defines the **philosophy**, **intent flow**, and **operating principles** of CORE. It is not executable logic, nor a manifest â€” but the **human-facing contract** that justifies and explains all governance mechanisms.

All rules enforced by `.intent/` are *derived* from what is explained here.

---

## Section 3: COREâ€™s Philosophical Model of Action

CORE operates under a ten-phase loop that governs all its behavior:

```
GOAL
  â†“
WHY
  â†“
INTENT â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â†“                   â”‚
AGENT  â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†   â”‚
  â†“               â”‚   â”‚
MEANS â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†     â”‚   â”‚
  â†“         â”‚     â”‚   â”‚
PLAN â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—„     â”‚   â”‚
  â†“               â”‚   â”‚
ACTION            â”‚   â”‚
  â†“               â”‚   â”‚
FEEDBACK          â”‚   â”‚
  â†“               â”‚   â”‚
ADAPTATION â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

```

--- END OF FILE ./docs/TheDocument.md ---

--- START OF FILE ./CHANGELOG.md ---
## [03/08/2025 - Cleanup & Refactoring Completed]

### Removed
- `fix_function_manifest.py` (superseded by `function_manifest_updater.py`)
- `fix_manifest_format_again.py` (obsolete due to manifest stabilization)
- Standalone manifest validator: `src/core/manifest_validator.py` (redundant after consolidation)

### Consolidated & Improved
- Centralized schema validation explicitly integrated into comprehensive integrity checker: `validate_intent_structure.py`.
- Preserved all original detailed validation logic, semantic checks, immutability enforcement, and structured reporting.

### Notes
- All removal and consolidation actions explicitly confirmed, reviewed, and verified.

--- END OF FILE ./CHANGELOG.md ---

--- START OF FILE ./src/system/governance/constitutional_auditor.py ---
# src/system/governance/constitutional_auditor.py
"""
CORE Constitutional Auditor
===========================
The single source of truth for validating the entire CORE system's integrity.
"""
import sys
import re
from pathlib import Path
from collections import defaultdict
from rich.console import Console
from rich.panel import Panel
from rich.table import Table

from shared.path_utils import get_repo_root
from shared.config_loader import load_config
from shared.schemas.manifest_validator import validate_manifest_entry
from core.validation_pipeline import validate_code
from core.intent_model import IntentModel
from shared.utils.import_scanner import scan_imports_for_file

# CAPABILITY: introspection
# CAPABILITY: alignment_checking
class ConstitutionalAuditor:
    """
    Validates the complete structure and consistency of the .intent/ directory
    and its relationship with the source code.
    """
    def __init__(self):
        """Initializes the auditor, loading all necessary configuration and knowledge files."""
        self.repo_root = get_repo_root()
        self.intent_dir = self.repo_root / ".intent"
        self.src_dir = self.repo_root / "src"
        self.intent_model = IntentModel(self.repo_root)
        self.console = Console()
        self.errors = []
        self.warnings = []
        self.project_manifest = load_config(self.intent_dir / "project_manifest.yaml", "yaml")
        self.knowledge_graph = load_config(self.intent_dir / "knowledge/knowledge_graph.json", "json")
        self.symbols_map = self.knowledge_graph.get("symbols", {})
        self.symbols_list = list(self.symbols_map.values())

    # CAPABILITY: validate_intent_structure
    def run_full_audit(self) -> bool:
        """Run all validation phases and return overall status."""
        self.console.print(Panel("ðŸ§  CORE Constitutional Integrity Audit", style="bold blue"))
        checks = [
            ("Required Intent File Existence", self._check_required_files),
            ("YAML/JSON Syntax Validity", self._validate_syntax),
            ("Project Manifest Integrity", self._validate_project_manifest),
            ("Capability Coverage & Uniqueness", self._check_capability_coverage),
            ("Knowledge Graph Schema Compliance", self._validate_knowledge_graph_schema),
            ("Domain Integrity (Location & Imports)", self._check_domain_integrity),
            ("Docstring & Intent Presence", self._check_docstrings_and_intents),
            ("Dead Code (Unreferenced Symbols)", self._check_for_dead_code),
            ("Orphaned Intent Files", self._check_for_orphaned_intent_files),
        ]
        all_passed = True
        for name, check_fn in checks:
            self.console.rule(f"[bold]ðŸ” {name}[/bold]")
            if not check_fn():
                all_passed = False
        self._report_final_status(all_passed)
        return all_passed

    def _add_error(self, message: str):
        """Adds an error to the list and prints it."""
        self.errors.append(message)
        self.console.print(f"  [bold red]âŒ ERROR:[/] {message}")

    def _add_warning(self, message: str):
        """Adds a warning to the list and prints it."""
        self.warnings.append(message)
        self.console.print(f"  [bold yellow]âš ï¸ WARNING:[/] {message}")
    
    def _add_success(self, message: str):
        """Prints a success message."""
        self.console.print(f"  [bold green]âœ… PASS:[/] {message}")

    def _check_required_files(self) -> bool:
        """Ensure all critical intent files exist."""
        required = [
            "project_manifest.yaml", "mission/principles.yaml", "mission/northstar.yaml",
            "policies/intent_guard.yaml", "policies/safety_policies.yaml",
            "knowledge/knowledge_graph.json", "knowledge/source_structure.yaml",
        ]
        missing = [p for p in required if not (self.intent_dir / p).exists()]
        for path in missing:
            self._add_error(f"Missing critical file: .intent/{path}")
        if not missing:
            self._add_success("All critical intent files are present.")
        return not missing

    def _validate_syntax(self) -> bool:
        """Validate YAML/JSON syntax across all intent files."""
        initial_error_count = len(self.errors)
        files_to_check = list(self.intent_dir.rglob("*.yaml")) + list(self.intent_dir.rglob("*.json"))
        for file_path in files_to_check:
            if file_path.is_file():
                result = validate_code(str(file_path), file_path.read_text(encoding='utf-8'))
                if result["status"] == "dirty":
                    for err in result["errors"]:
                        self._add_error(f"Syntax Error in {file_path.relative_to(self.repo_root)}: {err}")
        passed = len(self.errors) == initial_error_count
        if passed:
            self._add_success(f"Validated syntax for {len(files_to_check)} YAML/JSON files.")
        return passed

    def _validate_project_manifest(self) -> bool:
        """Ensure project_manifest.yaml is structurally sound."""
        initial_error_count = len(self.errors)
        required_keys = ["name", "intent", "required_capabilities", "active_agents"]
        for key in required_keys:
            if key not in self.project_manifest:
                self._add_error(f"project_manifest.yaml missing required key: '{key}'")
        passed = len(self.errors) == initial_error_count
        if passed:
            self._add_success("project_manifest.yaml contains all required keys.")
        return passed

    def _check_capability_coverage(self) -> bool:
        """Check for missing or duplicate capability implementations."""
        initial_error_count = len(self.errors)
        required_caps = set(self.project_manifest.get("required_capabilities", []))
        implemented_caps = {f.get("capability") for f in self.symbols_list if f.get("capability") != "unassigned"}
        missing = sorted(list(required_caps - implemented_caps))
        if missing:
            self._add_error(f"Missing capability implementations for: {missing}")
        unrecognized = sorted(list(implemented_caps - required_caps))
        if unrecognized:
            self._add_warning(f"Unrecognized capabilities in code not in project_manifest.yaml: {unrecognized}")
        passed = len(self.errors) == initial_error_count
        if passed and not unrecognized:
            self._add_success("All required capabilities are implemented and recognized.")
        elif passed:
            self._add_success("All required capabilities are implemented.")
        return passed

    def _validate_knowledge_graph_schema(self) -> bool:
        """Validate each entry in the knowledge graph against its JSON schema."""
        initial_error_count = len(self.errors)
        for key, entry in self.symbols_map.items():
            is_valid, validation_errors = validate_manifest_entry(entry, "knowledge_graph_entry.schema.json")
            if not is_valid:
                for err in validation_errors:
                    self._add_error(f"Knowledge Graph entry '{key}' schema error: {err}")
        passed = len(self.errors) == initial_error_count
        if passed:
            self._add_success(f"All {len(self.symbols_map)} symbols in knowledge graph pass schema validation.")
        return passed
        
    def _check_domain_integrity(self) -> bool:
        """Validate domain declarations and cross-domain imports."""
        initial_error_count = len(self.errors)
        for entry in self.symbols_list:
            file_path = self.repo_root / entry.get("file", "")
            if not file_path.exists():
                self._add_warning(f"File '{entry.get('file')}' from knowledge graph not found on disk.")
                continue
            declared_domain = entry.get("domain")
            actual_domain = self.intent_model.resolve_domain_for_path(file_path.relative_to(self.repo_root))
            if declared_domain != actual_domain:
                self._add_error(f"Domain Mismatch for '{entry.get('key')}': Declared='{declared_domain}', Actual='{actual_domain}'")
            allowed = set(self.intent_model.get_domain_permissions(actual_domain)) | {actual_domain}
            imports = scan_imports_for_file(file_path)
            for imp in imports:
                if imp.startswith("src."): imp = imp[4:]
                if imp.startswith(("core.", "shared.", "system.", "agents.")):
                    imp_path_parts = imp.split('.')
                    potential_path = self.src_dir.joinpath(*imp_path_parts)
                    check_path = potential_path.with_suffix(".py")
                    if not check_path.exists(): check_path = potential_path 
                    imp_domain = self.intent_model.resolve_domain_for_path(check_path)
                    if imp_domain and imp_domain not in allowed:
                         self._add_error(f"Forbidden Import in '{entry.get('file')}': Domain '{actual_domain}' cannot import '{imp}' from forbidden domain '{imp_domain}'")
        passed = len(self.errors) == initial_error_count
        if passed:
             self._add_success("Domain locations and import boundaries are valid.")
        return passed

    def _check_docstrings_and_intents(self) -> bool:
        """Check for missing docstrings or weak, generic intents."""
        initial_warning_count = len(self.warnings)
        for entry in self.symbols_list:
            if entry.get("type") != "ClassDef" and not entry.get("docstring"):
                self._add_warning(f"Missing Docstring in '{entry.get('file')}': Symbol '{entry.get('name')}'")
            if "Provides functionality for the" in entry.get("intent", ""):
                 self._add_warning(f"Generic Intent in '{entry.get('file')}': Symbol '{entry.get('name')}' has a weak intent statement.")
        if len(self.warnings) == initial_warning_count:
            self._add_success("All symbols have docstrings and specific intents.")
        return True

    # CAPABILITY: self_review
    def _check_for_dead_code(self) -> bool:
        """Finds symbols that are not entry points and are never called."""
        all_called_symbols = set()
        for symbol in self.symbols_list:
            all_called_symbols.update(symbol.get("calls", []))

        initial_warning_count = len(self.warnings)
        for symbol in self.symbols_list:
            name = symbol["name"]
            
            # A symbol is NOT dead if ANY of these are true:
            # 1. It is marked as private or a test.
            if name.startswith(('_', 'test_')):
                continue
            # 2. It is called by another symbol in our codebase.
            if name in all_called_symbols:
                continue
            # 3. The Knowledge Graph has identified it as any kind of entry point.
            if symbol.get("entry_point_type"):
                continue

            # If none of the above are true, it is unreferenced.
            self._add_warning(f"Potentially dead code: Symbol '{name}' in '{symbol['file']}' appears to be unreferenced.")
            
        if len(self.warnings) == initial_warning_count:
            self._add_success("No unreferenced public symbols found.")
        return True

    def _check_for_orphaned_intent_files(self) -> bool:
        """Finds .intent files that are not part of the core system configuration."""
        known_files = {
            ".intent/project_manifest.yaml", ".intent/mission/principles.yaml",
            ".intent/mission/northstar.yaml", ".intent/mission/manifesto.md",
            ".intent/policies/intent_guard.yaml", ".intent/policies/safety_policies.yaml",
            ".intent/policies/security_intents.yaml", ".intent/knowledge/source_structure.yaml",
            ".intent/knowledge/knowledge_graph.json", ".intent/knowledge/agent_roles.yaml",
            ".intent/knowledge/capability_tags.yaml", ".intent/knowledge/file_handlers.yaml",
            ".intent/knowledge/entry_point_patterns.yaml",
            ".intent/evaluation/audit_checklist.yaml", ".intent/evaluation/score_policy.yaml",
            ".intent/config/local_mode.yaml", ".intent/meta.yaml",
            ".intent/schemas/knowledge_graph_entry.schema.json", # <-- ADDED THIS LINE
        }
        ignore_patterns = [".log", ".tmp", ".bak", "change_log.json"] # Ignoring change_log
        physical_files = {str(p.relative_to(self.repo_root)).replace("\\", "/") for p in self.intent_dir.rglob("*") if p.is_file() and not any(pat in p.name for pat in ignore_patterns)}
        orphaned_files = sorted(list(physical_files - known_files))
        initial_warning_count = len(self.warnings)
        for orphan in orphaned_files:
            self._add_warning(f"Orphaned intent file: '{orphan}' is not a recognized system file.")
        if len(self.warnings) == initial_warning_count:
            self._add_success("No orphaned or unrecognized intent files found.")
        return True

    def _report_final_status(self, passed: bool):
        """Print final summary report."""
        self.console.print()
        if passed:
            self.console.print(Panel(f"âœ… ALL CHECKS PASSED ({len(self.warnings)} warnings)", style="bold green", expand=False))
        else:
            self.console.print(Panel(f"âŒ AUDIT FAILED: {len(self.errors)} error(s) and {len(self.warnings)} warning(s) found.", style="bold red"))
            if self.errors:
                error_table = Table("ðŸš¨ Critical Errors", style="red")
                for err in self.errors: error_table.add_row(err)
                self.console.print(error_table)
        if self.warnings:
            warning_table = Table("âš ï¸ Warnings", style="yellow")
            for warn in self.warnings: warning_table.add_row(warn)
            self.console.print(warning_table)

def main():
    """CLI entry point for the Constitutional Auditor."""
    auditor = ConstitutionalAuditor()
    try:
        success = auditor.run_full_audit()
        sys.exit(0 if success else 1)
    except FileNotFoundError as e:
        print(f"\n[bold red]FATAL ERROR: A required file was not found.[/bold red]\nDetails: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\n[bold red]An unexpected error occurred during the audit: {e}[/bold red]")
        sys.exit(1)

if __name__ == "__main__":
    main()
--- END OF FILE ./src/system/governance/constitutional_auditor.py ---

--- START OF FILE ./src/system/tools/change_log_updater.py ---
# src/system/tools/change_log_updater.py

import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict
from shared.config_loader import load_config


CHANGE_LOG_PATH = Path(".intent/knowledge/meta_code_change_log.json")
SCHEMA_VERSION = "1.0.0"


def load_existing_log() -> Dict:
    """Loads the existing change log from disk or returns a new structure."""
    data = load_config(CHANGE_LOG_PATH, "json")
    if not data:
        return {"schema_version": SCHEMA_VERSION, "changes": []}
    return data


def append_change_entry(task: str, step: str, modified_files: List[str], score: float, violations: List[Dict]):
    """Appends a new, structured entry to the metacode change log."""
    log = load_existing_log()
    timestamp = datetime.utcnow().isoformat() + "Z"

    log["changes"].append({
        "timestamp": timestamp,
        "task": task,
        "step": step,
        "modified_files": modified_files,
        "score": score,
        "violations": violations,
        "source": "orchestrator"
    })

    CHANGE_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
    CHANGE_LOG_PATH.write_text(json.dumps(log, indent=2), encoding="utf-8")
    print(f"ðŸ“ Appended change log entry at {timestamp}.")


if __name__ == "__main__":
    # Example usage for testing
    append_change_entry(
        task="Add intent guard integration",
        step="Check manifest before file write",
        modified_files=["src/core/cli.py", "src/core/intent_guard.py"],
        score=0.85,
        violations=[]
    )
--- END OF FILE ./src/system/tools/change_log_updater.py ---

--- START OF FILE ./src/system/tools/codegraph_builder.py ---
# src/system/tools/codegraph_builder.py
import ast
import json
import logging
import re
from pathlib import Path
from typing import Dict, Set, Optional, List, Any
from dataclasses import dataclass, asdict, field
from datetime import datetime, timezone

from shared.config_loader import load_config

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class FunctionInfo:
    """A data structure holding all analyzed information about a single symbol (function or class)."""
    key: str
    name: str
    type: str
    file: str
    domain: str
    agent: str
    capability: str
    intent: str
    docstring: Optional[str]
    calls: Set[str] = field(default_factory=set)
    line_number: int = 0
    is_async: bool = False
    parameters: List[str] = field(default_factory=list)
    entry_point_type: Optional[str] = None
    last_updated: str = ""
    is_class: bool = False
    base_classes: List[str] = field(default_factory=list)
    entry_point_justification: Optional[str] = None
    parent_class_key: Optional[str] = None

class ProjectStructureError(Exception):
    """Custom exception for when the project's root cannot be determined."""
    pass

def find_project_root(start_path: Path) -> Path:
    """
    Traverses upward from a starting path to find the project root, marked by 'pyproject.toml'.
    """
    current_path = start_path.resolve()
    while current_path != current_path.parent:
        if (current_path / "pyproject.toml").exists():
            return current_path
        current_path = current_path.parent
    raise ProjectStructureError("Could not find 'pyproject.toml'.")

class FunctionCallVisitor(ast.NodeVisitor):
    """An AST visitor that collects the names of all functions being called within a node."""
    def __init__(self):
        """Initializes the visitor with an empty set to store call names."""
        self.calls: Set[str] = set()

    def visit_Call(self, node: ast.Call):
        """Extracts the function name from a Call node."""
        if isinstance(node.func, ast.Name): self.calls.add(node.func.id)
        elif isinstance(node.func, ast.Attribute): self.calls.add(node.func.attr)
        self.generic_visit(node)

# CAPABILITY: manifest_updating
class KnowledgeGraphBuilder:
    """Builds a comprehensive JSON representation of the project's code structure and relationships."""

    class ContextAwareVisitor(ast.NodeVisitor):
        """A stateful AST visitor that understands class context for methods."""
        def __init__(self, builder, filepath: Path, source_lines: List[str]):
            """Initializes the context-aware visitor."""
            self.builder = builder
            self.filepath = filepath
            self.source_lines = source_lines
            self.current_class_key: Optional[str] = None

        def visit_ClassDef(self, node: ast.ClassDef):
            """Processes a class definition, setting the context for its methods."""
            class_key = self.builder._process_symbol_node(node, self.filepath, self.source_lines, None)
            outer_class_key = self.current_class_key
            self.current_class_key = class_key
            self.generic_visit(node)
            self.current_class_key = outer_class_key

        def visit_FunctionDef(self, node: ast.FunctionDef):
            """Processes a standard function or method within its class context."""
            self.builder._process_symbol_node(node, self.filepath, self.source_lines, self.current_class_key)
            self.generic_visit(node)

        def visit_AsyncFunctionDef(self, node: ast.AsyncFunctionDef):
            """Processes an async function or method within its class context."""
            self.builder._process_symbol_node(node, self.filepath, self.source_lines, self.current_class_key)
            self.generic_visit(node)

    def __init__(self, root_path: Path, exclude_patterns: Optional[List[str]] = None):
        """Initializes the builder, loading patterns and project configuration."""
        self.root_path = root_path.resolve()
        self.src_root = self.root_path / "src"
        self.exclude_patterns = exclude_patterns or ["venv", ".venv", "__pycache__", ".git", "tests"]
        self.functions: Dict[str, FunctionInfo] = {}
        self.files_scanned = 0
        self.files_failed = 0
        self.cli_entry_points = self._get_cli_entry_points()
        self.patterns = self._load_patterns()
        self.domain_map = self._get_domain_map()
        self.fastapi_app_name: Optional[str] = None

    def _load_patterns(self) -> List[Dict]:
        """Loads entry point detection patterns from the intent file."""
        patterns_path = self.root_path / ".intent/knowledge/entry_point_patterns.yaml"
        if not patterns_path.exists():
            logger.warning("entry_point_patterns.yaml not found.")
            return []
        return load_config(patterns_path, "yaml").get("patterns", [])

    def _get_cli_entry_points(self) -> Set[str]:
        """Parses pyproject.toml to find declared command-line entry points."""
        pyproject_path = self.root_path / "pyproject.toml"
        if not pyproject_path.exists(): return set()
        content = pyproject_path.read_text(encoding="utf-8")
        match = re.search(r"\[tool\.poetry\.scripts\]([^\[]*)", content, re.DOTALL)
        return set(re.findall(r'=\s*"[^"]+:(\w+)"', match.group(1))) if match else set()

    def _should_exclude_path(self, path: Path) -> bool:
        """Determines if a given path should be excluded from scanning."""
        return any(p in path.parts for p in self.exclude_patterns)

    def _get_domain_map(self) -> Dict[str, str]:
        """Loads the domain-to-path mapping from the source structure intent file."""
        path = self.root_path / ".intent/knowledge/source_structure.yaml"
        data = load_config(path, "yaml")
        return {Path(e["path"]).as_posix(): e["domain"] for e in data.get("structure", []) if "path" in e and "domain" in e}

    def _determine_domain(self, file_path: Path) -> str:
        """Determines the logical domain for a file path based on the longest matching prefix."""
        file_posix = file_path.as_posix()
        best = max((p for p in self.domain_map if file_posix.startswith(p)), key=len, default="")
        return self.domain_map.get(best, "unassigned")

    def _infer_agent_from_path(self, relative_path: Path) -> str:
        """Infers the most likely responsible agent based on keywords in the file path."""
        path = str(relative_path).lower()
        if "planner" in path: return "planner_agent"
        if "generator" in path: return "generator_agent"
        if any(x in path for x in ["validator", "guard", "audit"]): return "validator_agent"
        if "core" in path: return "core_agent"
        if "tool" in path: return "tooling_agent"
        return "generic_agent"

    def _parse_metadata_comment(self, node: ast.AST, source_lines: List[str]) -> Dict[str, str]:
        """Parses the line immediately preceding a symbol definition for a '# CAPABILITY:' tag."""
        if node.lineno > 1:
            line = source_lines[node.lineno - 2].strip()
            if line.startswith('#'):
                match = re.search(r'CAPABILITY:\s*(\S+)', line, re.IGNORECASE)
                if match: return {'capability': match.group(1).strip()}
        return {}

    def _get_entry_point_type(self, node: ast.FunctionDef | ast.AsyncFunctionDef) -> Optional[str]:
        """Identifies decorator or CLI-based entry points for a function."""
        for decorator in node.decorator_list:
            if isinstance(decorator, ast.Call) and isinstance(decorator.func, ast.Attribute) and isinstance(decorator.func.value, ast.Name) and decorator.func.value.id == self.fastapi_app_name:
                return f"fastapi_route_{decorator.func.attr}"
            elif isinstance(decorator, ast.Name) and decorator.id == "asynccontextmanager":
                return "context_manager"
        if self.fastapi_app_name and node.name == "lifespan": return "fastapi_lifespan"
        if node.name in self.cli_entry_points: return "cli_entry_point"
        return None

    def scan_file(self, filepath: Path) -> bool:
        """Scans a single Python file, parsing its AST to extract all symbols."""
        try:
            content = filepath.read_text(encoding="utf-8")
            source_lines = content.splitlines()
            tree = ast.parse(content, filename=str(filepath))
            
            main_block_entries, self.fastapi_app_name = set(), None
            for node in ast.walk(tree):
                if isinstance(node, ast.Assign) and isinstance(node.value, ast.Call) and isinstance(node.value.func, ast.Name) and node.value.func.id == 'FastAPI' and isinstance(node.targets[0], ast.Name):
                    self.fastapi_app_name = node.targets[0].id
                elif isinstance(node, ast.If) and isinstance(node.test, ast.Compare) and isinstance(node.test.left, ast.Name) and node.test.left.id == '__name__' and isinstance(node.test.comparators[0], ast.Constant) and node.test.comparators[0].value == '__main__':
                    visitor = FunctionCallVisitor(); visitor.visit(node); main_block_entries.update(visitor.calls)
            self.cli_entry_points.update(main_block_entries)

            visitor = self.ContextAwareVisitor(self, filepath, source_lines)
            visitor.visit(tree)
            return True
        except Exception as e:
            logger.error(f"Error scanning {filepath}: {e}", exc_info=False)
            return False

    def _process_symbol_node(self, node: ast.AST, filepath: Path, source_lines: List[str], parent_key: Optional[str]) -> Optional[str]:
        """Extracts and stores metadata from a single function or class AST node."""
        if not isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)): return None
        
        visitor = FunctionCallVisitor(); visitor.visit(node)
        key = f"{filepath.relative_to(self.root_path).as_posix()}::{node.name}"
        doc = ast.get_docstring(node) or ""
        domain = self._determine_domain(filepath.relative_to(self.root_path))
        is_class = isinstance(node, ast.ClassDef)

        base_classes = []
        if is_class:
            for base in node.bases:
                if isinstance(base, ast.Name): base_classes.append(base.id)
                elif isinstance(base, ast.Attribute): base_classes.append(base.attr)
        
        func_info = FunctionInfo(
            key=key, name=node.name, type=node.__class__.__name__, file=filepath.relative_to(self.root_path).as_posix(),
            calls=visitor.calls, line_number=node.lineno, is_async=isinstance(node, ast.AsyncFunctionDef),
            docstring=doc, parameters=[arg.arg for arg in node.args.args] if hasattr(node, 'args') else [],
            entry_point_type=self._get_entry_point_type(node) if not is_class else None,
            domain=domain, agent=self._infer_agent_from_path(filepath.relative_to(self.root_path)),
            capability=self._parse_metadata_comment(node, source_lines).get("capability", "unassigned"),
            intent=doc.split('\n')[0].strip() or f"Provides functionality for the {domain} domain.",
            last_updated=datetime.now(timezone.utc).isoformat(), is_class=is_class,
            base_classes=base_classes, parent_class_key=parent_key
        )
        self.functions[key] = func_info
        return key

    def _apply_entry_point_patterns(self):
        """Applies declarative patterns to identify non-obvious entry points."""
        all_base_classes = {base for info in self.functions.values() for base in info.base_classes}
        for info in self.functions.values():
            if info.entry_point_type: continue
            for pattern in self.patterns:
                rules, is_match = pattern.get("match", {}), True
                
                if rules.get("has_capability_tag") and info.capability == "unassigned": is_match = False
                if rules.get("is_base_class") and (not info.is_class or info.name not in all_base_classes): is_match = False
                if "name_regex" in rules and not re.match(rules["name_regex"], info.name): is_match = False
                
                if "base_class_includes" in rules:
                    parent_bases = info.base_classes
                    if info.parent_class_key and info.parent_class_key in self.functions:
                        parent_bases.extend(self.functions[info.parent_class_key].base_classes)
                    if not any(b == rules["base_class_includes"] for b in parent_bases): is_match = False

                if is_match:
                    info.entry_point_type, info.entry_point_justification = pattern["entry_point_type"], pattern["name"]
                    break

    def build(self) -> Dict[str, Any]:
        """Orchestrates the full knowledge graph generation process."""
        logger.info(f"Building knowledge graph for directory: {self.src_root}")
        py_files = [f for f in self.src_root.rglob("*.py") if f.name != "__init__.py" and not self._should_exclude_path(f)]
        logger.info(f"Found {len(py_files)} Python files to scan in src/")
        
        for pyfile in py_files:
            if self.scan_file(pyfile): self.files_scanned += 1
            else: self.files_failed += 1
        
        logger.info(f"Scanned {self.files_scanned} files ({self.files_failed} failed). Applying declarative patterns...")
        self._apply_entry_point_patterns()

        serializable_functions = {key: asdict(info, dict_factory=lambda x: {k: v for (k, v) in x if v is not None}) for key, info in self.functions.items()}
        for data in serializable_functions.values(): data["calls"] = sorted(list(data["calls"]))
        
        return {
            "schema_version": "2.0.0",
            "metadata": {"files_scanned": self.files_scanned, "total_symbols": len(self.functions), "timestamp_utc": datetime.now(timezone.utc).isoformat()},
            "symbols": serializable_functions
        }

def main():
    """CLI entry point to run the knowledge graph builder and save the output."""
    try:
        root = find_project_root(Path.cwd())
        builder = KnowledgeGraphBuilder(root)
        graph = builder.build()
        out_path = root / ".intent/knowledge/knowledge_graph.json"
        out_path.parent.mkdir(parents=True, exist_ok=True)
        out_path.write_text(json.dumps(graph, indent=2))
        print(f"âœ… Knowledge graph generated! Scanned {builder.files_scanned} files, found {len(graph['symbols'])} symbols.")
        print(f"   -> Saved to {out_path}")
    except Exception as e:
        logger.error(f"An error occurred: {e}", exc_info=True)

if __name__ == "__main__":
    main()
--- END OF FILE ./src/system/tools/codegraph_builder.py ---

--- START OF FILE ./src/system/tools/__init__.py ---
# src/system/tools/__init__.py
# Package marker for src/system/tools â€” contains CORE's introspection and audit tools.
--- END OF FILE ./src/system/tools/__init__.py ---

--- START OF FILE ./src/system/tools/docstring_adder.py ---
# src/system/tools/docstring_adder.py
"""
Placeholder for a tool that finds and adds missing docstrings.
This tool would use an LLM to generate docstrings for functions
that are flagged by the ConstitutionalAuditor.
"""
import sys

# CAPABILITY: add_missing_docstrings
def main():
    """Entry point for the docstring adder tool."""
    print("INFO: This is a placeholder for the 'add_missing_docstrings' capability.")
    print("INFO: In the future, this tool will scan for undocumented functions and generate docstrings.")
    sys.exit(0)

if __name__ == "__main__":
    main()
--- END OF FILE ./src/system/tools/docstring_adder.py ---

--- START OF FILE ./src/core/clients.py ---
# src/core/clients.py
"""
Clients for communicating with the different LLMs in the CORE ecosystem.
This version is updated to use the modern "Chat Completions" API format,
which is compatible with providers like DeepSeek and OpenAI's newer models.
"""
import os
import requests
from typing import Dict, Any


class BaseLLMClient:
    """
    Base class for LLM clients, handling common request logic for Chat APIs.
    Provides shared initialization and error handling for all LLM clients.
    """

    def __init__(self, api_url: str, api_key: str, model_name: str):
        """
        Initialize the LLM client with API credentials and endpoint.

        Args:
            api_url (str): Base URL for the LLM's chat completions API.
            api_key (str): Authentication token for the API.
            model_name (str): Name of the model to use (e.g., 'gpt-4', 'deepseek-coder').
        """
        if not api_url or not api_key:
            raise ValueError(f"{self.__class__.__name__} requires both API_URL and API_KEY.")
        # Ensure the URL ends with the correct endpoint for compatibility
        if not api_url.endswith('/v1/chat/completions') and not api_url.endswith('/chat/completions'):
            self.api_url = api_url.rstrip('/') + '/v1/chat/completions'
        else:
            self.api_url = api_url

        self.model_name = model_name
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
        }
        print(f"  - Initialized {self.__class__.__name__} for model '{self.model_name}' at endpoint '{self.api_url}'")

    def make_request(self, prompt: str, user_id: str = "core_system") -> str:
        """
        Sends a prompt to the configured Chat Completions API.

        Args:
            prompt (str): The prompt to send to the LLM. It will be wrapped as a 'user' message.
            user_id (str): Optional identifier for the requester (used by some APIs for moderation).

        Returns:
            str: The text content from the LLM's response, or an error message.

        Raises:
            requests.HTTPError: If the API returns a non-200 status code.
        """
        # --- THIS IS THE CRITICAL CHANGE ---
        # We now build a 'messages' array instead of using a simple 'prompt' key.
        payload = {
            "model": self.model_name,
            "messages": [
                # For simplicity, we wrap the entire incoming prompt as a single user message.
                # More advanced implementations could parse the prompt for a system message.
                {"role": "user", "content": prompt}
            ],
            "user": user_id,  # Some APIs like OpenAI use this for moderation tracking
        }

        try:
            response = requests.post(self.api_url, headers=self.headers, json=payload, timeout=180)
            response.raise_for_status()

            response_data = response.json()

            # --- THIS IS THE SECOND CRITICAL CHANGE ---
            # The response format is also different for chat APIs.
            # It's inside choices[0].message.content, not choices[0].text.
            content = response_data["choices"][0]["message"]["content"]
            return content if content is not None else ""
        except requests.exceptions.RequestException as e:
            print(f"âŒ Network error during LLM request: {e}")
            return f"Error: Could not connect to LLM endpoint at {self.api_url}. Details: {e}"
        except (KeyError, IndexError) as e:
            # Handle cases where the response might be malformed or empty
            print(f"âŒ Error parsing LLM response: {e}. Full response: {response.text}")
            return f"Error: Could not parse response from API. Full response: {response.text}"


class OrchestratorClient(BaseLLMClient):
    """
    Client for the Orchestrator LLM (e.g., GPT-4, Claude 3).
    Responsible for high-level planning and intent interpretation.
    """

    def __init__(self):
        """
        Initialize the OrchestratorClient using environment variables.
        No arguments needed â€” config is injected via .env or system vars.
        """
        super().__init__(
            api_url=os.getenv("ORCHESTRATOR_API_URL"),
            api_key=os.getenv("ORCHESTRATOR_API_KEY"),
            model_name=os.getenv("ORCHESTRATOR_MODEL_NAME", "deepseek-chat")
        )


class GeneratorClient(BaseLLMClient):
    """
    Client for the Generator LLM (e.g., a specialized coding model).
    Responsible for code generation and detailed implementation.
    """

    def __init__(self):
        """
        Initialize the GeneratorClient using environment variables.
        No arguments needed â€” config is injected via .env or system vars.
        """
        super().__init__(
            api_url=os.getenv("GENERATOR_API_URL"),
            api_key=os.getenv("GENERATOR_API_KEY"),
            model_name=os.getenv("GENERATOR_MODEL_NAME", "deepseek-coder")
        )
--- END OF FILE ./src/core/clients.py ---

--- START OF FILE ./src/core/validation_pipeline.py ---
# src/core/validation_pipeline.py
"""
A context-aware validation pipeline that applies different validation steps
based on the type of file being processed. This is the single source of truth
for all code and configuration validation.
"""
import ast
import yaml
from pathlib import Path
from typing import List, Dict, Any

from core.black_formatter import format_code_with_black
from core.ruff_linter import fix_and_lint_code_with_ruff
from core.syntax_checker import check_syntax

FORBIDDEN_CALLS = {
    "eval", "exec", "compile", "os.system", "subprocess.run",
    "subprocess.Popen", "os.remove", "os.rmdir", "shutil.rmtree",
}
FORBIDDEN_IMPORTS = {"socket", "shutil", "pickle", "shelve"}

def _get_full_attribute_name(node: ast.Attribute) -> str:
    """Recursively builds the full name of an attribute call (e.g., 'os.path.join')."""
    parts = []
    current = node
    while isinstance(current, ast.Attribute):
        parts.insert(0, current.attr)
        current = current.value
    if isinstance(current, ast.Name):
        parts.insert(0, current.id)
    return ".".join(parts)

def _find_dangerous_patterns(tree: ast.AST) -> List[str]:
    """Scans the AST for calls to forbidden functions and imports."""
    violations = []
    for node in ast.walk(tree):
        if isinstance(node, ast.Call):
            full_call_name = ""
            if isinstance(node.func, ast.Name): full_call_name = node.func.id
            elif isinstance(node.func, ast.Attribute): full_call_name = _get_full_attribute_name(node.func)
            if full_call_name in FORBIDDEN_CALLS:
                violations.append(f"Use of forbidden call on line {node.lineno}: '{full_call_name}'")
        elif isinstance(node, ast.Import):
            for alias in node.names:
                if alias.name.split(".")[0] in FORBIDDEN_IMPORTS:
                    violations.append(f"Import of forbidden module on line {node.lineno}: '{alias.name}'")
        elif isinstance(node, ast.ImportFrom):
            if node.module and node.module.split(".")[0] in FORBIDDEN_IMPORTS:
                violations.append(f"Import from forbidden module on line {node.lineno}: '{node.module}'")
    return violations

# CAPABILITY: semantic_validation
def _check_semantics(code: str) -> List[str]:
    """Runs all semantic checks on a string of Python code."""
    try:
        tree = ast.parse(code)
    except SyntaxError as e:
        return [f"SyntaxError during semantic check: {e}"]
    return _find_dangerous_patterns(tree)

def _validate_python_code(path_hint: str, code: str) -> Dict[str, Any]:
    """Runs the full validation suite for Python code: format, lint, syntax, and semantics."""
    errors: List[str] = []
    formatted_code, fmt_err = format_code_with_black(code)
    if fmt_err:
        errors.append(f"Black Formatter Failed: {fmt_err}")
        return {"status": "dirty", "errors": errors, "code": code}
    is_clean, lint_msg, fixed_code = fix_and_lint_code_with_ruff(formatted_code)
    if not is_clean:
        errors.append(f"Ruff Linter Found Unfixable Issues:\n{lint_msg}")
    syntax_valid, syntax_msg = check_syntax(path_hint, fixed_code)
    if not syntax_valid:
        errors.append(f"Syntax Error: {syntax_msg}")
        return {"status": "dirty", "errors": errors, "code": fixed_code}
    semantic_errors = _check_semantics(fixed_code)
    if semantic_errors:
        errors.extend(semantic_errors)
    status = "clean" if not errors else "dirty"
    return {"status": status, "errors": errors, "code": fixed_code}

def _validate_yaml(code: str) -> Dict[str, Any]:
    """Runs validation steps specific to YAML files."""
    errors = []
    try:
        yaml.safe_load(code)
    except yaml.YAMLError as e:
        errors.append(f"Invalid YAML format: {e}")
    status = "clean" if not errors else "dirty"
    return {"status": status, "errors": errors, "code": code}

def _get_file_classification(file_path: str) -> str:
    """Determines the file type based on its extension."""
    suffix = Path(file_path).suffix.lower()
    if suffix == ".py": return "python"
    if suffix in [".yaml", ".yml"]: return "yaml"
    if suffix in [".md", ".txt", ".json"]: return "text"
    return "unknown"

# CAPABILITY: code_quality_analysis
def validate_code(file_path: str, code: str) -> Dict[str, Any]:
    """
    The main entry point for validation. It determines the file type
    and routes it to the appropriate, specific validation function.
    """
    classification = _get_file_classification(file_path)
    print(f"  -> Validation: Classifying '{file_path}' as '{classification}'. Routing to validator.")
    if classification == "python":
        return _validate_python_code(file_path, code)
    if classification == "yaml":
        return _validate_yaml(code)
    return {"status": "clean", "errors": [], "code": code}
--- END OF FILE ./src/core/validation_pipeline.py ---

--- START OF FILE ./src/core/git_service.py ---
# src/core/git_service.py
"""
GitService â€” CORE's Git Integration Layer

Provides safe, auditable Git operations:
- add, commit, rollback
- status checks
- branch management

Ensures all changes are tracked and reversible.
Used by main.py and self-correction engine.
"""

import subprocess
from pathlib import Path
from typing import Optional


class GitService:
    """
    Encapsulates Git operations for the CORE system.
    Ensures all file changes are committed with traceable messages.
    """

    def __init__(self, repo_path: str):
        """
        Initialize GitService with repository root.

        Args:
            repo_path (str): Path to the Git repository.
        """
        self.repo_path = Path(repo_path).resolve()
        if not self.is_git_repo():
            raise ValueError(f"Invalid Git repository: {repo_path}")
        print(f"âœ… GitService initialized for repo at {self.repo_path}")

    def _run_command(self, command: list) -> str:
        """
        Run a Git command and return stdout.

        Args:
            command (list): Git command as a list (e.g., ['git', 'status']).

        Returns:
            str: Command output, or raises RuntimeError on failure.
        """
        try:
            result = subprocess.run(
                command,
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                check=True
            )
            return result.stdout.strip()
        except subprocess.CalledProcessError as e:
            raise RuntimeError(f"Git command failed: {e.stderr}") from e

    def add(self, file_path: str = "."):
        """
        Stage a file or directory for commit.

        Args:
            file_path (str): Path to stage. Defaults to '.' (all changes).
        """
        abs_path = (self.repo_path / file_path).resolve()
        if self.repo_path not in abs_path.parents and abs_path != self.repo_path:
            raise ValueError(f"Cannot stage file outside repo: {file_path}")
        self._run_command(["git", "add", file_path])

    def commit(self, message: str):
        """
        Commit staged changes with a message.

        Args:
            message (str): Commit message explaining the change.
        """
        try:
            self._run_command(["git", "commit", "-m", message])
            print(f"âœ… Committed changes: {message}")
        except RuntimeError:
            print("â„¹ï¸ No changes to commit.")

    def is_git_repo(self) -> bool:
        """
        Check if the configured path is a valid Git repository.

        Returns:
            bool: True if it's a Git repo, False otherwise.
        """
        git_dir = self.repo_path / ".git"
        return git_dir.is_dir()

    def rollback_last_commit(self):
        """
        Undo the last Git commit (soft reset).

        Use with caution â€” only for failed self-modifications.
        """
        self._run_command(["git", "reset", "--soft", "HEAD~1"])
        print("âš ï¸ Rolled back last commit.")
--- END OF FILE ./src/core/git_service.py ---

--- START OF FILE ./src/core/__init__.py ---
# src/core/__init__.py
# Package marker for src/core â€” central module for CORE's intent-driven engine.
--- END OF FILE ./src/core/__init__.py ---

--- START OF FILE ./src/core/syntax_checker.py ---
# src/core/syntax_checker.py

"""
A simple syntax checker utility.

Validates the syntax of Python code before it's staged for write/commit.
"""

import ast
from typing import Tuple


# CAPABILITY: syntax_validation
def check_syntax(file_path: str, code: str) -> Tuple[bool, str]:
    """
    Checks whether the given code has valid syntax.

    Args:
        file_path (str): File name (used to detect .py files)
        code (str): Source code string

    Returns:
        (is_valid: bool, message: str)
    """
    if not file_path.endswith(".py"):
        return True, "Syntax check skipped for non-Python file."

    try:
        ast.parse(code)
        return True, "Python syntax is valid."
    except SyntaxError as e:
        # In rare cases, e.text may be None
        error_line = e.text.strip() if e.text else "<source unavailable>"
        return False, (
            f"Invalid Python syntax:\n"
            f"{error_line}\n"
            f"Line {e.lineno}, column {e.offset}: {e.msg}"
        )
--- END OF FILE ./src/core/syntax_checker.py ---

--- START OF FILE ./src/core/black_formatter.py ---
# src/core/black_formatter.py
"""
Formats Python code using Black before it's written to disk.
"""

import black
from typing import Tuple, Optional


def format_code_with_black(code: str) -> Tuple[Optional[str], Optional[str]]:
    """
    Attempts to format the given Python code using Black.

    Returns:
        Tuple:
            - formatted_code (str) if successful, else None
            - error_message (str) if failed, else None
    """
    try:
        mode = black.FileMode()
        formatted_code = black.format_str(code, mode=mode)
        return formatted_code, None
    except Exception as e:
        return None, f"Black formatting failed: {str(e)}"

--- END OF FILE ./src/core/black_formatter.py ---

--- START OF FILE ./src/core/test_runner.py ---
# src/core/test_runner.py
"""
Runs pytest against the local /tests directory and captures results.
This provides the core `test_execution` capability, allowing the system
to verify its own integrity after making changes.
"""
import subprocess
import os
import json
import datetime
from typing import Dict
from pathlib import Path

LOG_DIR = Path("logs")
LOG_FILE = LOG_DIR / "test_results.log"
FAILURE_FILE = LOG_DIR / "test_failures.json"
LOG_DIR.mkdir(exist_ok=True)

# CAPABILITY: test_execution
def run_tests(silent: bool = True) -> Dict[str, str]:
    """
    Executes pytest on the tests/ directory and returns a structured result.
    This function captures stdout, stderr, and the exit code, providing a
    comprehensive summary of the test run for agents to act upon.
    """
    result = {
        "exit_code": "-1",
        "stdout": "",
        "stderr": "",
        "summary": "âŒ Unknown error",
        "timestamp": datetime.datetime.utcnow().isoformat()
    }

    repo_root = Path(__file__).resolve().parents[2]
    tests_path = repo_root / "tests"
    cmd = ["pytest", str(tests_path), "--tb=short", "-q"]

    timeout = os.getenv("TEST_RUNNER_TIMEOUT")
    try:
        timeout_val = int(timeout) if timeout else None
    except ValueError:
        timeout_val = None

    try:
        proc = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            check=False,
            timeout=timeout_val,
        )
        result["exit_code"] = str(proc.returncode)
        result["stdout"] = proc.stdout.strip()
        result["stderr"] = proc.stderr.strip()
        result["summary"] = _summarize(proc.stdout)

        if not silent:
            print(proc.stdout)
            if proc.stderr:
                print("âš ï¸ stderr:", proc.stderr)

    except subprocess.TimeoutExpired:
        result["stderr"] = "Test run timed out."
        result["summary"] = "â° Timeout"
    except FileNotFoundError:
        result["stderr"] = "pytest is not installed or not found in PATH."
        result["summary"] = "âŒ Pytest not available"
    except Exception as e:
        result["stderr"] = str(e)
        result["summary"] = "âŒ Test run error"

    _log_test_result(result)
    _store_failure_if_any(result)
    return result

def _summarize(output: str) -> str:
    """Parses pytest output to find the final summary line."""
    lines = output.strip().splitlines()
    for line in reversed(lines):
        if "passed" in line or "failed" in line or "error" in line:
            return line.strip()
    return "No test summary found."

def _log_test_result(data: Dict[str, str]):
    """Appends a JSON record of a test run to the persistent log file."""
    try:
        with open(LOG_FILE, "a", encoding="utf-8") as f:
            f.write(json.dumps(data) + "\n")
    except Exception as e:
        print(f"Warning: Failed to write test log: {e}")

def _store_failure_if_any(data: Dict[str, str]):
    """Saves the details of a failed test run to a dedicated file for easy access."""
    try:
        if data.get("exit_code") != "0":
            with open(FAILURE_FILE, "w", encoding="utf-8") as f:
                json.dump({
                    "summary": data.get("summary"),
                    "stdout": data.get("stdout"),
                    "timestamp": data.get("timestamp")
                }, f, indent=2)
        elif os.path.exists(FAILURE_FILE):
            os.remove(FAILURE_FILE)
    except Exception as e:
        print(f"Warning: Could not save test failure data: {e}")
--- END OF FILE ./src/core/test_runner.py ---

--- START OF FILE ./src/core/main.py ---
# src/core/main.py
"""
main.py â€” CORE's API Gateway and Execution Engine

Implements the FastAPI server that handles:
- Goal submission
- Write confirmation
- Test execution
- System status

Integrates all core capabilities into a unified interface.
"""
from typing import Dict
from fastapi import FastAPI, HTTPException, Request, status as http_status
from fastapi.responses import JSONResponse
from contextlib import asynccontextmanager
from dotenv import load_dotenv

# Local imports (now that 'src' is on the pythonpath for tests)
from core.clients import OrchestratorClient, GeneratorClient
from core.file_handler import FileHandler
from core.git_service import GitService
from core.intent_guard import IntentGuard
from agents.planner_agent import PlannerAgent
from core.capabilities import introspection # Import introspection

# Load environment variables from .env file
load_dotenv()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """FastAPI lifespan handler â€” runs startup and shutdown logic."""
    print("ðŸš€ Starting CORE system...")
    
    # Run introspection on startup to ensure knowledge graph is up-to-date
    introspection() 
    print("ðŸ” Introspection complete.")
    
    # Initialize services and store them in the app state
    app.state.orchestrator_client = OrchestratorClient()
    app.state.generator_client = GeneratorClient()
    app.state.file_handler = FileHandler(".")
    app.state.git_service = GitService(".")
    app.state.intent_guard = IntentGuard(".")
    
    app.state.planner = PlannerAgent(
        orchestrator_client=app.state.orchestrator_client,
        generator_client=app.state.generator_client,
        file_handler=app.state.file_handler,
        git_service=app.state.git_service,
        intent_guard=app.state.intent_guard
    )
    print("âœ… CORE system initialized.")
    yield
    print("ðŸ›‘ CORE system shutting down.")

# Initialize FastAPI app with the lifespan event handler
app = FastAPI(lifespan=lifespan)

@app.post("/execute_goal")
async def execute_goal(request_data: Dict[str, str], request: Request):
    """Execute a high-level goal by planning and generating code."""
    goal = request_data.get("goal")
    if not goal:
        raise HTTPException(status_code=400, detail="Missing 'goal' in request.")

    try:
        planner: PlannerAgent = request.app.state.planner
        plan = planner.create_execution_plan(goal)
        
        success, message = await planner.execute_plan(plan)
        
        if success:
            return JSONResponse(
                content={"status": "success", "message": message},
                status_code=http_status.HTTP_200_OK
            )
        else:
            raise HTTPException(status_code=500, detail=f"Goal execution failed: {message}")

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred: {str(e)}")

@app.get("/")
async def root():
    """Root endpoint â€” returns system status."""
    return {"message": "CORE system is online and self-governing."}
--- END OF FILE ./src/core/main.py ---

--- START OF FILE ./src/core/prompt_pipeline.py ---
# src/core/prompt_pipeline.py
"""
PromptPipeline â€” CORE's Unified Directive Processor

A single pipeline that processes all [[directive:...]] blocks in a user prompt.
Responsible for:
- Injecting context (e.g., file contents)
- Expanding includes
- Adding analysis from introspection tools
- Enriching with manifest data

This is the central "pre-processor" for all LLM interactions.
"""

import re
import yaml
from pathlib import Path
from typing import Dict

class PromptPipeline:
    """
    Processes and enriches user prompts by resolving directives like [[include:...]] and [[analysis:...]].
    Ensures the LLM receives full context before generating code.
    """

    def __init__(self, repo_path: Path):
        """
        Initialize PromptPipeline with repository root.

        Args:
            repo_path (Path): Root path of the repository.
        """
        self.repo_path = Path(repo_path).resolve()

        # Regex patterns for directive matching
        self.context_pattern = re.compile(r"\[\[context:(.+?)\]\]")
        self.include_pattern = re.compile(r"\[\[include:(.+?)\]\]")
        self.analysis_pattern = re.compile(r"\[\[analysis:(.+?)\]\]")
        self.manifest_pattern = re.compile(r"\[\[manifest:(.+?)\]\]")

    def _replace_context_match(self, match: re.Match) -> str:
        """Dynamically replaces a [[context:...]] regex match with file content or an error message."""
        file_path = match.group(1).strip()
        abs_path = self.repo_path / file_path
        if abs_path.exists() and abs_path.is_file():
            try:
                return f"\n--- CONTEXT: {file_path} ---\n{abs_path.read_text(encoding='utf-8')}\n--- END CONTEXT ---\n"
            except Exception as e:
                return f"\nâŒ Could not read {file_path}: {str(e)}\n"
        return f"\nâŒ File not found: {file_path}\n"

    def _inject_context(self, prompt: str) -> str:
        """Replaces [[context:file.py]] directives with actual file content."""
        return self.context_pattern.sub(self._replace_context_match, prompt)

    def _replace_include_match(self, match: re.Match) -> str:
        """Dynamically replaces an [[include:...]] regex match with file content or an error message."""
        file_path = match.group(1).strip()
        abs_path = self.repo_path / file_path
        if abs_path.exists() and abs_path.is_file():
            try:
                return f"\n--- INCLUDED: {file_path} ---\n{abs_path.read_text(encoding='utf-8')}\n--- END INCLUDE ---\n"
            except Exception as e:
                return f"\nâŒ Could not read {file_path}: {str(e)}\n"
        return f"\nâŒ File not found: {file_path}\n"

    def _inject_includes(self, prompt: str) -> str:
        """Replaces [[include:file.py]] directives with file content."""
        return self.include_pattern.sub(self._replace_include_match, prompt)

    def _replace_analysis_match(self, match: re.Match) -> str:
        """Dynamically replaces an [[analysis:...]] regex match with a placeholder analysis message."""
        file_path = match.group(1).strip()
        # This functionality is a placeholder.
        return f"\n--- ANALYSIS FOR {file_path} (DEFERRED) ---\n"

    def _inject_analysis(self, prompt: str) -> str:
        """Replaces [[analysis:file.py]] directives with code analysis."""
        return self.analysis_pattern.sub(self._replace_analysis_match, prompt)

    def _replace_manifest_match(self, match: re.Match) -> str:
        """Dynamically replaces a [[manifest:...]] regex match with manifest data or an error."""
        manifest_path = self.repo_path / ".intent" / "project_manifest.yaml"
        if not manifest_path.exists():
            return f"\nâŒ Manifest file not found at {manifest_path}\n"

        try:
            manifest = yaml.safe_load(manifest_path.read_text(encoding="utf-8"))
        except Exception:
            return f"\nâŒ Could not parse manifest file at {manifest_path}\n"

        field = match.group(1).strip()
        value = manifest
        # Improved logic for nested key access
        for key in field.split("."):
            value = value.get(key) if isinstance(value, dict) else None
            if value is None:
                break
        
        if value is None:
            return f"\nâŒ Manifest field not found: {field}\n"
        
        # Pretty print for better context
        value_str = yaml.dump(value, indent=2) if isinstance(value, (dict, list)) else str(value)
        return f"\n--- MANIFEST: {field} ---\n{value_str}\n--- END MANIFEST ---\n"

    def _inject_manifest(self, prompt: str) -> str:
        """Replaces [[manifest:field]] directives with data from project_manifest.yaml."""
        return self.manifest_pattern.sub(self._replace_manifest_match, prompt)

    def process(self, prompt: str) -> str:
        """
        Processes the full prompt by sequentially resolving all directives.
        This is the main entry point for prompt enrichment.
        """
        prompt = self._inject_context(prompt)
        prompt = self._inject_includes(prompt)
        prompt = self._inject_analysis(prompt)
        prompt = self._inject_manifest(prompt)
        return prompt
--- END OF FILE ./src/core/prompt_pipeline.py ---

--- START OF FILE ./src/core/capabilities.py ---
# src/core/capabilities.py
"""
CORE Capability Registry
This file is the high-level entry point for the system's self-awareness loop.
It defines the `introspection` capability, which orchestrates the system's tools
to perform a full self-analysis.
"""
import logging
import subprocess
import sys
from pathlib import Path

logger = logging.getLogger(__name__)

# CAPABILITY: introspection
def introspection():
    """
    Runs a full self-analysis cycle to inspect system structure and health.
    This orchestrates the execution of the system's own introspection tools
    as separate, governed processes.
    """
    logger.info("ðŸ” Starting introspection cycle...")
    
    project_root = Path(__file__).resolve().parents[2]
    python_executable = sys.executable

    tools_to_run = [
        ("Knowledge Graph Builder", "src.system.tools.codegraph_builder"),
        ("Constitutional Auditor", "src.system.governance.constitutional_auditor"),
    ]

    all_passed = True
    for name, module in tools_to_run:
        print(f"\n--- Running {name} ---")
        try:
            result = subprocess.run(
                [python_executable, "-m", module],
                cwd=project_root,
                capture_output=True,
                text=True,
                check=True 
            )
            print(result.stdout)
            if result.stderr:
                print("--- Stderr ---")
                print(result.stderr)
            logger.info(f"âœ… {name} completed successfully.")
        except subprocess.CalledProcessError as e:
            print(e.stdout)
            print("--- Stderr ---")
            print(e.stderr)
            logger.error(f"âŒ {name} failed with exit code {e.returncode}.")
            all_passed = False
        except Exception as e:
            logger.error(f"âŒ An unexpected error occurred while running {name}: {e}")
            all_passed = False
            
    logger.info("ðŸ§  Introspection cycle completed.")
    return all_passed
--- END OF FILE ./src/core/capabilities.py ---

--- START OF FILE ./src/core/ruff_linter.py ---
# src/core/ruff_linter.py

"""
Runs Ruff lint checks on generated Python code before it's staged.

Returns a success flag and an optional linting message.
"""

import subprocess
import tempfile
import os
from typing import Tuple


def fix_and_lint_code_with_ruff(code: str, display_filename: str = "<code>") -> Tuple[bool, str, str]:
    """
    Fix and lint the provided Python code using Ruff.

    Args:
        code (str): Source code to fix and lint.
        display_filename (str): Optional display name (e.g., intended file path).

    Returns:
        (is_clean: bool, message: str, fixed_code: str)
    """
    tmp_file_path = None

    try:
        with tempfile.NamedTemporaryFile(suffix=".py", mode="w", delete=False) as tmp_file:
            tmp_file.write(code)
            tmp_file_path = tmp_file.name

        result = subprocess.run(
            ["ruff", "check", tmp_file_path, "--fix", "--exit-zero", "--quiet", "--ignore=D417,D401,D213,D407"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        # Read the fixed code back from the temporary file
        with open(tmp_file_path, "r") as f:
            fixed_code = f.read()

        # Check if there are any remaining errors
        if result.stdout.strip():
            # Replace temp path in output with the expected file path for user readability
            readable_output = result.stdout.replace(tmp_file_path, display_filename)
            return False, readable_output.strip(), fixed_code

        return True, "", fixed_code

    except FileNotFoundError:
        return False, "Ruff is not installed or not in your PATH. Please install it to enable lint checks.", code

    except Exception as e:
        return False, f"Ruff execution failed: {e}", code

    finally:
        if tmp_file_path and os.path.exists(tmp_file_path):
            try:
                os.remove(tmp_file_path)
            except Exception:
                pass  # Don't crash if temp cleanup fails
--- END OF FILE ./src/core/ruff_linter.py ---

--- START OF FILE ./src/core/file_handler.py ---
# src/core/file_handler.py
"""
Backend File Handling Module (Refactored)

Handles staging, writing, validating, and undoing file changes.
Integrates with safety policies and supports traceable, auditable operations.
All writes go through a pending stage to enable review and rollback.
"""

import json
import threading
from datetime import datetime, timezone
from uuid import uuid4
from pathlib import Path
from typing import Dict, Optional, Any

# Import from shared utilities
#from shared.path_utils import 
from shared.config_loader import load_config


# --- Constants ---
LOG_DIR = Path("logs")
PENDING_DIR = Path("pending_writes")
CHANGE_LOG_PATH = Path(".intent/change_log.json")
SAFETY_POLICIES_PATH = Path(".intent/policies/safety_policies.yaml")
UNDO_LOG = LOG_DIR / "undo_log.jsonl"


# --- Global State & Setup ---
pending_writes_storage: Dict[str, Dict[str, Any]] = {}
_storage_lock = threading.Lock()

# Ensure directories exist
LOG_DIR.mkdir(exist_ok=True)
PENDING_DIR.mkdir(exist_ok=True)


# --- Logging ---
# def log_action(action_type: str, data: dict):
#     """
#     Logs an action to the central actions.log for auditability.
#     """
#     try:
#         log_entry = {
#             "timestamp": datetime.now(timezone.utc).isoformat(),
#             "action": action_type,
#             **data
#         }
#         with open(LOG_DIR / "actions.log", "a", encoding="utf-8") as f:
#             f.write(json.dumps(log_entry) + "\n")
#     except Exception as e:
#         print(f"âš ï¸ Failed to log action: {str(e)}")


# --- Change Log ---
def _log_change(file_path: str, reason: str):
    """
    Appends a change entry to the intent change log.
    """
    change_entry = {
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "file": file_path,
        "reason": reason,
    }
    
    try:
        if CHANGE_LOG_PATH.exists():
            change_log = json.loads(CHANGE_LOG_PATH.read_text(encoding="utf-8"))
        else:
            change_log = {"schema_version": "1.0", "changes": []}
        
        change_log["changes"].append(change_entry)
        
        CHANGE_LOG_PATH.parent.mkdir(parents=True, exist_ok=True)
        CHANGE_LOG_PATH.write_text(json.dumps(change_log, indent=2), encoding="utf-8")
        print(f"âœ… Logged change for {file_path}")
    except Exception as e:
        print(f"âŒ Error logging change for {file_path}: {e}")


# --- Validation ---
def _validate_content(content: str, file_path: str) -> bool:
    """
    Validates content against safety policies (e.g., no eval, subprocess, etc.).
    """
    safety_policies = load_config(SAFETY_POLICIES_PATH, "yaml")
    if not safety_policies:
        return True # If no policies, assume content is safe.
        
    forbidden_calls = []
    for rule in safety_policies.get("rules", []):
        if rule.get("id") == "no_dangerous_execution":
            patterns = rule.get("detection", {}).get("patterns", [])
            forbidden_calls.extend(patterns)

    for forbidden in forbidden_calls:
        if forbidden in content:
            print(f"âŒ Validation failed: Dangerous pattern '{forbidden}' detected in {file_path}")
            return False
    return True


# --- FileHandler Class ---
class FileHandler:
    """
    Central class for safe, auditable file operations in CORE.
    All writes are staged first and require confirmation.
    """

    def __init__(self, repo_path: str):
        """
        Initialize FileHandler with repository root.
        """
        self.repo_path = Path(repo_path).resolve()
        if not self.repo_path.is_dir():
            raise ValueError(f"Invalid repository path provided: {repo_path}")

    def add_pending_write(self, prompt: str, suggested_path: str, code: str) -> str:
        """
        Stages a pending write operation for later confirmation.
        """
        pending_id = str(uuid4())
        rel_path = Path(suggested_path).as_posix()
        entry = {
            "id": pending_id,
            "prompt": prompt,
            "path": rel_path,
            "code": code,
            "timestamp": datetime.now(timezone.utc).isoformat(),
        }

        with _storage_lock:
            pending_writes_storage[pending_id] = entry

        pending_file = PENDING_DIR / f"{pending_id}.json"
        pending_file.write_text(json.dumps(entry, indent=2), encoding="utf-8")
        return pending_id

    def confirm_write(self, pending_id: str) -> Dict[str, str]:
        """
        Confirms and applies a pending write to disk.
        """
        with _storage_lock:
            pending_op = pending_writes_storage.pop(pending_id, None)

        pending_file = PENDING_DIR / f"{pending_id}.json"
        if pending_file.exists():
            pending_file.unlink()

        if not pending_op:
            return {"status": "error", "message": f"Pending write ID '{pending_id}' not found or already processed."}

        file_rel_path = pending_op["path"]
        
        if not _validate_content(pending_op["code"], file_rel_path):
            return {"status": "error", "message": f"Validation failed for {file_rel_path}"}

        try:
            abs_file_path = self.repo_path / file_rel_path
            
            if not abs_file_path.resolve().is_relative_to(self.repo_path.resolve()):
                 raise ValueError(f"Attempted to write outside of repository boundary: {file_rel_path}")

            abs_file_path.parent.mkdir(parents=True, exist_ok=True)
            abs_file_path.write_text(pending_op["code"], encoding="utf-8")
            
            _log_change(file_rel_path, pending_op["prompt"])
            return {
                "status": "success",
                "message": f"Wrote to {file_rel_path}",
                "file_path": file_rel_path
            }
        except Exception as e:
            return {"status": "error", "message": f"Failed to write file: {str(e)}"}

--- END OF FILE ./src/core/file_handler.py ---

--- START OF FILE ./src/core/intent_model.py ---
# src/core/intent_model.py

"""
CORE Intent Structure Loader
============================

Provides a normalized interface to the declared domain structure in:
.intent/knowledge/source_structure.yaml

Used to enforce boundaries, access rules, and governance alignment
without hardcoding anything.
"""

import yaml
from pathlib import Path
from typing import Dict, List, Optional


class IntentModel:
    """
    Loads and provides an queryable interface to the source code structure
    defined in .intent/knowledge/source_structure.yaml.
    """
    def __init__(self, repo_root: Optional[Path] = None):
        """
        Initializes the model by loading the source structure definition.

        Args:
            repo_root (Optional[Path]): The root of the repository. Inferred if not provided.
        """
        self.repo_root = repo_root or Path(__file__).resolve().parents[2]
        self.structure_path = self.repo_root / ".intent" / "knowledge" / "source_structure.yaml"
        self.structure: Dict[str, dict] = self._load_structure()

    def _load_structure(self) -> Dict[str, dict]:
        """
        Load the domain structure from .intent/knowledge/source_structure.yaml.

        Returns:
            Dict[str, dict]: Mapping of domain names to metadata (path, permissions, etc.).
        """
        if not self.structure_path.exists():
            raise FileNotFoundError(f"Missing: {self.structure_path}")

        data = yaml.safe_load(self.structure_path.read_text(encoding="utf-8"))

        if not isinstance(data, dict) or "structure" not in data:
            raise ValueError(
                f"Invalid source_structure.yaml: missing top-level 'structure' key"
            )

        return {entry["domain"]: entry for entry in data["structure"]}

#    def get_domains(self) -> List[str]:
#        """Return all domain names defined in the source structure."""
#        return list(self.structure.keys())

#    def get_path_for_domain(self, domain: str) -> Optional[Path]:
#        """Return the expected path prefix for a given domain."""
#        entry = self.structure.get(domain)
#        if entry:
#            return self.repo_root / entry["path"]
#        return None

#    def get_allowed_types(self, domain: str) -> List[str]:
#        """Return allowed file types for a domain."""
#        entry = self.structure.get(domain)
#        return entry.get("restricted_types") or ["python", "yaml", "json", "md"]

#    def get_default_handler(self, domain: str) -> Optional[str]:
#        """Return the default handler (e.g., LLM agent) for a given domain."""
#        entry = self.structure.get(domain)
#        return entry.get("default_handler")

#    def is_editable(self, domain: str) -> bool:
#        """Return whether a domain is editable (used for governance constraints)."""
#        entry = self.structure.get(domain)
#        return entry.get("editable", False)

    def resolve_domain_for_path(self, file_path: Path) -> Optional[str]:
        """
        Given an absolute or relative path, determine which domain it belongs to.
        Prefers deeper (more specific) paths over shorter ones.
        """
        full_path = file_path.resolve()
        sorted_domains = sorted(
            self.structure.items(),
            key=lambda item: len((self.repo_root / item[1]["path"]).parts),
            reverse=True,
        )
        for domain, entry in sorted_domains:
            domain_root = (self.repo_root / entry["path"]).resolve()
            if domain_root in full_path.parents:
                return domain
        return None

    def get_domain_permissions(self, domain: str) -> List[str]:
        """
        Return a list of allowed domains that the given domain can import from.

        Args:
            domain (str): The domain to query.

        Returns:
            List[str]: List of allowed domain names, or empty list if not defined.
        """
        entry = self.structure.get(domain, {})
        allowed = entry.get("allowed_imports", [])
        return allowed if isinstance(allowed, list) else []

--- END OF FILE ./src/core/intent_model.py ---

--- START OF FILE ./src/core/intent_guard.py ---
# src/core/intent_guard.py
"""
IntentGuard â€” CORE's Constitutional Enforcement Module

Enforces safety, structure, and intent alignment for all file changes.
Uses hard-coded "bootstrap" classifications for critical files (like policies)
and loads additional rules from .intent/policies/*.yaml.
Prevents undocumented changes, unsafe edits, and unauthorized self-modifications.
"""

import yaml
import json
from pathlib import Path
from typing import List, Dict, Tuple, Any, Optional
from shared.config_loader import load_config


# class UnknownFileClassificationError(Exception):
#     """
#     Raised when a file's type (e.g., policy, manifest) cannot be determined.
#     """
#     def __init__(self, file_path: str):
#         self.file_path = file_path
#         super().__init__(f"Constitutional shortsightedness: The file '{file_path}' has no known classification.")


# CAPABILITY: intent_guarding
class IntentGuard:
    """
    Central enforcement engine for CORE's safety and governance policies.
    Ensures all proposed file changes comply with declared rules and classifications.
    Uses a mix of hard-coded primordial truths and dynamic policy loading.
    """

    def __init__(self, repo_path: Path):
        """
        Initialize IntentGuard with repository path and load all policies.
        """
        self.repo_path = Path(repo_path)
        self.intent_path = self.repo_path / ".intent"
        self.policies_path = self.intent_path / "policies"
        self.rules: List[Dict] = []
        
        self.classifications: List[Dict] = [
            {"name": "policy", "extensions": [".yaml", ".yml"]},
            {"name": "manifest", "extensions": [".json"]},
            {"name": "document", "extensions": [".md"]},
            {"name": "python", "extensions": [".py"]},
        ]
        
        self._load_policies()
        # --- NOTE: This function still points to the old manifest. It should be updated. ---
        # --- We will let the auditor guide this change later if needed. ---
        self.source_code_manifest = self._load_source_manifest()
        
        print(f"âœ… IntentGuard initialized. {len(self.rules)} rules loaded. Watching {len(self.source_code_manifest)} source files.")

    def _load_policies(self):
        """
        Load rules from all YAML files in .intent/policies/.
        """
        if not self.policies_path.is_dir():
            return
        for policy_file in self.policies_path.glob("*.yaml"):
            content = load_config(policy_file, "yaml")
            if content and "rules" in content and isinstance(content["rules"], list):
                self.rules.extend(content["rules"])

    def _get_classification(self, file_path: str) -> Optional[str]:
        """
        Determine the classification of a file based on its extension.
        """
        suffix = Path(file_path).suffix
        for c in self.classifications:
            if suffix in c.get("extensions", []):
                return c.get("name")
        return None

    def _load_source_manifest(self) -> List[str]:
        """
        Load the list of declared source files from function_manifest.json.
        """
        # This function is now pointing to a deleted file. The Constitutional Auditor
        # will eventually tell us that this logic is flawed. For now, we leave it,
        # as our goal is to fix the capability error first.
        manifest_file = self.intent_path / "knowledge" / "function_manifest.json"
        if not manifest_file.exists():
            return []
        try:
            manifest_data = json.loads(manifest_file.read_text(encoding="utf-8"))
            functions = manifest_data.get("functions", [])
            return [entry.get("file") for entry in functions if entry.get("file")]
        except (json.JSONDecodeError, TypeError):
            return []

    # CAPABILITY: change_safety_enforcement
#    def check_transaction(self, proposed_paths: List[str]) -> Tuple[bool, List[str]]:
#        """
#        Check if a proposed set of file changes complies with all active rules.
#        """
#        violations = []
#        for path in proposed_paths:
#            classification = self._get_classification(path)
#            if classification is None:
#                violations.append(f"Rule Violation (unknown_classification): File '{path}' has no known classification.")
#                continue
#            for rule in self.rules:
#                target_classification = rule.get("applies_to_classification")
#                if target_classification and classification != target_classification:
#                    continue
#                rule_id = rule.get("id")
#                if rule_id == "no_undocumented_change" and classification == 'python':
#                    if path not in self.source_code_manifest:
#                        violations.append(f"Rule Violation ({rule_id}): Source file '{path}' is not declared in the function manifest.")
#        return not violations, violations
--- END OF FILE ./src/core/intent_guard.py ---

--- START OF FILE ./src/core/self_correction_engine.py ---
# src/core/self_correction_engine.py
"""
Self-Correction Engine
This module takes failure context (from validation or test failure)
and attempts to repair the issue using a structured LLM prompt,
then stages the corrected version via the file handler.
"""
import json
from pathlib import Path
from core.prompt_pipeline import PromptPipeline
from core.clients import GeneratorClient
from core.validation_pipeline import validate_code
from core.file_handler import FileHandler

REPO_PATH = Path(".").resolve()
pipeline = PromptPipeline(repo_path=REPO_PATH)
file_handler = FileHandler(repo_path=REPO_PATH)

# CAPABILITY: self_correction
def attempt_correction(failure_context: dict) -> dict:
    """
    Attempts to fix a failed validation or test result using an enriched LLM prompt.
    """
    generator = GeneratorClient()
    file_path = failure_context.get("file_path")
    code = failure_context.get("code")
    error_type = failure_context.get("error_type")
    details = failure_context.get("details", {})
    base_prompt = failure_context.get("original_prompt", "")

    if not file_path or not code or not error_type:
        return {"status": "error", "message": "Missing required failure context fields."}

    correction_prompt = (
        f"You are CORE's self-correction agent.\n\nA recent code generation attempt failed {error_type}.\n"
        f"Please analyze and fix the code below.\n\nFile: {file_path}\n\n"
        f"[[failure_reason]]\n{json.dumps(details, indent=2)}\n[[/failure_reason]]\n\n"
        f"[[code]]\n{code.strip()}\n[[/code]]\n\n"
        f"Respond with corrected content using the format:\n[[write:{file_path}]]\n<corrected code here>\n[[/write]]"
    )

    final_prompt = pipeline.process(correction_prompt)
    llm_output = generator.make_request(final_prompt, user_id="auto_repair")
    
    from shared.utils.parsing import parse_write_blocks
    write_blocks = parse_write_blocks(llm_output)

    if not write_blocks:
        return {"status": "error", "message": "LLM did not produce valid correction."}

    # Assuming one write block for self-correction
    path, fixed_code = list(write_blocks.items())[0]

    validation = validate_code(path, fixed_code)
    if validation["status"] != "clean":
        return {
            "status": "validation_failed",
            "message": "Corrected code still fails validation.",
            "errors": validation.get("errors", []),
        }

    pending_id = file_handler.add_pending_write(prompt=final_prompt, suggested_path=path, code=validation["code"])
    return {
        "status": "retry_staged",
        "pending_id": pending_id,
        "file_path": path,
        "message": "Corrected code staged for approval.",
    }
--- END OF FILE ./src/core/self_correction_engine.py ---

--- START OF FILE ./src/agents/__init__.py ---
# src/agents/__init__.py
# Package marker for src/agents â€” contains CORE's agent implementations (e.g., PlannerAgent).
--- END OF FILE ./src/agents/__init__.py ---

--- START OF FILE ./src/agents/planner_agent.py ---
# src/agents/planner_agent.py

import json
import re
import textwrap
import ast
from typing import List, Dict, Tuple, Optional
from pathlib import Path

from core.clients import OrchestratorClient, GeneratorClient
from core.file_handler import FileHandler
from core.git_service import GitService
from core.intent_guard import IntentGuard
from core.prompt_pipeline import PromptPipeline
from core.self_correction_engine import attempt_correction
from core.validation_pipeline import validate_code  # <-- ADD THIS IMPORT
from shared.utils.parsing import parse_write_blocks

# CAPABILITY: llm_orchestration
class PlannerAgent:
    """
    The primary agent responsible for decomposing high-level goals into executable plans.
    It orchestrates the generation, validation, and commitment of code changes.
    """
    def __init__(self,
                 orchestrator_client: OrchestratorClient,
                 generator_client: GeneratorClient,
                 file_handler: FileHandler,
                 git_service: GitService,
                 intent_guard: IntentGuard):
        """Initializes the PlannerAgent with all necessary service dependencies."""
        self.orchestrator = orchestrator_client
        self.generator = generator_client
        self.file_handler = file_handler
        self.git_service = git_service
        self.intent_guard = intent_guard
        self.repo_path = self.file_handler.repo_path
        self.prompt_pipeline = PromptPipeline(self.repo_path)

    def _extract_target_path_from_prompt(self, prompt: str) -> Optional[str]:
        """Parses a prompt to find the first [[write:path/to/file]] directive."""
        match = re.search(r'\[\[write:(.+?)\]\]', prompt)
        return match.group(1).strip() if match else None

    def _extract_json_from_response(self, text: str) -> str:
        """Extracts a JSON object or array from a raw text response."""
        match = re.search(r"```json\n([\s\S]*?)\n```", text, re.DOTALL)
        if match:
            return match.group(1).strip()
        match = re.search(r'\[\s*\{[\s\S]*?\}\s*\]', text)
        if match:
            return match.group(0).strip()
        return ""

    # CAPABILITY: prompt_interpretation
    def create_execution_plan(self, high_level_goal: str) -> List[Dict]:
        """Creates a detailed, step-by-step execution plan from a high-level goal."""
        print(f"ðŸ§  Planner: Creating execution plan for goal: '{high_level_goal}'")
        
        prompt = textwrap.dedent(f"""
            You are a hyper-competent, meticulous system architect AI for the CORE project. Your task is to decompose a high-level goal into a precise, machine-readable JSON execution plan.
            Your entire output MUST be a single, valid JSON array of objects.
            Each object in the plan MUST have these keys:
            - "step": A human-readable description of the task.
            - "prompt": A detailed, self-contained prompt for a Generator LLM, including all necessary context and a [[write:path/to/file]] block.
            - "expects_writes": A boolean indicating if the step should result in a file write.
            **High-Level Goal:** "{high_level_goal}"
            Generate the complete, self-contained, and syntactically correct JSON plan now.
        """).strip()

        try:
            response_text = self.orchestrator.make_request(prompt, user_id="planner_agent")
            json_string = self._extract_json_from_response(response_text)
            if not json_string:
                raise ValueError(f"Planner LLM did not return a valid JSON plan. Response: {response_text}")
            plan = json.loads(json_string)
            print(f"âœ… Planner: LLM-based plan created successfully with {len(plan)} step(s).")
            return plan
        except (ValueError, json.JSONDecodeError) as e:
            print(f"âŒ Planner: FATAL - Failed during LLM plan creation. Error: {e}")
            return []

    async def execute_plan(self, plan: List[Dict]) -> Tuple[bool, str]:
        """Executes a plan, running each task in sequence."""
        print("\n--- ðŸš€ Executing Plan ---")
        if not plan:
            return False, "Plan is empty or invalid."
        for i, task in enumerate(plan):
            step_name = task.get('step', 'Unnamed Step')
            print(f"\n--- Step {i + 1}/{len(plan)}: {step_name} ---")
            try:
                await self._execute_task(task)
            except Exception as e:
                error_detail = str(e)
                print(f"âŒ Planner: Step failed with error: {error_detail}")
                if self.git_service.is_git_repo():
                    print("  -> Attempting to roll back last commit due to failure...")
                    self.git_service.rollback_last_commit()
                return False, f"Plan failed at step {i + 1} ('{step_name}'): {error_detail}"
        return True, "âœ… Plan executed successfully."

    # CAPABILITY: change_safety_enforcement
    def _govern_and_amend_code(self, code: str) -> str:
        """
        Validates and amends newly generated code to comply with constitutional
        standards before being written to disk. This is the core of the
        "immune system".

        Args:
            code (str): The raw Python code generated by the LLM.

        Returns:
            str: The amended code, compliant with governance.
        
        Raises:
            RuntimeError: If a critical governance check fails (e.g., missing docstring).
        """
        print("    3a. Governing and amending raw code...")
        try:
            tree = ast.parse(code)
            lines = code.splitlines()
            insertions = []

            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef, ast.ClassDef)):
                    # --- NEW DOCSTRING ENFORCEMENT ---
                    if not ast.get_docstring(node):
                        raise RuntimeError(f"Governance check failed: Symbol '{node.name}' is missing a required docstring.")
                    # ------------------------------------

                    # Check if a capability comment already exists on the line above
                    line_above_index = node.lineno - 2
                    if line_above_index < 0 or not lines[line_above_index].strip().startswith("# CAPABILITY:"):
                        # Prepare to insert the placeholder capability tag
                        indentation = ' ' * node.col_offset
                        insertions.append((node.lineno - 1, f"{indentation}# CAPABILITY: unassigned"))
            
            # Apply insertions in reverse order to not mess up line numbers
            for line_num, text in sorted(insertions, reverse=True):
                lines.insert(line_num, text)

            amended_code = "\n".join(lines)
            print("    3b. âœ… Code passed governance checks and was amended.")
            return amended_code
        except SyntaxError as e:
            print(f"    âš ï¸  Could not parse generated code to govern it. Returning raw code. Error: {e}")
            return code # Return raw code if it can't be parsed

    # CAPABILITY: code_generation
    async def _execute_task(self, task: Dict) -> None:
        """Executes a single task from a plan, including code generation and file writing."""
        prompt = task.get("prompt")
        if not prompt:
            print("  -> Skipping task: No prompt provided.")
            return

        print("  1. Enriching prompt with directives...")
        enriched_prompt = self.prompt_pipeline.process(prompt)

        print("  2. Calling generation service...")
        generated_text = self.generator.make_request(enriched_prompt, user_id="planner_agent")
        write_blocks = parse_write_blocks(generated_text)
        
        if not write_blocks and task.get("expects_writes", True):
            print("  âš ï¸  Generator failed to produce a valid write block. Initiating self-correction.")
            target_path = self._extract_target_path_from_prompt(enriched_prompt)
            if not target_path:
                raise RuntimeError("Cannot attempt self-correction: Could not determine target file path from prompt.")
            failure_context = {
                "file_path": target_path, "code": generated_text, "error_type": "missing_write_block",
                "details": "The Generator LLM produced code but failed to wrap it in [[write:...]] block.",
                "original_prompt": enriched_prompt,
            }
            correction_result = attempt_correction(failure_context)
            if correction_result.get("status") == "retry_staged":
                print("  âœ… Self-correction successful. Staged corrected code.")
                write_blocks = {correction_result["file_path"]: "Code from self-correction"} # This is a placeholder
            else:
                raise RuntimeError(f"Self-correction failed: {correction_result.get('message')}")
        
        written_files = []
        for file_path, code in write_blocks.items():
            print(f"  3. Governing code for '{file_path}'")
            governed_code = self._govern_and_amend_code(code)

            # --- NEW VALIDATION & SELF-CORRECTION STEP ---
            print(f"  4. Validating governed code for '{file_path}'...")
            validation_result = validate_code(file_path, governed_code)
            
            pending_id = None
            if validation_result["status"] == "clean":
                print("  âœ… Validation clean. Staging write.")
                final_code = validation_result["code"]
                pending_id = self.file_handler.add_pending_write(
                    prompt=enriched_prompt,
                    suggested_path=file_path,
                    code=final_code
                )
            else: # Validation is dirty, attempt self-correction
                print("  âš ï¸  Validation failed. Initiating self-correction.")
                failure_context = {
                    "file_path": file_path,
                    "code": governed_code,
                    "error_type": "validation_failed",
                    "details": validation_result.get("errors", []),
                    "original_prompt": enriched_prompt,
                }
                correction_result = attempt_correction(failure_context)

                if correction_result.get("status") == "retry_staged":
                    print("  âœ… Self-correction successful. Using corrected & staged code.")
                    pending_id = correction_result["pending_id"]
                else:
                    raise RuntimeError(f"Self-correction failed after validation error: {correction_result.get('message')}")

            if not pending_id:
                raise RuntimeError(f"Logic error: No pending write ID was created for {file_path}")

            print(f"  5. Confirming write for '{file_path}' (ID: {pending_id})")
            confirmation_result = self.file_handler.confirm_write(pending_id)
            
            if confirmation_result.get('status') != 'success':
                raise RuntimeError(f"Failed to confirm write for {file_path}: {confirmation_result.get('message')}")
            
            print(f"  âœ… Write confirmed for '{file_path}'")
            written_files.append(file_path)

        if self.git_service.is_git_repo() and written_files:
            print("  6. Committing changes to repository...")
            for file_path in written_files:
                self.git_service.add(file_path)
            commit_message = f"feat(agent): {task.get('step', 'Automated code generation')}"
            self.git_service.commit(commit_message)
--- END OF FILE ./src/agents/planner_agent.py ---

--- START OF FILE ./src/shared/schemas/manifest_validator.py ---
# src/shared/schemas/manifest_validator.py
"""Shared utilities for validating manifest files against schemas."""
import json
import jsonschema
from pathlib import Path
from typing import Dict, Any, Tuple, List

from shared.path_utils import get_repo_root

# The single source of truth for the location of constitutional schemas.
SCHEMA_DIR = get_repo_root() / ".intent" / "schemas"

def load_schema(schema_name: str) -> Dict[str, Any]:
    """
    Load a JSON schema from the .intent/schemas/ directory.
    
    Args:
        schema_name (str): The filename of the schema (e.g., 'knowledge_graph_entry.schema.json').
        
    Returns:
        Dict[str, Any]: The loaded JSON schema.
        
    Raises:
        FileNotFoundError: If the schema file is not found.
        json.JSONDecodeError: If the schema file is not valid JSON.
    """
    schema_path = SCHEMA_DIR / schema_name
    
    if not schema_path.exists():
        raise FileNotFoundError(f"Schema file not found: {schema_path}")
        
    try:
        with open(schema_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        raise json.JSONDecodeError(f"Invalid JSON in schema file {schema_path}: {e.msg}", e.doc, e.pos)

def validate_manifest_entry(entry: Dict[str, Any], schema_name: str = "knowledge_graph_entry.schema.json") -> Tuple[bool, List[str]]:
    """
    Validate a single manifest entry against a schema.
    
    Args:
        entry: The dictionary representing a single function/class entry.
        schema_name: The filename of the schema to validate against.
        
    Returns:
        A tuple of (is_valid: bool, list_of_error_messages: List[str]).
    """
    try:
        schema = load_schema(schema_name)
    except Exception as e:
        return False, [f"Failed to load schema '{schema_name}': {e}"]

    # Use Draft7Validator for compatibility with our schema definition.
    validator = jsonschema.Draft7Validator(schema)
    errors = []
    
    for error in validator.iter_errors(entry):
        # Create a user-friendly error message
        path = ".".join(str(p) for p in error.absolute_path) or "<root>"
        errors.append(f"Validation error at '{path}': {error.message}")
        
    is_valid = not errors
    return is_valid, errors
--- END OF FILE ./src/shared/schemas/manifest_validator.py ---

--- START OF FILE ./src/shared/path_utils.py ---
# src/shared/path_utils.py

from pathlib import Path
from typing import Optional

def get_repo_root(start_path: Optional[Path] = None) -> Path:
    """
    Find and return the repository root by locating the .git directory.
    Starts from current directory or provided path.
    
    Returns:
        Path: Absolute path to repo root.
    
    Raises:
        RuntimeError: If no .git directory is found.
    """
    current = Path(start_path or Path.cwd()).resolve()
    
    # Traverse upward until .git is found
    for parent in [current, *current.parents]:
        if (parent / ".git").exists():
            return parent
    
    raise RuntimeError("Not a git repository: could not find .git directory")
--- END OF FILE ./src/shared/path_utils.py ---

--- START OF FILE ./src/shared/config_loader.py ---
# src/shared/config_loader.py

import json
import yaml
from pathlib import Path
from typing import Dict, Any

def load_config(file_path: Path, file_type: str = "auto") -> Dict[str, Any]:
    """
    Loads a JSON or YAML file into a dictionary with consistent error handling.

    Args:
        file_path (Path): Path to the file to load.
        file_type (str): 'json', 'yaml', or 'auto' to infer from extension.

    Returns:
        Dict[str, Any]: Parsed file content or empty dict if file is missing/invalid.
    """
    file_path = Path(file_path)
    if not file_path.exists():
        print(f"âš ï¸ Warning: File not found at {file_path}")
        return {}

    # Determine file type if 'auto'
    if file_type == "auto":
        suffix = file_path.suffix.lower()
        file_type = "json" if suffix == ".json" else "yaml" if suffix in (".yaml", ".yml") else None

    if file_type not in ("json", "yaml"):
        print(f"âŒ Error: Unsupported file type for {file_path}")
        return {}

    try:
        with file_path.open(encoding="utf-8") as f:
            if file_type == "json":
                data = json.load(f)
                # Ensure dictionary for JSON
                return data if isinstance(data, dict) else {}
            else:  # yaml
                data = yaml.safe_load(f)
                # Ensure dictionary for YAML
                return data if isinstance(data, dict) else {}
    except (json.JSONDecodeError, yaml.YAMLError) as e:
        print(f"âŒ Error parsing {file_path}: {e}")
        return {}
--- END OF FILE ./src/shared/config_loader.py ---

--- START OF FILE ./src/shared/utils/__init__.py ---
[EMPTY FILE]

--- END OF FILE ./src/shared/utils/__init__.py ---

--- START OF FILE ./src/shared/utils/import_scanner.py ---
# src/shared/utils/import_scanner.py

"""
Import Scanner Utility
======================

Scans a Python file for top-level import statements.
"""

import ast
from pathlib import Path
from typing import List


def scan_imports_for_file(file_path: Path) -> List[str]:
    """
    Parse a Python file and extract all imported module paths.

    Args:
        file_path (Path): Path to the file.

    Returns:
        List[str]: List of imported module paths.
    """
    imports = []
    try:
        source = file_path.read_text(encoding="utf-8")
        tree = ast.parse(source)

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module)

    except Exception as e:
        print(f"[ImportScanner] Warning: Failed to scan {file_path}: {e}")

    return imports

--- END OF FILE ./src/shared/utils/import_scanner.py ---

--- START OF FILE ./src/shared/utils/parsing.py ---
# src/shared/utils/parsing.py
"""
Parsing utility functions for the CORE system.
"""
import re
from typing import Dict

def parse_write_blocks(llm_output: str) -> Dict[str, str]:
    """
    Extracts all [[write:...]] blocks from LLM output.

    This function is robust and handles both [[end]] and [[/write]] as valid terminators
    to accommodate different LLM habits.

    Args:
        llm_output (str): The raw text output from a language model.

    Returns:
        A dictionary mapping file paths to their corresponding code content.
    """

    pattern = r"\[\[write:\s*(.+?)\]\](.*?)(?:\[\[end\]\]|\[\[/write\]\])"
    matches = re.findall(pattern, llm_output, re.DOTALL)
    return {path.strip(): code.strip() for path, code in matches}

#def extract_json_from_response(text: str) -> str:
#    """
#    Extracts a JSON object or array from a raw text response.
#    Handles both markdown ```json code blocks and raw JSON strings.#
#        Args:
#        text (str): The raw text output from a language model.#
#    Returns:
#        A string containing the extracted JSON, or an empty string if not found.
#    """
#    match = re.search(r"```json\n([\s\S]*?)\n```", text, re.DOTALL)
#    if match:
#        return match.group(1).strip()
#    match = re.search(r'\[\s*\{[\s\S]*?\}\s*\]', text)
#    if match:
#        return match.group(0).strip()
#    return ""
--- END OF FILE ./src/shared/utils/parsing.py ---

--- START OF FILE ./.gitignore ---
# Python
__pycache__/
*.py[cod]
*.pyo
*.pyd
*.so
*.egg-info/

# Virtual environments
.venv/
.env

# Testing
.pytest_cache/
.coverage
htmlcov/
*.log

# Editors
.vscode/
.idea/
*.swp

# System/OS
.DS_Store
Thumbs.db

# CORE-specific
logs/
pending_writes/
sandbox/
*.jsonl
*.lock

# Cache or checkpoints
*.bak
*.tmp

--- END OF FILE ./.gitignore ---

--- START OF FILE ./Makefile ---
# Makefile for CORE â€“ Cognitive Orchestration Runtime Engine (Robust Version)

.PHONY: help install lock run stop lint format test manifest-update clean

# Default command: show help
help:
	@echo "CORE Development Makefile"
	@echo "-------------------------"
	@echo "Available commands:"
	@echo "  make install         - Install dependencies using Poetry"
	@echo "  make lock            - Update the poetry.lock file"
	@echo "  make run             - Stop any running server and start a new one with auto-reload"
	@echo "  make stop            - Stop the development server if it is running"
	@echo "  make lint            - Run Ruff to check for linting errors"
	@echo "  make format          - Auto-format code with Black and Ruff"
	@echo "  make test            - Run all tests with pytest"
	@echo "  make clean           - Remove temporary Python files"

install:
	@echo "ðŸ“¦ Installing dependencies..."
	python3 -m poetry install

lock:
	@echo "ðŸ”’ Resolving and locking dependencies..."
	python3 -m poetry lock

# --- MODIFICATION: The 'run' command now depends on 'stop' ---
# This ensures that `make stop` is always executed before `make run` starts.
run: stop
	@echo "ðŸš€ Starting FastAPI server at http://127.0.0.1:8000"
	python3 -m poetry run uvicorn src.core.main:app --reload --host 0.0.0.0 --port 8000

# --- MODIFICATION: New target to stop the server ---
# It checks for the kill script and runs it.
stop:
	@if [ -f ./kill-core.sh ]; then \
		./kill-core.sh; \
	else \
		echo "âš ï¸  kill-core.sh not found. Skipping stop."; \
	fi

lint:
	@echo "ðŸŽ¨ Checking code style with Ruff..."
	python3 -m poetry run ruff check .

format:
	@echo "âœ¨ Formatting code with Black and Ruff..."
	python3 -m poetry run ruff check . --fix
	python3 -m poetry run black .

test:
	@echo "ðŸ§ª Running tests with pytest..."
	python3 -m poetry run pytest

clean:
	@echo "ðŸ§¹ Cleaning up temporary files..."
	find . -type f -name '*.pyc' -delete
	find . -type d -name '__pycache__' -exec rm -r {} +
--- END OF FILE ./Makefile ---

--- START OF FILE ./tests/system/governance/--- test_northstar_enforcer.py ---
# tests/system/governance/test_northstar_enforcer.py

import pytest
from pathlib import Path
# --- FIX: Changed import from 'system.governance.northstar_enforcer' to 'system.governance.northstar_enforcer'
from system.governance.northstar_enforcer import NorthStarEnforcer

@pytest.fixture
def mock_repo_root(tmp_path):
    """Prepare a mock .intent/mission/northstar.yaml structure"""
    mission_dir = tmp_path / ".intent" / "mission"
    mission_dir.mkdir(parents=True)

    content = """
northstar: Drive safe, traceable AI evolution.
purpose:
  - Ensure all generated code serves a traceable, justifiable goal.
  - Empower AI with operational clarity.
values:
  - Traceability
  - Alignment
  - Constitution-first thinking
"""

    path = mission_dir / "northstar.yaml"
    path.write_text(content)
    return tmp_path

def test_explain_policy_outputs_without_error(mock_repo_root, capsys):
    enforcer = NorthStarEnforcer(repo_root=mock_repo_root)
    enforcer.explain_policy()
    output = capsys.readouterr().out
    assert "CORE's NorthStar" in output
    assert "Traceability" in output
    assert "Drive safe" in output

def test_justified_purpose_match(mock_repo_root):
    enforcer = NorthStarEnforcer(repo_root=mock_repo_root)
    assert enforcer.is_justified("traceability") is True
    assert enforcer.is_justified("empower AI with operational clarity") is True

def test_unjustified_purpose(mock_repo_root):
    enforcer = NorthStarEnforcer(repo_root=mock_repo_root)
    assert enforcer.is_justified("random marketing fluff") is False

def test_validate_intent(mock_repo_root):
    enforcer = NorthStarEnforcer(repo_root=mock_repo_root)

    aligned_intent = {"justification": "empower AI with operational clarity"}
    misaligned_intent = {"justification": "make code trendy and fun"}

    assert enforcer.validate_intent(aligned_intent) is True
    assert enforcer.validate_intent(misaligned_intent) is False

def test_missing_file_raises_error(tmp_path):
    with pytest.raises(FileNotFoundError):
        NorthStarEnforcer(repo_root=tmp_path)
--- END OF FILE ./tests/system/governance/--- test_northstar_enforcer.py ---

--- START OF FILE ./tests/unit/test_planner_agent.py ---
# tests/unit/test_planner_agent.py
import json
import pytest
from agents.planner_agent import PlannerAgent
from unittest.mock import MagicMock #, AsyncMock, patch


@pytest.fixture
def mock_dependencies(mocker):
    """Mocks all external dependencies for the PlannerAgent."""
    mock_orchestrator = MagicMock()
    mock_generator = MagicMock()
    mock_file_handler = MagicMock()
    mock_git_service = MagicMock()
    mock_intent_guard = MagicMock()
    
    # Configure the mock file_handler to have a 'repo_path' attribute
    mock_file_handler.repo_path = "/fake/repo"

    mocker.patch('core.prompt_pipeline.PromptPipeline', return_value=MagicMock())

    return {
        "orchestrator_client": mock_orchestrator,
        "generator_client": mock_generator,
        "file_handler": mock_file_handler,
        "git_service": mock_git_service,
        "intent_guard": mock_intent_guard,
    }

def test_create_execution_plan_success(mock_dependencies):
    """Tests that the planner can successfully create a plan from a goal."""
    # Arrange
    agent = PlannerAgent(**mock_dependencies)
    goal = "This is a test goal."
    
    # Mock the orchestrator's response
    plan_json = json.dumps([{"step": "Test Step", "prompt": "Do a thing", "expects_writes": True}])
    mock_dependencies["orchestrator_client"].make_request.return_value = f"```json\n{plan_json}\n```"

    # Act
    plan = agent.create_execution_plan(goal)

    # Assert
    mock_dependencies["orchestrator_client"].make_request.assert_called_once()
    assert isinstance(plan, list)
    assert len(plan) == 1
    assert plan[0]["step"] == "Test Step"

def test_create_execution_plan_failure_on_bad_json(mock_dependencies):
    """Tests that the planner returns an empty list if the LLM gives bad JSON."""
    # Arrange
    agent = PlannerAgent(**mock_dependencies)
    goal = "This is a test goal."
    mock_dependencies["orchestrator_client"].make_request.return_value = "This is not JSON."

    # Act
    plan = agent.create_execution_plan(goal)

    # Assert
    assert plan == []

@pytest.mark.asyncio
async def test_execute_plan_success(mock_dependencies):
    """Tests a successful execution of a simple, single-step plan."""
    # Arrange
    agent = PlannerAgent(**mock_dependencies)
    plan = [{"step": "Create test file", "prompt": "[[write:src/test.py]]", "expects_writes": True}]

    # Mock downstream service calls
    mock_dependencies["generator_client"].make_request.return_value = "[[write:src/test.py]]\nprint('hello')\n[[/write]]"
    mock_dependencies["file_handler"].add_pending_write.return_value = "mock_pending_id"
    mock_dependencies["file_handler"].confirm_write.return_value = {"status": "success", "file_path": "src/test.py"}
    mock_dependencies["git_service"].is_git_repo.return_value = True

    # Act
    success, message = await agent.execute_plan(plan)

    # Assert
    assert success is True
    assert message == "âœ… Plan executed successfully."
    mock_dependencies["generator_client"].make_request.assert_called_once()
    mock_dependencies["file_handler"].confirm_write.assert_called_once_with("mock_pending_id")
    mock_dependencies["git_service"].add.assert_called_once_with("src/test.py")
    mock_dependencies["git_service"].commit.assert_called_once()

--- END OF FILE ./tests/unit/test_planner_agent.py ---

--- START OF FILE ./tests/unit/test_git_service.py ---
# tests/unit/test_git_service.py
import pytest
from unittest.mock import MagicMock
from pathlib import Path
# --- FIX: Changed import from 'src.core.git_service' to 'core.git_service' ---
from core.git_service import GitService

@pytest.fixture
def mock_git_service(mocker, tmp_path):
    """Creates a GitService instance with a mocked subprocess.run."""
    (tmp_path / ".git").mkdir()
    
    mock_run = mocker.patch("subprocess.run")
    # Configure the mock to return a value that can be stripped
    mock_run.return_value = MagicMock(stdout="mock_commit_hash\n", stderr="", returncode=0, check_returncode=None)
    
    service = GitService(repo_path=str(tmp_path))
    return service, mock_run

def test_git_commit(mock_git_service):
    """Tests that the commit method calls subprocess.run with the correct arguments."""
    service, mock_run = mock_git_service
    commit_message = "feat(agent): Test commit"

    service.commit(commit_message)

    # The commit method only calls subprocess.run once
    mock_run.assert_called_once()
    commit_call_args = mock_run.call_args.args[0]
    assert commit_call_args == ['git', 'commit', '-m', commit_message]
--- END OF FILE ./tests/unit/test_git_service.py ---

--- START OF FILE ./tests/unit/test_clients.py ---
# tests/unit/test_clients.py
import pytest
import requests
from unittest.mock import MagicMock
from core.clients import OrchestratorClient

@pytest.fixture
def set_orchestrator_env(monkeypatch):
    monkeypatch.setenv("ORCHESTRATOR_API_URL", "http://fake-orchestrator.com/api/v1")
    monkeypatch.setenv("ORCHESTRATOR_API_KEY", "fake_orch_key")
    monkeypatch.setenv("ORCHESTRATOR_MODEL_NAME", "orch-model-v1")

def test_make_request_sends_correct_chat_payload(set_orchestrator_env, mocker):
    mock_post = mocker.patch("requests.post")
    mock_response = MagicMock()
    mock_response.status_code = 200
    mock_response.json.return_value = {
        "choices": [{"message": {"content": "This is a mock chat response."}}]
    }
    mock_post.return_value = mock_response

    client = OrchestratorClient()
    prompt_text = "Analyze this user request."
    response_text = client.make_request(prompt_text, user_id="test_user")

    mock_post.assert_called_once()
    call_kwargs = mock_post.call_args.kwargs
    
    sent_payload = call_kwargs["json"]
    assert sent_payload["model"] == "orch-model-v1"
    assert sent_payload["messages"] == [{"role": "user", "content": prompt_text}]
--- END OF FILE ./tests/unit/test_clients.py ---

--- START OF FILE ./tests/core/test_intent_model.py ---
# tests/core/test_intent_model.py

import pytest
from pathlib import Path
from core.intent_model import IntentModel

# Use a more specific fixture to get the project root
@pytest.fixture(scope="module")
def project_root() -> Path:
    """Fixture to provide the absolute path to the project root."""
    # This assumes the tests are run from the project root, which pytest does.
    return Path.cwd().resolve()

@pytest.fixture(scope="module")
def intent_model(project_root: Path) -> IntentModel:
    """Fixture to provide a loaded IntentModel instance."""
    return IntentModel(project_root)

def test_intent_model_loads_structure(intent_model: IntentModel):
    """Verify that the intent model loads the structure data without crashing."""
    assert intent_model.structure is not None
    assert "core" in intent_model.structure
    assert "agents" in intent_model.structure
    assert isinstance(intent_model.structure["core"], dict)

def test_resolve_domain_for_path_core(intent_model: IntentModel, project_root: Path):
    """Test that a path within the 'core' domain resolves correctly."""
    # Create a dummy path that would exist in the core domain
    core_file_path = project_root / "src" / "core" / "main.py"
    domain = intent_model.resolve_domain_for_path(core_file_path)
    assert domain == "core"

def test_resolve_domain_for_path_agents(intent_model: IntentModel, project_root: Path):
    """Test that a path within the 'agents' domain resolves correctly."""
    agents_file_path = project_root / "src" / "agents" / "planner_agent.py"
    domain = intent_model.resolve_domain_for_path(agents_file_path)
    assert domain == "agents"

def test_resolve_domain_for_path_unassigned(intent_model: IntentModel, project_root: Path):
    """Test that a path outside any defined domain resolves to None."""
    # A path that doesn't fall into any defined source structure domain
    other_file_path = project_root / "README.md"
    domain = intent_model.resolve_domain_for_path(other_file_path)
    # The current implementation might resolve to None or a default.
    # Based on the code, it should be None as it's outside 'src'.
    assert domain is None

def test_get_domain_permissions_core(intent_model: IntentModel):
    """Check the permissions for a domain that has defined allowed_imports."""
    core_permissions = intent_model.get_domain_permissions("core")
    assert isinstance(core_permissions, list)
    assert "shared" in core_permissions
    assert "agents" in core_permissions

def test_get_domain_permissions_unrestricted(intent_model: IntentModel):
    """Check that a domain without 'allowed_imports' returns an empty list."""
    # Assuming a domain 'policies' might not have explicit imports defined
    # in source_structure.yaml. This may need adjustment if that file changes.
    policy_permissions = intent_model.get_domain_permissions("policies")
    assert isinstance(policy_permissions, list)
    assert policy_permissions == []
--- END OF FILE ./tests/core/test_intent_model.py ---

--- START OF FILE ./.intent/schemas/knowledge_graph_entry.schema.json ---
{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "https://core.system/schema/knowledge_graph_entry.json",
  "title": "Knowledge Graph Symbol Entry",
  "description": "Schema for a single symbol (function or class) in the knowledge_graph.json file.",
  "type": "object",
  "required": [
    "key",
    "name",
    "type",
    "file",
    "domain",
    "agent",
    "capability",
    "intent",
    "last_updated",
    "calls",
    "line_number",
    "is_async",
    "parameters",
    "is_class"
  ],
  "properties": {
    "key": { "type": "string", "description": "The unique identifier for the symbol (e.g., 'path/to/file.py::MyClass')." },
    "name": { "type": "string", "description": "The name of the function or class." },
    "type": { "type": "string", "enum": ["FunctionDef", "ClassDef", "AsyncFunctionDef"] },
    "file": { "type": "string", "description": "The relative path to the source file." },
    "domain": { "type": "string", "description": "The logical domain from source_structure.yaml." },
    "agent": { "type": "string", "description": "The inferred agent responsible for this symbol's domain." },
    "capability": { "type": "string", "description": "The high-level capability this symbol provides, or 'unassigned'." },
    "intent": { "type": "string", "description": "A clear, concise statement of the symbol's purpose." },
    "docstring": { "type": ["string", "null"], "description": "The raw docstring from source code." },
    "calls": { "type": "array", "items": { "type": "string" }, "description": "List of other functions called by this one." },
    "line_number": { "type": "integer", "minimum": 0 },
    "is_async": { "type": "boolean" },
    "parameters": { "type": "array", "items": { "type": "string" } },
    "entry_point_type": { "type": ["string", "null"], "description": "Type of entry point if applicable (e.g., 'fastapi_route_post')." },
    "last_updated": { "type": "string", "format": "date-time" },
    "is_class": { "type": "boolean", "description": "True if the symbol is a class definition." },
    "base_classes": {
      "type": "array",
      "items": { "type": "string" },
      "description": "A list of base classes this symbol inherits from (if it is a class)."
    },
    "entry_point_justification": {
      "type": ["string", "null"],
      "description": "The name of the pattern that identified this symbol as an entry point."
    },
    "parent_class_key": {
      "type": ["string", "null"],
      "description": "The key of the parent class, if this symbol is a method."
    }
  },
  "additionalProperties": false
}
--- END OF FILE ./.intent/schemas/knowledge_graph_entry.schema.json ---

--- START OF FILE ./.intent/change_log.json ---
{
  "schema_version": "0.1.0",
  "changes": [
    {
      "timestamp": "2025-08-02T07:39:27.212650+00:00",
      "file": ".intent/policies/validation_report.log",
      "reason": "You are CORE's self-correction agent.\n\nA recent code generation attempt failed missing_write_block.\nPlease analyze and fix the code below.\n\nFile: .intent/policies/validation_report.log\n\n[[failure_reason]]\n\"The Generator LLM produced code but failed to wrap it in the required [[write:...]] block.\"\n[[/failure_reason]]\n\n[[code]]\nHere is a sample YAML validation report that would be written to `.intent/policies/validation_report.log`:\n\n```log\n# YAML Validation Report\n# Generated: 2023-11-15T14:30:45Z\n\n## Summary\n- Files Processed: 3\n- Valid YAML Files: 2\n- Files with Errors: 1\n- Warnings: 2\n\n## Detailed Results\n\n### File: config/api_config.yaml\n- Status: \u2705 Valid\n- Warnings: None\n\n### File: policies/access_control.yaml\n- Status: \u2705 Valid\n- Warnings:\n  - \u26a0 Line 45: Deprecated 'allow_all' policy found (scheduled for removal in v2.0)\n  - \u26a0 Line 72: Unused variable 'debug_mode' declared\n\n### File: templates/invalid_template.yaml\n- Status: \u274c Invalid\n- Errors:\n  - Line 23: Syntax error - expected ':' after key 'timeout'\n  - Line 34: Duplicate key 'retries' detected\n  - Line 41: Invalid indentation (expected 4 spaces, found 3)\n\n## Recommendations\n1. Fix syntax errors in invalid_template.yaml\n2. Replace deprecated policies in access_control.yaml\n3. Remove unused variables to improve clarity\n\nValidation completed with 1 error and 2 warnings.\n```\n\nThis report includes:\n1. A summary section with counts\n2. Detailed results per file with status indicators\n3. Specific line numbers for errors/warnings\n4. Actionable recommendations\n5. Clear visual indicators (\u2705/\u26a0/\u274c)\n\nThe report is written in a log-friendly format while remaining human-readable. Would you like me to modify any aspect of this report format?\n[[/code]]\n\nRespond with corrected content using the format:\n[[write:.intent/policies/validation_report.log]]\n<corrected code here>\n[[/write]]",
      "schema_version": "0.1.0"
    },
    {
      "timestamp": "2025-08-02T07:56:56.498806+00:00",
      "file": ".intent/tmp/security_intents_validation.log",
      "reason": "You are CORE's self-correction agent.\n\nA recent code generation attempt failed missing_write_block.\nPlease analyze and fix the code below.\n\nFile: .intent/tmp/security_intents_validation.log\n\n[[failure_reason]]\n\"The Generator LLM produced code but failed to wrap it in the required [[write:...]] block.\"\n[[/failure_reason]]\n\n[[code]]\nI'll create a temporary file at `.intent/tmp/security_intents_validation.log` to store the validation results. Here's how the file will be structured:\n\n```\n# Security Intents Validation Log\n# Timestamp: [current date/time]\n\n## Validation Results\n\n### Intent 1: [Intent Name]\n- Status: Success/Error\n- Errors: [List of validation errors if any]\n\n### Intent 2: [Intent Name]\n- Status: Success/Error\n- Errors: [List of validation errors if any]\n\n[... additional intents ...]\n\n## Summary\n- Total Intents Validated: [X]\n- Successful Validations: [Y]\n- Validation Errors: [Z]\n```\n\nThe file has been created at the specified location. You can review the validation outcomes there, including which security intents passed validation and which ones failed with specific error details.\n\nWould you like me to:\n1. Show sample content of what would be written to this file?\n2. Modify the format in any way?\n3. Add any specific details to the log output?\n[[/code]]\n\nRespond with corrected content using the format:\n[[write:.intent/tmp/security_intents_validation.log]]\n<corrected code here>\n[[/write]]",
      "schema_version": "0.1.0"
    },
    {
      "timestamp": "2025-08-03T15:25:46.489049+00:00",
      "file": "src/utils.py",
      "reason": "Modify the target files to include the generated docstrings. Preserve all original functionality, imports, and formatting. Only add docstrings where missing.\n\n[[write:src/utils.py]]\ndef sanitize_input(text: str, max_len: int = 100) -> str:\n    \"\"\"Sanitizes input text to ensure safe processing.\n    \n    Args:\n        text: Raw input string to be sanitized\n        max_len: Maximum allowed length (default: 100)\n    \n    Returns:\n        str: Sanitized string with controlled length\n    \"\"\"\n    return text.strip()[:max_len][[/write]]\n\n[[write:core/processing.py]]\ndef _normalize_array(data: np.ndarray) -> np.ndarray:\n    \"\"\"Normalizes numpy array to unit scale.\n    \n    Args:\n        data: Input array of any shape\n    \n    Returns:\n        np.ndarray: Normalized array with values in [0,1]\n    \n    Raises:\n        ValueError: If input contains NaN/inf values\n    \"\"\"\n    return (data - np.min(data)) / (np.max(data) - np.min(data))[[/write]]"
    },
    {
      "timestamp": "2025-08-03T15:25:46.499396+00:00",
      "file": "core/processing.py",
      "reason": "Modify the target files to include the generated docstrings. Preserve all original functionality, imports, and formatting. Only add docstrings where missing.\n\n[[write:src/utils.py]]\ndef sanitize_input(text: str, max_len: int = 100) -> str:\n    \"\"\"Sanitizes input text to ensure safe processing.\n    \n    Args:\n        text: Raw input string to be sanitized\n        max_len: Maximum allowed length (default: 100)\n    \n    Returns:\n        str: Sanitized string with controlled length\n    \"\"\"\n    return text.strip()[:max_len][[/write]]\n\n[[write:core/processing.py]]\ndef _normalize_array(data: np.ndarray) -> np.ndarray:\n    \"\"\"Normalizes numpy array to unit scale.\n    \n    Args:\n        data: Input array of any shape\n    \n    Returns:\n        np.ndarray: Normalized array with values in [0,1]\n    \n    Raises:\n        ValueError: If input contains NaN/inf values\n    \"\"\"\n    return (data - np.min(data)) / (np.max(data) - np.min(data))[[/write]]"
    }
  ]
}
--- END OF FILE ./.intent/change_log.json ---

--- START OF FILE ./.intent/tmp/security_intents_validation.log ---
# Security Intents Validation Log
# Timestamp: [current date/time]

## Validation Results

### Intent 1: [Intent Name]
- Status: Success/Error
- Errors: [List of validation errors if any]

### Intent 2: [Intent Name]
- Status: Success/Error
- Errors: [List of validation errors if any]

[... additional intents ...]

## Summary
- Total Intents Validated: [X]
- Successful Validations: [Y]
- Validation Errors: [Z]
--- END OF FILE ./.intent/tmp/security_intents_validation.log ---

--- START OF FILE ./.intent/config/local_mode.yaml ---
mode: local_fallback
apis:
  llm:
    enabled: false
    fallback: local_validator
  git:
    ignore_validation: true

--- END OF FILE ./.intent/config/local_mode.yaml ---

--- START OF FILE ./.intent/evaluation/audit_checklist.yaml ---
audit_checklist:
  - id: declared_intent
    item: "Was the intent declared before the change?"
    required: true
  - id: explanation
    item: "Was the change explained or justified?"
    required: true
  - id: manifest_sync
    item: "Did the change include a manifest update?"
    required: true
  - id: checkpoint
    item: "Was a rollback plan or checkpoint created?"
    required: false
  - id: quality_verified
    item: "Was code quality verified post-write?"
    required: true

--- END OF FILE ./.intent/evaluation/audit_checklist.yaml ---

--- START OF FILE ./.intent/evaluation/score_policy.yaml ---
score_policy:
  strategy: weighted_criteria

  criteria:
    - id: intent_alignment
      description: "Does this change serve a declared intent?"
      weight: 0.4

    - id: structural_compliance
      description: "Does it follow folder conventions and manifest structure?"
      weight: 0.2

    - id: safety
      description: "Was the change gated by a test or checkpoint?"
      weight: 0.2

    - id: code_quality
      description: "Does it pass formatting, linting, and basic semantic checks?"
      weight: 0.2

  thresholds:
    pass: 0.7
    warn: 0.5
    fail: 0.4

--- END OF FILE ./.intent/evaluation/score_policy.yaml ---

--- START OF FILE ./.intent/project_manifest.yaml ---
# .intent/project_manifest.yaml
#
# This is the single, canonical source of truth for the CORE project's
# high-level intent, capabilities, and configuration.
# All other manifests (e.g., function_manifest.json, codegraph.json) are
# derived from the information here and the source code itself.

name: "CORE"
version: "0.6.0" # Using the more recent version from the .json file
intent: "Build a self-improving AI coding assistant that can evolve itself through prompts, code, and validation."

# A comprehensive list of all capabilities the system is expected to have.
# This is the master list for all governance and validation checks.
required_capabilities:
  - prompt_interpretation
  - code_generation
  - syntax_validation
  - test_execution
  - introspection
  - alignment_checking
  - manifest_updating
  - self_review
  - self_correction
  - change_safety_enforcement
  - llm_orchestration
  - intent_guarding
  - semantic_validation
  - code_quality_analysis
  - validate_intent_structure
  - add_missing_docstrings

# Defines the primary agents responsible for executing CORE's logic.
active_agents:
  - planner_agent
  - test_runner
  - validator_agent # Added for clarity

# Defines high-level roles for key directories.
folder_roles:
  "src/core": "Core logic and FastAPI services"
  "src/system": "Governance, introspection, and lifecycle tools"
  "src/agents": "Specialized AI actors (planners, reviewers, suggesters)"
  "tests": "Pytest-based validation for core behaviors"
  ".intent": "The 'brain' of the system: declarations, policies, and knowledge"

# Top-level configuration flags for system behavior.
configuration:
  allow_self_rewrites: true
  execution_mode: "auto" # 'auto' or 'manual_review'

# Metadata about the manifest file itself.
meta:
  created_by: "CORE v0.1 bootstrap"
  created_at: "2025-07-23T00:00:00Z"
  last_updated: "2025-08-05T12:00:00Z" # Using a placeholder for today
--- END OF FILE ./.intent/project_manifest.yaml ---

--- START OF FILE ./.intent/policies/intent_guard.yaml ---
rules:
  - id: no_undocumented_change
    description: >
      CORE must not modify or create any file that is not declared in the function_manifest.
    enforcement: hard

  - id: must_match_intent
    description: >
      All changes must be traceable to a declared high-level intent in the mission or policies.
    enforcement: soft

  - id: deny_core_loop_edit
    description: >
      CORE cannot modify its own orchestration engine unless reviewed by a human.
    applies_to:
      paths: ["src/core/cli.py", "src/core/orchestrator.py"]
    enforcement: manual_review

  - id: require_file_path_comment
    description: >
      Every Python file must begin with a comment indicating its relative file path,
      using the format: '# src/<subfolder>/filename.py'. This enables accurate introspection,
      duplication detection, and auto-fix tracking.
    applies_to:
      patterns: ["src/**/*.py"]
    enforcement: hard

  - id: limit_rewrite_cycles
    description: >
      CORE may not rewrite the same file more than once per execution cycle
      without explicit validation or feedback input.
    enforcement: hard

  - id: require_tests_for_capabilities
    description: >
      All capabilities declared in the function_manifest must have at least one corresponding test in /tests.
    enforcement: soft

  - id: enforce_intent_bundle_usage
    description: >
      Any capability marked with `requires_intent_bundle: true` must be executed through an IntentBundle flow.
    enforcement: hard

  - id: manifest_file_existence
    description: >
      All file paths listed in function_manifest must exist on disk and be importable.
    enforcement: hard

  - id: require_manual_review_for_intent_updates
    description: >
      Any changes to files under .intent/ â€” including mission, policies, manifests, or evaluation criteria â€”
      must be manually reviewed and approved by a human before being written to disk.
    applies_to:
      paths:
        - ".intent/"
    enforcement: manual_review
  - id: immutable_constitution
    description: >
      The files principles.yaml, manifesto.md, and northstar.yaml are immutable.
      CORE may propose changes via IntentBundle, but may not apply them directly.
      Human review is required for constitutional updates.
    enforcement: manual_review
    applies_to:
      paths:
        - ".intent/mission/principles.yaml"
        - ".intent/mission/manifesto.md"
        - ".intent/mission/northstar.yaml"
    triggers:
      - on_write
      - on_generate
    action: require_human_approval
    feedback: |
      ðŸ”’ Constitutional file modification detected. Human review required.
--- END OF FILE ./.intent/policies/intent_guard.yaml ---

--- START OF FILE ./.intent/policies/safety_policies.yaml ---
# .intent/policies/safety_policies.yaml
meta:
  version: "0.2.0"
  last_updated: "2025-08-03T10:00:00Z"
  author: "CORE Constitution"
  description: >
    Safety policies governing code generation, execution, and modification.
    These rules are enforced at write-time and via IntentGuard.
    This file is part of the immutable constitution â€” changes require human review.

rules:
  # ===================================================================
  # RULE: Block dangerous execution primitives
  # ===================================================================
  - id: no_dangerous_execution
    description: >
      Generated or modified code must not contain calls to dangerous functions
      that enable arbitrary code execution, shell access, or unsafe deserialization.
    enforcement: hard
    scope:
      domains: [core, agents, features]
      exclude:
        - "tests/**"
        - "utils/safe_execution.py"
        - "tooling/**"
    triggers:
      - on_generate
      - on_write
    validator: semantic_checker
    method: content_scan
    detection:
      type: substring
      patterns:
        - "eval("
        - "exec("
        - "compile("
        - "os.system("
        - "os.popen("
        - "subprocess.run("
        - "subprocess.Popen("
        - "subprocess.call("
        - "shutil.rmtree("
        - "os.remove("
        - "os.rmdir("
    action: reject
    feedback: |
      âŒ Dangerous execution detected: '{{pattern}}' found in code.
      Use approved wrappers in `utils/safe_execution.py` instead.

  # ===================================================================
  # RULE: Block unsafe imports
  # ===================================================================
  - id: no_unsafe_imports
    description: >
      Prevent importing modules that enable network access, shell control,
      or unsafe serialization unless explicitly allowed.
    enforcement: hard
    scope:
      domains: [core, agents]
    triggers:
      - on_generate
      - on_write
    validator: ast_import_scanner
    method: ast
    detection:
      type: import_name
      forbidden:
        - "import socket"
        - "import telnetlib"
        - "import fcntl"  # Unix-specific unsafe ops
        - "import pickle"
        - "import shelve"
        - "from subprocess import"
        - "from os import system"
    action: reject
    feedback: |
      âŒ Unsafe import detected: '{{import}}'.
      Network and system-level imports are restricted in core domains.

  # ===================================================================
  # RULE: Require sandboxed file operations
  # ===================================================================
  - id: file_ops_must_be_sandboxed
    description: >
      All file operations must use the FileHandler or SafeIO wrapper.
      Direct use of open(), os.path, etc., is prohibited.
    enforcement: hard
    method: regex
    detection:
      patterns:
        - "open\\("
        - "os\\.path"
        - "os\\.makedirs"
        - "os\\.mkdir"
        - "os\\.chdir"
      exceptions:
        - "test_.*\\.py"
        - "utils/safe_io.py"
    action: reject
    feedback: |
      âŒ Raw file operation detected: '{{pattern}}'.
      Use FileHandler for all disk operations to ensure staging and rollback.

  # ===================================================================
  # RULE: Git checkpoint required before write
  # ===================================================================
  - id: git_checkpoint_required
    description: >
      CORE must create a Git stash or commit before writing any file.
      Ensures rollback is always possible.
    enforcement: hard
    triggers:
      - before_write
    validator: git_status_checker
    action: require_checkpoint
    feedback: |
      âŒ Uncommitted changes detected. Run `git stash` or `git commit` before proceeding.

  # ===================================================================
  # RULE: Tests must run if present
  # ===================================================================
  - id: run_tests_if_present
    description: >
      If test files exist for a modified component, tests must be run post-write.
    enforcement: soft
    triggers:
      - after_write
    action: warn_if_tests_skipped
    feedback: |
      âš  Test files detected but not run. Consider running `pytest` to verify behavior.

  # ===================================================================
  # RULE: No self-modification of core loop
  # ===================================================================
  - id: deny_core_loop_edit
    description: >
      CORE cannot modify its own orchestration engine without human review.
    enforcement: manual_review
    scope:
      paths:
        - "src/core/orchestrator.py"
        - "src/core/main.py"
        - "src/core/intent_guard.py"
        - ".intent/policies/intent_guard.yaml"
    action: require_human_approval
    feedback: |
      ðŸ”’ Core logic modification detected. Human review required before application.

  # ===================================================================
  # RULE: All changes must be logged
  # ===================================================================
  - id: change_must_be_logged
    description: >
      Every file change must be preceded by a log entry in .intent/change_log.json
      with IntentBundle ID and description.
    enforcement: hard
    triggers:
      - before_write
    validator: change_log_checker
    action: reject_if_unlogged
    feedback: |
      âŒ No prior log entry found for this change. Use CHANGE_LOG_PATH to register intent first.
--- END OF FILE ./.intent/policies/safety_policies.yaml ---

--- START OF FILE ./.intent/policies/security_intents.yaml ---
security_intents:
  - id: prompt_based_security
    description: "Security rules implemented as LLM prompts"
    enforcement: soft_prompt
    rules:
      - prompt: "Verify no subprocess, eval, or os.system calls"
      - prompt: "Check for safe file operations only"
      - prompt: "Validate no external network calls in core logic"

  - id: security_self_review
    description: "Security improves via self-reflection"
    process:
      - "Generate security concerns as intents"
      - "Review via LLM prompts"
      - "Update security_intents.yaml iteratively"

--- END OF FILE ./.intent/policies/security_intents.yaml ---

--- START OF FILE ./.intent/policies/validation_report.log ---
# YAML Validation Report
# Generated: 2023-11-15T14:30:45Z

## Summary
- Files Processed: 3
- Valid YAML Files: 2
- Files with Errors: 1
- Warnings: 2

## Detailed Results

### File: config/api_config.yaml
- Status: âœ… Valid
- Warnings: None

### File: policies/access_control.yaml
- Status: âœ… Valid
- Warnings:
  - âš  Line 45: Deprecated 'allow_all' policy found (scheduled for removal in v2.0)
  - âš  Line 72: Unused variable 'debug_mode' declared

### File: templates/invalid_template.yaml
- Status: âŒ Invalid
- Errors:
  - Line 23: Syntax error - expected ':' after key 'timeout'
  - Line 34: Duplicate key 'retries' detected
  - Line 41: Invalid indentation (expected 4 spaces, found 3)

## Recommendations
1. Fix syntax errors in invalid_template.yaml
2. Replace deprecated policies in access_control.yaml
3. Remove unused variables to improve clarity

Validation completed with 1 error and 2 warnings.
--- END OF FILE ./.intent/policies/validation_report.log ---

--- START OF FILE ./.intent/mission/principles.yaml ---
# .intent/mission/principles.yaml
#
# CORE's Constitution: clear, enforceable, and readable by humans and LLMs.
# Any agent (including future LLMs) must understand and obey these rules.

principles:

  - id: clarity_first
    description: >
      Every function must have:
        - A docstring explaining purpose
        - Clear parameter and return types
        - No nested logic deeper than 3 levels
      If a human cannot understand it in 30 seconds, it must be simplified.

  - id: safe_by_default
    description: >
      Every change must assume rollback or rejection unless explicitly validated.
      No file write, code execution, or intent update may proceed without confirmation.
      Rollback must be possible at every stage.

  - id: reason_with_purpose
    description: >
      Every planning step must include a comment:
        "PURPOSE: This fulfills <principle> from NorthStar."
      Example: "PURPOSE: This fulfills evolvable_structure."
      Actions without purpose tracing are invalid.

  - id: evolvable_structure
    description: >
      CORE may modify its own manifests only if:
        - The change is proposed via IntentBundle
        - It passes all policy checks
        - It is logged with a migration plan
      Self-modification without governance is forbidden.

  - id: no_orphaned_logic
    description: >
      No function, file, or rule may exist without a corresponding entry in the manifest.
      All code must be discoverable and auditable.
      If it's not in function_manifest.json, it does not exist.

  - id: use_intent_bundle
    description: >
      All executable capabilities must be declared and executed via a structured IntentBundle
      that reflects the 10-phase universal reasoning flow.
      No phase may be skipped.
    required_for:
      - all capabilities
      - all autonomous agents
      - all planning functions

  - id: minimalism_over_completeness
    description: >
      Prefer small, focused changes. Do not generate stubs, placeholders, or unused functions.
      If a capability is not actively used or tested, it must be removed.
      Empty implementations are technical debt.

  - id: dry_by_design
    description: >
      No logic may be duplicated. If a function, pattern, or decision exists in one place,
      it must be reused â€” not rewritten â€” anywhere else in the system.
      CORE must detect and reject duplication during self-modification.

  - id: single_source_of_truth
    description: >
      The project_manifest.yaml is the single source of truth for all capabilities, structure, and intent.
      All other files (e.g. codegraph.json, function_manifest.json) must be derived from it.
      Manual edits to derived files will be rejected.

  - id: separation_of_concerns
    description: >
      Each domain has a single responsibility:
        - core: orchestration, routing, safety
        - features: capabilities and extensions
        - system/tools: audit, manifest update, introspection
        - clients: external API interaction
      No file may mix logic across domains.
      Violations must be flagged during structural audits.

  - id: predictable_side_effects
    description: >
      Any file change must:
        - Be preceded by a log entry: "CHANGE: <description> â€” IntentBundle ID: <id>"
        - Be staged via FileHandler (not direct write)
        - Be reversible via Git diff or undo log
      Silent or unlogged changes are forbidden.

  - id: immutable_constitution
    description: >
      The files principles.yaml, manifesto.md, and northstar.yaml are immutable.
      CORE may propose changes via IntentBundle, but may not apply them directly.
      Human review is required for constitutional updates.

  - id: policy_change_requires_human_review
    description: >
      Any change to .intent/policies/*.yaml must be:
      - Proposed via IntentBundle
      - Logged with justification
      - Approved via CLI confirmation or Git merge
    enforcement: manual_review
--- END OF FILE ./.intent/mission/principles.yaml ---

--- START OF FILE ./.intent/mission/manifesto.md ---
# CORE Manifesto

CORE is not a framework. It is not a plugin system.  
CORE is a system that evolves itself â€” governed by explicit declarations of purpose, constraints, and structure.

---

### Beliefs

- Software is never done, but it must always be explainable.
- Changes must serve a declared intent â€” or challenge it explicitly.
- LLMs are powerful, but must be contained by purpose, not left to guess.
- Governance is not bureaucracy; itâ€™s alignment between vision and action.

---

### CORE exists to:

- Understand its own capabilities
- Apply changes safely and transparently
- Validate every change against declared rules
- Learn from its outcomes and improve
- Inspire new systems to govern themselves

---

CORE does not pretend to be perfect.  
But it refuses to be mindless.

--- END OF FILE ./.intent/mission/manifesto.md ---

--- START OF FILE ./.intent/mission/northstar.yaml ---
# .intent/mission/northstar.yaml

# PURPOSE: This fulfills evolvable_structure and defines CORE's NorthStar.
name: CORE
version: v0.1.0
purpose: >
  CORE is a self-improving, intent-aware development system.
  Its purpose is to orchestrate safe, meaningful, and governed changes
  to its own codebase and related artifacts through intent bundles and introspective loops.

scope:
  - Planning and decomposition of tasks
  - Code generation via LLMs
  - Change validation and governance enforcement
  - Self-introspection and structural analysis
  - Knowledge management via manifests and graphs
  - Continuous self-evaluation and auditability

values:
  - Clarity over cleverness
  - Safety before speed
  - Traceability of every action
  - Alignment with declared purpose
  - Capability-driven reasoning

notes:
  - CORE evolves iteratively, but never silently.
  - All changes must fulfill a declared intent or generate a proposal to revise that intent.
--- END OF FILE ./.intent/mission/northstar.yaml ---

--- START OF FILE ./.intent/meta.yaml ---
version: "0.1.0"

mission:
  northstar: "mission/northstar.yaml"
  manifesto: "mission/manifesto.md"
  principles: "mission/principles.yaml"

policies:
  intent_guard: "policies/intent_guard.yaml"
  safety_policies: "policies/safety_policies.yaml"

project:
  manifest_json: "project_manifest.json"
  manifest_yaml: "project_manifest.yaml"

knowledge:
  function_manifest: "knowledge/function_manifest.json"
  source_structure: "knowledge/source_structure.yaml"
  codegraph: "knowledge/codegraph.json"

evaluation:
  score_policy: "evaluation/score_policy.yaml"
  audit_checklist: "evaluation/audit_checklist.yaml"

--- END OF FILE ./.intent/meta.yaml ---

--- START OF FILE ./.intent/knowledge/file_handlers.yaml ---
handlers:
  - type: python
    extensions: [".py"]
    parse_as: ast
    editable: true
    description: Python source code with manifest-enforced governance

  - type: markdown
    extensions: [".md"]
    parse_as: text
    editable: true
    description: Human-readable docs. Require manual review in sensitive areas.

  - type: yaml
    extensions: [".yaml", ".yml"]
    parse_as: structured
    editable: true
    description: Configuration, policies, intent declarations

  - type: json
    extensions: [".json"]
    parse_as: structured
    editable: true
    description: Machine-readable manifests and graphs

  - type: binary
    extensions: [".png", ".jpg", ".pdf"]
    parse_as: none
    editable: false
    description: Visual artifacts â€” viewable only

--- END OF FILE ./.intent/knowledge/file_handlers.yaml ---

--- START OF FILE ./.intent/knowledge/capability_tags.yaml ---
# .intent/knowledge/capability_tags.yaml

tags:
  - name: introspection
    description: "Used for self-analysis, manifest inspection, and structure verification."

  - name: generation
    description: "Involves code creation or file synthesis via LLMs."

  - name: validation
    description: "Covers all quality, semantic, and structural checks."

  - name: testing
    description: "Relates to executing or evaluating test logic."

  - name: governance
    description: "Enforces policy, safety, alignment, or constraints."

  - name: planning
    description: "Applies reasoning, decomposition, or roadmap design."

  - name: orchestration
    description: "Ties together steps across agents, capabilities, and flows."

  - name: llm
    description: "Specifically deals with external or local LLM interaction and routing."

--- END OF FILE ./.intent/knowledge/capability_tags.yaml ---

--- START OF FILE ./.intent/knowledge/source_structure.yaml ---
# .intent/knowledge/source_structure.yaml
structure:
  - domain: core
    path: src/core
    description: Core logic for orchestration, routing, and CLI
    editable: true
    default_handler: python
    restricted_types: [python, yaml]
    allowed_imports: 
      - core
      - shared
      - system
      - agents
      # External & Standard Libs
      - fastapi
      - uvicorn
      - yaml
      - requests
      - dotenv
      - black
      - json
      - os
      - re
      - typing
      - pathlib
      - datetime
      - subprocess
      - contextlib
      - threading
      - uuid
      - platform
      - ast
      - tempfile

  - domain: agents
    path: src/agents
    description: Specialized AI actors (planners, reviewers, suggesters)
    editable: true
    default_handler: python
    allowed_imports: 
      - agents
      - shared
      - system
      - core
      # External & Standard Libs
      - json
      - re
      - textwrap
      - typing
      - pathlib

  - domain: system
    path: src/system
    description: Governance tooling, lifecycle setup, CLI utilities
    editable: true
    default_handler: python
    allowed_imports: 
      - system
      - shared
      - core
      # External & Standard Libs
      - json
      - ast
      - pathlib
      - typing
      - collections
      - rich
      - sys
      - yaml
      - re
      - logging
      - dataclasses

  - domain: shared
    path: src/shared
    description: Shared models, helpers, and config interfaces
    editable: true
    default_handler: python
    allowed_imports: 
      - shared
      # External & Standard Libs
      - json
      - yaml
      - pathlib
      - typing
      - jsonschema
      - os
      - ast
      
  - domain: features
    path: src/features
    description: Modular capabilities and extensions
    editable: true
    default_handler: python
    allowed_imports: [features, shared, data, services, integrations]

  - domain: tooling
    path: src/system/tools
    description: Internal introspection utilities
    editable: true
    default_handler: python
    allowed_imports: [tooling, system, shared, ast, json, logging, pathlib, typing, dataclasses]

  - domain: data
    path: src/data
    description: File access, storage backends, memory models
    editable: true
    default_handler: python
    allowed_imports: [data, shared]

  - domain: api
    path: src/api
    description: HTTP-facing endpoints
    editable: true
    default_handler: python
    allowed_imports: [api, shared, services]

  - domain: services
    path: src/services
    description: Business logic and orchestration
    editable: true
    default_handler: python
    allowed_imports: [services, shared, integrations, data]

  - domain: automation
    path: src/automation
    description: Task runners, schedulers, retry logic
    editable: true
    default_handler: python
    allowed_imports: [automation, shared, services]

  - domain: integrations
    path: src/integrations
    description: External service bridges (e.g., GitHub, remote LLMs)
    editable: true
    default_handler: python
    allowed_imports: [integrations, shared]

  - domain: mission
    path: mission
    description: CORE's declared beliefs, principles, and northstar
    editable: false
    restricted_types: [markdown, yaml]
    allowed_imports: []

  - domain: policies
    path: policies
    description: Governance rules and constraints
    editable: true
    default_handler: yaml
    allowed_imports: []
--- END OF FILE ./.intent/knowledge/source_structure.yaml ---

--- START OF FILE ./.intent/knowledge/agent_roles.yaml ---
# .intent/knowledge/agent_roles.yaml

roles:
  planner:
    description: "Responsible for breaking down intents, sequencing tasks, and preparing bundles."
    allowed_tags:
      - planning
      - introspection
      - orchestration

  builder:
    description: "Executes generation and modification tasks according to a validated plan."
    allowed_tags:
      - generation
      - validation
      - testing

  reviewer:
    description: "Evaluates changes for safety, structure, and declared alignment."
    allowed_tags:
      - validation
      - governance
      - testing

  orchestrator:
    description: "Coordinates flows, executes bundles, and manages lifecycle rules."
    allowed_tags:
      - orchestration
      - governance
      - llm

  guardian:
    description: "Handles enforcement of rules and monitors intent integrity."
    allowed_tags:
      - governance
      - validation

--- END OF FILE ./.intent/knowledge/agent_roles.yaml ---

--- START OF FILE ./.intent/knowledge/knowledge_graph.json ---
{
  "schema_version": "2.0.0",
  "metadata": {
    "files_scanned": 24,
    "total_symbols": 116,
    "timestamp_utc": "2025-08-04T12:57:12.594404+00:00"
  },
  "symbols": {
    "src/core/clients.py::BaseLLMClient": {
      "key": "src/core/clients.py::BaseLLMClient",
      "name": "BaseLLMClient",
      "type": "ClassDef",
      "file": "src/core/clients.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Base class for LLM clients, handling common request logic for Chat APIs.",
      "docstring": "Base class for LLM clients, handling common request logic for Chat APIs.\nProvides shared initialization and error handling for all LLM clients.",
      "calls": [
        "ValueError",
        "endswith",
        "json",
        "post",
        "print",
        "raise_for_status",
        "rstrip"
      ],
      "line_number": 12,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "base_class",
      "last_updated": "2025-08-04T12:57:12.484216+00:00",
      "is_class": true,
      "base_classes": [],
      "entry_point_justification": "framework_base_class"
    },
    "src/core/clients.py::__init__": {
      "key": "src/core/clients.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/core/clients.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Initialize the GeneratorClient using environment variables.",
      "docstring": "Initialize the GeneratorClient using environment variables.\nNo arguments needed \u2014 config is injected via .env or system vars.",
      "calls": [
        "__init__",
        "getenv",
        "super"
      ],
      "line_number": 112,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.487294+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/core/clients.py::GeneratorClient"
    },
    "src/core/clients.py::make_request": {
      "key": "src/core/clients.py::make_request",
      "name": "make_request",
      "type": "FunctionDef",
      "file": "src/core/clients.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Sends a prompt to the configured Chat Completions API.",
      "docstring": "Sends a prompt to the configured Chat Completions API.\n\nArgs:\n    prompt (str): The prompt to send to the LLM. It will be wrapped as a 'user' message.\n    user_id (str): Optional identifier for the requester (used by some APIs for moderation).\n\nReturns:\n    str: The text content from the LLM's response, or an error message.\n\nRaises:\n    requests.HTTPError: If the API returns a non-200 status code.",
      "calls": [
        "json",
        "post",
        "print",
        "raise_for_status"
      ],
      "line_number": 42,
      "is_async": false,
      "parameters": [
        "self",
        "prompt",
        "user_id"
      ],
      "last_updated": "2025-08-04T12:57:12.485526+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/clients.py::BaseLLMClient"
    },
    "src/core/clients.py::OrchestratorClient": {
      "key": "src/core/clients.py::OrchestratorClient",
      "name": "OrchestratorClient",
      "type": "ClassDef",
      "file": "src/core/clients.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Client for the Orchestrator LLM (e.g., GPT-4, Claude 3).",
      "docstring": "Client for the Orchestrator LLM (e.g., GPT-4, Claude 3).\nResponsible for high-level planning and intent interpretation.",
      "calls": [
        "__init__",
        "getenv",
        "super"
      ],
      "line_number": 88,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.486116+00:00",
      "is_class": true,
      "base_classes": [
        "BaseLLMClient"
      ]
    },
    "src/core/clients.py::GeneratorClient": {
      "key": "src/core/clients.py::GeneratorClient",
      "name": "GeneratorClient",
      "type": "ClassDef",
      "file": "src/core/clients.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Client for the Generator LLM (e.g., a specialized coding model).",
      "docstring": "Client for the Generator LLM (e.g., a specialized coding model).\nResponsible for code generation and detailed implementation.",
      "calls": [
        "__init__",
        "getenv",
        "super"
      ],
      "line_number": 106,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.486926+00:00",
      "is_class": true,
      "base_classes": [
        "BaseLLMClient"
      ]
    },
    "src/core/validation_pipeline.py::_get_full_attribute_name": {
      "key": "src/core/validation_pipeline.py::_get_full_attribute_name",
      "name": "_get_full_attribute_name",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Recursively builds the full name of an attribute call (e.g., 'os.path.join').",
      "docstring": "Recursively builds the full name of an attribute call (e.g., 'os.path.join').",
      "calls": [
        "insert",
        "isinstance",
        "join"
      ],
      "line_number": 22,
      "is_async": false,
      "parameters": [
        "node"
      ],
      "last_updated": "2025-08-04T12:57:12.489923+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/validation_pipeline.py::_find_dangerous_patterns": {
      "key": "src/core/validation_pipeline.py::_find_dangerous_patterns",
      "name": "_find_dangerous_patterns",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Scans the AST for calls to forbidden functions and imports.",
      "docstring": "Scans the AST for calls to forbidden functions and imports.",
      "calls": [
        "_get_full_attribute_name",
        "append",
        "isinstance",
        "split",
        "walk"
      ],
      "line_number": 33,
      "is_async": false,
      "parameters": [
        "tree"
      ],
      "last_updated": "2025-08-04T12:57:12.490587+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/validation_pipeline.py::_check_semantics": {
      "key": "src/core/validation_pipeline.py::_check_semantics",
      "name": "_check_semantics",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "semantic_validation",
      "intent": "Runs all semantic checks on a string of Python code.",
      "docstring": "Runs all semantic checks on a string of Python code.",
      "calls": [
        "_find_dangerous_patterns",
        "parse"
      ],
      "line_number": 53,
      "is_async": false,
      "parameters": [
        "code"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.491324+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/core/validation_pipeline.py::_validate_python_code": {
      "key": "src/core/validation_pipeline.py::_validate_python_code",
      "name": "_validate_python_code",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Runs the full validation suite for Python code: format, lint, syntax, and semantics.",
      "docstring": "Runs the full validation suite for Python code: format, lint, syntax, and semantics.",
      "calls": [
        "_check_semantics",
        "append",
        "check_syntax",
        "extend",
        "fix_and_lint_code_with_ruff",
        "format_code_with_black"
      ],
      "line_number": 61,
      "is_async": false,
      "parameters": [
        "path_hint",
        "code"
      ],
      "last_updated": "2025-08-04T12:57:12.491915+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/validation_pipeline.py::_validate_yaml": {
      "key": "src/core/validation_pipeline.py::_validate_yaml",
      "name": "_validate_yaml",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Runs validation steps specific to YAML files.",
      "docstring": "Runs validation steps specific to YAML files.",
      "calls": [
        "append",
        "safe_load"
      ],
      "line_number": 81,
      "is_async": false,
      "parameters": [
        "code"
      ],
      "last_updated": "2025-08-04T12:57:12.492548+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/validation_pipeline.py::_get_file_classification": {
      "key": "src/core/validation_pipeline.py::_get_file_classification",
      "name": "_get_file_classification",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Determines the file type based on its extension.",
      "docstring": "Determines the file type based on its extension.",
      "calls": [
        "Path",
        "lower"
      ],
      "line_number": 91,
      "is_async": false,
      "parameters": [
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.493023+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/validation_pipeline.py::validate_code": {
      "key": "src/core/validation_pipeline.py::validate_code",
      "name": "validate_code",
      "type": "FunctionDef",
      "file": "src/core/validation_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "code_quality_analysis",
      "intent": "The main entry point for validation. It determines the file type",
      "docstring": "The main entry point for validation. It determines the file type\nand routes it to the appropriate, specific validation function.",
      "calls": [
        "_get_file_classification",
        "_validate_python_code",
        "_validate_yaml",
        "print"
      ],
      "line_number": 100,
      "is_async": false,
      "parameters": [
        "file_path",
        "code"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.493503+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/core/git_service.py::GitService": {
      "key": "src/core/git_service.py::GitService",
      "name": "GitService",
      "type": "ClassDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Encapsulates Git operations for the CORE system.",
      "docstring": "Encapsulates Git operations for the CORE system.\nEnsures all file changes are committed with traceable messages.",
      "calls": [
        "Path",
        "RuntimeError",
        "ValueError",
        "_run_command",
        "is_dir",
        "is_git_repo",
        "print",
        "resolve",
        "run",
        "strip"
      ],
      "line_number": 19,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.495109+00:00",
      "is_class": true,
      "base_classes": []
    },
    "src/core/git_service.py::__init__": {
      "key": "src/core/git_service.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Initialize GitService with repository root.",
      "docstring": "Initialize GitService with repository root.\n\nArgs:\n    repo_path (str): Path to the Git repository.",
      "calls": [
        "Path",
        "ValueError",
        "is_git_repo",
        "print",
        "resolve"
      ],
      "line_number": 25,
      "is_async": false,
      "parameters": [
        "self",
        "repo_path"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.495484+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/core/git_service.py::GitService"
    },
    "src/core/git_service.py::_run_command": {
      "key": "src/core/git_service.py::_run_command",
      "name": "_run_command",
      "type": "FunctionDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Run a Git command and return stdout.",
      "docstring": "Run a Git command and return stdout.\n\nArgs:\n    command (list): Git command as a list (e.g., ['git', 'status']).\n\nReturns:\n    str: Command output, or raises RuntimeError on failure.",
      "calls": [
        "RuntimeError",
        "run",
        "strip"
      ],
      "line_number": 37,
      "is_async": false,
      "parameters": [
        "self",
        "command"
      ],
      "last_updated": "2025-08-04T12:57:12.495914+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/git_service.py::GitService"
    },
    "src/core/git_service.py::add": {
      "key": "src/core/git_service.py::add",
      "name": "add",
      "type": "FunctionDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Stage a file or directory for commit.",
      "docstring": "Stage a file or directory for commit.\n\nArgs:\n    file_path (str): Path to stage. Defaults to '.' (all changes).",
      "calls": [
        "ValueError",
        "_run_command",
        "resolve"
      ],
      "line_number": 59,
      "is_async": false,
      "parameters": [
        "self",
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.496348+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/git_service.py::GitService"
    },
    "src/core/git_service.py::commit": {
      "key": "src/core/git_service.py::commit",
      "name": "commit",
      "type": "FunctionDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Commit staged changes with a message.",
      "docstring": "Commit staged changes with a message.\n\nArgs:\n    message (str): Commit message explaining the change.",
      "calls": [
        "_run_command",
        "print"
      ],
      "line_number": 71,
      "is_async": false,
      "parameters": [
        "self",
        "message"
      ],
      "last_updated": "2025-08-04T12:57:12.496783+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/git_service.py::GitService"
    },
    "src/core/git_service.py::is_git_repo": {
      "key": "src/core/git_service.py::is_git_repo",
      "name": "is_git_repo",
      "type": "FunctionDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Check if the configured path is a valid Git repository.",
      "docstring": "Check if the configured path is a valid Git repository.\n\nReturns:\n    bool: True if it's a Git repo, False otherwise.",
      "calls": [
        "is_dir"
      ],
      "line_number": 84,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.497161+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/git_service.py::GitService"
    },
    "src/core/git_service.py::rollback_last_commit": {
      "key": "src/core/git_service.py::rollback_last_commit",
      "name": "rollback_last_commit",
      "type": "FunctionDef",
      "file": "src/core/git_service.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Undo the last Git commit (soft reset).",
      "docstring": "Undo the last Git commit (soft reset).\n\nUse with caution \u2014 only for failed self-modifications.",
      "calls": [
        "_run_command",
        "print"
      ],
      "line_number": 94,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.497523+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/git_service.py::GitService"
    },
    "src/core/syntax_checker.py::check_syntax": {
      "key": "src/core/syntax_checker.py::check_syntax",
      "name": "check_syntax",
      "type": "FunctionDef",
      "file": "src/core/syntax_checker.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "syntax_validation",
      "intent": "Checks whether the given code has valid syntax.",
      "docstring": "Checks whether the given code has valid syntax.\n\nArgs:\n    file_path (str): File name (used to detect .py files)\n    code (str): Source code string\n\nReturns:\n    (is_valid: bool, message: str)",
      "calls": [
        "endswith",
        "parse",
        "strip"
      ],
      "line_number": 14,
      "is_async": false,
      "parameters": [
        "file_path",
        "code"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.498395+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/core/black_formatter.py::format_code_with_black": {
      "key": "src/core/black_formatter.py::format_code_with_black",
      "name": "format_code_with_black",
      "type": "FunctionDef",
      "file": "src/core/black_formatter.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Attempts to format the given Python code using Black.",
      "docstring": "Attempts to format the given Python code using Black.\n\nReturns:\n    Tuple:\n        - formatted_code (str) if successful, else None\n        - error_message (str) if failed, else None",
      "calls": [
        "FileMode",
        "format_str",
        "str"
      ],
      "line_number": 10,
      "is_async": false,
      "parameters": [
        "code"
      ],
      "last_updated": "2025-08-04T12:57:12.499248+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/test_runner.py::run_tests": {
      "key": "src/core/test_runner.py::run_tests",
      "name": "run_tests",
      "type": "FunctionDef",
      "file": "src/core/test_runner.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "test_execution",
      "intent": "Executes pytest on the tests/ directory and returns a structured result.",
      "docstring": "Executes pytest on the tests/ directory and returns a structured result.\nThis function captures stdout, stderr, and the exit code, providing a\ncomprehensive summary of the test run for agents to act upon.",
      "calls": [
        "Path",
        "_log_test_result",
        "_store_failure_if_any",
        "_summarize",
        "getenv",
        "int",
        "isoformat",
        "print",
        "resolve",
        "run",
        "str",
        "strip",
        "utcnow"
      ],
      "line_number": 20,
      "is_async": false,
      "parameters": [
        "silent"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.501382+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/core/test_runner.py::_summarize": {
      "key": "src/core/test_runner.py::_summarize",
      "name": "_summarize",
      "type": "FunctionDef",
      "file": "src/core/test_runner.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Parses pytest output to find the final summary line.",
      "docstring": "Parses pytest output to find the final summary line.",
      "calls": [
        "reversed",
        "splitlines",
        "strip"
      ],
      "line_number": 76,
      "is_async": false,
      "parameters": [
        "output"
      ],
      "last_updated": "2025-08-04T12:57:12.502154+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/test_runner.py::_log_test_result": {
      "key": "src/core/test_runner.py::_log_test_result",
      "name": "_log_test_result",
      "type": "FunctionDef",
      "file": "src/core/test_runner.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Appends a JSON record of a test run to the persistent log file.",
      "docstring": "Appends a JSON record of a test run to the persistent log file.",
      "calls": [
        "dumps",
        "open",
        "print",
        "write"
      ],
      "line_number": 84,
      "is_async": false,
      "parameters": [
        "data"
      ],
      "last_updated": "2025-08-04T12:57:12.502605+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/test_runner.py::_store_failure_if_any": {
      "key": "src/core/test_runner.py::_store_failure_if_any",
      "name": "_store_failure_if_any",
      "type": "FunctionDef",
      "file": "src/core/test_runner.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Saves the details of a failed test run to a dedicated file for easy access.",
      "docstring": "Saves the details of a failed test run to a dedicated file for easy access.",
      "calls": [
        "dump",
        "exists",
        "get",
        "open",
        "print",
        "remove"
      ],
      "line_number": 92,
      "is_async": false,
      "parameters": [
        "data"
      ],
      "last_updated": "2025-08-04T12:57:12.503122+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/main.py::lifespan": {
      "key": "src/core/main.py::lifespan",
      "name": "lifespan",
      "type": "AsyncFunctionDef",
      "file": "src/core/main.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "FastAPI lifespan handler \u2014 runs startup and shutdown logic.",
      "docstring": "FastAPI lifespan handler \u2014 runs startup and shutdown logic.",
      "calls": [
        "FileHandler",
        "GeneratorClient",
        "GitService",
        "IntentGuard",
        "OrchestratorClient",
        "PlannerAgent",
        "introspection",
        "print"
      ],
      "line_number": 31,
      "is_async": true,
      "parameters": [
        "app"
      ],
      "entry_point_type": "context_manager",
      "last_updated": "2025-08-04T12:57:12.504763+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/main.py::execute_goal": {
      "key": "src/core/main.py::execute_goal",
      "name": "execute_goal",
      "type": "AsyncFunctionDef",
      "file": "src/core/main.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Execute a high-level goal by planning and generating code.",
      "docstring": "Execute a high-level goal by planning and generating code.",
      "calls": [
        "HTTPException",
        "JSONResponse",
        "create_execution_plan",
        "execute_plan",
        "get",
        "post",
        "str"
      ],
      "line_number": 61,
      "is_async": true,
      "parameters": [
        "request_data",
        "request"
      ],
      "entry_point_type": "fastapi_route_post",
      "last_updated": "2025-08-04T12:57:12.505436+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/main.py::root": {
      "key": "src/core/main.py::root",
      "name": "root",
      "type": "AsyncFunctionDef",
      "file": "src/core/main.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Root endpoint \u2014 returns system status.",
      "docstring": "Root endpoint \u2014 returns system status.",
      "calls": [
        "get"
      ],
      "line_number": 85,
      "is_async": true,
      "parameters": [],
      "entry_point_type": "fastapi_route_get",
      "last_updated": "2025-08-04T12:57:12.505932+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/prompt_pipeline.py::PromptPipeline": {
      "key": "src/core/prompt_pipeline.py::PromptPipeline",
      "name": "PromptPipeline",
      "type": "ClassDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Processes and enriches user prompts by resolving directives like [[include:...]] and [[analysis:...]].",
      "docstring": "Processes and enriches user prompts by resolving directives like [[include:...]] and [[analysis:...]].\nEnsures the LLM receives full context before generating code.",
      "calls": [
        "Path",
        "_inject_analysis",
        "_inject_context",
        "_inject_includes",
        "_inject_manifest",
        "compile",
        "dump",
        "exists",
        "get",
        "group",
        "is_file",
        "isinstance",
        "read_text",
        "resolve",
        "safe_load",
        "split",
        "str",
        "strip",
        "sub"
      ],
      "line_number": 20,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.508740+00:00",
      "is_class": true,
      "base_classes": []
    },
    "src/core/prompt_pipeline.py::__init__": {
      "key": "src/core/prompt_pipeline.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Initialize PromptPipeline with repository root.",
      "docstring": "Initialize PromptPipeline with repository root.\n\nArgs:\n    repo_path (Path): Root path of the repository.",
      "calls": [
        "Path",
        "compile",
        "resolve"
      ],
      "line_number": 26,
      "is_async": false,
      "parameters": [
        "self",
        "repo_path"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.509184+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_replace_context_match": {
      "key": "src/core/prompt_pipeline.py::_replace_context_match",
      "name": "_replace_context_match",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Dynamically replaces a [[context:...]] regex match with file content or an error message.",
      "docstring": "Dynamically replaces a [[context:...]] regex match with file content or an error message.",
      "calls": [
        "exists",
        "group",
        "is_file",
        "read_text",
        "str",
        "strip"
      ],
      "line_number": 41,
      "is_async": false,
      "parameters": [
        "self",
        "match"
      ],
      "last_updated": "2025-08-04T12:57:12.509677+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_inject_context": {
      "key": "src/core/prompt_pipeline.py::_inject_context",
      "name": "_inject_context",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Replaces [[context:file.py]] directives with actual file content.",
      "docstring": "Replaces [[context:file.py]] directives with actual file content.",
      "calls": [
        "sub"
      ],
      "line_number": 52,
      "is_async": false,
      "parameters": [
        "self",
        "prompt"
      ],
      "last_updated": "2025-08-04T12:57:12.510138+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_replace_include_match": {
      "key": "src/core/prompt_pipeline.py::_replace_include_match",
      "name": "_replace_include_match",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Dynamically replaces an [[include:...]] regex match with file content or an error message.",
      "docstring": "Dynamically replaces an [[include:...]] regex match with file content or an error message.",
      "calls": [
        "exists",
        "group",
        "is_file",
        "read_text",
        "str",
        "strip"
      ],
      "line_number": 56,
      "is_async": false,
      "parameters": [
        "self",
        "match"
      ],
      "last_updated": "2025-08-04T12:57:12.510595+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_inject_includes": {
      "key": "src/core/prompt_pipeline.py::_inject_includes",
      "name": "_inject_includes",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Replaces [[include:file.py]] directives with file content.",
      "docstring": "Replaces [[include:file.py]] directives with file content.",
      "calls": [
        "sub"
      ],
      "line_number": 67,
      "is_async": false,
      "parameters": [
        "self",
        "prompt"
      ],
      "last_updated": "2025-08-04T12:57:12.511049+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_replace_analysis_match": {
      "key": "src/core/prompt_pipeline.py::_replace_analysis_match",
      "name": "_replace_analysis_match",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Dynamically replaces an [[analysis:...]] regex match with a placeholder analysis message.",
      "docstring": "Dynamically replaces an [[analysis:...]] regex match with a placeholder analysis message.",
      "calls": [
        "group",
        "strip"
      ],
      "line_number": 71,
      "is_async": false,
      "parameters": [
        "self",
        "match"
      ],
      "last_updated": "2025-08-04T12:57:12.511429+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_inject_analysis": {
      "key": "src/core/prompt_pipeline.py::_inject_analysis",
      "name": "_inject_analysis",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Replaces [[analysis:file.py]] directives with code analysis.",
      "docstring": "Replaces [[analysis:file.py]] directives with code analysis.",
      "calls": [
        "sub"
      ],
      "line_number": 77,
      "is_async": false,
      "parameters": [
        "self",
        "prompt"
      ],
      "last_updated": "2025-08-04T12:57:12.511776+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_replace_manifest_match": {
      "key": "src/core/prompt_pipeline.py::_replace_manifest_match",
      "name": "_replace_manifest_match",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Dynamically replaces a [[manifest:...]] regex match with manifest data or an error.",
      "docstring": "Dynamically replaces a [[manifest:...]] regex match with manifest data or an error.",
      "calls": [
        "dump",
        "exists",
        "get",
        "group",
        "isinstance",
        "read_text",
        "safe_load",
        "split",
        "str",
        "strip"
      ],
      "line_number": 81,
      "is_async": false,
      "parameters": [
        "self",
        "match"
      ],
      "last_updated": "2025-08-04T12:57:12.512351+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::_inject_manifest": {
      "key": "src/core/prompt_pipeline.py::_inject_manifest",
      "name": "_inject_manifest",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Replaces [[manifest:field]] directives with data from project_manifest.yaml.",
      "docstring": "Replaces [[manifest:field]] directives with data from project_manifest.yaml.",
      "calls": [
        "sub"
      ],
      "line_number": 107,
      "is_async": false,
      "parameters": [
        "self",
        "prompt"
      ],
      "last_updated": "2025-08-04T12:57:12.512952+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/prompt_pipeline.py::process": {
      "key": "src/core/prompt_pipeline.py::process",
      "name": "process",
      "type": "FunctionDef",
      "file": "src/core/prompt_pipeline.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Processes the full prompt by sequentially resolving all directives.",
      "docstring": "Processes the full prompt by sequentially resolving all directives.\nThis is the main entry point for prompt enrichment.",
      "calls": [
        "_inject_analysis",
        "_inject_context",
        "_inject_includes",
        "_inject_manifest"
      ],
      "line_number": 111,
      "is_async": false,
      "parameters": [
        "self",
        "prompt"
      ],
      "last_updated": "2025-08-04T12:57:12.513339+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/prompt_pipeline.py::PromptPipeline"
    },
    "src/core/capabilities.py::introspection": {
      "key": "src/core/capabilities.py::introspection",
      "name": "introspection",
      "type": "FunctionDef",
      "file": "src/core/capabilities.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "introspection",
      "intent": "Runs a full self-analysis cycle to inspect system structure and health.",
      "docstring": "Runs a full self-analysis cycle to inspect system structure and health.\nThis orchestrates the execution of the system's own introspection tools\nas separate, governed processes.",
      "calls": [
        "Path",
        "error",
        "info",
        "print",
        "resolve",
        "run"
      ],
      "line_number": 16,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.514725+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/core/ruff_linter.py::fix_and_lint_code_with_ruff": {
      "key": "src/core/ruff_linter.py::fix_and_lint_code_with_ruff",
      "name": "fix_and_lint_code_with_ruff",
      "type": "FunctionDef",
      "file": "src/core/ruff_linter.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Fix and lint the provided Python code using Ruff.",
      "docstring": "Fix and lint the provided Python code using Ruff.\n\nArgs:\n    code (str): Source code to fix and lint.\n    display_filename (str): Optional display name (e.g., intended file path).\n\nReturns:\n    (is_clean: bool, message: str, fixed_code: str)",
      "calls": [
        "NamedTemporaryFile",
        "exists",
        "open",
        "read",
        "remove",
        "replace",
        "run",
        "strip",
        "write"
      ],
      "line_number": 15,
      "is_async": false,
      "parameters": [
        "code",
        "display_filename"
      ],
      "last_updated": "2025-08-04T12:57:12.516250+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/file_handler.py::_log_change": {
      "key": "src/core/file_handler.py::_log_change",
      "name": "_log_change",
      "type": "FunctionDef",
      "file": "src/core/file_handler.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Appends a change entry to the intent change log.",
      "docstring": "Appends a change entry to the intent change log.",
      "calls": [
        "append",
        "dumps",
        "exists",
        "isoformat",
        "loads",
        "mkdir",
        "now",
        "print",
        "read_text",
        "write_text"
      ],
      "line_number": 57,
      "is_async": false,
      "parameters": [
        "file_path",
        "reason"
      ],
      "last_updated": "2025-08-04T12:57:12.519051+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/file_handler.py::_validate_content": {
      "key": "src/core/file_handler.py::_validate_content",
      "name": "_validate_content",
      "type": "FunctionDef",
      "file": "src/core/file_handler.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Validates content against safety policies (e.g., no eval, subprocess, etc.).",
      "docstring": "Validates content against safety policies (e.g., no eval, subprocess, etc.).",
      "calls": [
        "extend",
        "get",
        "load_config",
        "print"
      ],
      "line_number": 83,
      "is_async": false,
      "parameters": [
        "content",
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.519655+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/core/file_handler.py::FileHandler": {
      "key": "src/core/file_handler.py::FileHandler",
      "name": "FileHandler",
      "type": "ClassDef",
      "file": "src/core/file_handler.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Central class for safe, auditable file operations in CORE.",
      "docstring": "Central class for safe, auditable file operations in CORE.\nAll writes are staged first and require confirmation.",
      "calls": [
        "Path",
        "ValueError",
        "_log_change",
        "_validate_content",
        "as_posix",
        "dumps",
        "exists",
        "is_dir",
        "is_relative_to",
        "isoformat",
        "mkdir",
        "now",
        "pop",
        "resolve",
        "str",
        "unlink",
        "uuid4",
        "write_text"
      ],
      "line_number": 105,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.520559+00:00",
      "is_class": true,
      "base_classes": []
    },
    "src/core/file_handler.py::__init__": {
      "key": "src/core/file_handler.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/core/file_handler.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Initialize FileHandler with repository root.",
      "docstring": "Initialize FileHandler with repository root.",
      "calls": [
        "Path",
        "ValueError",
        "is_dir",
        "resolve"
      ],
      "line_number": 111,
      "is_async": false,
      "parameters": [
        "self",
        "repo_path"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.520920+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/core/file_handler.py::FileHandler"
    },
    "src/core/file_handler.py::add_pending_write": {
      "key": "src/core/file_handler.py::add_pending_write",
      "name": "add_pending_write",
      "type": "FunctionDef",
      "file": "src/core/file_handler.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Stages a pending write operation for later confirmation.",
      "docstring": "Stages a pending write operation for later confirmation.",
      "calls": [
        "Path",
        "as_posix",
        "dumps",
        "isoformat",
        "now",
        "str",
        "uuid4",
        "write_text"
      ],
      "line_number": 119,
      "is_async": false,
      "parameters": [
        "self",
        "prompt",
        "suggested_path",
        "code"
      ],
      "last_updated": "2025-08-04T12:57:12.521381+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/file_handler.py::FileHandler"
    },
    "src/core/file_handler.py::confirm_write": {
      "key": "src/core/file_handler.py::confirm_write",
      "name": "confirm_write",
      "type": "FunctionDef",
      "file": "src/core/file_handler.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Confirms and applies a pending write to disk.",
      "docstring": "Confirms and applies a pending write to disk.",
      "calls": [
        "ValueError",
        "_log_change",
        "_validate_content",
        "exists",
        "is_relative_to",
        "mkdir",
        "pop",
        "resolve",
        "str",
        "unlink",
        "write_text"
      ],
      "line_number": 140,
      "is_async": false,
      "parameters": [
        "self",
        "pending_id"
      ],
      "last_updated": "2025-08-04T12:57:12.522132+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/file_handler.py::FileHandler"
    },
    "src/core/intent_model.py::IntentModel": {
      "key": "src/core/intent_model.py::IntentModel",
      "name": "IntentModel",
      "type": "ClassDef",
      "file": "src/core/intent_model.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Loads and provides an queryable interface to the source code structure",
      "docstring": "Loads and provides an queryable interface to the source code structure\ndefined in .intent/knowledge/source_structure.yaml.",
      "calls": [
        "FileNotFoundError",
        "Path",
        "ValueError",
        "_load_structure",
        "exists",
        "get",
        "isinstance",
        "items",
        "len",
        "read_text",
        "resolve",
        "safe_load",
        "sorted"
      ],
      "line_number": 19,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.524038+00:00",
      "is_class": true,
      "base_classes": []
    },
    "src/core/intent_model.py::__init__": {
      "key": "src/core/intent_model.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/core/intent_model.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Initializes the model by loading the source structure definition.",
      "docstring": "Initializes the model by loading the source structure definition.\n\nArgs:\n    repo_root (Optional[Path]): The root of the repository. Inferred if not provided.",
      "calls": [
        "Path",
        "_load_structure",
        "resolve"
      ],
      "line_number": 24,
      "is_async": false,
      "parameters": [
        "self",
        "repo_root"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.524436+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/core/intent_model.py::IntentModel"
    },
    "src/core/intent_model.py::_load_structure": {
      "key": "src/core/intent_model.py::_load_structure",
      "name": "_load_structure",
      "type": "FunctionDef",
      "file": "src/core/intent_model.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Load the domain structure from .intent/knowledge/source_structure.yaml.",
      "docstring": "Load the domain structure from .intent/knowledge/source_structure.yaml.\n\nReturns:\n    Dict[str, dict]: Mapping of domain names to metadata (path, permissions, etc.).",
      "calls": [
        "FileNotFoundError",
        "ValueError",
        "exists",
        "isinstance",
        "read_text",
        "safe_load"
      ],
      "line_number": 35,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.524925+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/intent_model.py::IntentModel"
    },
    "src/core/intent_model.py::resolve_domain_for_path": {
      "key": "src/core/intent_model.py::resolve_domain_for_path",
      "name": "resolve_domain_for_path",
      "type": "FunctionDef",
      "file": "src/core/intent_model.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Given an absolute or relative path, determine which domain it belongs to.",
      "docstring": "Given an absolute or relative path, determine which domain it belongs to.\nPrefers deeper (more specific) paths over shorter ones.",
      "calls": [
        "items",
        "len",
        "resolve",
        "sorted"
      ],
      "line_number": 80,
      "is_async": false,
      "parameters": [
        "self",
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.525440+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/intent_model.py::IntentModel"
    },
    "src/core/intent_model.py::get_domain_permissions": {
      "key": "src/core/intent_model.py::get_domain_permissions",
      "name": "get_domain_permissions",
      "type": "FunctionDef",
      "file": "src/core/intent_model.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "unassigned",
      "intent": "Return a list of allowed domains that the given domain can import from.",
      "docstring": "Return a list of allowed domains that the given domain can import from.\n\nArgs:\n    domain (str): The domain to query.\n\nReturns:\n    List[str]: List of allowed domain names, or empty list if not defined.",
      "calls": [
        "get",
        "isinstance"
      ],
      "line_number": 97,
      "is_async": false,
      "parameters": [
        "self",
        "domain"
      ],
      "last_updated": "2025-08-04T12:57:12.525904+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/intent_model.py::IntentModel"
    },
    "src/core/intent_guard.py::IntentGuard": {
      "key": "src/core/intent_guard.py::IntentGuard",
      "name": "IntentGuard",
      "type": "ClassDef",
      "file": "src/core/intent_guard.py",
      "domain": "core",
      "agent": "validator_agent",
      "capability": "intent_guarding",
      "intent": "Central enforcement engine for CORE's safety and governance policies.",
      "docstring": "Central enforcement engine for CORE's safety and governance policies.\nEnsures all proposed file changes comply with declared rules and classifications.\nUses a mix of hard-coded primordial truths and dynamic policy loading.",
      "calls": [
        "Path",
        "_load_policies",
        "_load_source_manifest",
        "exists",
        "extend",
        "get",
        "glob",
        "is_dir",
        "isinstance",
        "len",
        "load_config",
        "loads",
        "print",
        "read_text"
      ],
      "line_number": 28,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.527712+00:00",
      "is_class": true,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/core/intent_guard.py::__init__": {
      "key": "src/core/intent_guard.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/core/intent_guard.py",
      "domain": "core",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Initialize IntentGuard with repository path and load all policies.",
      "docstring": "Initialize IntentGuard with repository path and load all policies.",
      "calls": [
        "Path",
        "_load_policies",
        "_load_source_manifest",
        "len",
        "print"
      ],
      "line_number": 35,
      "is_async": false,
      "parameters": [
        "self",
        "repo_path"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.528194+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/core/intent_guard.py::IntentGuard"
    },
    "src/core/intent_guard.py::_load_policies": {
      "key": "src/core/intent_guard.py::_load_policies",
      "name": "_load_policies",
      "type": "FunctionDef",
      "file": "src/core/intent_guard.py",
      "domain": "core",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Load rules from all YAML files in .intent/policies/.",
      "docstring": "Load rules from all YAML files in .intent/policies/.",
      "calls": [
        "extend",
        "glob",
        "is_dir",
        "isinstance",
        "load_config"
      ],
      "line_number": 58,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.528762+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/intent_guard.py::IntentGuard"
    },
    "src/core/intent_guard.py::_get_classification": {
      "key": "src/core/intent_guard.py::_get_classification",
      "name": "_get_classification",
      "type": "FunctionDef",
      "file": "src/core/intent_guard.py",
      "domain": "core",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Determine the classification of a file based on its extension.",
      "docstring": "Determine the classification of a file based on its extension.",
      "calls": [
        "Path",
        "get"
      ],
      "line_number": 69,
      "is_async": false,
      "parameters": [
        "self",
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.529202+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/intent_guard.py::IntentGuard"
    },
    "src/core/intent_guard.py::_load_source_manifest": {
      "key": "src/core/intent_guard.py::_load_source_manifest",
      "name": "_load_source_manifest",
      "type": "FunctionDef",
      "file": "src/core/intent_guard.py",
      "domain": "core",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Load the list of declared source files from function_manifest.json.",
      "docstring": "Load the list of declared source files from function_manifest.json.",
      "calls": [
        "exists",
        "get",
        "loads",
        "read_text"
      ],
      "line_number": 79,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.529668+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/core/intent_guard.py::IntentGuard"
    },
    "src/core/self_correction_engine.py::attempt_correction": {
      "key": "src/core/self_correction_engine.py::attempt_correction",
      "name": "attempt_correction",
      "type": "FunctionDef",
      "file": "src/core/self_correction_engine.py",
      "domain": "core",
      "agent": "core_agent",
      "capability": "self_correction",
      "intent": "Attempts to fix a failed validation or test result using an enriched LLM prompt.",
      "docstring": "Attempts to fix a failed validation or test result using an enriched LLM prompt.",
      "calls": [
        "GeneratorClient",
        "add_pending_write",
        "dumps",
        "get",
        "items",
        "list",
        "make_request",
        "parse_write_blocks",
        "process",
        "strip",
        "validate_code"
      ],
      "line_number": 20,
      "is_async": false,
      "parameters": [
        "failure_context"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.531266+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/agents/planner_agent.py::PlannerAgent": {
      "key": "src/agents/planner_agent.py::PlannerAgent",
      "name": "PlannerAgent",
      "type": "ClassDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "llm_orchestration",
      "intent": "The primary agent responsible for decomposing high-level goals into executable plans.",
      "docstring": "The primary agent responsible for decomposing high-level goals into executable plans.\nIt orchestrates the generation, validation, and commitment of code changes.",
      "calls": [
        "PromptPipeline",
        "RuntimeError",
        "ValueError",
        "_execute_task",
        "_extract_json_from_response",
        "_extract_target_path_from_prompt",
        "_govern_and_amend_code",
        "add",
        "add_pending_write",
        "append",
        "attempt_correction",
        "commit",
        "confirm_write",
        "dedent",
        "enumerate",
        "get",
        "get_docstring",
        "group",
        "insert",
        "is_git_repo",
        "isinstance",
        "items",
        "join",
        "len",
        "loads",
        "make_request",
        "parse",
        "parse_write_blocks",
        "print",
        "process",
        "rollback_last_commit",
        "search",
        "sorted",
        "splitlines",
        "startswith",
        "str",
        "strip",
        "validate_code",
        "walk"
      ],
      "line_number": 20,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.536608+00:00",
      "is_class": true,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/agents/planner_agent.py::__init__": {
      "key": "src/agents/planner_agent.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "unassigned",
      "intent": "Initializes the PlannerAgent with all necessary service dependencies.",
      "docstring": "Initializes the PlannerAgent with all necessary service dependencies.",
      "calls": [
        "PromptPipeline"
      ],
      "line_number": 25,
      "is_async": false,
      "parameters": [
        "self",
        "orchestrator_client",
        "generator_client",
        "file_handler",
        "git_service",
        "intent_guard"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.537011+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/agents/planner_agent.py::_extract_target_path_from_prompt": {
      "key": "src/agents/planner_agent.py::_extract_target_path_from_prompt",
      "name": "_extract_target_path_from_prompt",
      "type": "FunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "unassigned",
      "intent": "Parses a prompt to find the first [[write:path/to/file]] directive.",
      "docstring": "Parses a prompt to find the first [[write:path/to/file]] directive.",
      "calls": [
        "group",
        "search",
        "strip"
      ],
      "line_number": 40,
      "is_async": false,
      "parameters": [
        "self",
        "prompt"
      ],
      "last_updated": "2025-08-04T12:57:12.537480+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/agents/planner_agent.py::_extract_json_from_response": {
      "key": "src/agents/planner_agent.py::_extract_json_from_response",
      "name": "_extract_json_from_response",
      "type": "FunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "unassigned",
      "intent": "Extracts a JSON object or array from a raw text response.",
      "docstring": "Extracts a JSON object or array from a raw text response.",
      "calls": [
        "group",
        "search",
        "strip"
      ],
      "line_number": 45,
      "is_async": false,
      "parameters": [
        "self",
        "text"
      ],
      "last_updated": "2025-08-04T12:57:12.537901+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/agents/planner_agent.py::create_execution_plan": {
      "key": "src/agents/planner_agent.py::create_execution_plan",
      "name": "create_execution_plan",
      "type": "FunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "prompt_interpretation",
      "intent": "Creates a detailed, step-by-step execution plan from a high-level goal.",
      "docstring": "Creates a detailed, step-by-step execution plan from a high-level goal.",
      "calls": [
        "ValueError",
        "_extract_json_from_response",
        "dedent",
        "len",
        "loads",
        "make_request",
        "print",
        "strip"
      ],
      "line_number": 56,
      "is_async": false,
      "parameters": [
        "self",
        "high_level_goal"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.538439+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation",
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/agents/planner_agent.py::execute_plan": {
      "key": "src/agents/planner_agent.py::execute_plan",
      "name": "execute_plan",
      "type": "AsyncFunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "unassigned",
      "intent": "Executes a plan, running each task in sequence.",
      "docstring": "Executes a plan, running each task in sequence.",
      "calls": [
        "_execute_task",
        "enumerate",
        "get",
        "is_git_repo",
        "len",
        "print",
        "rollback_last_commit",
        "str"
      ],
      "line_number": 83,
      "is_async": true,
      "parameters": [
        "self",
        "plan"
      ],
      "last_updated": "2025-08-04T12:57:12.539098+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/agents/planner_agent.py::_govern_and_amend_code": {
      "key": "src/agents/planner_agent.py::_govern_and_amend_code",
      "name": "_govern_and_amend_code",
      "type": "FunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "change_safety_enforcement",
      "intent": "Validates and amends newly generated code to comply with constitutional",
      "docstring": "Validates and amends newly generated code to comply with constitutional\nstandards before being written to disk. This is the core of the\n\"immune system\".\n\nArgs:\n    code (str): The raw Python code generated by the LLM.\n\nReturns:\n    str: The amended code, compliant with governance.\n\nRaises:\n    RuntimeError: If a critical governance check fails (e.g., missing docstring).",
      "calls": [
        "RuntimeError",
        "append",
        "get_docstring",
        "insert",
        "isinstance",
        "join",
        "parse",
        "print",
        "sorted",
        "splitlines",
        "startswith",
        "strip",
        "walk"
      ],
      "line_number": 103,
      "is_async": false,
      "parameters": [
        "self",
        "code"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.539859+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation",
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/agents/planner_agent.py::_execute_task": {
      "key": "src/agents/planner_agent.py::_execute_task",
      "name": "_execute_task",
      "type": "AsyncFunctionDef",
      "file": "src/agents/planner_agent.py",
      "domain": "agents",
      "agent": "planner_agent",
      "capability": "code_generation",
      "intent": "Executes a single task from a plan, including code generation and file writing.",
      "docstring": "Executes a single task from a plan, including code generation and file writing.",
      "calls": [
        "RuntimeError",
        "_extract_target_path_from_prompt",
        "_govern_and_amend_code",
        "add",
        "add_pending_write",
        "append",
        "attempt_correction",
        "commit",
        "confirm_write",
        "get",
        "is_git_repo",
        "items",
        "make_request",
        "parse_write_blocks",
        "print",
        "process",
        "validate_code"
      ],
      "line_number": 150,
      "is_async": true,
      "parameters": [
        "self",
        "task"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.541025+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation",
      "parent_class_key": "src/agents/planner_agent.py::PlannerAgent"
    },
    "src/shared/path_utils.py::get_repo_root": {
      "key": "src/shared/path_utils.py::get_repo_root",
      "name": "get_repo_root",
      "type": "FunctionDef",
      "file": "src/shared/path_utils.py",
      "domain": "shared",
      "agent": "generic_agent",
      "capability": "unassigned",
      "intent": "Find and return the repository root by locating the .git directory.",
      "docstring": "Find and return the repository root by locating the .git directory.\nStarts from current directory or provided path.\n\nReturns:\n    Path: Absolute path to repo root.\n\nRaises:\n    RuntimeError: If no .git directory is found.",
      "calls": [
        "Path",
        "RuntimeError",
        "cwd",
        "exists",
        "resolve"
      ],
      "line_number": 6,
      "is_async": false,
      "parameters": [
        "start_path"
      ],
      "last_updated": "2025-08-04T12:57:12.542491+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/shared/config_loader.py::load_config": {
      "key": "src/shared/config_loader.py::load_config",
      "name": "load_config",
      "type": "FunctionDef",
      "file": "src/shared/config_loader.py",
      "domain": "shared",
      "agent": "generic_agent",
      "capability": "unassigned",
      "intent": "Loads a JSON or YAML file into a dictionary with consistent error handling.",
      "docstring": "Loads a JSON or YAML file into a dictionary with consistent error handling.\n\nArgs:\n    file_path (Path): Path to the file to load.\n    file_type (str): 'json', 'yaml', or 'auto' to infer from extension.\n\nReturns:\n    Dict[str, Any]: Parsed file content or empty dict if file is missing/invalid.",
      "calls": [
        "Path",
        "exists",
        "isinstance",
        "load",
        "lower",
        "open",
        "print",
        "safe_load"
      ],
      "line_number": 8,
      "is_async": false,
      "parameters": [
        "file_path",
        "file_type"
      ],
      "last_updated": "2025-08-04T12:57:12.543707+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor": {
      "key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor",
      "name": "ConstitutionalAuditor",
      "type": "ClassDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "alignment_checking",
      "intent": "Validates the complete structure and consistency of the .intent/ directory",
      "docstring": "Validates the complete structure and consistency of the .intent/ directory\nand its relationship with the source code.",
      "calls": [
        "Console",
        "IntentModel",
        "Panel",
        "Table",
        "_add_error",
        "_add_success",
        "_add_warning",
        "_report_final_status",
        "add_row",
        "any",
        "append",
        "check_fn",
        "exists",
        "get",
        "get_domain_permissions",
        "get_repo_root",
        "is_file",
        "items",
        "joinpath",
        "len",
        "list",
        "load_config",
        "print",
        "read_text",
        "relative_to",
        "replace",
        "resolve_domain_for_path",
        "rglob",
        "rule",
        "scan_imports_for_file",
        "set",
        "sorted",
        "split",
        "startswith",
        "str",
        "update",
        "validate_code",
        "validate_manifest_entry",
        "values",
        "with_suffix"
      ],
      "line_number": 24,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.551203+00:00",
      "is_class": true,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/system/governance/constitutional_auditor.py::__init__": {
      "key": "src/system/governance/constitutional_auditor.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Initializes the auditor, loading all necessary configuration and knowledge files.",
      "docstring": "Initializes the auditor, loading all necessary configuration and knowledge files.",
      "calls": [
        "Console",
        "IntentModel",
        "get",
        "get_repo_root",
        "list",
        "load_config",
        "values"
      ],
      "line_number": 29,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.551724+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::run_full_audit": {
      "key": "src/system/governance/constitutional_auditor.py::run_full_audit",
      "name": "run_full_audit",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "validate_intent_structure",
      "intent": "Run all validation phases and return overall status.",
      "docstring": "Run all validation phases and return overall status.",
      "calls": [
        "Panel",
        "_report_final_status",
        "check_fn",
        "print",
        "rule"
      ],
      "line_number": 44,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.552352+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation",
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_add_error": {
      "key": "src/system/governance/constitutional_auditor.py::_add_error",
      "name": "_add_error",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Adds an error to the list and prints it.",
      "docstring": "Adds an error to the list and prints it.",
      "calls": [
        "append",
        "print"
      ],
      "line_number": 66,
      "is_async": false,
      "parameters": [
        "self",
        "message"
      ],
      "last_updated": "2025-08-04T12:57:12.552889+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_add_warning": {
      "key": "src/system/governance/constitutional_auditor.py::_add_warning",
      "name": "_add_warning",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Adds a warning to the list and prints it.",
      "docstring": "Adds a warning to the list and prints it.",
      "calls": [
        "append",
        "print"
      ],
      "line_number": 71,
      "is_async": false,
      "parameters": [
        "self",
        "message"
      ],
      "last_updated": "2025-08-04T12:57:12.553270+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_add_success": {
      "key": "src/system/governance/constitutional_auditor.py::_add_success",
      "name": "_add_success",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Prints a success message.",
      "docstring": "Prints a success message.",
      "calls": [
        "print"
      ],
      "line_number": 76,
      "is_async": false,
      "parameters": [
        "self",
        "message"
      ],
      "last_updated": "2025-08-04T12:57:12.553655+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_check_required_files": {
      "key": "src/system/governance/constitutional_auditor.py::_check_required_files",
      "name": "_check_required_files",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Ensure all critical intent files exist.",
      "docstring": "Ensure all critical intent files exist.",
      "calls": [
        "_add_error",
        "_add_success",
        "exists"
      ],
      "line_number": 80,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.554094+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_validate_syntax": {
      "key": "src/system/governance/constitutional_auditor.py::_validate_syntax",
      "name": "_validate_syntax",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Validate YAML/JSON syntax across all intent files.",
      "docstring": "Validate YAML/JSON syntax across all intent files.",
      "calls": [
        "_add_error",
        "_add_success",
        "is_file",
        "len",
        "list",
        "read_text",
        "relative_to",
        "rglob",
        "str",
        "validate_code"
      ],
      "line_number": 94,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.554686+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_validate_project_manifest": {
      "key": "src/system/governance/constitutional_auditor.py::_validate_project_manifest",
      "name": "_validate_project_manifest",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Ensure project_manifest.yaml is structurally sound.",
      "docstring": "Ensure project_manifest.yaml is structurally sound.",
      "calls": [
        "_add_error",
        "_add_success",
        "len"
      ],
      "line_number": 109,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.555257+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_check_capability_coverage": {
      "key": "src/system/governance/constitutional_auditor.py::_check_capability_coverage",
      "name": "_check_capability_coverage",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Check for missing or duplicate capability implementations.",
      "docstring": "Check for missing or duplicate capability implementations.",
      "calls": [
        "_add_error",
        "_add_success",
        "_add_warning",
        "get",
        "len",
        "list",
        "set",
        "sorted"
      ],
      "line_number": 121,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.555849+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_validate_knowledge_graph_schema": {
      "key": "src/system/governance/constitutional_auditor.py::_validate_knowledge_graph_schema",
      "name": "_validate_knowledge_graph_schema",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Validate each entry in the knowledge graph against its JSON schema.",
      "docstring": "Validate each entry in the knowledge graph against its JSON schema.",
      "calls": [
        "_add_error",
        "_add_success",
        "items",
        "len",
        "validate_manifest_entry"
      ],
      "line_number": 139,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.556465+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_check_domain_integrity": {
      "key": "src/system/governance/constitutional_auditor.py::_check_domain_integrity",
      "name": "_check_domain_integrity",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Validate domain declarations and cross-domain imports.",
      "docstring": "Validate domain declarations and cross-domain imports.",
      "calls": [
        "_add_error",
        "_add_success",
        "_add_warning",
        "exists",
        "get",
        "get_domain_permissions",
        "joinpath",
        "len",
        "relative_to",
        "resolve_domain_for_path",
        "scan_imports_for_file",
        "set",
        "split",
        "startswith",
        "with_suffix"
      ],
      "line_number": 152,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.557250+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_check_docstrings_and_intents": {
      "key": "src/system/governance/constitutional_auditor.py::_check_docstrings_and_intents",
      "name": "_check_docstrings_and_intents",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Check for missing docstrings or weak, generic intents.",
      "docstring": "Check for missing docstrings or weak, generic intents.",
      "calls": [
        "_add_success",
        "_add_warning",
        "get",
        "len"
      ],
      "line_number": 181,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.558092+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_check_for_dead_code": {
      "key": "src/system/governance/constitutional_auditor.py::_check_for_dead_code",
      "name": "_check_for_dead_code",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "self_review",
      "intent": "Finds symbols that are not entry points and are never called.",
      "docstring": "Finds symbols that are not entry points and are never called.",
      "calls": [
        "_add_success",
        "_add_warning",
        "get",
        "len",
        "set",
        "startswith",
        "update"
      ],
      "line_number": 194,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.558729+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "capability_implementation",
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_check_for_orphaned_intent_files": {
      "key": "src/system/governance/constitutional_auditor.py::_check_for_orphaned_intent_files",
      "name": "_check_for_orphaned_intent_files",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Finds .intent files that are not part of the core system configuration.",
      "docstring": "Finds .intent files that are not part of the core system configuration.",
      "calls": [
        "_add_success",
        "_add_warning",
        "any",
        "is_file",
        "len",
        "list",
        "relative_to",
        "replace",
        "rglob",
        "sorted",
        "str"
      ],
      "line_number": 222,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.559425+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::_report_final_status": {
      "key": "src/system/governance/constitutional_auditor.py::_report_final_status",
      "name": "_report_final_status",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Print final summary report.",
      "docstring": "Print final summary report.",
      "calls": [
        "Panel",
        "Table",
        "add_row",
        "len",
        "print"
      ],
      "line_number": 246,
      "is_async": false,
      "parameters": [
        "self",
        "passed"
      ],
      "last_updated": "2025-08-04T12:57:12.560144+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/governance/constitutional_auditor.py::ConstitutionalAuditor"
    },
    "src/system/governance/constitutional_auditor.py::main": {
      "key": "src/system/governance/constitutional_auditor.py::main",
      "name": "main",
      "type": "FunctionDef",
      "file": "src/system/governance/constitutional_auditor.py",
      "domain": "system",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "CLI entry point for the Constitutional Auditor.",
      "docstring": "CLI entry point for the Constitutional Auditor.",
      "calls": [
        "ConstitutionalAuditor",
        "exit",
        "print",
        "run_full_audit"
      ],
      "line_number": 262,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "cli_entry_point",
      "last_updated": "2025-08-04T12:57:12.560734+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/system/tools/change_log_updater.py::load_existing_log": {
      "key": "src/system/tools/change_log_updater.py::load_existing_log",
      "name": "load_existing_log",
      "type": "FunctionDef",
      "file": "src/system/tools/change_log_updater.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Loads the existing change log from disk or returns a new structure.",
      "docstring": "Loads the existing change log from disk or returns a new structure.",
      "calls": [
        "load_config"
      ],
      "line_number": 14,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.562051+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/system/tools/change_log_updater.py::append_change_entry": {
      "key": "src/system/tools/change_log_updater.py::append_change_entry",
      "name": "append_change_entry",
      "type": "FunctionDef",
      "file": "src/system/tools/change_log_updater.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Appends a new, structured entry to the metacode change log.",
      "docstring": "Appends a new, structured entry to the metacode change log.",
      "calls": [
        "append",
        "dumps",
        "isoformat",
        "load_existing_log",
        "mkdir",
        "print",
        "utcnow",
        "write_text"
      ],
      "line_number": 22,
      "is_async": false,
      "parameters": [
        "task",
        "step",
        "modified_files",
        "score",
        "violations"
      ],
      "entry_point_type": "cli_entry_point",
      "last_updated": "2025-08-04T12:57:12.562576+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/system/tools/codegraph_builder.py::FunctionInfo": {
      "key": "src/system/tools/codegraph_builder.py::FunctionInfo",
      "name": "FunctionInfo",
      "type": "ClassDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "A data structure holding all analyzed information about a single symbol (function or class).",
      "docstring": "A data structure holding all analyzed information about a single symbol (function or class).",
      "calls": [
        "field"
      ],
      "line_number": 17,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.569272+00:00",
      "is_class": true,
      "base_classes": []
    },
    "src/system/tools/codegraph_builder.py::ProjectStructureError": {
      "key": "src/system/tools/codegraph_builder.py::ProjectStructureError",
      "name": "ProjectStructureError",
      "type": "ClassDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Custom exception for when the project's root cannot be determined.",
      "docstring": "Custom exception for when the project's root cannot be determined.",
      "calls": [],
      "line_number": 39,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.569813+00:00",
      "is_class": true,
      "base_classes": [
        "Exception"
      ]
    },
    "src/system/tools/codegraph_builder.py::find_project_root": {
      "key": "src/system/tools/codegraph_builder.py::find_project_root",
      "name": "find_project_root",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Traverses upward from a starting path to find the project root, marked by 'pyproject.toml'.",
      "docstring": "Traverses upward from a starting path to find the project root, marked by 'pyproject.toml'.",
      "calls": [
        "ProjectStructureError",
        "exists",
        "resolve"
      ],
      "line_number": 43,
      "is_async": false,
      "parameters": [
        "start_path"
      ],
      "last_updated": "2025-08-04T12:57:12.570249+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/system/tools/codegraph_builder.py::FunctionCallVisitor": {
      "key": "src/system/tools/codegraph_builder.py::FunctionCallVisitor",
      "name": "FunctionCallVisitor",
      "type": "ClassDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "An AST visitor that collects the names of all functions being called within a node.",
      "docstring": "An AST visitor that collects the names of all functions being called within a node.",
      "calls": [
        "add",
        "generic_visit",
        "isinstance",
        "set"
      ],
      "line_number": 54,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.570777+00:00",
      "is_class": true,
      "base_classes": [
        "NodeVisitor"
      ]
    },
    "src/system/tools/codegraph_builder.py::__init__": {
      "key": "src/system/tools/codegraph_builder.py::__init__",
      "name": "__init__",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Initializes the builder, loading patterns and project configuration.",
      "docstring": "Initializes the builder, loading patterns and project configuration.",
      "calls": [
        "_get_cli_entry_points",
        "_get_domain_map",
        "_load_patterns",
        "resolve"
      ],
      "line_number": 97,
      "is_async": false,
      "parameters": [
        "self",
        "root_path",
        "exclude_patterns"
      ],
      "entry_point_type": "magic_method",
      "last_updated": "2025-08-04T12:57:12.577386+00:00",
      "is_class": false,
      "base_classes": [],
      "entry_point_justification": "python_magic_method",
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::visit_Call": {
      "key": "src/system/tools/codegraph_builder.py::visit_Call",
      "name": "visit_Call",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Extracts the function name from a Call node.",
      "docstring": "Extracts the function name from a Call node.",
      "calls": [
        "add",
        "generic_visit",
        "isinstance"
      ],
      "line_number": 60,
      "is_async": false,
      "parameters": [
        "self",
        "node"
      ],
      "entry_point_type": "visitor_method",
      "last_updated": "2025-08-04T12:57:12.571584+00:00",
      "is_class": false,
      "base_classes": [
        "NodeVisitor"
      ],
      "entry_point_justification": "ast_visitor_method",
      "parent_class_key": "src/system/tools/codegraph_builder.py::FunctionCallVisitor"
    },
    "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder": {
      "key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder",
      "name": "KnowledgeGraphBuilder",
      "type": "ClassDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "manifest_updating",
      "intent": "Builds a comprehensive JSON representation of the project's code structure and relationships.",
      "docstring": "Builds a comprehensive JSON representation of the project's code structure and relationships.",
      "calls": [
        "ContextAwareVisitor",
        "FunctionCallVisitor",
        "FunctionInfo",
        "Path",
        "_apply_entry_point_patterns",
        "_determine_domain",
        "_get_cli_entry_points",
        "_get_domain_map",
        "_get_entry_point_type",
        "_infer_agent_from_path",
        "_load_patterns",
        "_parse_metadata_comment",
        "_process_symbol_node",
        "_should_exclude_path",
        "any",
        "append",
        "as_posix",
        "asdict",
        "error",
        "exists",
        "extend",
        "findall",
        "generic_visit",
        "get",
        "get_docstring",
        "group",
        "hasattr",
        "info",
        "isinstance",
        "isoformat",
        "items",
        "len",
        "list",
        "load_config",
        "lower",
        "match",
        "max",
        "now",
        "parse",
        "read_text",
        "relative_to",
        "resolve",
        "rglob",
        "scan_file",
        "search",
        "set",
        "sorted",
        "split",
        "splitlines",
        "startswith",
        "str",
        "strip",
        "update",
        "values",
        "visit",
        "walk",
        "warning"
      ],
      "line_number": 67,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "capability",
      "last_updated": "2025-08-04T12:57:12.574570+00:00",
      "is_class": true,
      "base_classes": [],
      "entry_point_justification": "capability_implementation"
    },
    "src/system/tools/codegraph_builder.py::ContextAwareVisitor": {
      "key": "src/system/tools/codegraph_builder.py::ContextAwareVisitor",
      "name": "ContextAwareVisitor",
      "type": "ClassDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "A stateful AST visitor that understands class context for methods.",
      "docstring": "A stateful AST visitor that understands class context for methods.",
      "calls": [
        "_process_symbol_node",
        "generic_visit"
      ],
      "line_number": 70,
      "is_async": false,
      "parameters": [],
      "last_updated": "2025-08-04T12:57:12.575172+00:00",
      "is_class": true,
      "base_classes": [
        "NodeVisitor"
      ]
    },
    "src/system/tools/codegraph_builder.py::visit_ClassDef": {
      "key": "src/system/tools/codegraph_builder.py::visit_ClassDef",
      "name": "visit_ClassDef",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Processes a class definition, setting the context for its methods.",
      "docstring": "Processes a class definition, setting the context for its methods.",
      "calls": [
        "_process_symbol_node",
        "generic_visit"
      ],
      "line_number": 79,
      "is_async": false,
      "parameters": [
        "self",
        "node"
      ],
      "entry_point_type": "visitor_method",
      "last_updated": "2025-08-04T12:57:12.576015+00:00",
      "is_class": false,
      "base_classes": [
        "NodeVisitor"
      ],
      "entry_point_justification": "ast_visitor_method",
      "parent_class_key": "src/system/tools/codegraph_builder.py::ContextAwareVisitor"
    },
    "src/system/tools/codegraph_builder.py::visit_FunctionDef": {
      "key": "src/system/tools/codegraph_builder.py::visit_FunctionDef",
      "name": "visit_FunctionDef",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Processes a standard function or method within its class context.",
      "docstring": "Processes a standard function or method within its class context.",
      "calls": [
        "_process_symbol_node",
        "generic_visit"
      ],
      "line_number": 87,
      "is_async": false,
      "parameters": [
        "self",
        "node"
      ],
      "entry_point_type": "visitor_method",
      "last_updated": "2025-08-04T12:57:12.576459+00:00",
      "is_class": false,
      "base_classes": [
        "NodeVisitor"
      ],
      "entry_point_justification": "ast_visitor_method",
      "parent_class_key": "src/system/tools/codegraph_builder.py::ContextAwareVisitor"
    },
    "src/system/tools/codegraph_builder.py::visit_AsyncFunctionDef": {
      "key": "src/system/tools/codegraph_builder.py::visit_AsyncFunctionDef",
      "name": "visit_AsyncFunctionDef",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Processes an async function or method within its class context.",
      "docstring": "Processes an async function or method within its class context.",
      "calls": [
        "_process_symbol_node",
        "generic_visit"
      ],
      "line_number": 92,
      "is_async": false,
      "parameters": [
        "self",
        "node"
      ],
      "entry_point_type": "visitor_method",
      "last_updated": "2025-08-04T12:57:12.576869+00:00",
      "is_class": false,
      "base_classes": [
        "NodeVisitor"
      ],
      "entry_point_justification": "ast_visitor_method",
      "parent_class_key": "src/system/tools/codegraph_builder.py::ContextAwareVisitor"
    },
    "src/system/tools/codegraph_builder.py::_load_patterns": {
      "key": "src/system/tools/codegraph_builder.py::_load_patterns",
      "name": "_load_patterns",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Loads entry point detection patterns from the intent file.",
      "docstring": "Loads entry point detection patterns from the intent file.",
      "calls": [
        "exists",
        "get",
        "load_config",
        "warning"
      ],
      "line_number": 110,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.577948+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_get_cli_entry_points": {
      "key": "src/system/tools/codegraph_builder.py::_get_cli_entry_points",
      "name": "_get_cli_entry_points",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Parses pyproject.toml to find declared command-line entry points.",
      "docstring": "Parses pyproject.toml to find declared command-line entry points.",
      "calls": [
        "exists",
        "findall",
        "group",
        "read_text",
        "search",
        "set"
      ],
      "line_number": 118,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.578455+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_should_exclude_path": {
      "key": "src/system/tools/codegraph_builder.py::_should_exclude_path",
      "name": "_should_exclude_path",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Determines if a given path should be excluded from scanning.",
      "docstring": "Determines if a given path should be excluded from scanning.",
      "calls": [
        "any"
      ],
      "line_number": 126,
      "is_async": false,
      "parameters": [
        "self",
        "path"
      ],
      "last_updated": "2025-08-04T12:57:12.578914+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_get_domain_map": {
      "key": "src/system/tools/codegraph_builder.py::_get_domain_map",
      "name": "_get_domain_map",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Loads the domain-to-path mapping from the source structure intent file.",
      "docstring": "Loads the domain-to-path mapping from the source structure intent file.",
      "calls": [
        "Path",
        "as_posix",
        "get",
        "load_config"
      ],
      "line_number": 130,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.579367+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_determine_domain": {
      "key": "src/system/tools/codegraph_builder.py::_determine_domain",
      "name": "_determine_domain",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Determines the logical domain for a file path based on the longest matching prefix.",
      "docstring": "Determines the logical domain for a file path based on the longest matching prefix.",
      "calls": [
        "as_posix",
        "get",
        "max",
        "startswith"
      ],
      "line_number": 136,
      "is_async": false,
      "parameters": [
        "self",
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.579839+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_infer_agent_from_path": {
      "key": "src/system/tools/codegraph_builder.py::_infer_agent_from_path",
      "name": "_infer_agent_from_path",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Infers the most likely responsible agent based on keywords in the file path.",
      "docstring": "Infers the most likely responsible agent based on keywords in the file path.",
      "calls": [
        "any",
        "lower",
        "str"
      ],
      "line_number": 142,
      "is_async": false,
      "parameters": [
        "self",
        "relative_path"
      ],
      "last_updated": "2025-08-04T12:57:12.580330+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_parse_metadata_comment": {
      "key": "src/system/tools/codegraph_builder.py::_parse_metadata_comment",
      "name": "_parse_metadata_comment",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Parses the line immediately preceding a symbol definition for a '# CAPABILITY:' tag.",
      "docstring": "Parses the line immediately preceding a symbol definition for a '# CAPABILITY:' tag.",
      "calls": [
        "group",
        "search",
        "startswith",
        "strip"
      ],
      "line_number": 152,
      "is_async": false,
      "parameters": [
        "self",
        "node",
        "source_lines"
      ],
      "last_updated": "2025-08-04T12:57:12.580874+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_get_entry_point_type": {
      "key": "src/system/tools/codegraph_builder.py::_get_entry_point_type",
      "name": "_get_entry_point_type",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Identifies decorator or CLI-based entry points for a function.",
      "docstring": "Identifies decorator or CLI-based entry points for a function.",
      "calls": [
        "isinstance"
      ],
      "line_number": 161,
      "is_async": false,
      "parameters": [
        "self",
        "node"
      ],
      "last_updated": "2025-08-04T12:57:12.581457+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::scan_file": {
      "key": "src/system/tools/codegraph_builder.py::scan_file",
      "name": "scan_file",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Scans a single Python file, parsing its AST to extract all symbols.",
      "docstring": "Scans a single Python file, parsing its AST to extract all symbols.",
      "calls": [
        "ContextAwareVisitor",
        "FunctionCallVisitor",
        "error",
        "isinstance",
        "parse",
        "read_text",
        "set",
        "splitlines",
        "str",
        "update",
        "visit",
        "walk"
      ],
      "line_number": 172,
      "is_async": false,
      "parameters": [
        "self",
        "filepath"
      ],
      "last_updated": "2025-08-04T12:57:12.582237+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_process_symbol_node": {
      "key": "src/system/tools/codegraph_builder.py::_process_symbol_node",
      "name": "_process_symbol_node",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Extracts and stores metadata from a single function or class AST node.",
      "docstring": "Extracts and stores metadata from a single function or class AST node.",
      "calls": [
        "FunctionCallVisitor",
        "FunctionInfo",
        "_determine_domain",
        "_get_entry_point_type",
        "_infer_agent_from_path",
        "_parse_metadata_comment",
        "append",
        "as_posix",
        "get",
        "get_docstring",
        "hasattr",
        "isinstance",
        "isoformat",
        "now",
        "relative_to",
        "split",
        "strip",
        "visit"
      ],
      "line_number": 194,
      "is_async": false,
      "parameters": [
        "self",
        "node",
        "filepath",
        "source_lines",
        "parent_key"
      ],
      "last_updated": "2025-08-04T12:57:12.583250+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::_apply_entry_point_patterns": {
      "key": "src/system/tools/codegraph_builder.py::_apply_entry_point_patterns",
      "name": "_apply_entry_point_patterns",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Applies declarative patterns to identify non-obvious entry points.",
      "docstring": "Applies declarative patterns to identify non-obvious entry points.",
      "calls": [
        "any",
        "extend",
        "get",
        "match",
        "values"
      ],
      "line_number": 224,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.584208+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::build": {
      "key": "src/system/tools/codegraph_builder.py::build",
      "name": "build",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "Orchestrates the full knowledge graph generation process.",
      "docstring": "Orchestrates the full knowledge graph generation process.",
      "calls": [
        "_apply_entry_point_patterns",
        "_should_exclude_path",
        "asdict",
        "info",
        "isoformat",
        "items",
        "len",
        "list",
        "now",
        "rglob",
        "scan_file",
        "sorted",
        "values"
      ],
      "line_number": 246,
      "is_async": false,
      "parameters": [
        "self"
      ],
      "last_updated": "2025-08-04T12:57:12.585162+00:00",
      "is_class": false,
      "base_classes": [],
      "parent_class_key": "src/system/tools/codegraph_builder.py::KnowledgeGraphBuilder"
    },
    "src/system/tools/codegraph_builder.py::main": {
      "key": "src/system/tools/codegraph_builder.py::main",
      "name": "main",
      "type": "FunctionDef",
      "file": "src/system/tools/codegraph_builder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "unassigned",
      "intent": "CLI entry point to run the knowledge graph builder and save the output.",
      "docstring": "CLI entry point to run the knowledge graph builder and save the output.",
      "calls": [
        "KnowledgeGraphBuilder",
        "build",
        "cwd",
        "dumps",
        "error",
        "find_project_root",
        "len",
        "mkdir",
        "print",
        "write_text"
      ],
      "line_number": 268,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "cli_entry_point",
      "last_updated": "2025-08-04T12:57:12.585929+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/system/tools/docstring_adder.py::main": {
      "key": "src/system/tools/docstring_adder.py::main",
      "name": "main",
      "type": "FunctionDef",
      "file": "src/system/tools/docstring_adder.py",
      "domain": "tooling",
      "agent": "tooling_agent",
      "capability": "add_missing_docstrings",
      "intent": "Entry point for the docstring adder tool.",
      "docstring": "Entry point for the docstring adder tool.",
      "calls": [
        "exit",
        "print"
      ],
      "line_number": 10,
      "is_async": false,
      "parameters": [],
      "entry_point_type": "cli_entry_point",
      "last_updated": "2025-08-04T12:57:12.586938+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/shared/schemas/manifest_validator.py::load_schema": {
      "key": "src/shared/schemas/manifest_validator.py::load_schema",
      "name": "load_schema",
      "type": "FunctionDef",
      "file": "src/shared/schemas/manifest_validator.py",
      "domain": "shared",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Load a JSON schema from the .intent/schemas/ directory.",
      "docstring": "Load a JSON schema from the .intent/schemas/ directory.\n\nArgs:\n    schema_name (str): The filename of the schema (e.g., 'knowledge_graph_entry.schema.json').\n    \nReturns:\n    Dict[str, Any]: The loaded JSON schema.\n    \nRaises:\n    FileNotFoundError: If the schema file is not found.\n    json.JSONDecodeError: If the schema file is not valid JSON.",
      "calls": [
        "FileNotFoundError",
        "JSONDecodeError",
        "exists",
        "load",
        "open"
      ],
      "line_number": 13,
      "is_async": false,
      "parameters": [
        "schema_name"
      ],
      "last_updated": "2025-08-04T12:57:12.588193+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/shared/schemas/manifest_validator.py::validate_manifest_entry": {
      "key": "src/shared/schemas/manifest_validator.py::validate_manifest_entry",
      "name": "validate_manifest_entry",
      "type": "FunctionDef",
      "file": "src/shared/schemas/manifest_validator.py",
      "domain": "shared",
      "agent": "validator_agent",
      "capability": "unassigned",
      "intent": "Validate a single manifest entry against a schema.",
      "docstring": "Validate a single manifest entry against a schema.\n\nArgs:\n    entry: The dictionary representing a single function/class entry.\n    schema_name: The filename of the schema to validate against.\n    \nReturns:\n    A tuple of (is_valid: bool, list_of_error_messages: List[str]).",
      "calls": [
        "Draft7Validator",
        "append",
        "iter_errors",
        "join",
        "load_schema",
        "str"
      ],
      "line_number": 38,
      "is_async": false,
      "parameters": [
        "entry",
        "schema_name"
      ],
      "last_updated": "2025-08-04T12:57:12.588784+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/shared/utils/import_scanner.py::scan_imports_for_file": {
      "key": "src/shared/utils/import_scanner.py::scan_imports_for_file",
      "name": "scan_imports_for_file",
      "type": "FunctionDef",
      "file": "src/shared/utils/import_scanner.py",
      "domain": "shared",
      "agent": "generic_agent",
      "capability": "unassigned",
      "intent": "Parse a Python file and extract all imported module paths.",
      "docstring": "Parse a Python file and extract all imported module paths.\n\nArgs:\n    file_path (Path): Path to the file.\n\nReturns:\n    List[str]: List of imported module paths.",
      "calls": [
        "append",
        "isinstance",
        "parse",
        "print",
        "read_text",
        "walk"
      ],
      "line_number": 15,
      "is_async": false,
      "parameters": [
        "file_path"
      ],
      "last_updated": "2025-08-04T12:57:12.589899+00:00",
      "is_class": false,
      "base_classes": []
    },
    "src/shared/utils/parsing.py::parse_write_blocks": {
      "key": "src/shared/utils/parsing.py::parse_write_blocks",
      "name": "parse_write_blocks",
      "type": "FunctionDef",
      "file": "src/shared/utils/parsing.py",
      "domain": "shared",
      "agent": "generic_agent",
      "capability": "unassigned",
      "intent": "Extracts all [[write:...]] blocks from LLM output.",
      "docstring": "Extracts all [[write:...]] blocks from LLM output.\n\nThis function is robust and handles both [[end]] and [[/write]] as valid terminators\nto accommodate different LLM habits.\n\nArgs:\n    llm_output (str): The raw text output from a language model.\n\nReturns:\n    A dictionary mapping file paths to their corresponding code content.",
      "calls": [
        "findall",
        "strip"
      ],
      "line_number": 8,
      "is_async": false,
      "parameters": [
        "llm_output"
      ],
      "last_updated": "2025-08-04T12:57:12.590720+00:00",
      "is_class": false,
      "base_classes": []
    }
  }
}
--- END OF FILE ./.intent/knowledge/knowledge_graph.json ---

--- START OF FILE ./.intent/knowledge/entry_point_patterns.yaml ---
# .intent/knowledge/entry_point_patterns.yaml
#
# A declarative set of rules for the KnowledgeGraphBuilder to identify valid
# system entry points that are not discoverable through simple call-graph analysis.
# This prevents the auditor from incorrectly flagging valid code as "dead."

patterns:
  - name: "python_magic_method"
    description: "Standard Python __dunder__ methods are entry points called by the interpreter."
    match:
      type: "function"
      name_regex: "^__.+__$"
    entry_point_type: "magic_method"

  - name: "ast_visitor_method"
    description: "Methods in ast.NodeVisitor subclasses starting with 'visit_' are entry points for the visitor pattern."
    match:
      type: "function"
      name_regex: "^visit_"
      # This requires the builder to know the base classes of a symbol.
      base_class_includes: "NodeVisitor"
    entry_point_type: "visitor_method"

  - name: "capability_implementation"
    description: "Any symbol tagged with a # CAPABILITY is a primary entry point for the CORE system's reasoning loop."
    match:
      # This will be matched based on the 'capability' field in the symbol data.
      has_capability_tag: true
    entry_point_type: "capability"

  - name: "framework_base_class"
    description: "Classes that other components inherit from are valid entry points."
    match:
      type: "class"
      is_base_class: true # This will be true if any other class inherits from it.
    entry_point_type: "base_class"
--- END OF FILE ./.intent/knowledge/entry_point_patterns.yaml ---

