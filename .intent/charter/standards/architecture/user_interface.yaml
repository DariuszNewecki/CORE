# .intent/charter/standards/architecture/user_interface.yaml
id: standard_architecture_user_interface
version: "1.0.0"
title: "Architecture Standard – User Interface"
type: "standard_architecture"
status: active

owners:
  accountable: "Architecture Owner"
  responsible:
    - "Core Maintainer"

review:
  frequency: "12 months"

schema_id: "standard.architecture.user_interface"

description: |
  Defines how end users interact with CORE through conversational interface,
  distinct from operator tooling.

  Two interfaces serve different audiences:
  - core: End-user conversational interface (src/api/cli_user.py)
  - core-admin: Operator tooling interface (src/body/cli/main.py)

  This pattern establishes the architectural boundaries and governance
  for conversational interaction with CORE.

category: interface
layer: api

# =============================================================================
# PRINCIPLES
# =============================================================================

principles:
  - id: single_conversation_entry
    statement: "End users interact ONLY through conversational interface"
    rationale: |
      Users shouldn't need to understand CORE's internal architecture,
      command structure, or constitutional patterns. Natural language
      is the only interface they see.

  - id: constitutional_by_default
    statement: "All operations route through governance automatically"
    rationale: |
      End users can't bypass constitutional checks. Everything goes through
      ConversationalAgent → Mind → Body, ensuring safety by default.

  - id: operator_escape_hatch
    statement: "Operators retain full access via core-admin"
    rationale: |
      When the conversational interface fails or for advanced operations,
      operators can use core-admin for direct system access.

  - id: progressive_autonomy
    statement: "Interface evolves from read-only to full autonomy"
    rationale: |
      Phase 1: Information retrieval only
      Phase 2: Proposal generation with approval
      Phase 3: Full autonomous execution

# =============================================================================
# ARCHITECTURE
# =============================================================================

architecture:
  entry_points:
    end_user:
      binary: "core"
      location: "src/api/cli_user.py"
      purpose: "Conversational interface for end users"
      routing: "api.cli_user → will.agents.conversational_agent"

    operator:
      binary: "core-admin"
      location: "src/body/cli/main.py"
      purpose: "Direct system access for operators"
      routing: "body.cli.main → direct Body/Mind access"

  conversation_flow:
    - step: "User message received"
      handler: "cli_user.main()"

    - step: "ConversationalAgent processing"
      handler: "conversational_agent.process_message()"
      details: |
        - Extract context via ContextBuilder
        - Send to LLM for analysis
        - (Phase 2) Parse into proposals
        - (Phase 3) Execute via Body

    - step: "Response returned"
      format: "Natural language text"

  phase_roadmap:
    phase_1:
      status: "current"
      capabilities:
        - "Natural language queries about codebase"
        - "Context extraction and minimal bundling"
        - "LLM-powered analysis and explanation"
        - "Read-only, no modifications"

    phase_2:
      status: "planned"
      capabilities:
        - "Parse LLM responses into actionable proposals"
        - "Submit proposals through Mind governance"
        - "User approval workflow"
        - "Simple autonomous fixes"

    phase_3:
      status: "future"
      capabilities:
        - "Full autonomous code generation"
        - "Multi-step problem solving"
        - "Self-healing and optimization"
        - "Strategic refactoring"

# =============================================================================
# CONTRACTS
# =============================================================================

contracts:
  conversational_agent:
    location: "src/will/agents/conversational_agent.py"
    responsibilities:
      - "Parse user intent from natural language"
      - "Extract minimal context via ContextBuilder"
      - "Communicate with LLM services"
      - "Format responses for end users"
      - "(Future) Generate and submit proposals"

    dependencies:
      - "services.context.ContextBuilder"
      - "services.CognitiveService"
      - "(Future) mind.governance checks"
      - "(Future) body.actions for execution"

    constraints:
      - "Phase 1: Read-only operations only"
      - "All context extraction respects Mind policies"
      - "No direct filesystem or database writes"
      - "All proposals must go through governance"

  context_extraction:
    governed_by: ".intent/charter/schemas/operations/conversational_context_bundle_schema.yaml"
    rules:
      - "Extract minimal context (max 50k tokens)"
      - "Respect privacy and redaction policies"
      - "Use semantic search when available"
      - "Fail safe if context unavailable"

# =============================================================================
# GOVERNANCE
# =============================================================================

governance:
  policies:
    - "headless_body"          # Agent doesn't depend on UI
    - "ui_single_owner"        # CLI owns presentation
    - "context_minimization"   # Only necessary context
    - "logging_standards"      # Agent logs activity
    - "read_only_phase1"       # No writes in Phase 1

  audits:
    - "DomainPlacementCheck"   # cli_user.py in api/, agent in will/
    - "CapabilityOwnerCheck"   # Conversational capability owned
    - "BodyContractsCheck"     # No Body layer violations

# =============================================================================
# FUTURE INTERFACES
# =============================================================================

future_interfaces:
  web_ui:
    location: "src/api/web/"
    technology: "FastAPI + React/HTMX"
    entry_point: "POST /api/chat"
    routing: "Same ConversationalAgent"

  mobile_app:
    location: "External (uses API)"
    entry_point: "POST /api/chat"
    routing: "Same ConversationalAgent"

  ide_plugin:
    location: "External (uses API or CLI)"
    integration: "Calls 'core' binary or API"
    routing: "Same ConversationalAgent"

# =============================================================================
# EXAMPLES
# =============================================================================

examples:
  - description: "User asks about a specific class"
    command: 'core "what does ContextBuilder do?"'
    flow: |
      1. Extract keywords: ["ContextBuilder"]
      2. Search knowledge graph for ContextBuilder
      3. Extract code, docstring, usage examples
      4. Send context + question to LLM
      5. Return: "ContextBuilder is responsible for..."

  - description: "User reports a problem"
    command: 'core "my tests are failing"'
    flow: |
      Phase 1: "I'd need more context. Which tests are failing?"
      Phase 2: Extract test files, analyze failures, propose fix
      Phase 3: Analyze failures, generate fix, submit proposal, execute

  - description: "User requests refactoring"
    command: 'core "refactor src/services/context/builder.py for clarity"'
    flow: |
      Phase 1: "I can analyze the file for you, but can't modify it yet"
      Phase 2: Analyze file, generate refactor proposal, wait for approval
      Phase 3: Analyze, propose, get approval, execute, report results

# =============================================================================
# RELATED PATTERNS
# =============================================================================

related_patterns:
  - "atomic_actions"              # ConversationalAgent uses atomic actions
  - "agent_patterns"              # ConversationalAgent follows agent patterns
  - "conversational_context_extractor"  # Uses CCE for context bundling
  - "command_patterns"            # Distinct from core-admin commands
