🧪 Running tests with pytest...
python3 -m poetry run pytest 
============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-7.4.4, pluggy-1.6.0
rootdir: /opt/dev/CORE
configfile: pyproject.toml
testpaths: tests
plugins: cov-4.1.0, mock-3.14.1, anyio-4.9.0, asyncio-0.21.0
asyncio: mode=Mode.AUTO
collected 28 items

tests/admin/test_guard_drift_cli.py ....                                 [ 14%]
tests/core/test_intent_model.py ......                                   [ 35%]
tests/governance/test_local_mode_governance.py .                         [ 39%]
tests/integration/test_full_run.py F                                     [ 42%]
tests/unit/test_agent_utils.py ....                                      [ 57%]
tests/unit/test_clients.py .                                             [ 60%]
tests/unit/test_git_service.py ....                                      [ 75%]
tests/unit/test_planner_agent.py .F....F                                 [100%]

=================================== FAILURES ===================================
_________________________ test_execute_goal_end_to_end _________________________

mock_llm_clients = (<MagicMock name='OrchestratorClient' spec='OrchestratorClient' id='132707805363664'>, <MagicMock name='GeneratorClient' spec='GeneratorClient' id='132707760929584'>)
test_git_repo = PosixPath('/tmp/pytest-of-lira/pytest-61/test_execute_goal_end_to_end0')
monkeypatch = <_pytest.monkeypatch.MonkeyPatch object at 0x78b26ef64ad0>
mocker = <pytest_mock.plugin.MockerFixture object at 0x78b26ef8fb60>

    def test_execute_goal_end_to_end(mock_llm_clients, test_git_repo, monkeypatch, mocker):
        """
        Tests the entire /execute_goal endpoint flow.
        - Mocks LLM responses.
        - Runs against a real temporary file system with a Git repo.
        - Asserts that the file is created with the correct content.
        - Asserts that a Git commit was made.
        """
        # Use monkeypatch to change the current working directory for the test
        monkeypatch.chdir(test_git_repo)
    
        # Mock the GitService to track commit calls
        mock_git_service_instance = MagicMock()
        mock_git_service_instance.is_git_repo.return_value = True
        mocker.patch('core.main.GitService', return_value=mock_git_service_instance)
    
        with TestClient(app) as client:
            # 1. Make the API call
            response = client.post("/execute_goal", json={"goal": "Create a hello world script"})
    
            # 2. Assert the API response is successful
>           assert response.status_code == 200
E           assert 500 == 200
E            +  where 500 = <Response [500 Internal Server Error]>.status_code

/opt/dev/CORE/tests/integration/test_full_run.py:68: AssertionError
---------------------------- Captured stdout setup -----------------------------
Initialized empty Git repository in /tmp/pytest-of-lira/pytest-61/test_execute_goal_end_to_end0/.git/
---------------------------- Captured stderr setup -----------------------------
hint: Using 'master' as the name for the initial branch. This default branch name
hint: is subject to change. To configure the initial branch name to use in all
hint: of your new repositories, which will suppress this warning, call:
hint: 
hint: 	git config --global init.defaultBranch <name>
hint: 
hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and
hint: 'development'. The just-created branch can be renamed via this command:
hint: 
hint: 	git branch -m <name>
----------------------------- Captured stdout call -----------------------------
[20:34:36] INFO     🚀 Starting CORE system...                                  
           INFO     🧠 Performing startup introspection...                      
           INFO     🔍 Starting introspection cycle...                          
           INFO     Running Knowledge Graph Builder...                          
[20:34:36] INFO     Building knowledge graph for directory: /opt/dev/CORE/src   
           INFO     Found 57 Python files to scan in src/                       
           INFO     Scanned 57 files (0 failed). Applying declarative           
                    patterns...                                                 
           INFO     ✅ Knowledge graph generated! Scanned 57 files, found 242   
                    symbols.                                                    
           INFO        -> Saved to                                              
                    /opt/dev/CORE/.intent/knowledge/knowledge_graph.json        

           INFO     ✅ Knowledge Graph Builder completed successfully.          
           INFO     Running Constitutional Auditor...                           
[20:34:36] INFO     🔍 Starting manifest aggregation...                         
           INFO        -> Aggregated capabilities from 5 domain manifests.      
           WARNING  Temporarily disabling the 'check_for_dead_code' check due to
                    known false positives with CLI commands.                    
[20:34:37] INFO     [1;34m╭────────────────────────────────────────╮[0m         
                    [1;34m│[0m[1;34m [0m[1;34m🧠 CORE Constitutional Integrity  
                    Audit[0m[1;34m [0m[1;34m│[0m                                
                    [1;34m╰────────────────────────────────────────╯[0m         
           INFO     🔍 [bold]Running Check:[/bold] Ensures all implemented      
                    capabilities are valid.                                     
           INFO     ✅ All implemented capabilities are constitutionally        
                    defined.                                                    
           INFO     🔍 [bold]Running Check:[/bold] Finds symbols missing        
                    docstrings or having generic intents.                       
           INFO     ✅ All symbols have docstrings and specific intents.        
           INFO     🔍 [bold]Running Check:[/bold] Finds .intent files that are 
                    not referenced in meta.yaml.                                
           INFO     ✅ No orphaned or unrecognized intent files found.          
           INFO     🔍 [bold]Running Check:[/bold] Verifies that all files      
                    declared in meta.yaml exist on disk.                        
           INFO     ✅ All 24 constitutionally-required files are present.      
           INFO     🔍 [bold]Running Check:[/bold] Validates the syntax of all  
                    .intent YAML/JSON files (including proposals).              
           INFO     ✅ Validated syntax for 22 YAML/JSON files.                 
           INFO     🔍 [bold]Running Check:[/bold] Validate each cr-*.yaml/json 
                    proposal against proposal.schema.json.                      
           INFO     ✅ No pending proposals found.                              
           INFO     🔍 [bold]Running Check:[/bold] Detect content/signature     
                    drift:                                                      
           INFO     🔍 [bold]Running Check:[/bold] Emit a friendly summary of   
                    pending proposals.                                          
           INFO     ✅ No pending proposals.                                    
           INFO     🔍 [bold]Running Check:[/bold] Finds symbols with identical 
                    structural hashes, violating `dry_by_design`, using         
                    content-addressed knowledge graph for accurate duplication  
                    detection.                                                  
           INFO     ✅ No structural code duplication found.                    
           INFO     🔍 [bold]Running Check:[/bold] Ensures all required         
                    capabilities are implemented.                               
           INFO     ✅ All required capabilities are implemented.               
           INFO     🔍 [bold]Running Check:[/bold] Checks for domain mismatches 
                    and illegal imports.                                        
[20:34:38] INFO     ✅ Domain locations and import boundaries are valid.        
           INFO     🔍 [bold]Running Check:[/bold] Validates all knowledge graph
                    symbols against the schema.                                 
           INFO     ✅ All 242 symbols in knowledge graph pass schema           
                    validation.                                                 
           INFO     🔍 [bold]Running Check:[/bold] Validates the integrity of   
                    project_manifest.yaml.                                      
           INFO     ✅ project_manifest.yaml contains all required keys.        
           INFO     🔍 [bold]Running Check:[/bold] Measures code complexity and 
                    atomicity against defined policies.                         
           WARNING  ⚠️ File 'src/system/admin/proposals.py' is a complexity      
                    outlier (180 LLOC vs. project average of 73). This may      
                    violate the 'separation_of_concerns' principle.             
           WARNING  ⚠️ File 'src/system/tools/codegraph_builder.py' is a         
                    complexity outlier (252 LLOC vs. project average of 73).    
                    This may violate the 'separation_of_concerns' principle.    
           WARNING  ⚠️ File 'src/system/governance/checks/proposal_checks.py' is 
                    a complexity outlier (190 LLOC vs. project average of 73).  
                    This may violate the 'separation_of_concerns' principle.    
           INFO     🔍 [bold]Running Check:[/bold] Verifies that required       
                    environment variables specified in runtime_requirements.yaml
                    are set, returning a list of audit findings for missing     
                    variables or configuration issues.                          
           INFO     ✅ All required environment variables are set.              
           INFO     [1;32m╭───────────────────────────────────╮[0m              
                    [1;32m│[0m[1;32m [0m[1;32m✅ ALL CHECKS PASSED (3           
                    warnings)[0m[1;32m [0m[1;32m│[0m                            
                    [1;32m╰───────────────────────────────────╯[0m              
           INFO     [33m┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                    ━━━━━━━━━━━━━━━━━━━━━━━┓[0m                                 
                    [33m┃[0m[1;33m [0m[1;33m⚠️ Warnings                          
                    [0m[1;33m [0m[33m┃[0m                                       
                    [33m┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
                    ━━━━━━━━━━━━━━━━━━━━━━━┩[0m                                 
                    [33m│[0m File 'src/system/admin/proposals.py' is a          
                    complexity outlier (180 LLOC vs.   [33m│[0m                 
                    [33m│[0m project average of 73). This may violate the       
                    'separation_of_concerns'        [33m│[0m                    
                    [33m│[0m principle.                                         
                    [33m│[0m                                                    
                    [33m│[0m File 'src/system/tools/codegraph_builder.py' is a  
                    complexity outlier (252    [33m│[0m                         
                    [33m│[0m LLOC vs. project average of 73). This may violate  
                    the                        [33m│[0m                         
                    [33m│[0m 'separation_of_concerns' principle.                
                    [33m│[0m                                                    
                    [33m│[0m File                                               
                    'src/system/governance/checks/proposal_checks.py' is a      
                    complexity       [33m│[0m                                   
                    [33m│[0m outlier (190 LLOC vs. project average of 73). This 
                    may violate the           [33m│[0m                          
                    [33m│[0m 'separation_of_concerns' principle.                
                    [33m│[0m                                                    
                    [33m└───────────────────────────────────────────────────────
                    ───────────────────────┘[0m                                 

[20:34:38] INFO     ✅ Constitutional Auditor completed successfully.           
           INFO     🧠 Introspection cycle completed.                           
           INFO     ✅ Introspection complete. System state is constitutionally 
                    valid.                                                      
           INFO     🛠️  Initializing shared services...                          
           INFO     IntentGuard initialized. 0 rules loaded. Watching 0 source  
                    files.                                                      
           INFO     ✅ CORE system is online and ready.                         
           INFO     🎯 Received new goal: 'Create a hello world script'         
           ERROR    💥 An unexpected error occurred during goal execution:      
                    PlannerAgent.__init__() got an unexpected keyword argument  
                    'intent_guard'                                              
                    ╭─────────── Traceback (most recent call last) ────────────╮
                    │ /opt/dev/CORE/src/core/main.py:70 in execute_goal        │
                    │                                                          │
                    │   67 │   # This prevents state from leaking between diff │
                    │   68 │   try:                                            │
                    │   69 │   │   file_handler = FileHandler(".")             │
                    │ ❱ 70 │   │   planner = PlannerAgent(                     │
                    │   71 │   │   │   orchestrator_client=request.app.state.o │
                    │   72 │   │   │   generator_client=request.app.state.gene │
                    │   73 │   │   │   file_handler=file_handler,              │
                    ╰──────────────────────────────────────────────────────────╯
                    TypeError: PlannerAgent.__init__() got an unexpected keyword
                    argument 'intent_guard'                                     
           INFO     HTTP Request: POST http://testserver/execute_goal "HTTP/1.1 
                    500 Internal Server Error"                                  
           INFO     🛑 CORE system shutting down.                               
------------------------------ Captured log call -------------------------------
INFO     core.main:main.py:35 🚀 Starting CORE system...
INFO     core.main:main.py:37 🧠 Performing startup introspection...
INFO     core.capabilities:capabilities.py:24 🔍 Starting introspection cycle...
INFO     core.capabilities:capabilities.py:36 Running Knowledge Graph Builder...
INFO     core.capabilities:capabilities.py:55 ✅ Knowledge Graph Builder completed successfully.
INFO     core.capabilities:capabilities.py:36 Running Constitutional Auditor...
INFO     core.capabilities:capabilities.py:55 ✅ Constitutional Auditor completed successfully.
INFO     core.capabilities:capabilities.py:68 🧠 Introspection cycle completed.
INFO     core.main:main.py:41 ✅ Introspection complete. System state is constitutionally valid.
INFO     core.main:main.py:44 🛠️  Initializing shared services...
INFO     core.intent_guard:intent_guard.py:38 IntentGuard initialized. 0 rules loaded. Watching 0 source files.
INFO     core.main:main.py:49 ✅ CORE system is online and ready.
INFO     core.main:main.py:63 🎯 Received new goal: 'Create a hello world script'
ERROR    core.main:main.py:91 💥 An unexpected error occurred during goal execution: PlannerAgent.__init__() got an unexpected keyword argument 'intent_guard'
Traceback (most recent call last):
  File "/opt/dev/CORE/src/core/main.py", line 70, in execute_goal
    planner = PlannerAgent(
              ^^^^^^^^^^^^^
TypeError: PlannerAgent.__init__() got an unexpected keyword argument 'intent_guard'
INFO     httpx:_client.py:1025 HTTP Request: POST http://testserver/execute_goal "HTTP/1.1 500 Internal Server Error"
INFO     core.main:main.py:51 🛑 CORE system shutting down.
______________ test_create_execution_plan_fails_on_invalid_action ______________

self = <agents.planner_agent.PlannerAgent object at 0x78b26eb2a4e0>
high_level_goal = 'Test goal'

    def create_execution_plan(self, high_level_goal: str) -> List[ExecutionTask]:
        """Creates a high-level, code-agnostic execution plan."""
        plan_id = f"plan_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}"
        self._setup_logging_context(high_level_goal, plan_id)
    
        log.info(f"🧠 Step 1: Decomposing goal into a high-level plan...")
    
        prompt_template = textwrap.dedent("""
            You are a hyper-competent, meticulous system architect AI. Your task is to decompose a high-level goal into a JSON execution plan.
            Your entire output MUST be a single, valid JSON array of objects.
    
            **High-Level Goal:** "{goal}"
    
            **Available Actions & Required Parameters:**
            - Action: `create_file` -> Params: `{{ "file_path": "<path>" }}`
            - Action: `edit_function` -> Params: `{{ "file_path": "<path>", "symbol_name": "<func_name>" }}`
            - Action: `add_capability_tag` -> Params: `{{ "file_path": "<path>", "symbol_name": "<func_name>", "tag": "<tag_name>" }}`
    
            **CRITICAL RULE:** Do NOT include a `"code"` parameter in this step. Generate the code-free JSON plan now.
        """).strip()
    
        final_prompt = prompt_template.format(goal=high_level_goal)
        enriched_prompt = self.prompt_pipeline.process(final_prompt)
    
        for attempt in range(self.config.max_retries):
            try:
                response_text = self.orchestrator.make_request(enriched_prompt, user_id="planner_agent_architect")
                parsed_json = self._extract_json_from_response(response_text)
                if not parsed_json: raise ValueError("No valid JSON found in response")
                if isinstance(parsed_json, dict): parsed_json = [parsed_json]
    
>               validated_plan = [ExecutionTask(**task) for task in parsed_json]
E               pydantic_core._pydantic_core.ValidationError: 2 validation errors for ExecutionTask
E               action
E                 Input should be 'add_capability_tag', 'create_file' or 'edit_function' [type=literal_error, input_value='make_coffee', input_type=str]
E                   For further information visit https://errors.pydantic.dev/2.11/v/literal_error
E               params.file_path
E                 Field required [type=missing, input_value={}, input_type=dict]
E                   For further information visit https://errors.pydantic.dev/2.11/v/missing

src/agents/planner_agent.py:128: ValidationError

During handling of the above exception, another exception occurred:

mock_dependencies = {'config': PlannerConfig(max_retries=3, validation_enabled=True, auto_commit=True, rollback_on_failure=True, task_time...44076848'>, 'generator_client': <MagicMock id='132707761617040'>, 'git_service': <MagicMock id='132707761421872'>, ...}

    def test_create_execution_plan_fails_on_invalid_action(mock_dependencies):
        """Tests that the planner fails if the plan contains an invalid action."""
        agent = PlannerAgent(**mock_dependencies)
        goal = "Test goal"
    
        invalid_plan_json = json.dumps([{"step": "Invalid action", "action": "make_coffee", "params": {}}])
        mock_dependencies["orchestrator_client"].make_request.return_value = f"```json\n{invalid_plan_json}\n```"
    
        with patch('core.prompt_pipeline.PromptPipeline.process', return_value="enriched_prompt"):
            with pytest.raises(ValidationError): # Pydantic V2 raises ValidationError for invalid literals
>               agent.create_execution_plan(goal)

tests/unit/test_planner_agent.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <agents.planner_agent.PlannerAgent object at 0x78b26eb2a4e0>
high_level_goal = 'Test goal'

    def create_execution_plan(self, high_level_goal: str) -> List[ExecutionTask]:
        """Creates a high-level, code-agnostic execution plan."""
        plan_id = f"plan_{datetime.now(timezone.utc).strftime('%Y%m%d_%H%M%S')}"
        self._setup_logging_context(high_level_goal, plan_id)
    
        log.info(f"🧠 Step 1: Decomposing goal into a high-level plan...")
    
        prompt_template = textwrap.dedent("""
            You are a hyper-competent, meticulous system architect AI. Your task is to decompose a high-level goal into a JSON execution plan.
            Your entire output MUST be a single, valid JSON array of objects.
    
            **High-Level Goal:** "{goal}"
    
            **Available Actions & Required Parameters:**
            - Action: `create_file` -> Params: `{{ "file_path": "<path>" }}`
            - Action: `edit_function` -> Params: `{{ "file_path": "<path>", "symbol_name": "<func_name>" }}`
            - Action: `add_capability_tag` -> Params: `{{ "file_path": "<path>", "symbol_name": "<func_name>", "tag": "<tag_name>" }}`
    
            **CRITICAL RULE:** Do NOT include a `"code"` parameter in this step. Generate the code-free JSON plan now.
        """).strip()
    
        final_prompt = prompt_template.format(goal=high_level_goal)
        enriched_prompt = self.prompt_pipeline.process(final_prompt)
    
        for attempt in range(self.config.max_retries):
            try:
                response_text = self.orchestrator.make_request(enriched_prompt, user_id="planner_agent_architect")
                parsed_json = self._extract_json_from_response(response_text)
                if not parsed_json: raise ValueError("No valid JSON found in response")
                if isinstance(parsed_json, dict): parsed_json = [parsed_json]
    
                validated_plan = [ExecutionTask(**task) for task in parsed_json]
                for task in validated_plan: self._validate_task_params(task)
    
                self._log_plan_summary(validated_plan)
                return validated_plan
    
            except (ValueError, json.JSONDecodeError, ValidationError) as e:
                log.warning(f"Plan creation attempt {attempt + 1} failed: {e}")
                if attempt == self.config.max_retries - 1:
>                   raise PlanExecutionError("Failed to create a valid high-level plan after max retries.")
E                   agents.plan_executor.PlanExecutionError: Failed to create a valid high-level plan after max retries.

src/agents/planner_agent.py:137: PlanExecutionError
----------------------------- Captured stdout call -----------------------------
           INFO     🧠 Step 1: Decomposing goal into a high-level plan...       
           WARNING  Plan creation attempt 1 failed: 2 validation errors for     
                    ExecutionTask                                               
                    action                                                      
                      Input should be 'add_capability_tag', 'create_file' or    
                    'edit_function' [type=literal_error,                        
                    input_value='make_coffee', input_type=str]                  
                        For further information visit                           
                    https://errors.pydantic.dev/2.11/v/literal_error            
                    params.file_path                                            
                      Field required [type=missing, input_value={},             
                    input_type=dict]                                            
                        For further information visit                           
                    https://errors.pydantic.dev/2.11/v/missing                  
           WARNING  Plan creation attempt 2 failed: 2 validation errors for     
                    ExecutionTask                                               
                    action                                                      
                      Input should be 'add_capability_tag', 'create_file' or    
                    'edit_function' [type=literal_error,                        
                    input_value='make_coffee', input_type=str]                  
                        For further information visit                           
                    https://errors.pydantic.dev/2.11/v/literal_error            
                    params.file_path                                            
                      Field required [type=missing, input_value={},             
                    input_type=dict]                                            
                        For further information visit                           
                    https://errors.pydantic.dev/2.11/v/missing                  
           WARNING  Plan creation attempt 3 failed: 2 validation errors for     
                    ExecutionTask                                               
                    action                                                      
                      Input should be 'add_capability_tag', 'create_file' or    
                    'edit_function' [type=literal_error,                        
                    input_value='make_coffee', input_type=str]                  
                        For further information visit                           
                    https://errors.pydantic.dev/2.11/v/literal_error            
                    params.file_path                                            
                      Field required [type=missing, input_value={},             
                    input_type=dict]                                            
                        For further information visit                           
                    https://errors.pydantic.dev/2.11/v/missing                  
------------------------------ Captured log call -------------------------------
INFO     agents.planner_agent:planner_agent.py:102 🧠 Step 1: Decomposing goal into a high-level plan...
WARNING  agents.planner_agent:planner_agent.py:135 Plan creation attempt 1 failed: 2 validation errors for ExecutionTask
action
  Input should be 'add_capability_tag', 'create_file' or 'edit_function' [type=literal_error, input_value='make_coffee', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/literal_error
params.file_path
  Field required [type=missing, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
WARNING  agents.planner_agent:planner_agent.py:135 Plan creation attempt 2 failed: 2 validation errors for ExecutionTask
action
  Input should be 'add_capability_tag', 'create_file' or 'edit_function' [type=literal_error, input_value='make_coffee', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/literal_error
params.file_path
  Field required [type=missing, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
WARNING  agents.planner_agent:planner_agent.py:135 Plan creation attempt 3 failed: 2 validation errors for ExecutionTask
action
  Input should be 'add_capability_tag', 'create_file' or 'edit_function' [type=literal_error, input_value='make_coffee', input_type=str]
    For further information visit https://errors.pydantic.dev/2.11/v/literal_error
params.file_path
  Field required [type=missing, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.11/v/missing
___________________ test_plan_executor_edit_function_success ___________________

mock_code_editor_class = <MagicMock name='CodeEditor' id='132707744257168'>
mock_validate_code = <MagicMock name='validate_code' id='132707744261200'>
mock_dependencies = {'config': PlannerConfig(max_retries=3, validation_enabled=True, auto_commit=True, rollback_on_failure=True, task_time...44561584'>, 'generator_client': <MagicMock id='132707744548768'>, 'git_service': <MagicMock id='132707749126720'>, ...}
tmp_path = PosixPath('/tmp/pytest-of-lira/pytest-61/test_plan_executor_edit_functi0')

    @pytest.mark.asyncio
    @patch('agents.plan_executor.validate_code')
    @patch('agents.plan_executor.CodeEditor')
    def test_plan_executor_edit_function_success(mock_code_editor_class, mock_validate_code, mock_dependencies, tmp_path):
        """Happy Path: Verifies that a valid 'edit_function' task succeeds via the executor."""
        # Setup mocks
        mock_editor_instance = mock_code_editor_class.return_value
        mock_validate_code.return_value = {"status": "clean", "code": 'def my_func():\n    # A new comment\n    return 2\n', "violations": []}
    
        # Initialize the executor
        executor = PlanExecutor(
            file_handler=mock_dependencies["file_handler"],
            git_service=mock_dependencies["git_service"],
            config=mock_dependencies["config"]
        )
        executor.repo_path = tmp_path
    
        original_code = textwrap.dedent("""
            def my_func():
                return 1
        """)
        target_file = tmp_path / "src/feature.py"
        target_file.parent.mkdir(exist_ok=True)
        target_file.write_text(original_code)
    
        new_function_code = textwrap.dedent("""
            def my_func():
                # A new comment
                return 2
        """)
        validated_and_formatted_snippet = 'def my_func():\n    # A new comment\n    return 2\n'
    
        params = TaskParams(
            file_path="src/feature.py",
            symbol_name="my_func",
            code=new_function_code
        )
    
        # Execute the method
        import asyncio
>       asyncio.run(executor._execute_edit_function(params))

tests/unit/test_planner_agent.py:179: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/usr/lib/python3.12/asyncio/runners.py:194: in run
    return runner.run(main)
/usr/lib/python3.12/asyncio/runners.py:118: in run
    return self._loop.run_until_complete(task)
/usr/lib/python3.12/asyncio/base_events.py:687: in run_until_complete
    return future.result()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <agents.plan_executor.PlanExecutor object at 0x78b26df44200>
params = TaskParams(file_path='src/feature.py', symbol_name='my_func', tag=None, code='\ndef my_func():\n    # A new comment\n    return 2\n')

    async def _execute_edit_function(self, params: TaskParams):
        """Executes the 'edit_function' action using the CodeEditor."""
        file_path, symbol_name, new_code = params.file_path, params.symbol_name, params.code
        full_path = self.repo_path / file_path
    
        if not full_path.exists():
            raise FileNotFoundError(f"Cannot edit function, file not found: '{file_path}'")
    
>       original_code = await self._executor(None, full_path.read_text, "utf-8")
E       RuntimeError: Task <Task pending name='Task-20' coro=<PlanExecutor._execute_edit_function() running at /opt/dev/CORE/src/agents/plan_executor.py:122> cb=[_run_until_complete_cb() at /usr/lib/python3.12/asyncio/base_events.py:182]> got Future <Future pending cb=[_chain_future.<locals>._call_check_cancel() at /usr/lib/python3.12/asyncio/futures.py:387]> attached to a different loop

src/agents/plan_executor.py:122: RuntimeError
=============================== warnings summary ===============================
.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:323
  /opt/dev/CORE/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:323: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/
    warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)

tests/unit/test_planner_agent.py::test_create_execution_plan_success
  /opt/dev/CORE/src/agents/plan_executor.py:37: DeprecationWarning: There is no current event loop
    self._executor = asyncio.get_event_loop().run_in_executor

tests/unit/test_planner_agent.py::test_plan_executor_create_file_success
  tests/unit/test_planner_agent.py:78: PytestWarning: The test <Function test_plan_executor_create_file_success> is marked with '@pytest.mark.asyncio' but it is not an async function. Please remove asyncio marker. If the test is not marked explicitly, check for global markers applied via 'pytestmark'.
    @pytest.mark.asyncio

tests/unit/test_planner_agent.py::test_plan_executor_create_file_fails_on_validation_error
  tests/unit/test_planner_agent.py:104: PytestWarning: The test <Function test_plan_executor_create_file_fails_on_validation_error> is marked with '@pytest.mark.asyncio' but it is not an async function. Please remove asyncio marker. If the test is not marked explicitly, check for global markers applied via 'pytestmark'.
    @pytest.mark.asyncio

tests/unit/test_planner_agent.py::test_plan_executor_create_file_fails_if_file_exists
  tests/unit/test_planner_agent.py:123: PytestWarning: The test <Function test_plan_executor_create_file_fails_if_file_exists> is marked with '@pytest.mark.asyncio' but it is not an async function. Please remove asyncio marker. If the test is not marked explicitly, check for global markers applied via 'pytestmark'.
    @pytest.mark.asyncio

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================== short test summary info ============================
FAILED tests/integration/test_full_run.py::test_execute_goal_end_to_end - ass...
FAILED tests/unit/test_planner_agent.py::test_create_execution_plan_fails_on_invalid_action
FAILED tests/unit/test_planner_agent.py::test_plan_executor_edit_function_success
=================== 3 failed, 25 passed, 5 warnings in 3.67s ===================
