# CORE Environment Variables
# ---------------------------
# This file defines the concrete LLM resources available to the system.
# Each resource is given a unique name (e.g., DEEPSEEK_CHAT) which is then
# mapped to a cognitive role in .intent/knowledge/resource_manifest.yaml.

# --- Path Configuration ---
MIND=".intent"
BODY="src"
REPO_PATH="."

# --- System & Logging ---
CORE_ENV="development"
LOG_LEVEL="INFO"
CORE_ACTION_LOG_PATH="logs/action_log.jsonl"
LLM_ENABLED="true"

# --- Dev Fastpath (for local development) ---
CORE_DEV_FASTPATH="true"

# ======================================================================
#                LLM RESOURCE REGISTRY
# ======================================================================

# -- Resource: deepseek_chat --
# Used by default for planning, documentation, and analysis roles.
DEEPSEEK_CHAT_API_URL="https://api.deepseek.com"
DEEPSEEK_CHAT_API_KEY="your_api_key_here"
DEEPSEEK_CHAT_MODEL_NAME="deepseek-chat"

# -- Resource: deepseek_coder --
# Used by default for the Coder role.
DEEPSEEK_CODER_API_URL="https://api.deepseek.com"
DEEPSEEK_CODER_API_KEY="your_api_key_here"
DEEPSEEK_CODER_MODEL_NAME="deepseek-coder"

# -- Example for adding a new resource (uncomment and configure to use) --
# ANTHROPIC_CLAUDE_SONNET_API_URL="https://api.anthropic.com/v1"
# ANTHROPIC_CLAUDE_SONNET_API_KEY="your_anthropic_key_here"
# ANTHROPIC_CLAUDE_SONNET_MODEL_NAME="claude-3-5-sonnet-20240620"


# ======================================================================
#                EMBEDDING & VECTOR STORE
# ======================================================================
# Configuration for generating semantic vectors (embeddings) and storing them.

# -- Resource: local_embedding --
# Used by the Vectorizer role to create embeddings for code and documents.
# This can point to a local Ollama instance or any OpenAI-compatible API.
LOCAL_EMBEDDING_API_URL="http://localhost:11434"
LOCAL_EMBEDDING_API_KEY="" # Usually not required for local models
LOCAL_EMBEDDING_MODEL_NAME="nomic-embed-text"
LOCAL_EMBEDDING_DIM=768
EMBED_MODEL_REVISION="2025-09-15" # A date or version tag to track model changes
EMBEDDING_MAX_CONCURRENT_REQUESTS=4

# -- Qdrant Vector Database --
# The store for all semantic vectors. See docker-compose.yml to run locally.
QDRANT_URL="http://localhost:6333"
QDRANT_COLLECTION_NAME="core_capabilities"
