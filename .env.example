# CORE Environment Variables
# ---------------------------
# This file defines the concrete LLM resources available to the system.
# Each resource is given a unique name (e.g., DEEPSEEK_CHAT) which is then
# mapped to a cognitive role in .intent/knowledge/resource_manifest.yaml.

# --- Path Configuration ---
MIND=".intent"
BODY="src"
REPO_PATH="."

# --- System & Logging ---
CORE_ENV="development"
LOG_LEVEL="INFO"
CORE_ACTION_LOG_PATH="logs/action_log.jsonl"
LLM_ENABLED="true"

# --- Dev Fastpath (for local development) ---
CORE_DEV_FASTPATH="true"

# ======================================================================
#                LLM RESOURCE REGISTRY
# ======================================================================

# -- Resource: deepseek_chat --
# Used by default for planning, documentation, and analysis roles.
DEEPSEEK_CHAT_API_URL="https://api.deepseek.com"
DEEPSEEK_CHAT_API_KEY="your_api_key_here"
DEEPSEEK_CHAT_MODEL_NAME="deepseek-chat"
DEEPSEEK_CHAT_MAX_TOKENS=2048
DEEPSEEK_CHAT_MAX_REQUESTS=20

# -- Resource: deepseek_coder --
# Used by default for the Coder role.
DEEPSEEK_CODER_API_URL="https://api.deepseek.com"
DEEPSEEK_CODER_API_KEY="your_api_key_here"
DEEPSEEK_CODER_MODEL_NAME="deepseek-coder"
DEEPSEEK_CODER_MAX_TOKENS=2048
DEEPSEEK_CODER_MAX_REQUESTS=20

# -- Example for adding a new resource (uncomment and configure to use) --
# OPENAI_GPT4_API_URL="https://api.openai.com/v1"
# OPENAI_GPT4_API_KEY="your_openai_key_here"
# OPENAI_GPT4_MODEL_NAME="gpt-4-turbo"